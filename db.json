{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"source/asset/logo.png","path":"asset/logo.png","modified":1,"renderable":0},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.ttf","path":"fonts/BreeSerif-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.otf","path":"fonts/BreeSerif-Regular.otf","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.woff2","path":"fonts/BreeSerif-Regular.woff2","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.svg","path":"fonts/opensans-regular-webfont.svg","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.eot","path":"fonts/opensans-regular-webfont.eot","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.woff","path":"fonts/opensans-regular-webfont.woff","modified":1,"renderable":1},{"_id":"themes/crisp/source/js/ga.js","path":"js/ga.js","modified":1,"renderable":1},{"_id":"themes/crisp/source/styles/crisp.css","path":"styles/crisp.css","modified":1,"renderable":1},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.ttf","path":"fonts/opensans-regular-webfont.ttf","modified":1,"renderable":1}],"Cache":[{"_id":"themes/crisp/.gitignore","hash":"854da42f35444ed19a8164cb7c213f66ae0e178c","modified":1651147206010},{"_id":"themes/crisp/LICENSE","hash":"7bc66e9632b475079619f585722930b551c3c081","modified":1651147206013},{"_id":"themes/crisp/_config.yml","hash":"679e9c83a37ad20b91e53ad8f1bfc71d582a149e","modified":1651147206021},{"_id":"themes/crisp/README.md","hash":"5df65fb6d4c854289509f5389e7380ce4b23ce09","modified":1651147206018},{"_id":"source/_posts/golang-dispatch.md","hash":"949a260d6a53fd0a1f7e4e96d133e52277e60057","modified":1651145806326},{"_id":"source/_posts/chaos_engineering.md","hash":"a23fe467cd7e8bb50f52eee01c74350963f108af","modified":1651145806305},{"_id":"source/_posts/golang-gmp.md","hash":"a4769f920a2c473558173b8957161f808c902cac","modified":1651145806339},{"_id":"source/_posts/golang-lockg.md","hash":"4c6f1421729d06c7dd2ccb25f0142ff79561815f","modified":1651145806423},{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1651145806430},{"_id":"source/_posts/java-gc-2.md","hash":"08c60a6aa338c75eb6b029332b0c94fee376c281","modified":1651145806465},{"_id":"source/_posts/hello.md","hash":"91660f6ee34f5eada042486ae897864e790fb202","modified":1651145806446},{"_id":"source/_posts/level-db-demo.md","hash":"76827c8461d63ed1fcceec290491713c664e3211","modified":1651145806487},{"_id":"source/_posts/level-db-chan.md","hash":"c2667bba46b7ace755db8af18e5c10646533bc36","modified":1651145806475},{"_id":"source/_posts/java-gc-1.md","hash":"5ebf9ab3e1f8f92c386278bd721ce0a82ef269f9","modified":1651145806456},{"_id":"source/_posts/level-db-start.md","hash":"8e01adfa36ec306aefbcccd6de3b853eb2a72e70","modified":1651145806525},{"_id":"source/_posts/level-db-read.md","hash":"936b2f2fefecc8429cb14e4f10d2f1bb464e1deb","modified":1651145806508},{"_id":"source/_posts/level-db-file.md","hash":"9a3957899c9c6aea8d0adf4c91266f6c5f338a06","modified":1651145806495},{"_id":"source/_posts/level-db-write.md","hash":"d8adf79a6f761d064832be37a17b42dc7709fada","modified":1651145806539},{"_id":"source/_posts/re0-golang.md","hash":"7f49d16d397317139cd5ebbee95003949ccac320","modified":1651145806564},{"_id":"source/_posts/note-framework-0.md","hash":"04c7709b5d87889b960ec0e52bb5e9f6aedebed2","modified":1651145806553},{"_id":"source/_posts/my-vim-config.md","hash":"b48a1e6443040f002aceae66f2270dfebd90cc12","modified":1651146644738},{"_id":"source/_posts/re0-redis-event.md","hash":"18bb32cbcd804d51e5b46835816836a654e5ee17","modified":1651145806597},{"_id":"source/_posts/re0-redis-expire.md","hash":"2dbe9ec020aa079bd9a279e637cbb17b702698a4","modified":1651145806612},{"_id":"source/_posts/re0-redis-master.md","hash":"72b6c6d86ffdf3e454844958e9ffaf560b25a317","modified":1651145806625},{"_id":"source/_posts/re0-redis-pipeline.md","hash":"0a80d4adf9c7c21dcc31be35d6b71b1d991158c8","modified":1651145806653},{"_id":"source/_posts/re0-mysql.md","hash":"6148072aab6de38918f9d023c857123495f85124","modified":1651145806577},{"_id":"source/_posts/re0-redis-memory.md","hash":"17e506654f5e51c4acf2ea2884e55bb310aad787","modified":1651145806639},{"_id":"source/_posts/re0-redis-redlock.md","hash":"49bec3757475de66cfa431e0107f618ba53146a3","modified":1651145806686},{"_id":"source/_posts/re0-redis-protocol.md","hash":"6e0ec25ae45ebe83a91e5ad69cd0ed6e9c5961a7","modified":1651145806662},{"_id":"source/_posts/re0-redis-struct.md","hash":"88fc72784f076329e9d44e1661cfcbe3d356570a","modified":1651145806709},{"_id":"source/_posts/re0-system.md","hash":"ddf532e76b111361b10251ab8560b40c0f4206ae","modified":1651145806734},{"_id":"source/asset/logo.png","hash":"594be3ccc0d0c608f8563bc946dd8a6f655fceac","modified":1651145806835},{"_id":"source/_posts/re0-redis.md","hash":"720991e3c265a4a59025fe03ff67d63579b967bf","modified":1651145806722},{"_id":"source/_posts/rpc-monitor.md","hash":"966a4410d837c5c1cd6cb113803a6ff125b7a096","modified":1651145806747},{"_id":"source/about/index.md","hash":"6f8b46d58ca04fd92645963205a05691de7cae59","modified":1651145806795},{"_id":"themes/crisp/layout/archive.ejs","hash":"36e89b37f520533bef85fb32b714214257fad1d0","modified":1651147206073},{"_id":"themes/crisp/layout/index.ejs","hash":"36e89b37f520533bef85fb32b714214257fad1d0","modified":1651147206093},{"_id":"themes/crisp/layout/category.ejs","hash":"36e89b37f520533bef85fb32b714214257fad1d0","modified":1651147206079},{"_id":"themes/crisp/layout/page.ejs","hash":"e1c5903079fc342915025cfad9cf9e70a5cd83cc","modified":1651147206105},{"_id":"themes/crisp/layout/post.ejs","hash":"ae761feddc98f4d3260e7591ed9fc91d9a49d0ab","modified":1651147206110},{"_id":"themes/crisp/layout/layout.ejs","hash":"46ca3eff9492e1dc6830bf5485c21dd0a113b9f8","modified":1651147206099},{"_id":"themes/crisp/layout/tag.ejs","hash":"5d8f22da9d3662c647599faaf21f02477432d556","modified":1651147206117},{"_id":"source/_posts/golang-gmp/1767848-9c4b06362907280d.webp","hash":"a2d94ed54535836041705f8ca5dc646e8f6fb794","modified":1651145806373},{"_id":"source/_posts/golang-gmp/3184f3.jpg","hash":"b2c90a1b47cc0bf045ec6b94212ab7c6d9ef4f2d","modified":1651145806396},{"_id":"source/_posts/golang-gmp/567399-d400f4b192f3dc48.webp","hash":"174a3c0d3aae5476bdba0db5ea0c918fd462e5e1","modified":1651145806412},{"_id":"themes/crisp/layout/_partial/index.ejs","hash":"0cc9becdde690a8b66ae5e1809f0c8bf660840ab","modified":1651147206048},{"_id":"themes/crisp/layout/_partial/post.ejs","hash":"6f7a6730c11300af14b9caf451c3ceb8dc810ea3","modified":1651147206065},{"_id":"themes/crisp/layout/_partial/page.ejs","hash":"3c4a7f68dcf7c205512069c9da99c9ff9d6ac3ef","modified":1651147206058},{"_id":"themes/crisp/layout/_partial/follow.ejs","hash":"21d54afed53c579fc823382af7f746136d4cf1e8","modified":1651147206038},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.ttf","hash":"9e42f8b3aa1e670934ecaab1a4060a00f17fa2ed","modified":1651147206157},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.otf","hash":"f982b73492d5d6c82aa684f6bce894c63f6b2c79","modified":1651147206144},{"_id":"themes/crisp/source/fonts/BreeSerif-Regular.woff2","hash":"9407e77734344a53e33ef703dc40024d941f6280","modified":1651147206163},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.svg","hash":"dce2b68dd6b6c28b773994e35e4fc3e0e539ffdf","modified":1651147206178},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.eot","hash":"606c985eaaef071488c12e5ea0a985d5b545eae7","modified":1651147206171},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.woff","hash":"d6f86451bee7c843a0c23e61995e25927abb176a","modified":1651147206195},{"_id":"themes/crisp/source/js/ga.js","hash":"a96d26c095fac491b4d48a32d60e4ee46a208a19","modified":1651147206206},{"_id":"themes/crisp/source/styles/crisp.css","hash":"5dfff8b3964c633c65f7ba60d2246a3aeab57183","modified":1651147206219},{"_id":"themes/crisp/source/fonts/opensans-regular-webfont.ttf","hash":"6d72a9e751414873228dd1c43ec7b16da1c2a285","modified":1651147206189},{"_id":"themes/crisp/screenshot.png","hash":"d0ea355c7da51f97ae0781f0ccaa7cea3ca6268e","modified":1651147206129}],"Category":[],"Data":[],"Page":[{"title":"关于我","date":"2021-09-15T05:58:29.000Z","_content":"\n一个码农","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2021-09-15 13:58:29\n---\n\n一个码农","updated":"2022-04-28T11:36:46.795Z","path":"about/index.html","comments":1,"layout":"page","_id":"cl2iyg58h000bmauy5znz381u","content":"<p>一个码农</p>\n","site":{"data":{}},"excerpt":"","more":"<p>一个码农</p>\n"}],"Post":[{"title":"Golang调度讲解","date":"2020-07-08T07:38:21.000Z","_content":"\nGolang调度是runtime中的核心部分，要说涉及到的东西，从基本的线程协程切换、GC的STW，到锁的暂停，都有相关涉猎。今天请个假休息一下，有空整理整理最近看的调度知识。\n\n## 调度基本知识\n\n### 进程、线程和协程\n\n进程和线程的区别都不用说了，简单来说就是，最初，大佬们觉得，每个任务肯定都有独立的内存空间、句柄等等等。只要保证程序直接能够不互相干扰就行。\n\n当机器性能不断的提升，程序员们发现，我任务太多了，需要执行很久，但是并不需要那么多的空间。如果照原来的方法每个任务都分配空间就特别耗时和耗资源，于是决定在进程的基础上拆分出线程，你只负责执行任务就行了。\n\n按道理，线程已经足够轻量，大数据时代又来了。现在需要大量的碎片计算，就像请求一个hello world，执行的任务不耗时，但是频繁。这时候的线程切换就是一个问题，主要原因是，线程的切换需要切换至操作系统的内核态，不断地做内存的复制，页表的cache很容易就失效，耗时因此增加。\n\n程序员再次想起，只要尽可能的不做内核态的切换，就可以减少这样的风险。于是出现了用户态的线程，也就是协程。\n\n\n### 并发模型\n\n大家在学习Golang源码中可以顺便思考一下，为什么是GMP模型？这就引出《七周七并发模型》书中的其他的并发模型：\n\n- 通过无变量的函数式编程实现并发，是无锁并发的一种模型；\n- Clojure对于状态和标识的分离，可以轻松实现内存事务模型；\n- Erlang的Actor模型是容错性非常高的分布式并发模型；\n- CSP模型是另一种分布式并发模型，被Go和Clojure采用；\n- GPU的并行计算主要针对数据密集型计算的并行，搞游戏的一定要看；\n- Hadoop和Storm分别适合超大数据量的批处理和流式处理。\n\nCSP（Communicating Sequential Processes）是由Tony Hoare在1978的论文上首次提出的。 它是处理并发编程的一种设计模式或者模型，指导并发程序的设计，提供了一种并发程序可实践的组织方法或者设计范式。通过此方法，可以减少并发程序引入的其它缺点，减少和规避并发程序的常见缺点和bug，并且可以被数学理论所论证。\n\n> 经典名言：Do not communicate by sharing memory; instead, share memory by communicating\n\n该模型主要的最终实现在于golang中的channel和goroutine。\n\n### GMP模型\n\n在golang实现之前，其实解决线程切换开销大的问题可能有各种各样的方式。nginx中通过epollo来进行事件管理，还有python中的yield进行用户态的手动切换。这些都属于非抢占式的，核心问题就是如果中间出现过量的超时操作，很容易就会导致进程阻塞。\n\n而golang的GMP模型中参考操作系统中的线程切换制作了sysmon线程用于做协程的抢占操作。\n\n在GMP模型特殊之处也是在于中间P层的存在，在1.1之前，是不存在P层。这就导致了，G其实是挂载在全局的链表中。每次切换协程都会抢占一个全局锁，于是给GM中增加了一个P层。\n\n### 特殊的线程、协程\n\n在golang中，存在2个特殊的线程：sysmon、templateThread。前者主要用于实现golang的抢占式调度，后者则是作为fork线程时使用的模板线程。\n\n同时还存在一个特殊的协程：signalG，功能也就是用于接收进程的信号。\n\n这3者可以单独讲解。本文主要讲解整体的正常线程调度流程。\n\n## 进程启动\n\n### 最初的入口和空间\n\n首先，golang的启动入口rt0_go（asm_arm64.s文件）。\n\n```\n\tMOVW\tR0, 8(RSP) // argc\n\tMOVD\tR1, 16(RSP) // argv\n\n\t// create istack out of the given (operating system) stack.\n\t// _cgo_init may update stackguard.\n\tMOVD\t$runtime·g0(SB), g\n\tMOVD\tRSP, R7\n\tMOVD\t$(-64*1024)(R7), R0\n\tMOVD\tR0, g_stackguard0(g)\n\tMOVD\tR0, g_stackguard1(g)\n\tMOVD\tR0, (g_stack+stack_lo)(g)\n\tMOVD\tR7, (g_stack+stack_hi)(g)\n\n    ... ...\nnocgo:\n\tBL\truntime·save_g(SB)\n\t// update stackguard after _cgo_init\n\tMOVD\t(g_stack+stack_lo)(g), R0\n\tADD\t$const__StackGuard, R0\n\tMOVD\tR0, g_stackguard0(g)\n\tMOVD\tR0, g_stackguard1(g)\n\n\t// set the per-goroutine and per-mach \"registers\"\n\tMOVD\t$runtime·m0(SB), R0\n\n\t// save m->g0 = g0\n\tMOVD\tg, m_g0(R0)\n\t// save m0 to g0->m\n\tMOVD\tR0, g_m(g)\n\n\tMOVW\t8(RSP), R0\t// copy argc\n\tMOVW\tR0, -8(RSP)\n\tMOVD\t16(RSP), R0\t\t// copy argv\n\tMOVD\tR0, 0(RSP)\n```\n\n这段汇编其实不用特别讨论，主要做的就是初始化的一个流程：  \n1. 赋值stack.lo和stack.hi属性\n2. 保存g0对象\n3. 设置m对象，包括m->g0、g0->m，做一个m0和g0的绑定\n4. 复制argc和argv\n\n以上基本上就是一些属性的赋值，后续就是执行了一系列的初始化函数。\n\n```\n\tBL\truntime·args(SB)\n\tBL\truntime·osinit(SB)\n\tBL\truntime·schedinit(SB)\n```\n\n这3个函数，不是特别影响调度流程，具体功能主要是对一些功能进行初始化，例如内存管理、信号、mp链表、GC等功能的初始化。\n\n在以上部分，现在基本上只存在一个m0代表主线程，一个g0代表主线程中的g0空间，还要一个signalG空间（并不在执行链表中），同时初始化了maxprocs个p，且在m0上面挂载了一个p对象。这时候，需要开始执行main函数，则需要一个新的g来执行方法。\n\n```\n\tMOVD\t$runtime·mainPC(SB), R0\t\t// entry\n\tMOVD\tRSP, R7\n\tMOVD.W\t$0, -8(R7)\n\tMOVD.W\tR0, -8(R7)\n\tMOVD.W\t$0, -8(R7)\n\tMOVD.W\t$0, -8(R7)\n\tMOVD\tR7, RSP\n\tBL\truntime·newproc(SB)\n```\n\n`newproc`方法会将`runtime.main`函数作为入参传入，功能等同于`go runtime.main()`。而`newproc`方法具体功能主要就是创建一个g并插入当前的p中。\n\n到这一步为止，整个进程还是只存在一个线程，但是存在3个g：g0、signalG、mainG。之后，就开始执行一个调度流程。\n\n```\n    BL\truntime·mstart(SB)\n```\n\n### 调度启动流程\n\n这是每个线程进入循环的入口。为什么这么说，代码如下：\n```\nfunc newosproc(mp *m) {\n\t... ...\n\tret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))\n```\n这就是创建一个线程的代码，印象中的线程创建是`thread_create`方法，底层最后还是调用的`clone`方法[参考](https://linux.die.net/man/2/clone)，所有golang自行封装了一个方法。而这个调用的最后一个方法就是`mstart`方法。\n\n\n进入`mstart`方法后，核心功能具体可以分为4部分：  \n1. osStack的判断\n2. stackguard的赋值\n3. mstart1的调用\n4. mexit方法，m的退出函数\n\n首先，先确定stackguard的功能，通过汇编指令，我们可以看到每个函数中都能有一段代码：\n```\nTEXT runtime.main(SB) /opt/go/src/runtime/proc.go\n        proc.go:113             0x430690        64488b0c25f8ffffff      mov rcx, qword ptr fs:[0xfffffff8]\n        proc.go:113             0x430699        483b6110                cmp rsp, qword ptr [rcx+0x10]\n        proc.go:113             0x43069d        0f86f9020000            jbe 0x43099c\n=>      proc.go:113             0x4306a3*       4883ec50                sub rsp, 0x50\n        ... ...\n        proc.go:113             0x43099c        e86f8b0200              call $runtime.morestack_noctxt\n        <autogenerated>:1       0x4309a1        e9eafcffff              jmp $runtime.main\n```\n第一行和第二行的具体功能分别是从TLS中获取当前的g对象、得到stackguard属性值。\n这一整段的代码也就是表示如果当前的rsp比stackguard小的话，就认为是需要进行栈扩展。具体的值，也就是stack.lo+_StackGuard(896)。这一段就不具体叙述。\n\n第二个问题是为什么要判断osStack？这就是要知道什么情况下会出现osStack，也就是系统栈空间。核心代码如下：\n```\nfunc allocm(_p_ *p, fn func()) *m {\n    ... ...\n\tif iscgo || GOOS == \"solaris\" || GOOS == \"illumos\" || GOOS == \"windows\" || GOOS == \"plan9\" || GOOS == \"darwin\" {\n\t\tmp.g0 = malg(-1)\n\t} else {\n\t\tmp.g0 = malg(8192 * sys.StackGuardMultiplier)\n\t}\n```\n主要是当创建m的时候，m里面的g0的栈根据不同的系统或者cgo会创建系统的栈空间，否则就会使用heap中的空间。而在`mstart`方法中，判断是否为osStack，主要是需要判断，当前的栈是否可复用，如果是操作系统自动分配的栈是不在heap中的，无法回收管理，所以直接释放，若是在heap中，则需要进行回收操作。\n\n而`mexit`函数，功能主要也是做一系列的变量释放、回收操作。后续会引出相关功能。\n\n之后，方法会进入`mstart1`函数中\n```\nfunc mstart1() {\n\t_g_ := getg()\n\n\tif _g_ != _g_.m.g0 {\n\t\tthrow(\"bad runtime·mstart\")\n\t}\n\n\tsave(getcallerpc(), getcallersp())\n\tasminit()\n\tminit()\n\n\tif _g_.m == &m0 {\n\t\tmstartm0()\n\t}\n\n\tif fn := _g_.m.mstartfn; fn != nil {\n\t\tfn()\n\t}\n\n\tif _g_.m != &m0 {\n\t\tacquirep(_g_.m.nextp.ptr())\n\t\t_g_.m.nextp = 0\n\t}\n\tschedule()\n}\n```\n\n首先，当前方法保存了上一个函数的pc和sp地址，功能也就是为了调用mexit方法，这里不做叙述。再之后就是2个初始化方法，`asminit`方法，在大部分操作系统中是没有函数体的，而`minit`函数中，具体做的事情是信号的初始化，也就是每个m都有自己的一个信号栈。这一部分不在此次学习范围内。\n\n而后续的`mstartm0`函数，功能具体描述大致有2部分：创建扩展的线程、初始化信号回调方法。俩者也就是只会在m0上面执行一次，不在调度功能内，暂时不做过多介绍。\n\n> 问：扩展线程的功能是干嘛的？\n\n再之后就会有`mstartfn`函数的执行，这一个函数具体会存在3种情况：sysmon抢占线程、templateThread模板线程、mspinning自旋方法。前2者在前面也提到过是2个特殊的线程，进入后便会不断的轮询等待。后者的自旋只是对当前的m做了一个自旋的标记。\n\n而后，针对非m0的m要进行一个p的绑定，m0为啥不需要呢？当然是因为m0在之前就已经绑定好了。\n\n### 开始调度循环\n\n题目是调度循环，而代码中其实是没有一个for循环，最后的逻辑是进入了一个execute方法，那具体是如何实现循环？\n\n循环具体涉及到了几个函数的循环：`schedule->execute->goexit->goexit1->goexit0->schedule`\n\n#### Schedule函数\n\n函数的第一段逻辑，主要会判断当前m是否存在绑定的g，如果存在，则暂停当前m，而后执行`lockedg`。Why？这一段不是主流程，稍后再看。\n\n> 什么情况下会从暂停m？\n\n```\n\tif _g_.m.lockedg != 0 {\n\t\tstoplockedm()\n\t\texecute(_g_.m.lockedg.ptr(), false) // Never returns.\n\t}\n```\n\n之后就是`gcwaiting`变量的判断，该变量不为0的情况主要是在GC的STW阶段。如果是STW阶段，则会暂停当前的m，等到startTheWorld时，会将所有的p唤醒。\n```\n\tif sched.gcwaiting != 0 {\n\t\tgcstopm()\n\t\tgoto top\n\t}\n```\n\n下面就是`runSafePointFn`这个名字，主要功能就是在GC前，需要打开所有的p读写屏障。而这个逻辑，就是简单的需要保证每个P都需要执行一遍。\n\n```\n\tif pp.runSafePointFn != 0 {\n\t\trunSafePointFn()\n\t}\n```\n\n再之后就是执行当前p上挂载的定时器\n\n```\ncheckTimers(pp, 0)\n```\n\n上述都是一些m特殊的处理流程，等处理完后，就需要开始寻找g来进行执行。\n\n```\n\tif gp == nil && gcBlackenEnabled != 0 {\n\t\tgp = gcController.findRunnableGCWorker(_g_.m.p.ptr())\n\t\ttryWakeP = tryWakeP || gp != nil\n\t}\n\tif gp == nil {\n\t\tif _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {\n\t\t\tlock(&sched.lock)\n\t\t\tgp = globrunqget(_g_.m.p.ptr(), 1)\n\t\t\tunlock(&sched.lock)\n\t\t}\n\t}\n\tif gp == nil {\n\t\tgp, inheritTime = runqget(_g_.m.p.ptr())\n\t}\n```\n\n上述代码，基本上也就是3块逻辑：优先执行gc的g、其次查看是否需要获取全局列表、最后查看当前p的列表。\n\n```\n\tif gp.lockedm != 0 {\n\t\t// Hands off own p to the locked m,\n\t\t// then blocks waiting for a new p.\n\t\tstartlockedm(gp)\n\t\tgoto top\n\t}\n\n\texecute(gp, inheritTime)\n```\n\n最后针对绑定的g进行特殊处理。否则就执行`execute`方法\n\n> 会从哪些地方去获取g？优先级是什么？\n\n#### Execute函数\n\n该函数主要功能切换当前上下文至指定的g中，具体源码如下，没有特别的逻辑，都是将g属性初始化一遍。\n\n```\nfunc execute(gp *g, inheritTime bool) {\n\t_g_ := getg()\n\n\t_g_.m.curg = gp\n\tgp.m = _g_.m\n\tcasgstatus(gp, _Grunnable, _Grunning)\n\tgp.waitsince = 0\n\tgp.preempt = false\n\tgp.stackguard0 = gp.stack.lo + _StackGuard\n\tif !inheritTime {\n\t\t_g_.m.p.ptr().schedtick++\n\t}\n\n\tgogo(&gp.sched)\n}\n```\n\n而`gogo`方法是真正在汇编层切换寄存器的逻辑，传入的sched就是这个g的上下文信息，包含4个寄存器信息，代码如下：\n```\nTEXT runtime·gogo(SB), NOSPLIT, $16-8\n\tMOVQ\tbuf+0(FP), BX\t\t// gobuf\n\tMOVQ\tgobuf_g(BX), DX\n\tMOVQ\t0(DX), CX\t\t// make sure g != nil\n\tget_tls(CX)\n\tMOVQ\tDX, g(CX)\t\t// 保存g至tls中\n\t// 恢复sp，ax，dx，bp寄存器\n\tMOVQ\tgobuf_sp(BX), SP\t// restore SP\n\tMOVQ\tgobuf_ret(BX), AX\n\tMOVQ\tgobuf_ctxt(BX), DX\n\tMOVQ\tgobuf_bp(BX), BP\n\t// 清空gobuf\n\tMOVQ\t$0, gobuf_sp(BX)\t// clear to help garbage collector\n\tMOVQ\t$0, gobuf_ret(BX)\n\tMOVQ\t$0, gobuf_ctxt(BX)\n\tMOVQ\t$0, gobuf_bp(BX)\n\tMOVQ\tgobuf_pc(BX), BX\n\tJMP\tBX\n```\n\n#### Goexit函数\n\ngoexit方法是当当前线程执行完毕后执行的析构方法，设置的方法为：\n```\nfunc gostartcallfn(gobuf *gobuf, fv *funcval) {\n    var fn unsafe.Pointer\n    if fv != nil {\n        fn = unsafe.Pointer(fv.fn)\n    } else {\n        fn = unsafe.Pointer(funcPC(nilfunc))\n    }\n    gostartcall(gobuf, fn, unsafe.Pointer(fv))\n}\n\n// adjust Gobuf as if it executed a call to fn with context ctxt\n// and then did an immediate gosave.\nfunc gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) {\n    sp := buf.sp\n    if sys.RegSize > sys.PtrSize {\n        sp -= sys.PtrSize\n        *(*uintptr)(unsafe.Pointer(sp)) = 0\n    }\n    sp -= sys.PtrSize\n    *(*uintptr)(unsafe.Pointer(sp)) = buf.pc // 注意这里，这个，这里的 buf.pc 实际上是 goexit 的 pc\n    buf.sp = sp\n    buf.pc = uintptr(fn)\n    buf.ctxt = ctxt\n}\n```\n\n在 gostartcall 中把 newproc1 时设置到 buf.pc 中的 goexit 的函数地址放到了 goroutine 的栈顶，然后重新设置 buf.pc 为 goroutine 函数的位置。这样做的目的是为了在执行完任何 goroutine 的函数时，通过 RET 指令，都能从栈顶把 sp 保存的 goexit 的指令 pop 到 pc 寄存器，效果相当于任何 goroutine 执行函数执行完之后，都会去执行 runtime.goexit，完成一些清理工作后再进入 schedule。\n\n\n当前流程只剩下`goexit->goexit1->goexit0`，代码还算可读，直接上代码：\n```\nTEXT runtime·goexit(SB),NOSPLIT,$0-0\n\tBYTE\t$0x90\t// NOP\n\tCALL\truntime·goexit1(SB)\t// does not return\n\t// traceback from goexit1 must hit code range of goexit\n\tBYTE\t$0x90\t// NOP\n\n\t... ... \n\n// Finishes execution of the current goroutine.\nfunc goexit1() {\n\tif raceenabled {\n\t\tracegoend()\n\t}\n\tif trace.enabled {\n\t\ttraceGoEnd()\n\t}\n\tmcall(goexit0)\n}\n```\n在代码来看，goexit和goexit1目标只是切换到g0协程中并执行`goexit0`中，第一部分，大部分都是变量清空，并清空当前的g状态置为_Gdead。\n\n```\nfunc goexit0(gp *g) {\n\t_g_ := getg()\n\n\tcasgstatus(gp, _Grunning, _Gdead)\n\tif isSystemGoroutine(gp, false) {\n\t\tatomic.Xadd(&sched.ngsys, -1)\n\t}\n\tgp.m = nil\n\tlocked := gp.lockedm != 0\n\tgp.lockedm = 0\n\t_g_.m.lockedg = 0\n\tgp.preemptStop = false\n\tgp.paniconfault = false\n\tgp._defer = nil // should be true already but just in case.\n\tgp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data.\n\tgp.writebuf = nil\n\tgp.waitreason = 0\n\tgp.param = nil\n\tgp.labels = nil\n\tgp.timer = nil\n\tif gcBlackenEnabled != 0 && gp.gcAssistBytes > 0 {\n\t\tscanCredit := int64(gcController.assistWorkPerByte * float64(gp.gcAssistBytes))\n\t\tatomic.Xaddint64(&gcController.bgScanCredit, scanCredit)\n\t\tgp.gcAssistBytes = 0\n\t}\n\tdropg()\n```\n\n清空完自身的g后，主要就剩下清理其他的信息，例如：写入g的队列中，清空m，进入调度。\n\n```\nfunc goexit0(gp *g) {\n\t... ...\n\tgfput(_g_.m.p.ptr(), gp)\n\tif locked {\n\t\tif GOOS != \"plan9\" { // See golang.org/issue/22227.\n\t\t\tgogo(&_g_.m.g0.sched)\n\t\t} else {\n\t\t\t_g_.m.lockedExt = 0\n\t\t}\n\t}\n\tschedule()\n```\n\n## 待办事项\n- 定时执行逻辑\n- 锁定线程逻辑\n- tryWakeP逻辑\n- findrunnable逻辑\n- mcall、notesleep逻辑\n- inheritTime功能","source":"_posts/golang-dispatch.md","raw":"---\ntitle: Golang调度讲解\ndate: 2020-07-08 15:38:21\ntags:\n---\n\nGolang调度是runtime中的核心部分，要说涉及到的东西，从基本的线程协程切换、GC的STW，到锁的暂停，都有相关涉猎。今天请个假休息一下，有空整理整理最近看的调度知识。\n\n## 调度基本知识\n\n### 进程、线程和协程\n\n进程和线程的区别都不用说了，简单来说就是，最初，大佬们觉得，每个任务肯定都有独立的内存空间、句柄等等等。只要保证程序直接能够不互相干扰就行。\n\n当机器性能不断的提升，程序员们发现，我任务太多了，需要执行很久，但是并不需要那么多的空间。如果照原来的方法每个任务都分配空间就特别耗时和耗资源，于是决定在进程的基础上拆分出线程，你只负责执行任务就行了。\n\n按道理，线程已经足够轻量，大数据时代又来了。现在需要大量的碎片计算，就像请求一个hello world，执行的任务不耗时，但是频繁。这时候的线程切换就是一个问题，主要原因是，线程的切换需要切换至操作系统的内核态，不断地做内存的复制，页表的cache很容易就失效，耗时因此增加。\n\n程序员再次想起，只要尽可能的不做内核态的切换，就可以减少这样的风险。于是出现了用户态的线程，也就是协程。\n\n\n### 并发模型\n\n大家在学习Golang源码中可以顺便思考一下，为什么是GMP模型？这就引出《七周七并发模型》书中的其他的并发模型：\n\n- 通过无变量的函数式编程实现并发，是无锁并发的一种模型；\n- Clojure对于状态和标识的分离，可以轻松实现内存事务模型；\n- Erlang的Actor模型是容错性非常高的分布式并发模型；\n- CSP模型是另一种分布式并发模型，被Go和Clojure采用；\n- GPU的并行计算主要针对数据密集型计算的并行，搞游戏的一定要看；\n- Hadoop和Storm分别适合超大数据量的批处理和流式处理。\n\nCSP（Communicating Sequential Processes）是由Tony Hoare在1978的论文上首次提出的。 它是处理并发编程的一种设计模式或者模型，指导并发程序的设计，提供了一种并发程序可实践的组织方法或者设计范式。通过此方法，可以减少并发程序引入的其它缺点，减少和规避并发程序的常见缺点和bug，并且可以被数学理论所论证。\n\n> 经典名言：Do not communicate by sharing memory; instead, share memory by communicating\n\n该模型主要的最终实现在于golang中的channel和goroutine。\n\n### GMP模型\n\n在golang实现之前，其实解决线程切换开销大的问题可能有各种各样的方式。nginx中通过epollo来进行事件管理，还有python中的yield进行用户态的手动切换。这些都属于非抢占式的，核心问题就是如果中间出现过量的超时操作，很容易就会导致进程阻塞。\n\n而golang的GMP模型中参考操作系统中的线程切换制作了sysmon线程用于做协程的抢占操作。\n\n在GMP模型特殊之处也是在于中间P层的存在，在1.1之前，是不存在P层。这就导致了，G其实是挂载在全局的链表中。每次切换协程都会抢占一个全局锁，于是给GM中增加了一个P层。\n\n### 特殊的线程、协程\n\n在golang中，存在2个特殊的线程：sysmon、templateThread。前者主要用于实现golang的抢占式调度，后者则是作为fork线程时使用的模板线程。\n\n同时还存在一个特殊的协程：signalG，功能也就是用于接收进程的信号。\n\n这3者可以单独讲解。本文主要讲解整体的正常线程调度流程。\n\n## 进程启动\n\n### 最初的入口和空间\n\n首先，golang的启动入口rt0_go（asm_arm64.s文件）。\n\n```\n\tMOVW\tR0, 8(RSP) // argc\n\tMOVD\tR1, 16(RSP) // argv\n\n\t// create istack out of the given (operating system) stack.\n\t// _cgo_init may update stackguard.\n\tMOVD\t$runtime·g0(SB), g\n\tMOVD\tRSP, R7\n\tMOVD\t$(-64*1024)(R7), R0\n\tMOVD\tR0, g_stackguard0(g)\n\tMOVD\tR0, g_stackguard1(g)\n\tMOVD\tR0, (g_stack+stack_lo)(g)\n\tMOVD\tR7, (g_stack+stack_hi)(g)\n\n    ... ...\nnocgo:\n\tBL\truntime·save_g(SB)\n\t// update stackguard after _cgo_init\n\tMOVD\t(g_stack+stack_lo)(g), R0\n\tADD\t$const__StackGuard, R0\n\tMOVD\tR0, g_stackguard0(g)\n\tMOVD\tR0, g_stackguard1(g)\n\n\t// set the per-goroutine and per-mach \"registers\"\n\tMOVD\t$runtime·m0(SB), R0\n\n\t// save m->g0 = g0\n\tMOVD\tg, m_g0(R0)\n\t// save m0 to g0->m\n\tMOVD\tR0, g_m(g)\n\n\tMOVW\t8(RSP), R0\t// copy argc\n\tMOVW\tR0, -8(RSP)\n\tMOVD\t16(RSP), R0\t\t// copy argv\n\tMOVD\tR0, 0(RSP)\n```\n\n这段汇编其实不用特别讨论，主要做的就是初始化的一个流程：  \n1. 赋值stack.lo和stack.hi属性\n2. 保存g0对象\n3. 设置m对象，包括m->g0、g0->m，做一个m0和g0的绑定\n4. 复制argc和argv\n\n以上基本上就是一些属性的赋值，后续就是执行了一系列的初始化函数。\n\n```\n\tBL\truntime·args(SB)\n\tBL\truntime·osinit(SB)\n\tBL\truntime·schedinit(SB)\n```\n\n这3个函数，不是特别影响调度流程，具体功能主要是对一些功能进行初始化，例如内存管理、信号、mp链表、GC等功能的初始化。\n\n在以上部分，现在基本上只存在一个m0代表主线程，一个g0代表主线程中的g0空间，还要一个signalG空间（并不在执行链表中），同时初始化了maxprocs个p，且在m0上面挂载了一个p对象。这时候，需要开始执行main函数，则需要一个新的g来执行方法。\n\n```\n\tMOVD\t$runtime·mainPC(SB), R0\t\t// entry\n\tMOVD\tRSP, R7\n\tMOVD.W\t$0, -8(R7)\n\tMOVD.W\tR0, -8(R7)\n\tMOVD.W\t$0, -8(R7)\n\tMOVD.W\t$0, -8(R7)\n\tMOVD\tR7, RSP\n\tBL\truntime·newproc(SB)\n```\n\n`newproc`方法会将`runtime.main`函数作为入参传入，功能等同于`go runtime.main()`。而`newproc`方法具体功能主要就是创建一个g并插入当前的p中。\n\n到这一步为止，整个进程还是只存在一个线程，但是存在3个g：g0、signalG、mainG。之后，就开始执行一个调度流程。\n\n```\n    BL\truntime·mstart(SB)\n```\n\n### 调度启动流程\n\n这是每个线程进入循环的入口。为什么这么说，代码如下：\n```\nfunc newosproc(mp *m) {\n\t... ...\n\tret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))\n```\n这就是创建一个线程的代码，印象中的线程创建是`thread_create`方法，底层最后还是调用的`clone`方法[参考](https://linux.die.net/man/2/clone)，所有golang自行封装了一个方法。而这个调用的最后一个方法就是`mstart`方法。\n\n\n进入`mstart`方法后，核心功能具体可以分为4部分：  \n1. osStack的判断\n2. stackguard的赋值\n3. mstart1的调用\n4. mexit方法，m的退出函数\n\n首先，先确定stackguard的功能，通过汇编指令，我们可以看到每个函数中都能有一段代码：\n```\nTEXT runtime.main(SB) /opt/go/src/runtime/proc.go\n        proc.go:113             0x430690        64488b0c25f8ffffff      mov rcx, qword ptr fs:[0xfffffff8]\n        proc.go:113             0x430699        483b6110                cmp rsp, qword ptr [rcx+0x10]\n        proc.go:113             0x43069d        0f86f9020000            jbe 0x43099c\n=>      proc.go:113             0x4306a3*       4883ec50                sub rsp, 0x50\n        ... ...\n        proc.go:113             0x43099c        e86f8b0200              call $runtime.morestack_noctxt\n        <autogenerated>:1       0x4309a1        e9eafcffff              jmp $runtime.main\n```\n第一行和第二行的具体功能分别是从TLS中获取当前的g对象、得到stackguard属性值。\n这一整段的代码也就是表示如果当前的rsp比stackguard小的话，就认为是需要进行栈扩展。具体的值，也就是stack.lo+_StackGuard(896)。这一段就不具体叙述。\n\n第二个问题是为什么要判断osStack？这就是要知道什么情况下会出现osStack，也就是系统栈空间。核心代码如下：\n```\nfunc allocm(_p_ *p, fn func()) *m {\n    ... ...\n\tif iscgo || GOOS == \"solaris\" || GOOS == \"illumos\" || GOOS == \"windows\" || GOOS == \"plan9\" || GOOS == \"darwin\" {\n\t\tmp.g0 = malg(-1)\n\t} else {\n\t\tmp.g0 = malg(8192 * sys.StackGuardMultiplier)\n\t}\n```\n主要是当创建m的时候，m里面的g0的栈根据不同的系统或者cgo会创建系统的栈空间，否则就会使用heap中的空间。而在`mstart`方法中，判断是否为osStack，主要是需要判断，当前的栈是否可复用，如果是操作系统自动分配的栈是不在heap中的，无法回收管理，所以直接释放，若是在heap中，则需要进行回收操作。\n\n而`mexit`函数，功能主要也是做一系列的变量释放、回收操作。后续会引出相关功能。\n\n之后，方法会进入`mstart1`函数中\n```\nfunc mstart1() {\n\t_g_ := getg()\n\n\tif _g_ != _g_.m.g0 {\n\t\tthrow(\"bad runtime·mstart\")\n\t}\n\n\tsave(getcallerpc(), getcallersp())\n\tasminit()\n\tminit()\n\n\tif _g_.m == &m0 {\n\t\tmstartm0()\n\t}\n\n\tif fn := _g_.m.mstartfn; fn != nil {\n\t\tfn()\n\t}\n\n\tif _g_.m != &m0 {\n\t\tacquirep(_g_.m.nextp.ptr())\n\t\t_g_.m.nextp = 0\n\t}\n\tschedule()\n}\n```\n\n首先，当前方法保存了上一个函数的pc和sp地址，功能也就是为了调用mexit方法，这里不做叙述。再之后就是2个初始化方法，`asminit`方法，在大部分操作系统中是没有函数体的，而`minit`函数中，具体做的事情是信号的初始化，也就是每个m都有自己的一个信号栈。这一部分不在此次学习范围内。\n\n而后续的`mstartm0`函数，功能具体描述大致有2部分：创建扩展的线程、初始化信号回调方法。俩者也就是只会在m0上面执行一次，不在调度功能内，暂时不做过多介绍。\n\n> 问：扩展线程的功能是干嘛的？\n\n再之后就会有`mstartfn`函数的执行，这一个函数具体会存在3种情况：sysmon抢占线程、templateThread模板线程、mspinning自旋方法。前2者在前面也提到过是2个特殊的线程，进入后便会不断的轮询等待。后者的自旋只是对当前的m做了一个自旋的标记。\n\n而后，针对非m0的m要进行一个p的绑定，m0为啥不需要呢？当然是因为m0在之前就已经绑定好了。\n\n### 开始调度循环\n\n题目是调度循环，而代码中其实是没有一个for循环，最后的逻辑是进入了一个execute方法，那具体是如何实现循环？\n\n循环具体涉及到了几个函数的循环：`schedule->execute->goexit->goexit1->goexit0->schedule`\n\n#### Schedule函数\n\n函数的第一段逻辑，主要会判断当前m是否存在绑定的g，如果存在，则暂停当前m，而后执行`lockedg`。Why？这一段不是主流程，稍后再看。\n\n> 什么情况下会从暂停m？\n\n```\n\tif _g_.m.lockedg != 0 {\n\t\tstoplockedm()\n\t\texecute(_g_.m.lockedg.ptr(), false) // Never returns.\n\t}\n```\n\n之后就是`gcwaiting`变量的判断，该变量不为0的情况主要是在GC的STW阶段。如果是STW阶段，则会暂停当前的m，等到startTheWorld时，会将所有的p唤醒。\n```\n\tif sched.gcwaiting != 0 {\n\t\tgcstopm()\n\t\tgoto top\n\t}\n```\n\n下面就是`runSafePointFn`这个名字，主要功能就是在GC前，需要打开所有的p读写屏障。而这个逻辑，就是简单的需要保证每个P都需要执行一遍。\n\n```\n\tif pp.runSafePointFn != 0 {\n\t\trunSafePointFn()\n\t}\n```\n\n再之后就是执行当前p上挂载的定时器\n\n```\ncheckTimers(pp, 0)\n```\n\n上述都是一些m特殊的处理流程，等处理完后，就需要开始寻找g来进行执行。\n\n```\n\tif gp == nil && gcBlackenEnabled != 0 {\n\t\tgp = gcController.findRunnableGCWorker(_g_.m.p.ptr())\n\t\ttryWakeP = tryWakeP || gp != nil\n\t}\n\tif gp == nil {\n\t\tif _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {\n\t\t\tlock(&sched.lock)\n\t\t\tgp = globrunqget(_g_.m.p.ptr(), 1)\n\t\t\tunlock(&sched.lock)\n\t\t}\n\t}\n\tif gp == nil {\n\t\tgp, inheritTime = runqget(_g_.m.p.ptr())\n\t}\n```\n\n上述代码，基本上也就是3块逻辑：优先执行gc的g、其次查看是否需要获取全局列表、最后查看当前p的列表。\n\n```\n\tif gp.lockedm != 0 {\n\t\t// Hands off own p to the locked m,\n\t\t// then blocks waiting for a new p.\n\t\tstartlockedm(gp)\n\t\tgoto top\n\t}\n\n\texecute(gp, inheritTime)\n```\n\n最后针对绑定的g进行特殊处理。否则就执行`execute`方法\n\n> 会从哪些地方去获取g？优先级是什么？\n\n#### Execute函数\n\n该函数主要功能切换当前上下文至指定的g中，具体源码如下，没有特别的逻辑，都是将g属性初始化一遍。\n\n```\nfunc execute(gp *g, inheritTime bool) {\n\t_g_ := getg()\n\n\t_g_.m.curg = gp\n\tgp.m = _g_.m\n\tcasgstatus(gp, _Grunnable, _Grunning)\n\tgp.waitsince = 0\n\tgp.preempt = false\n\tgp.stackguard0 = gp.stack.lo + _StackGuard\n\tif !inheritTime {\n\t\t_g_.m.p.ptr().schedtick++\n\t}\n\n\tgogo(&gp.sched)\n}\n```\n\n而`gogo`方法是真正在汇编层切换寄存器的逻辑，传入的sched就是这个g的上下文信息，包含4个寄存器信息，代码如下：\n```\nTEXT runtime·gogo(SB), NOSPLIT, $16-8\n\tMOVQ\tbuf+0(FP), BX\t\t// gobuf\n\tMOVQ\tgobuf_g(BX), DX\n\tMOVQ\t0(DX), CX\t\t// make sure g != nil\n\tget_tls(CX)\n\tMOVQ\tDX, g(CX)\t\t// 保存g至tls中\n\t// 恢复sp，ax，dx，bp寄存器\n\tMOVQ\tgobuf_sp(BX), SP\t// restore SP\n\tMOVQ\tgobuf_ret(BX), AX\n\tMOVQ\tgobuf_ctxt(BX), DX\n\tMOVQ\tgobuf_bp(BX), BP\n\t// 清空gobuf\n\tMOVQ\t$0, gobuf_sp(BX)\t// clear to help garbage collector\n\tMOVQ\t$0, gobuf_ret(BX)\n\tMOVQ\t$0, gobuf_ctxt(BX)\n\tMOVQ\t$0, gobuf_bp(BX)\n\tMOVQ\tgobuf_pc(BX), BX\n\tJMP\tBX\n```\n\n#### Goexit函数\n\ngoexit方法是当当前线程执行完毕后执行的析构方法，设置的方法为：\n```\nfunc gostartcallfn(gobuf *gobuf, fv *funcval) {\n    var fn unsafe.Pointer\n    if fv != nil {\n        fn = unsafe.Pointer(fv.fn)\n    } else {\n        fn = unsafe.Pointer(funcPC(nilfunc))\n    }\n    gostartcall(gobuf, fn, unsafe.Pointer(fv))\n}\n\n// adjust Gobuf as if it executed a call to fn with context ctxt\n// and then did an immediate gosave.\nfunc gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) {\n    sp := buf.sp\n    if sys.RegSize > sys.PtrSize {\n        sp -= sys.PtrSize\n        *(*uintptr)(unsafe.Pointer(sp)) = 0\n    }\n    sp -= sys.PtrSize\n    *(*uintptr)(unsafe.Pointer(sp)) = buf.pc // 注意这里，这个，这里的 buf.pc 实际上是 goexit 的 pc\n    buf.sp = sp\n    buf.pc = uintptr(fn)\n    buf.ctxt = ctxt\n}\n```\n\n在 gostartcall 中把 newproc1 时设置到 buf.pc 中的 goexit 的函数地址放到了 goroutine 的栈顶，然后重新设置 buf.pc 为 goroutine 函数的位置。这样做的目的是为了在执行完任何 goroutine 的函数时，通过 RET 指令，都能从栈顶把 sp 保存的 goexit 的指令 pop 到 pc 寄存器，效果相当于任何 goroutine 执行函数执行完之后，都会去执行 runtime.goexit，完成一些清理工作后再进入 schedule。\n\n\n当前流程只剩下`goexit->goexit1->goexit0`，代码还算可读，直接上代码：\n```\nTEXT runtime·goexit(SB),NOSPLIT,$0-0\n\tBYTE\t$0x90\t// NOP\n\tCALL\truntime·goexit1(SB)\t// does not return\n\t// traceback from goexit1 must hit code range of goexit\n\tBYTE\t$0x90\t// NOP\n\n\t... ... \n\n// Finishes execution of the current goroutine.\nfunc goexit1() {\n\tif raceenabled {\n\t\tracegoend()\n\t}\n\tif trace.enabled {\n\t\ttraceGoEnd()\n\t}\n\tmcall(goexit0)\n}\n```\n在代码来看，goexit和goexit1目标只是切换到g0协程中并执行`goexit0`中，第一部分，大部分都是变量清空，并清空当前的g状态置为_Gdead。\n\n```\nfunc goexit0(gp *g) {\n\t_g_ := getg()\n\n\tcasgstatus(gp, _Grunning, _Gdead)\n\tif isSystemGoroutine(gp, false) {\n\t\tatomic.Xadd(&sched.ngsys, -1)\n\t}\n\tgp.m = nil\n\tlocked := gp.lockedm != 0\n\tgp.lockedm = 0\n\t_g_.m.lockedg = 0\n\tgp.preemptStop = false\n\tgp.paniconfault = false\n\tgp._defer = nil // should be true already but just in case.\n\tgp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data.\n\tgp.writebuf = nil\n\tgp.waitreason = 0\n\tgp.param = nil\n\tgp.labels = nil\n\tgp.timer = nil\n\tif gcBlackenEnabled != 0 && gp.gcAssistBytes > 0 {\n\t\tscanCredit := int64(gcController.assistWorkPerByte * float64(gp.gcAssistBytes))\n\t\tatomic.Xaddint64(&gcController.bgScanCredit, scanCredit)\n\t\tgp.gcAssistBytes = 0\n\t}\n\tdropg()\n```\n\n清空完自身的g后，主要就剩下清理其他的信息，例如：写入g的队列中，清空m，进入调度。\n\n```\nfunc goexit0(gp *g) {\n\t... ...\n\tgfput(_g_.m.p.ptr(), gp)\n\tif locked {\n\t\tif GOOS != \"plan9\" { // See golang.org/issue/22227.\n\t\t\tgogo(&_g_.m.g0.sched)\n\t\t} else {\n\t\t\t_g_.m.lockedExt = 0\n\t\t}\n\t}\n\tschedule()\n```\n\n## 待办事项\n- 定时执行逻辑\n- 锁定线程逻辑\n- tryWakeP逻辑\n- findrunnable逻辑\n- mcall、notesleep逻辑\n- inheritTime功能","slug":"golang-dispatch","published":1,"updated":"2022-04-28T11:36:46.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg57i0000mauy0d0fe3qb","content":"<p>Golang调度是runtime中的核心部分，要说涉及到的东西，从基本的线程协程切换、GC的STW，到锁的暂停，都有相关涉猎。今天请个假休息一下，有空整理整理最近看的调度知识。</p>\n<h2 id=\"调度基本知识\"><a href=\"#调度基本知识\" class=\"headerlink\" title=\"调度基本知识\"></a>调度基本知识</h2><h3 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h3><p>进程和线程的区别都不用说了，简单来说就是，最初，大佬们觉得，每个任务肯定都有独立的内存空间、句柄等等等。只要保证程序直接能够不互相干扰就行。</p>\n<p>当机器性能不断的提升，程序员们发现，我任务太多了，需要执行很久，但是并不需要那么多的空间。如果照原来的方法每个任务都分配空间就特别耗时和耗资源，于是决定在进程的基础上拆分出线程，你只负责执行任务就行了。</p>\n<p>按道理，线程已经足够轻量，大数据时代又来了。现在需要大量的碎片计算，就像请求一个hello world，执行的任务不耗时，但是频繁。这时候的线程切换就是一个问题，主要原因是，线程的切换需要切换至操作系统的内核态，不断地做内存的复制，页表的cache很容易就失效，耗时因此增加。</p>\n<p>程序员再次想起，只要尽可能的不做内核态的切换，就可以减少这样的风险。于是出现了用户态的线程，也就是协程。</p>\n<h3 id=\"并发模型\"><a href=\"#并发模型\" class=\"headerlink\" title=\"并发模型\"></a>并发模型</h3><p>大家在学习Golang源码中可以顺便思考一下，为什么是GMP模型？这就引出《七周七并发模型》书中的其他的并发模型：</p>\n<ul>\n<li>通过无变量的函数式编程实现并发，是无锁并发的一种模型；</li>\n<li>Clojure对于状态和标识的分离，可以轻松实现内存事务模型；</li>\n<li>Erlang的Actor模型是容错性非常高的分布式并发模型；</li>\n<li>CSP模型是另一种分布式并发模型，被Go和Clojure采用；</li>\n<li>GPU的并行计算主要针对数据密集型计算的并行，搞游戏的一定要看；</li>\n<li>Hadoop和Storm分别适合超大数据量的批处理和流式处理。</li>\n</ul>\n<p>CSP（Communicating Sequential Processes）是由Tony Hoare在1978的论文上首次提出的。 它是处理并发编程的一种设计模式或者模型，指导并发程序的设计，提供了一种并发程序可实践的组织方法或者设计范式。通过此方法，可以减少并发程序引入的其它缺点，减少和规避并发程序的常见缺点和bug，并且可以被数学理论所论证。</p>\n<blockquote>\n<p>经典名言：Do not communicate by sharing memory; instead, share memory by communicating</p>\n</blockquote>\n<p>该模型主要的最终实现在于golang中的channel和goroutine。</p>\n<h3 id=\"GMP模型\"><a href=\"#GMP模型\" class=\"headerlink\" title=\"GMP模型\"></a>GMP模型</h3><p>在golang实现之前，其实解决线程切换开销大的问题可能有各种各样的方式。nginx中通过epollo来进行事件管理，还有python中的yield进行用户态的手动切换。这些都属于非抢占式的，核心问题就是如果中间出现过量的超时操作，很容易就会导致进程阻塞。</p>\n<p>而golang的GMP模型中参考操作系统中的线程切换制作了sysmon线程用于做协程的抢占操作。</p>\n<p>在GMP模型特殊之处也是在于中间P层的存在，在1.1之前，是不存在P层。这就导致了，G其实是挂载在全局的链表中。每次切换协程都会抢占一个全局锁，于是给GM中增加了一个P层。</p>\n<h3 id=\"特殊的线程、协程\"><a href=\"#特殊的线程、协程\" class=\"headerlink\" title=\"特殊的线程、协程\"></a>特殊的线程、协程</h3><p>在golang中，存在2个特殊的线程：sysmon、templateThread。前者主要用于实现golang的抢占式调度，后者则是作为fork线程时使用的模板线程。</p>\n<p>同时还存在一个特殊的协程：signalG，功能也就是用于接收进程的信号。</p>\n<p>这3者可以单独讲解。本文主要讲解整体的正常线程调度流程。</p>\n<h2 id=\"进程启动\"><a href=\"#进程启动\" class=\"headerlink\" title=\"进程启动\"></a>进程启动</h2><h3 id=\"最初的入口和空间\"><a href=\"#最初的入口和空间\" class=\"headerlink\" title=\"最初的入口和空间\"></a>最初的入口和空间</h3><p>首先，golang的启动入口rt0_go（asm_arm64.s文件）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\tMOVW\tR0, 8(RSP) &#x2F;&#x2F; argc</span><br><span class=\"line\">\tMOVD\tR1, 16(RSP) &#x2F;&#x2F; argv</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; create istack out of the given (operating system) stack.</span><br><span class=\"line\">\t&#x2F;&#x2F; _cgo_init may update stackguard.</span><br><span class=\"line\">\tMOVD\t$runtime·g0(SB), g</span><br><span class=\"line\">\tMOVD\tRSP, R7</span><br><span class=\"line\">\tMOVD\t$(-64*1024)(R7), R0</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard0(g)</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard1(g)</span><br><span class=\"line\">\tMOVD\tR0, (g_stack+stack_lo)(g)</span><br><span class=\"line\">\tMOVD\tR7, (g_stack+stack_hi)(g)</span><br><span class=\"line\"></span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">nocgo:</span><br><span class=\"line\">\tBL\truntime·save_g(SB)</span><br><span class=\"line\">\t&#x2F;&#x2F; update stackguard after _cgo_init</span><br><span class=\"line\">\tMOVD\t(g_stack+stack_lo)(g), R0</span><br><span class=\"line\">\tADD\t$const__StackGuard, R0</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard0(g)</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard1(g)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; set the per-goroutine and per-mach &quot;registers&quot;</span><br><span class=\"line\">\tMOVD\t$runtime·m0(SB), R0</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; save m-&gt;g0 &#x3D; g0</span><br><span class=\"line\">\tMOVD\tg, m_g0(R0)</span><br><span class=\"line\">\t&#x2F;&#x2F; save m0 to g0-&gt;m</span><br><span class=\"line\">\tMOVD\tR0, g_m(g)</span><br><span class=\"line\"></span><br><span class=\"line\">\tMOVW\t8(RSP), R0\t&#x2F;&#x2F; copy argc</span><br><span class=\"line\">\tMOVW\tR0, -8(RSP)</span><br><span class=\"line\">\tMOVD\t16(RSP), R0\t\t&#x2F;&#x2F; copy argv</span><br><span class=\"line\">\tMOVD\tR0, 0(RSP)</span><br></pre></td></tr></table></figure>\n\n<p>这段汇编其实不用特别讨论，主要做的就是初始化的一个流程：  </p>\n<ol>\n<li>赋值stack.lo和stack.hi属性</li>\n<li>保存g0对象</li>\n<li>设置m对象，包括m-&gt;g0、g0-&gt;m，做一个m0和g0的绑定</li>\n<li>复制argc和argv</li>\n</ol>\n<p>以上基本上就是一些属性的赋值，后续就是执行了一系列的初始化函数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BL\truntime·args(SB)</span><br><span class=\"line\">BL\truntime·osinit(SB)</span><br><span class=\"line\">BL\truntime·schedinit(SB)</span><br></pre></td></tr></table></figure>\n\n<p>这3个函数，不是特别影响调度流程，具体功能主要是对一些功能进行初始化，例如内存管理、信号、mp链表、GC等功能的初始化。</p>\n<p>在以上部分，现在基本上只存在一个m0代表主线程，一个g0代表主线程中的g0空间，还要一个signalG空间（并不在执行链表中），同时初始化了maxprocs个p，且在m0上面挂载了一个p对象。这时候，需要开始执行main函数，则需要一个新的g来执行方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOVD\t$runtime·mainPC(SB), R0\t\t&#x2F;&#x2F; entry</span><br><span class=\"line\">MOVD\tRSP, R7</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD.W\tR0, -8(R7)</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD\tR7, RSP</span><br><span class=\"line\">BL\truntime·newproc(SB)</span><br></pre></td></tr></table></figure>\n\n<p><code>newproc</code>方法会将<code>runtime.main</code>函数作为入参传入，功能等同于<code>go runtime.main()</code>。而<code>newproc</code>方法具体功能主要就是创建一个g并插入当前的p中。</p>\n<p>到这一步为止，整个进程还是只存在一个线程，但是存在3个g：g0、signalG、mainG。之后，就开始执行一个调度流程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BL\truntime·mstart(SB)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"调度启动流程\"><a href=\"#调度启动流程\" class=\"headerlink\" title=\"调度启动流程\"></a>调度启动流程</h3><p>这是每个线程进入循环的入口。为什么这么说，代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newosproc(mp *m) &#123;</span><br><span class=\"line\">\t... ...</span><br><span class=\"line\">\tret :&#x3D; clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))</span><br></pre></td></tr></table></figure>\n<p>这就是创建一个线程的代码，印象中的线程创建是<code>thread_create</code>方法，底层最后还是调用的<code>clone</code>方法<a href=\"https://linux.die.net/man/2/clone\" target=\"_blank\" rel=\"noopener\">参考</a>，所有golang自行封装了一个方法。而这个调用的最后一个方法就是<code>mstart</code>方法。</p>\n<p>进入<code>mstart</code>方法后，核心功能具体可以分为4部分：  </p>\n<ol>\n<li>osStack的判断</li>\n<li>stackguard的赋值</li>\n<li>mstart1的调用</li>\n<li>mexit方法，m的退出函数</li>\n</ol>\n<p>首先，先确定stackguard的功能，通过汇编指令，我们可以看到每个函数中都能有一段代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime.main(SB) &#x2F;opt&#x2F;go&#x2F;src&#x2F;runtime&#x2F;proc.go</span><br><span class=\"line\">        proc.go:113             0x430690        64488b0c25f8ffffff      mov rcx, qword ptr fs:[0xfffffff8]</span><br><span class=\"line\">        proc.go:113             0x430699        483b6110                cmp rsp, qword ptr [rcx+0x10]</span><br><span class=\"line\">        proc.go:113             0x43069d        0f86f9020000            jbe 0x43099c</span><br><span class=\"line\">&#x3D;&gt;      proc.go:113             0x4306a3*       4883ec50                sub rsp, 0x50</span><br><span class=\"line\">        ... ...</span><br><span class=\"line\">        proc.go:113             0x43099c        e86f8b0200              call $runtime.morestack_noctxt</span><br><span class=\"line\">        &lt;autogenerated&gt;:1       0x4309a1        e9eafcffff              jmp $runtime.main</span><br></pre></td></tr></table></figure>\n<p>第一行和第二行的具体功能分别是从TLS中获取当前的g对象、得到stackguard属性值。<br>这一整段的代码也就是表示如果当前的rsp比stackguard小的话，就认为是需要进行栈扩展。具体的值，也就是stack.lo+_StackGuard(896)。这一段就不具体叙述。</p>\n<p>第二个问题是为什么要判断osStack？这就是要知道什么情况下会出现osStack，也就是系统栈空间。核心代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func allocm(_p_ *p, fn func()) *m &#123;</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tif iscgo || GOOS &#x3D;&#x3D; &quot;solaris&quot; || GOOS &#x3D;&#x3D; &quot;illumos&quot; || GOOS &#x3D;&#x3D; &quot;windows&quot; || GOOS &#x3D;&#x3D; &quot;plan9&quot; || GOOS &#x3D;&#x3D; &quot;darwin&quot; &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(-1)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(8192 * sys.StackGuardMultiplier)</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>主要是当创建m的时候，m里面的g0的栈根据不同的系统或者cgo会创建系统的栈空间，否则就会使用heap中的空间。而在<code>mstart</code>方法中，判断是否为osStack，主要是需要判断，当前的栈是否可复用，如果是操作系统自动分配的栈是不在heap中的，无法回收管理，所以直接释放，若是在heap中，则需要进行回收操作。</p>\n<p>而<code>mexit</code>函数，功能主要也是做一系列的变量释放、回收操作。后续会引出相关功能。</p>\n<p>之后，方法会进入<code>mstart1</code>函数中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func mstart1() &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_ !&#x3D; _g_.m.g0 &#123;</span><br><span class=\"line\">\t\tthrow(&quot;bad runtime·mstart&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsave(getcallerpc(), getcallersp())</span><br><span class=\"line\">\tasminit()</span><br><span class=\"line\">\tminit()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_.m &#x3D;&#x3D; &amp;m0 &#123;</span><br><span class=\"line\">\t\tmstartm0()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif fn :&#x3D; _g_.m.mstartfn; fn !&#x3D; nil &#123;</span><br><span class=\"line\">\t\tfn()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_.m !&#x3D; &amp;m0 &#123;</span><br><span class=\"line\">\t\tacquirep(_g_.m.nextp.ptr())</span><br><span class=\"line\">\t\t_g_.m.nextp &#x3D; 0</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tschedule()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先，当前方法保存了上一个函数的pc和sp地址，功能也就是为了调用mexit方法，这里不做叙述。再之后就是2个初始化方法，<code>asminit</code>方法，在大部分操作系统中是没有函数体的，而<code>minit</code>函数中，具体做的事情是信号的初始化，也就是每个m都有自己的一个信号栈。这一部分不在此次学习范围内。</p>\n<p>而后续的<code>mstartm0</code>函数，功能具体描述大致有2部分：创建扩展的线程、初始化信号回调方法。俩者也就是只会在m0上面执行一次，不在调度功能内，暂时不做过多介绍。</p>\n<blockquote>\n<p>问：扩展线程的功能是干嘛的？</p>\n</blockquote>\n<p>再之后就会有<code>mstartfn</code>函数的执行，这一个函数具体会存在3种情况：sysmon抢占线程、templateThread模板线程、mspinning自旋方法。前2者在前面也提到过是2个特殊的线程，进入后便会不断的轮询等待。后者的自旋只是对当前的m做了一个自旋的标记。</p>\n<p>而后，针对非m0的m要进行一个p的绑定，m0为啥不需要呢？当然是因为m0在之前就已经绑定好了。</p>\n<h3 id=\"开始调度循环\"><a href=\"#开始调度循环\" class=\"headerlink\" title=\"开始调度循环\"></a>开始调度循环</h3><p>题目是调度循环，而代码中其实是没有一个for循环，最后的逻辑是进入了一个execute方法，那具体是如何实现循环？</p>\n<p>循环具体涉及到了几个函数的循环：<code>schedule-&gt;execute-&gt;goexit-&gt;goexit1-&gt;goexit0-&gt;schedule</code></p>\n<h4 id=\"Schedule函数\"><a href=\"#Schedule函数\" class=\"headerlink\" title=\"Schedule函数\"></a>Schedule函数</h4><p>函数的第一段逻辑，主要会判断当前m是否存在绑定的g，如果存在，则暂停当前m，而后执行<code>lockedg</code>。Why？这一段不是主流程，稍后再看。</p>\n<blockquote>\n<p>什么情况下会从暂停m？</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if _g_.m.lockedg !&#x3D; 0 &#123;</span><br><span class=\"line\">\tstoplockedm()</span><br><span class=\"line\">\texecute(_g_.m.lockedg.ptr(), false) &#x2F;&#x2F; Never returns.</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>之后就是<code>gcwaiting</code>变量的判断，该变量不为0的情况主要是在GC的STW阶段。如果是STW阶段，则会暂停当前的m，等到startTheWorld时，会将所有的p唤醒。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if sched.gcwaiting !&#x3D; 0 &#123;</span><br><span class=\"line\">\tgcstopm()</span><br><span class=\"line\">\tgoto top</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>下面就是<code>runSafePointFn</code>这个名字，主要功能就是在GC前，需要打开所有的p读写屏障。而这个逻辑，就是简单的需要保证每个P都需要执行一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if pp.runSafePointFn !&#x3D; 0 &#123;</span><br><span class=\"line\">\trunSafePointFn()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>再之后就是执行当前p上挂载的定时器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">checkTimers(pp, 0)</span><br></pre></td></tr></table></figure>\n\n<p>上述都是一些m特殊的处理流程，等处理完后，就需要开始寻找g来进行执行。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if gp &#x3D;&#x3D; nil &amp;&amp; gcBlackenEnabled !&#x3D; 0 &#123;</span><br><span class=\"line\">\tgp &#x3D; gcController.findRunnableGCWorker(_g_.m.p.ptr())</span><br><span class=\"line\">\ttryWakeP &#x3D; tryWakeP || gp !&#x3D; nil</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">if gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\tif _g_.m.p.ptr().schedtick%61 &#x3D;&#x3D; 0 &amp;&amp; sched.runqsize &gt; 0 &#123;</span><br><span class=\"line\">\t\tlock(&amp;sched.lock)</span><br><span class=\"line\">\t\tgp &#x3D; globrunqget(_g_.m.p.ptr(), 1)</span><br><span class=\"line\">\t\tunlock(&amp;sched.lock)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">if gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\tgp, inheritTime &#x3D; runqget(_g_.m.p.ptr())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上述代码，基本上也就是3块逻辑：优先执行gc的g、其次查看是否需要获取全局列表、最后查看当前p的列表。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if gp.lockedm !&#x3D; 0 &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; Hands off own p to the locked m,</span><br><span class=\"line\">\t&#x2F;&#x2F; then blocks waiting for a new p.</span><br><span class=\"line\">\tstartlockedm(gp)</span><br><span class=\"line\">\tgoto top</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">execute(gp, inheritTime)</span><br></pre></td></tr></table></figure>\n\n<p>最后针对绑定的g进行特殊处理。否则就执行<code>execute</code>方法</p>\n<blockquote>\n<p>会从哪些地方去获取g？优先级是什么？</p>\n</blockquote>\n<h4 id=\"Execute函数\"><a href=\"#Execute函数\" class=\"headerlink\" title=\"Execute函数\"></a>Execute函数</h4><p>该函数主要功能切换当前上下文至指定的g中，具体源码如下，没有特别的逻辑，都是将g属性初始化一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func execute(gp *g, inheritTime bool) &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\t_g_.m.curg &#x3D; gp</span><br><span class=\"line\">\tgp.m &#x3D; _g_.m</span><br><span class=\"line\">\tcasgstatus(gp, _Grunnable, _Grunning)</span><br><span class=\"line\">\tgp.waitsince &#x3D; 0</span><br><span class=\"line\">\tgp.preempt &#x3D; false</span><br><span class=\"line\">\tgp.stackguard0 &#x3D; gp.stack.lo + _StackGuard</span><br><span class=\"line\">\tif !inheritTime &#123;</span><br><span class=\"line\">\t\t_g_.m.p.ptr().schedtick++</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tgogo(&amp;gp.sched)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>而<code>gogo</code>方法是真正在汇编层切换寄存器的逻辑，传入的sched就是这个g的上下文信息，包含4个寄存器信息，代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime·gogo(SB), NOSPLIT, $16-8</span><br><span class=\"line\">\tMOVQ\tbuf+0(FP), BX\t\t&#x2F;&#x2F; gobuf</span><br><span class=\"line\">\tMOVQ\tgobuf_g(BX), DX</span><br><span class=\"line\">\tMOVQ\t0(DX), CX\t\t&#x2F;&#x2F; make sure g !&#x3D; nil</span><br><span class=\"line\">\tget_tls(CX)</span><br><span class=\"line\">\tMOVQ\tDX, g(CX)\t\t&#x2F;&#x2F; 保存g至tls中</span><br><span class=\"line\">\t&#x2F;&#x2F; 恢复sp，ax，dx，bp寄存器</span><br><span class=\"line\">\tMOVQ\tgobuf_sp(BX), SP\t&#x2F;&#x2F; restore SP</span><br><span class=\"line\">\tMOVQ\tgobuf_ret(BX), AX</span><br><span class=\"line\">\tMOVQ\tgobuf_ctxt(BX), DX</span><br><span class=\"line\">\tMOVQ\tgobuf_bp(BX), BP</span><br><span class=\"line\">\t&#x2F;&#x2F; 清空gobuf</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_sp(BX)\t&#x2F;&#x2F; clear to help garbage collector</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_ret(BX)</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_ctxt(BX)</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_bp(BX)</span><br><span class=\"line\">\tMOVQ\tgobuf_pc(BX), BX</span><br><span class=\"line\">\tJMP\tBX</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Goexit函数\"><a href=\"#Goexit函数\" class=\"headerlink\" title=\"Goexit函数\"></a>Goexit函数</h4><p>goexit方法是当当前线程执行完毕后执行的析构方法，设置的方法为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func gostartcallfn(gobuf *gobuf, fv *funcval) &#123;</span><br><span class=\"line\">    var fn unsafe.Pointer</span><br><span class=\"line\">    if fv !&#x3D; nil &#123;</span><br><span class=\"line\">        fn &#x3D; unsafe.Pointer(fv.fn)</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        fn &#x3D; unsafe.Pointer(funcPC(nilfunc))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    gostartcall(gobuf, fn, unsafe.Pointer(fv))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; adjust Gobuf as if it executed a call to fn with context ctxt</span><br><span class=\"line\">&#x2F;&#x2F; and then did an immediate gosave.</span><br><span class=\"line\">func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) &#123;</span><br><span class=\"line\">    sp :&#x3D; buf.sp</span><br><span class=\"line\">    if sys.RegSize &gt; sys.PtrSize &#123;</span><br><span class=\"line\">        sp -&#x3D; sys.PtrSize</span><br><span class=\"line\">        *(*uintptr)(unsafe.Pointer(sp)) &#x3D; 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    sp -&#x3D; sys.PtrSize</span><br><span class=\"line\">    *(*uintptr)(unsafe.Pointer(sp)) &#x3D; buf.pc &#x2F;&#x2F; 注意这里，这个，这里的 buf.pc 实际上是 goexit 的 pc</span><br><span class=\"line\">    buf.sp &#x3D; sp</span><br><span class=\"line\">    buf.pc &#x3D; uintptr(fn)</span><br><span class=\"line\">    buf.ctxt &#x3D; ctxt</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在 gostartcall 中把 newproc1 时设置到 buf.pc 中的 goexit 的函数地址放到了 goroutine 的栈顶，然后重新设置 buf.pc 为 goroutine 函数的位置。这样做的目的是为了在执行完任何 goroutine 的函数时，通过 RET 指令，都能从栈顶把 sp 保存的 goexit 的指令 pop 到 pc 寄存器，效果相当于任何 goroutine 执行函数执行完之后，都会去执行 runtime.goexit，完成一些清理工作后再进入 schedule。</p>\n<p>当前流程只剩下<code>goexit-&gt;goexit1-&gt;goexit0</code>，代码还算可读，直接上代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime·goexit(SB),NOSPLIT,$0-0</span><br><span class=\"line\">\tBYTE\t$0x90\t&#x2F;&#x2F; NOP</span><br><span class=\"line\">\tCALL\truntime·goexit1(SB)\t&#x2F;&#x2F; does not return</span><br><span class=\"line\">\t&#x2F;&#x2F; traceback from goexit1 must hit code range of goexit</span><br><span class=\"line\">\tBYTE\t$0x90\t&#x2F;&#x2F; NOP</span><br><span class=\"line\"></span><br><span class=\"line\">\t... ... </span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Finishes execution of the current goroutine.</span><br><span class=\"line\">func goexit1() &#123;</span><br><span class=\"line\">\tif raceenabled &#123;</span><br><span class=\"line\">\t\tracegoend()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif trace.enabled &#123;</span><br><span class=\"line\">\t\ttraceGoEnd()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tmcall(goexit0)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在代码来看，goexit和goexit1目标只是切换到g0协程中并执行<code>goexit0</code>中，第一部分，大部分都是变量清空，并清空当前的g状态置为_Gdead。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func goexit0(gp *g) &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tcasgstatus(gp, _Grunning, _Gdead)</span><br><span class=\"line\">\tif isSystemGoroutine(gp, false) &#123;</span><br><span class=\"line\">\t\tatomic.Xadd(&amp;sched.ngsys, -1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgp.m &#x3D; nil</span><br><span class=\"line\">\tlocked :&#x3D; gp.lockedm !&#x3D; 0</span><br><span class=\"line\">\tgp.lockedm &#x3D; 0</span><br><span class=\"line\">\t_g_.m.lockedg &#x3D; 0</span><br><span class=\"line\">\tgp.preemptStop &#x3D; false</span><br><span class=\"line\">\tgp.paniconfault &#x3D; false</span><br><span class=\"line\">\tgp._defer &#x3D; nil &#x2F;&#x2F; should be true already but just in case.</span><br><span class=\"line\">\tgp._panic &#x3D; nil &#x2F;&#x2F; non-nil for Goexit during panic. points at stack-allocated data.</span><br><span class=\"line\">\tgp.writebuf &#x3D; nil</span><br><span class=\"line\">\tgp.waitreason &#x3D; 0</span><br><span class=\"line\">\tgp.param &#x3D; nil</span><br><span class=\"line\">\tgp.labels &#x3D; nil</span><br><span class=\"line\">\tgp.timer &#x3D; nil</span><br><span class=\"line\">\tif gcBlackenEnabled !&#x3D; 0 &amp;&amp; gp.gcAssistBytes &gt; 0 &#123;</span><br><span class=\"line\">\t\tscanCredit :&#x3D; int64(gcController.assistWorkPerByte * float64(gp.gcAssistBytes))</span><br><span class=\"line\">\t\tatomic.Xaddint64(&amp;gcController.bgScanCredit, scanCredit)</span><br><span class=\"line\">\t\tgp.gcAssistBytes &#x3D; 0</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdropg()</span><br></pre></td></tr></table></figure>\n\n<p>清空完自身的g后，主要就剩下清理其他的信息，例如：写入g的队列中，清空m，进入调度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func goexit0(gp *g) &#123;</span><br><span class=\"line\">\t... ...</span><br><span class=\"line\">\tgfput(_g_.m.p.ptr(), gp)</span><br><span class=\"line\">\tif locked &#123;</span><br><span class=\"line\">\t\tif GOOS !&#x3D; &quot;plan9&quot; &#123; &#x2F;&#x2F; See golang.org&#x2F;issue&#x2F;22227.</span><br><span class=\"line\">\t\t\tgogo(&amp;_g_.m.g0.sched)</span><br><span class=\"line\">\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\t_g_.m.lockedExt &#x3D; 0</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tschedule()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"待办事项\"><a href=\"#待办事项\" class=\"headerlink\" title=\"待办事项\"></a>待办事项</h2><ul>\n<li>定时执行逻辑</li>\n<li>锁定线程逻辑</li>\n<li>tryWakeP逻辑</li>\n<li>findrunnable逻辑</li>\n<li>mcall、notesleep逻辑</li>\n<li>inheritTime功能</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>Golang调度是runtime中的核心部分，要说涉及到的东西，从基本的线程协程切换、GC的STW，到锁的暂停，都有相关涉猎。今天请个假休息一下，有空整理整理最近看的调度知识。</p>\n<h2 id=\"调度基本知识\"><a href=\"#调度基本知识\" class=\"headerlink\" title=\"调度基本知识\"></a>调度基本知识</h2><h3 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h3><p>进程和线程的区别都不用说了，简单来说就是，最初，大佬们觉得，每个任务肯定都有独立的内存空间、句柄等等等。只要保证程序直接能够不互相干扰就行。</p>\n<p>当机器性能不断的提升，程序员们发现，我任务太多了，需要执行很久，但是并不需要那么多的空间。如果照原来的方法每个任务都分配空间就特别耗时和耗资源，于是决定在进程的基础上拆分出线程，你只负责执行任务就行了。</p>\n<p>按道理，线程已经足够轻量，大数据时代又来了。现在需要大量的碎片计算，就像请求一个hello world，执行的任务不耗时，但是频繁。这时候的线程切换就是一个问题，主要原因是，线程的切换需要切换至操作系统的内核态，不断地做内存的复制，页表的cache很容易就失效，耗时因此增加。</p>\n<p>程序员再次想起，只要尽可能的不做内核态的切换，就可以减少这样的风险。于是出现了用户态的线程，也就是协程。</p>\n<h3 id=\"并发模型\"><a href=\"#并发模型\" class=\"headerlink\" title=\"并发模型\"></a>并发模型</h3><p>大家在学习Golang源码中可以顺便思考一下，为什么是GMP模型？这就引出《七周七并发模型》书中的其他的并发模型：</p>\n<ul>\n<li>通过无变量的函数式编程实现并发，是无锁并发的一种模型；</li>\n<li>Clojure对于状态和标识的分离，可以轻松实现内存事务模型；</li>\n<li>Erlang的Actor模型是容错性非常高的分布式并发模型；</li>\n<li>CSP模型是另一种分布式并发模型，被Go和Clojure采用；</li>\n<li>GPU的并行计算主要针对数据密集型计算的并行，搞游戏的一定要看；</li>\n<li>Hadoop和Storm分别适合超大数据量的批处理和流式处理。</li>\n</ul>\n<p>CSP（Communicating Sequential Processes）是由Tony Hoare在1978的论文上首次提出的。 它是处理并发编程的一种设计模式或者模型，指导并发程序的设计，提供了一种并发程序可实践的组织方法或者设计范式。通过此方法，可以减少并发程序引入的其它缺点，减少和规避并发程序的常见缺点和bug，并且可以被数学理论所论证。</p>\n<blockquote>\n<p>经典名言：Do not communicate by sharing memory; instead, share memory by communicating</p>\n</blockquote>\n<p>该模型主要的最终实现在于golang中的channel和goroutine。</p>\n<h3 id=\"GMP模型\"><a href=\"#GMP模型\" class=\"headerlink\" title=\"GMP模型\"></a>GMP模型</h3><p>在golang实现之前，其实解决线程切换开销大的问题可能有各种各样的方式。nginx中通过epollo来进行事件管理，还有python中的yield进行用户态的手动切换。这些都属于非抢占式的，核心问题就是如果中间出现过量的超时操作，很容易就会导致进程阻塞。</p>\n<p>而golang的GMP模型中参考操作系统中的线程切换制作了sysmon线程用于做协程的抢占操作。</p>\n<p>在GMP模型特殊之处也是在于中间P层的存在，在1.1之前，是不存在P层。这就导致了，G其实是挂载在全局的链表中。每次切换协程都会抢占一个全局锁，于是给GM中增加了一个P层。</p>\n<h3 id=\"特殊的线程、协程\"><a href=\"#特殊的线程、协程\" class=\"headerlink\" title=\"特殊的线程、协程\"></a>特殊的线程、协程</h3><p>在golang中，存在2个特殊的线程：sysmon、templateThread。前者主要用于实现golang的抢占式调度，后者则是作为fork线程时使用的模板线程。</p>\n<p>同时还存在一个特殊的协程：signalG，功能也就是用于接收进程的信号。</p>\n<p>这3者可以单独讲解。本文主要讲解整体的正常线程调度流程。</p>\n<h2 id=\"进程启动\"><a href=\"#进程启动\" class=\"headerlink\" title=\"进程启动\"></a>进程启动</h2><h3 id=\"最初的入口和空间\"><a href=\"#最初的入口和空间\" class=\"headerlink\" title=\"最初的入口和空间\"></a>最初的入口和空间</h3><p>首先，golang的启动入口rt0_go（asm_arm64.s文件）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\tMOVW\tR0, 8(RSP) &#x2F;&#x2F; argc</span><br><span class=\"line\">\tMOVD\tR1, 16(RSP) &#x2F;&#x2F; argv</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; create istack out of the given (operating system) stack.</span><br><span class=\"line\">\t&#x2F;&#x2F; _cgo_init may update stackguard.</span><br><span class=\"line\">\tMOVD\t$runtime·g0(SB), g</span><br><span class=\"line\">\tMOVD\tRSP, R7</span><br><span class=\"line\">\tMOVD\t$(-64*1024)(R7), R0</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard0(g)</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard1(g)</span><br><span class=\"line\">\tMOVD\tR0, (g_stack+stack_lo)(g)</span><br><span class=\"line\">\tMOVD\tR7, (g_stack+stack_hi)(g)</span><br><span class=\"line\"></span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">nocgo:</span><br><span class=\"line\">\tBL\truntime·save_g(SB)</span><br><span class=\"line\">\t&#x2F;&#x2F; update stackguard after _cgo_init</span><br><span class=\"line\">\tMOVD\t(g_stack+stack_lo)(g), R0</span><br><span class=\"line\">\tADD\t$const__StackGuard, R0</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard0(g)</span><br><span class=\"line\">\tMOVD\tR0, g_stackguard1(g)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; set the per-goroutine and per-mach &quot;registers&quot;</span><br><span class=\"line\">\tMOVD\t$runtime·m0(SB), R0</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#x2F;&#x2F; save m-&gt;g0 &#x3D; g0</span><br><span class=\"line\">\tMOVD\tg, m_g0(R0)</span><br><span class=\"line\">\t&#x2F;&#x2F; save m0 to g0-&gt;m</span><br><span class=\"line\">\tMOVD\tR0, g_m(g)</span><br><span class=\"line\"></span><br><span class=\"line\">\tMOVW\t8(RSP), R0\t&#x2F;&#x2F; copy argc</span><br><span class=\"line\">\tMOVW\tR0, -8(RSP)</span><br><span class=\"line\">\tMOVD\t16(RSP), R0\t\t&#x2F;&#x2F; copy argv</span><br><span class=\"line\">\tMOVD\tR0, 0(RSP)</span><br></pre></td></tr></table></figure>\n\n<p>这段汇编其实不用特别讨论，主要做的就是初始化的一个流程：  </p>\n<ol>\n<li>赋值stack.lo和stack.hi属性</li>\n<li>保存g0对象</li>\n<li>设置m对象，包括m-&gt;g0、g0-&gt;m，做一个m0和g0的绑定</li>\n<li>复制argc和argv</li>\n</ol>\n<p>以上基本上就是一些属性的赋值，后续就是执行了一系列的初始化函数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BL\truntime·args(SB)</span><br><span class=\"line\">BL\truntime·osinit(SB)</span><br><span class=\"line\">BL\truntime·schedinit(SB)</span><br></pre></td></tr></table></figure>\n\n<p>这3个函数，不是特别影响调度流程，具体功能主要是对一些功能进行初始化，例如内存管理、信号、mp链表、GC等功能的初始化。</p>\n<p>在以上部分，现在基本上只存在一个m0代表主线程，一个g0代表主线程中的g0空间，还要一个signalG空间（并不在执行链表中），同时初始化了maxprocs个p，且在m0上面挂载了一个p对象。这时候，需要开始执行main函数，则需要一个新的g来执行方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOVD\t$runtime·mainPC(SB), R0\t\t&#x2F;&#x2F; entry</span><br><span class=\"line\">MOVD\tRSP, R7</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD.W\tR0, -8(R7)</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD.W\t$0, -8(R7)</span><br><span class=\"line\">MOVD\tR7, RSP</span><br><span class=\"line\">BL\truntime·newproc(SB)</span><br></pre></td></tr></table></figure>\n\n<p><code>newproc</code>方法会将<code>runtime.main</code>函数作为入参传入，功能等同于<code>go runtime.main()</code>。而<code>newproc</code>方法具体功能主要就是创建一个g并插入当前的p中。</p>\n<p>到这一步为止，整个进程还是只存在一个线程，但是存在3个g：g0、signalG、mainG。之后，就开始执行一个调度流程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BL\truntime·mstart(SB)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"调度启动流程\"><a href=\"#调度启动流程\" class=\"headerlink\" title=\"调度启动流程\"></a>调度启动流程</h3><p>这是每个线程进入循环的入口。为什么这么说，代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newosproc(mp *m) &#123;</span><br><span class=\"line\">\t... ...</span><br><span class=\"line\">\tret :&#x3D; clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))</span><br></pre></td></tr></table></figure>\n<p>这就是创建一个线程的代码，印象中的线程创建是<code>thread_create</code>方法，底层最后还是调用的<code>clone</code>方法<a href=\"https://linux.die.net/man/2/clone\" target=\"_blank\" rel=\"noopener\">参考</a>，所有golang自行封装了一个方法。而这个调用的最后一个方法就是<code>mstart</code>方法。</p>\n<p>进入<code>mstart</code>方法后，核心功能具体可以分为4部分：  </p>\n<ol>\n<li>osStack的判断</li>\n<li>stackguard的赋值</li>\n<li>mstart1的调用</li>\n<li>mexit方法，m的退出函数</li>\n</ol>\n<p>首先，先确定stackguard的功能，通过汇编指令，我们可以看到每个函数中都能有一段代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime.main(SB) &#x2F;opt&#x2F;go&#x2F;src&#x2F;runtime&#x2F;proc.go</span><br><span class=\"line\">        proc.go:113             0x430690        64488b0c25f8ffffff      mov rcx, qword ptr fs:[0xfffffff8]</span><br><span class=\"line\">        proc.go:113             0x430699        483b6110                cmp rsp, qword ptr [rcx+0x10]</span><br><span class=\"line\">        proc.go:113             0x43069d        0f86f9020000            jbe 0x43099c</span><br><span class=\"line\">&#x3D;&gt;      proc.go:113             0x4306a3*       4883ec50                sub rsp, 0x50</span><br><span class=\"line\">        ... ...</span><br><span class=\"line\">        proc.go:113             0x43099c        e86f8b0200              call $runtime.morestack_noctxt</span><br><span class=\"line\">        &lt;autogenerated&gt;:1       0x4309a1        e9eafcffff              jmp $runtime.main</span><br></pre></td></tr></table></figure>\n<p>第一行和第二行的具体功能分别是从TLS中获取当前的g对象、得到stackguard属性值。<br>这一整段的代码也就是表示如果当前的rsp比stackguard小的话，就认为是需要进行栈扩展。具体的值，也就是stack.lo+_StackGuard(896)。这一段就不具体叙述。</p>\n<p>第二个问题是为什么要判断osStack？这就是要知道什么情况下会出现osStack，也就是系统栈空间。核心代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func allocm(_p_ *p, fn func()) *m &#123;</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tif iscgo || GOOS &#x3D;&#x3D; &quot;solaris&quot; || GOOS &#x3D;&#x3D; &quot;illumos&quot; || GOOS &#x3D;&#x3D; &quot;windows&quot; || GOOS &#x3D;&#x3D; &quot;plan9&quot; || GOOS &#x3D;&#x3D; &quot;darwin&quot; &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(-1)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(8192 * sys.StackGuardMultiplier)</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>主要是当创建m的时候，m里面的g0的栈根据不同的系统或者cgo会创建系统的栈空间，否则就会使用heap中的空间。而在<code>mstart</code>方法中，判断是否为osStack，主要是需要判断，当前的栈是否可复用，如果是操作系统自动分配的栈是不在heap中的，无法回收管理，所以直接释放，若是在heap中，则需要进行回收操作。</p>\n<p>而<code>mexit</code>函数，功能主要也是做一系列的变量释放、回收操作。后续会引出相关功能。</p>\n<p>之后，方法会进入<code>mstart1</code>函数中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func mstart1() &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_ !&#x3D; _g_.m.g0 &#123;</span><br><span class=\"line\">\t\tthrow(&quot;bad runtime·mstart&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsave(getcallerpc(), getcallersp())</span><br><span class=\"line\">\tasminit()</span><br><span class=\"line\">\tminit()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_.m &#x3D;&#x3D; &amp;m0 &#123;</span><br><span class=\"line\">\t\tmstartm0()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif fn :&#x3D; _g_.m.mstartfn; fn !&#x3D; nil &#123;</span><br><span class=\"line\">\t\tfn()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif _g_.m !&#x3D; &amp;m0 &#123;</span><br><span class=\"line\">\t\tacquirep(_g_.m.nextp.ptr())</span><br><span class=\"line\">\t\t_g_.m.nextp &#x3D; 0</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tschedule()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先，当前方法保存了上一个函数的pc和sp地址，功能也就是为了调用mexit方法，这里不做叙述。再之后就是2个初始化方法，<code>asminit</code>方法，在大部分操作系统中是没有函数体的，而<code>minit</code>函数中，具体做的事情是信号的初始化，也就是每个m都有自己的一个信号栈。这一部分不在此次学习范围内。</p>\n<p>而后续的<code>mstartm0</code>函数，功能具体描述大致有2部分：创建扩展的线程、初始化信号回调方法。俩者也就是只会在m0上面执行一次，不在调度功能内，暂时不做过多介绍。</p>\n<blockquote>\n<p>问：扩展线程的功能是干嘛的？</p>\n</blockquote>\n<p>再之后就会有<code>mstartfn</code>函数的执行，这一个函数具体会存在3种情况：sysmon抢占线程、templateThread模板线程、mspinning自旋方法。前2者在前面也提到过是2个特殊的线程，进入后便会不断的轮询等待。后者的自旋只是对当前的m做了一个自旋的标记。</p>\n<p>而后，针对非m0的m要进行一个p的绑定，m0为啥不需要呢？当然是因为m0在之前就已经绑定好了。</p>\n<h3 id=\"开始调度循环\"><a href=\"#开始调度循环\" class=\"headerlink\" title=\"开始调度循环\"></a>开始调度循环</h3><p>题目是调度循环，而代码中其实是没有一个for循环，最后的逻辑是进入了一个execute方法，那具体是如何实现循环？</p>\n<p>循环具体涉及到了几个函数的循环：<code>schedule-&gt;execute-&gt;goexit-&gt;goexit1-&gt;goexit0-&gt;schedule</code></p>\n<h4 id=\"Schedule函数\"><a href=\"#Schedule函数\" class=\"headerlink\" title=\"Schedule函数\"></a>Schedule函数</h4><p>函数的第一段逻辑，主要会判断当前m是否存在绑定的g，如果存在，则暂停当前m，而后执行<code>lockedg</code>。Why？这一段不是主流程，稍后再看。</p>\n<blockquote>\n<p>什么情况下会从暂停m？</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if _g_.m.lockedg !&#x3D; 0 &#123;</span><br><span class=\"line\">\tstoplockedm()</span><br><span class=\"line\">\texecute(_g_.m.lockedg.ptr(), false) &#x2F;&#x2F; Never returns.</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>之后就是<code>gcwaiting</code>变量的判断，该变量不为0的情况主要是在GC的STW阶段。如果是STW阶段，则会暂停当前的m，等到startTheWorld时，会将所有的p唤醒。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if sched.gcwaiting !&#x3D; 0 &#123;</span><br><span class=\"line\">\tgcstopm()</span><br><span class=\"line\">\tgoto top</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>下面就是<code>runSafePointFn</code>这个名字，主要功能就是在GC前，需要打开所有的p读写屏障。而这个逻辑，就是简单的需要保证每个P都需要执行一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if pp.runSafePointFn !&#x3D; 0 &#123;</span><br><span class=\"line\">\trunSafePointFn()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>再之后就是执行当前p上挂载的定时器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">checkTimers(pp, 0)</span><br></pre></td></tr></table></figure>\n\n<p>上述都是一些m特殊的处理流程，等处理完后，就需要开始寻找g来进行执行。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if gp &#x3D;&#x3D; nil &amp;&amp; gcBlackenEnabled !&#x3D; 0 &#123;</span><br><span class=\"line\">\tgp &#x3D; gcController.findRunnableGCWorker(_g_.m.p.ptr())</span><br><span class=\"line\">\ttryWakeP &#x3D; tryWakeP || gp !&#x3D; nil</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">if gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\tif _g_.m.p.ptr().schedtick%61 &#x3D;&#x3D; 0 &amp;&amp; sched.runqsize &gt; 0 &#123;</span><br><span class=\"line\">\t\tlock(&amp;sched.lock)</span><br><span class=\"line\">\t\tgp &#x3D; globrunqget(_g_.m.p.ptr(), 1)</span><br><span class=\"line\">\t\tunlock(&amp;sched.lock)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">if gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\tgp, inheritTime &#x3D; runqget(_g_.m.p.ptr())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上述代码，基本上也就是3块逻辑：优先执行gc的g、其次查看是否需要获取全局列表、最后查看当前p的列表。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if gp.lockedm !&#x3D; 0 &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; Hands off own p to the locked m,</span><br><span class=\"line\">\t&#x2F;&#x2F; then blocks waiting for a new p.</span><br><span class=\"line\">\tstartlockedm(gp)</span><br><span class=\"line\">\tgoto top</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">execute(gp, inheritTime)</span><br></pre></td></tr></table></figure>\n\n<p>最后针对绑定的g进行特殊处理。否则就执行<code>execute</code>方法</p>\n<blockquote>\n<p>会从哪些地方去获取g？优先级是什么？</p>\n</blockquote>\n<h4 id=\"Execute函数\"><a href=\"#Execute函数\" class=\"headerlink\" title=\"Execute函数\"></a>Execute函数</h4><p>该函数主要功能切换当前上下文至指定的g中，具体源码如下，没有特别的逻辑，都是将g属性初始化一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func execute(gp *g, inheritTime bool) &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\t_g_.m.curg &#x3D; gp</span><br><span class=\"line\">\tgp.m &#x3D; _g_.m</span><br><span class=\"line\">\tcasgstatus(gp, _Grunnable, _Grunning)</span><br><span class=\"line\">\tgp.waitsince &#x3D; 0</span><br><span class=\"line\">\tgp.preempt &#x3D; false</span><br><span class=\"line\">\tgp.stackguard0 &#x3D; gp.stack.lo + _StackGuard</span><br><span class=\"line\">\tif !inheritTime &#123;</span><br><span class=\"line\">\t\t_g_.m.p.ptr().schedtick++</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tgogo(&amp;gp.sched)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>而<code>gogo</code>方法是真正在汇编层切换寄存器的逻辑，传入的sched就是这个g的上下文信息，包含4个寄存器信息，代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime·gogo(SB), NOSPLIT, $16-8</span><br><span class=\"line\">\tMOVQ\tbuf+0(FP), BX\t\t&#x2F;&#x2F; gobuf</span><br><span class=\"line\">\tMOVQ\tgobuf_g(BX), DX</span><br><span class=\"line\">\tMOVQ\t0(DX), CX\t\t&#x2F;&#x2F; make sure g !&#x3D; nil</span><br><span class=\"line\">\tget_tls(CX)</span><br><span class=\"line\">\tMOVQ\tDX, g(CX)\t\t&#x2F;&#x2F; 保存g至tls中</span><br><span class=\"line\">\t&#x2F;&#x2F; 恢复sp，ax，dx，bp寄存器</span><br><span class=\"line\">\tMOVQ\tgobuf_sp(BX), SP\t&#x2F;&#x2F; restore SP</span><br><span class=\"line\">\tMOVQ\tgobuf_ret(BX), AX</span><br><span class=\"line\">\tMOVQ\tgobuf_ctxt(BX), DX</span><br><span class=\"line\">\tMOVQ\tgobuf_bp(BX), BP</span><br><span class=\"line\">\t&#x2F;&#x2F; 清空gobuf</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_sp(BX)\t&#x2F;&#x2F; clear to help garbage collector</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_ret(BX)</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_ctxt(BX)</span><br><span class=\"line\">\tMOVQ\t$0, gobuf_bp(BX)</span><br><span class=\"line\">\tMOVQ\tgobuf_pc(BX), BX</span><br><span class=\"line\">\tJMP\tBX</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Goexit函数\"><a href=\"#Goexit函数\" class=\"headerlink\" title=\"Goexit函数\"></a>Goexit函数</h4><p>goexit方法是当当前线程执行完毕后执行的析构方法，设置的方法为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func gostartcallfn(gobuf *gobuf, fv *funcval) &#123;</span><br><span class=\"line\">    var fn unsafe.Pointer</span><br><span class=\"line\">    if fv !&#x3D; nil &#123;</span><br><span class=\"line\">        fn &#x3D; unsafe.Pointer(fv.fn)</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        fn &#x3D; unsafe.Pointer(funcPC(nilfunc))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    gostartcall(gobuf, fn, unsafe.Pointer(fv))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; adjust Gobuf as if it executed a call to fn with context ctxt</span><br><span class=\"line\">&#x2F;&#x2F; and then did an immediate gosave.</span><br><span class=\"line\">func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) &#123;</span><br><span class=\"line\">    sp :&#x3D; buf.sp</span><br><span class=\"line\">    if sys.RegSize &gt; sys.PtrSize &#123;</span><br><span class=\"line\">        sp -&#x3D; sys.PtrSize</span><br><span class=\"line\">        *(*uintptr)(unsafe.Pointer(sp)) &#x3D; 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    sp -&#x3D; sys.PtrSize</span><br><span class=\"line\">    *(*uintptr)(unsafe.Pointer(sp)) &#x3D; buf.pc &#x2F;&#x2F; 注意这里，这个，这里的 buf.pc 实际上是 goexit 的 pc</span><br><span class=\"line\">    buf.sp &#x3D; sp</span><br><span class=\"line\">    buf.pc &#x3D; uintptr(fn)</span><br><span class=\"line\">    buf.ctxt &#x3D; ctxt</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在 gostartcall 中把 newproc1 时设置到 buf.pc 中的 goexit 的函数地址放到了 goroutine 的栈顶，然后重新设置 buf.pc 为 goroutine 函数的位置。这样做的目的是为了在执行完任何 goroutine 的函数时，通过 RET 指令，都能从栈顶把 sp 保存的 goexit 的指令 pop 到 pc 寄存器，效果相当于任何 goroutine 执行函数执行完之后，都会去执行 runtime.goexit，完成一些清理工作后再进入 schedule。</p>\n<p>当前流程只剩下<code>goexit-&gt;goexit1-&gt;goexit0</code>，代码还算可读，直接上代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TEXT runtime·goexit(SB),NOSPLIT,$0-0</span><br><span class=\"line\">\tBYTE\t$0x90\t&#x2F;&#x2F; NOP</span><br><span class=\"line\">\tCALL\truntime·goexit1(SB)\t&#x2F;&#x2F; does not return</span><br><span class=\"line\">\t&#x2F;&#x2F; traceback from goexit1 must hit code range of goexit</span><br><span class=\"line\">\tBYTE\t$0x90\t&#x2F;&#x2F; NOP</span><br><span class=\"line\"></span><br><span class=\"line\">\t... ... </span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Finishes execution of the current goroutine.</span><br><span class=\"line\">func goexit1() &#123;</span><br><span class=\"line\">\tif raceenabled &#123;</span><br><span class=\"line\">\t\tracegoend()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif trace.enabled &#123;</span><br><span class=\"line\">\t\ttraceGoEnd()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tmcall(goexit0)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在代码来看，goexit和goexit1目标只是切换到g0协程中并执行<code>goexit0</code>中，第一部分，大部分都是变量清空，并清空当前的g状态置为_Gdead。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func goexit0(gp *g) &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tcasgstatus(gp, _Grunning, _Gdead)</span><br><span class=\"line\">\tif isSystemGoroutine(gp, false) &#123;</span><br><span class=\"line\">\t\tatomic.Xadd(&amp;sched.ngsys, -1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgp.m &#x3D; nil</span><br><span class=\"line\">\tlocked :&#x3D; gp.lockedm !&#x3D; 0</span><br><span class=\"line\">\tgp.lockedm &#x3D; 0</span><br><span class=\"line\">\t_g_.m.lockedg &#x3D; 0</span><br><span class=\"line\">\tgp.preemptStop &#x3D; false</span><br><span class=\"line\">\tgp.paniconfault &#x3D; false</span><br><span class=\"line\">\tgp._defer &#x3D; nil &#x2F;&#x2F; should be true already but just in case.</span><br><span class=\"line\">\tgp._panic &#x3D; nil &#x2F;&#x2F; non-nil for Goexit during panic. points at stack-allocated data.</span><br><span class=\"line\">\tgp.writebuf &#x3D; nil</span><br><span class=\"line\">\tgp.waitreason &#x3D; 0</span><br><span class=\"line\">\tgp.param &#x3D; nil</span><br><span class=\"line\">\tgp.labels &#x3D; nil</span><br><span class=\"line\">\tgp.timer &#x3D; nil</span><br><span class=\"line\">\tif gcBlackenEnabled !&#x3D; 0 &amp;&amp; gp.gcAssistBytes &gt; 0 &#123;</span><br><span class=\"line\">\t\tscanCredit :&#x3D; int64(gcController.assistWorkPerByte * float64(gp.gcAssistBytes))</span><br><span class=\"line\">\t\tatomic.Xaddint64(&amp;gcController.bgScanCredit, scanCredit)</span><br><span class=\"line\">\t\tgp.gcAssistBytes &#x3D; 0</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdropg()</span><br></pre></td></tr></table></figure>\n\n<p>清空完自身的g后，主要就剩下清理其他的信息，例如：写入g的队列中，清空m，进入调度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func goexit0(gp *g) &#123;</span><br><span class=\"line\">\t... ...</span><br><span class=\"line\">\tgfput(_g_.m.p.ptr(), gp)</span><br><span class=\"line\">\tif locked &#123;</span><br><span class=\"line\">\t\tif GOOS !&#x3D; &quot;plan9&quot; &#123; &#x2F;&#x2F; See golang.org&#x2F;issue&#x2F;22227.</span><br><span class=\"line\">\t\t\tgogo(&amp;_g_.m.g0.sched)</span><br><span class=\"line\">\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\t_g_.m.lockedExt &#x3D; 0</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tschedule()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"待办事项\"><a href=\"#待办事项\" class=\"headerlink\" title=\"待办事项\"></a>待办事项</h2><ul>\n<li>定时执行逻辑</li>\n<li>锁定线程逻辑</li>\n<li>tryWakeP逻辑</li>\n<li>findrunnable逻辑</li>\n<li>mcall、notesleep逻辑</li>\n<li>inheritTime功能</li>\n</ul>\n"},{"title":"关于混沌工程的理解","_content":"\n## 前言\n\n混沌工程一直在我心中是一个模糊的概念，摘要百度百科的解释：通过一系列可控的实验和执行实验的原则，混沌工程将揭 示出分布式系统中随时发生的各类事件是如何逐步导致系统整体不可用的。\n\n在滴滴内部对应的便是放火系统，其中便有了如何放火、防火、监控等各类方法，以在执行混沌操作时，对线上业务影响最少。\n\n## 概要\n\n混沌工程是一个主动发现系统中脆弱点的整套方法论，所谓方法论，就是关于人们认识世界、改造世界的方法的理论。其目标是提高系统对不确定事件的抵御能力。\n\n但这并非易事，首先所有系统都是足够复杂，这就会导致工程未来演练故障时也需要足够复杂，而在本来复杂的系统中进行改动，这本书就是一个风险极高的事情。\n\n## 背景\n\n时代背景的主要原因是系统架构在逐步演进，从服务集群到分布式系统，开始微服务化、容器化、上云。服务之间开始逐步隔离，而用户需求变更的更加频繁，复杂化、多样性、快速化，促使了版本迭代不断增速：CICD、敏捷开发、devops、ABtest。\n\n所有的变更最终肯定会反映在系统复杂度上的增加，频繁的变更最大的挑战便是稳定性，如何使系统在频繁变更的过程中，继续保持自身的扩展性、稳定性、弹性能力、容错灾备能力，便是当今各公司需要解决的问题。\n\n混沌工程中，最好的手段，便是演练，通过故障注入的方式模拟线上异常，提前预警，避免大规模事故的发现。\n\n## 实施\n\n### 因素\n\n既然是复杂系统的稳定性工具，那还是需要考虑用户在使用稳定性工具时的感受，保证工具拥有可靠性、安全性、可扩展性、可定制化、可伸缩性、可维护性、用户体验等。\n\n### 维度\n\n用故障注入作为手段来实施工程，那我们就需要从系统稳定性开始考虑如何保证影响可控的情况下如何正常开展演练。\n\n1）建立稳定状态的假设（清晰可衡量的指标）\n\n2）用多样的生产事件做验证（多样性降低误差）\n\n3）在生产环境做验证（真实场景）\n\n4）自动化开展实验（持续运行）\n\n5）控制最小化爆炸半径（影响范围）\n\n而，做到这么几点才能保证混沌工程能够正常的推广下去。\n\n### 经验\n\n混沌工程的考虑维度我们已经列出来了。但是如何推广工程又是另外一套方法论，因为如何把事做好本身就是很难的事情。\n\n所以，在做事之前，考虑好影响，提前建立预期，对于混沌工程而言，总会不断的和故障打交道，于是就需要建立面向失败设计和拥抱失败的技术文化，让大家能够接受失败。同时先从简单的场景开始尝试，逐渐增加组织对系统的信心\n\n其实，工程需要一个实施目标，评估整体工程推进的情况，\n\n在前期：需要对历史故障的复现率以及解决率，确保故障改进的有效性；**中期**：提高监控发现率，验证故障发现能力的全面性和监控的完备程度；**后期**：故障的“发现-定位-恢复”市场这种综合性指标；\n\n最终希望是能达到在控制风险的前提下不断提升混沌工程效率https://zhuanlan.zhihu.com/p/354401594)","source":"_posts/chaos_engineering.md","raw":"---\ntitle: 关于混沌工程的理解\n---\n\n## 前言\n\n混沌工程一直在我心中是一个模糊的概念，摘要百度百科的解释：通过一系列可控的实验和执行实验的原则，混沌工程将揭 示出分布式系统中随时发生的各类事件是如何逐步导致系统整体不可用的。\n\n在滴滴内部对应的便是放火系统，其中便有了如何放火、防火、监控等各类方法，以在执行混沌操作时，对线上业务影响最少。\n\n## 概要\n\n混沌工程是一个主动发现系统中脆弱点的整套方法论，所谓方法论，就是关于人们认识世界、改造世界的方法的理论。其目标是提高系统对不确定事件的抵御能力。\n\n但这并非易事，首先所有系统都是足够复杂，这就会导致工程未来演练故障时也需要足够复杂，而在本来复杂的系统中进行改动，这本书就是一个风险极高的事情。\n\n## 背景\n\n时代背景的主要原因是系统架构在逐步演进，从服务集群到分布式系统，开始微服务化、容器化、上云。服务之间开始逐步隔离，而用户需求变更的更加频繁，复杂化、多样性、快速化，促使了版本迭代不断增速：CICD、敏捷开发、devops、ABtest。\n\n所有的变更最终肯定会反映在系统复杂度上的增加，频繁的变更最大的挑战便是稳定性，如何使系统在频繁变更的过程中，继续保持自身的扩展性、稳定性、弹性能力、容错灾备能力，便是当今各公司需要解决的问题。\n\n混沌工程中，最好的手段，便是演练，通过故障注入的方式模拟线上异常，提前预警，避免大规模事故的发现。\n\n## 实施\n\n### 因素\n\n既然是复杂系统的稳定性工具，那还是需要考虑用户在使用稳定性工具时的感受，保证工具拥有可靠性、安全性、可扩展性、可定制化、可伸缩性、可维护性、用户体验等。\n\n### 维度\n\n用故障注入作为手段来实施工程，那我们就需要从系统稳定性开始考虑如何保证影响可控的情况下如何正常开展演练。\n\n1）建立稳定状态的假设（清晰可衡量的指标）\n\n2）用多样的生产事件做验证（多样性降低误差）\n\n3）在生产环境做验证（真实场景）\n\n4）自动化开展实验（持续运行）\n\n5）控制最小化爆炸半径（影响范围）\n\n而，做到这么几点才能保证混沌工程能够正常的推广下去。\n\n### 经验\n\n混沌工程的考虑维度我们已经列出来了。但是如何推广工程又是另外一套方法论，因为如何把事做好本身就是很难的事情。\n\n所以，在做事之前，考虑好影响，提前建立预期，对于混沌工程而言，总会不断的和故障打交道，于是就需要建立面向失败设计和拥抱失败的技术文化，让大家能够接受失败。同时先从简单的场景开始尝试，逐渐增加组织对系统的信心\n\n其实，工程需要一个实施目标，评估整体工程推进的情况，\n\n在前期：需要对历史故障的复现率以及解决率，确保故障改进的有效性；**中期**：提高监控发现率，验证故障发现能力的全面性和监控的完备程度；**后期**：故障的“发现-定位-恢复”市场这种综合性指标；\n\n最终希望是能达到在控制风险的前提下不断提升混沌工程效率https://zhuanlan.zhihu.com/p/354401594)","slug":"chaos_engineering","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.305Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg57n0001mauy1uku1eki","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>混沌工程一直在我心中是一个模糊的概念，摘要百度百科的解释：通过一系列可控的实验和执行实验的原则，混沌工程将揭 示出分布式系统中随时发生的各类事件是如何逐步导致系统整体不可用的。</p>\n<p>在滴滴内部对应的便是放火系统，其中便有了如何放火、防火、监控等各类方法，以在执行混沌操作时，对线上业务影响最少。</p>\n<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><p>混沌工程是一个主动发现系统中脆弱点的整套方法论，所谓方法论，就是关于人们认识世界、改造世界的方法的理论。其目标是提高系统对不确定事件的抵御能力。</p>\n<p>但这并非易事，首先所有系统都是足够复杂，这就会导致工程未来演练故障时也需要足够复杂，而在本来复杂的系统中进行改动，这本书就是一个风险极高的事情。</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>时代背景的主要原因是系统架构在逐步演进，从服务集群到分布式系统，开始微服务化、容器化、上云。服务之间开始逐步隔离，而用户需求变更的更加频繁，复杂化、多样性、快速化，促使了版本迭代不断增速：CICD、敏捷开发、devops、ABtest。</p>\n<p>所有的变更最终肯定会反映在系统复杂度上的增加，频繁的变更最大的挑战便是稳定性，如何使系统在频繁变更的过程中，继续保持自身的扩展性、稳定性、弹性能力、容错灾备能力，便是当今各公司需要解决的问题。</p>\n<p>混沌工程中，最好的手段，便是演练，通过故障注入的方式模拟线上异常，提前预警，避免大规模事故的发现。</p>\n<h2 id=\"实施\"><a href=\"#实施\" class=\"headerlink\" title=\"实施\"></a>实施</h2><h3 id=\"因素\"><a href=\"#因素\" class=\"headerlink\" title=\"因素\"></a>因素</h3><p>既然是复杂系统的稳定性工具，那还是需要考虑用户在使用稳定性工具时的感受，保证工具拥有可靠性、安全性、可扩展性、可定制化、可伸缩性、可维护性、用户体验等。</p>\n<h3 id=\"维度\"><a href=\"#维度\" class=\"headerlink\" title=\"维度\"></a>维度</h3><p>用故障注入作为手段来实施工程，那我们就需要从系统稳定性开始考虑如何保证影响可控的情况下如何正常开展演练。</p>\n<p>1）建立稳定状态的假设（清晰可衡量的指标）</p>\n<p>2）用多样的生产事件做验证（多样性降低误差）</p>\n<p>3）在生产环境做验证（真实场景）</p>\n<p>4）自动化开展实验（持续运行）</p>\n<p>5）控制最小化爆炸半径（影响范围）</p>\n<p>而，做到这么几点才能保证混沌工程能够正常的推广下去。</p>\n<h3 id=\"经验\"><a href=\"#经验\" class=\"headerlink\" title=\"经验\"></a>经验</h3><p>混沌工程的考虑维度我们已经列出来了。但是如何推广工程又是另外一套方法论，因为如何把事做好本身就是很难的事情。</p>\n<p>所以，在做事之前，考虑好影响，提前建立预期，对于混沌工程而言，总会不断的和故障打交道，于是就需要建立面向失败设计和拥抱失败的技术文化，让大家能够接受失败。同时先从简单的场景开始尝试，逐渐增加组织对系统的信心</p>\n<p>其实，工程需要一个实施目标，评估整体工程推进的情况，</p>\n<p>在前期：需要对历史故障的复现率以及解决率，确保故障改进的有效性；<strong>中期</strong>：提高监控发现率，验证故障发现能力的全面性和监控的完备程度；<strong>后期</strong>：故障的“发现-定位-恢复”市场这种综合性指标；</p>\n<p>最终希望是能达到在控制风险的前提下不断提升混沌工程效率<a href=\"https://zhuanlan.zhihu.com/p/354401594\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/354401594</a>)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>混沌工程一直在我心中是一个模糊的概念，摘要百度百科的解释：通过一系列可控的实验和执行实验的原则，混沌工程将揭 示出分布式系统中随时发生的各类事件是如何逐步导致系统整体不可用的。</p>\n<p>在滴滴内部对应的便是放火系统，其中便有了如何放火、防火、监控等各类方法，以在执行混沌操作时，对线上业务影响最少。</p>\n<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><p>混沌工程是一个主动发现系统中脆弱点的整套方法论，所谓方法论，就是关于人们认识世界、改造世界的方法的理论。其目标是提高系统对不确定事件的抵御能力。</p>\n<p>但这并非易事，首先所有系统都是足够复杂，这就会导致工程未来演练故障时也需要足够复杂，而在本来复杂的系统中进行改动，这本书就是一个风险极高的事情。</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>时代背景的主要原因是系统架构在逐步演进，从服务集群到分布式系统，开始微服务化、容器化、上云。服务之间开始逐步隔离，而用户需求变更的更加频繁，复杂化、多样性、快速化，促使了版本迭代不断增速：CICD、敏捷开发、devops、ABtest。</p>\n<p>所有的变更最终肯定会反映在系统复杂度上的增加，频繁的变更最大的挑战便是稳定性，如何使系统在频繁变更的过程中，继续保持自身的扩展性、稳定性、弹性能力、容错灾备能力，便是当今各公司需要解决的问题。</p>\n<p>混沌工程中，最好的手段，便是演练，通过故障注入的方式模拟线上异常，提前预警，避免大规模事故的发现。</p>\n<h2 id=\"实施\"><a href=\"#实施\" class=\"headerlink\" title=\"实施\"></a>实施</h2><h3 id=\"因素\"><a href=\"#因素\" class=\"headerlink\" title=\"因素\"></a>因素</h3><p>既然是复杂系统的稳定性工具，那还是需要考虑用户在使用稳定性工具时的感受，保证工具拥有可靠性、安全性、可扩展性、可定制化、可伸缩性、可维护性、用户体验等。</p>\n<h3 id=\"维度\"><a href=\"#维度\" class=\"headerlink\" title=\"维度\"></a>维度</h3><p>用故障注入作为手段来实施工程，那我们就需要从系统稳定性开始考虑如何保证影响可控的情况下如何正常开展演练。</p>\n<p>1）建立稳定状态的假设（清晰可衡量的指标）</p>\n<p>2）用多样的生产事件做验证（多样性降低误差）</p>\n<p>3）在生产环境做验证（真实场景）</p>\n<p>4）自动化开展实验（持续运行）</p>\n<p>5）控制最小化爆炸半径（影响范围）</p>\n<p>而，做到这么几点才能保证混沌工程能够正常的推广下去。</p>\n<h3 id=\"经验\"><a href=\"#经验\" class=\"headerlink\" title=\"经验\"></a>经验</h3><p>混沌工程的考虑维度我们已经列出来了。但是如何推广工程又是另外一套方法论，因为如何把事做好本身就是很难的事情。</p>\n<p>所以，在做事之前，考虑好影响，提前建立预期，对于混沌工程而言，总会不断的和故障打交道，于是就需要建立面向失败设计和拥抱失败的技术文化，让大家能够接受失败。同时先从简单的场景开始尝试，逐渐增加组织对系统的信心</p>\n<p>其实，工程需要一个实施目标，评估整体工程推进的情况，</p>\n<p>在前期：需要对历史故障的复现率以及解决率，确保故障改进的有效性；<strong>中期</strong>：提高监控发现率，验证故障发现能力的全面性和监控的完备程度；<strong>后期</strong>：故障的“发现-定位-恢复”市场这种综合性指标；</p>\n<p>最终希望是能达到在控制风险的前提下不断提升混沌工程效率<a href=\"https://zhuanlan.zhihu.com/p/354401594\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/354401594</a>)</p>\n"},{"title":"Golang-GMP模型","date":"2020-07-19T10:04:28.000Z","_content":"\n## 前言\n\n\n## GMP模型\n\n### 关于线程和协程\n\n在计算机操作系统中,轻量级进程（LWP）是一种实现多任务的方法。与普通进程相比，LWP与其他进程共享所有（或大部分）它的逻辑地址空间和系统资源；与线程相比，LWP有它自己的进程标识符，优先级，状态，以及栈和局部存储区，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。另外，线程既可由应用程序管理，又可由内核管理，而LWP只能由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。\n\n![img](1767848-9c4b06362907280d.webp)\n\n### Golang中的模型\n\n有2个支持高并发的模型：CSP和Actor（erlang）。Go选择了CSP，Go为了提供更容易的并发使用方法，提供了2个重要的概念`goroutine`和`channel`。\n\n**goroutine**来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被`runtime`调度，转移到其他可运行的线程上。\n\n![img](3184f3.jpg)\n\n其实**老调度器**有4个缺点：详见[Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!)\n\n1. 创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争\n2. M转移G会造成延迟和额外的系统开销。\n3. M中的mcache是用来存放小对象的，mcache和栈都和M关联造成了大量的内存开销和差的局部性\n4. 系统调用导致频繁的线程阻塞和取消阻塞操作增加了系统开销。\n\n所以Go语言在2012年重新设计了调度器方案（[Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!)，[设计方案](https://golang.org/s/go11sched)）。\n\n![img](567399-d400f4b192f3dc48.webp)\n\n## 关于GMP模型\n\n### 关于Machine\n \nmachine代表一个线程，每次创建一个M的时候，都会有一个底层线程创建；所有的G任务，最终还是在M上执行。\n\nmachine的字段多达几十个，但将其进行粗劣的分类是可以明确m的具体职责：\n\n1. 特殊g的管理：g0、gsignal、curg\n2. p的管理：p、nextp、oldp\n3. 状态管理：locks、preemptoff、mallocing、throwing、dying、incgo、signalPending、blocked\n4. 锁的管理：lockedg、lockedExt、lockedInt、nextwaitm、waitlock\n5. cgo运行相关：ncgocall、ncgo、cgoCallersUse、cgoCallers\n\n从字段中可以看出，在m层，主要方向有几个关键词：锁、抢占、cgo、g与p的管理、信号。主要原因还是由于m是一个贴近操作系统的结构体，而操作系统的调度的核心问题也是锁、信号，阻塞等。\n\n> 如何解决m和m的绑定问题？\n\n#### 创建Machine\n\n创建m的时机有3类：sysmon抢占线程、templateThread模板线程、运行p。前2者是特殊的线程，不会进入调度系统中。创建m的方法是直接调用`runtime.newm`方法：\n```\nfunc newm(fn func(), _p_ *p) {\n\t// 分配一个m对象\n\tmp := allocm(_p_, fn)\n\t// 设置下一个执行的p\n\tmp.nextp.set(_p_)\n\t// 初始化系统信号拦截\n\tmp.sigmask = initSigmask\n    ... ...\n\tnewm1(mp)\n}\n```\n可以看出在m的创建流程中，具体分为2步：结构体的创建、线程的创建。在`allocm`方法中，核心是需要申请一个m的对象以及相关的g0空间，而针对不同的操作系统，g0的内存空间又区分为是使用系统分配，还是go指定。\n```\nfunc allocm(_p_ *p, fn func()) *m {\n\n    ... ...\n\tmp := new(m)\n\tmp.mstartfn = fn\n\tmcommoninit(mp)\n\n\tif iscgo || GOOS == \"solaris\" || GOOS == \"illumos\" || GOOS == \"windows\" || GOOS == \"plan9\" || GOOS == \"darwin\" {\n\t\tmp.g0 = malg(-1)\n\t} else {\n\t\tmp.g0 = malg(8192 * sys.StackGuardMultiplier)\n\t}\n\tmp.g0.m = mp\n\n\treturn mp\n}\n```\n而在`runtime.newm1`方法中，主要是直接调用`runtime.newosproc`方法，正如其名，就是用于创建一个系统的线程。\n```\nfunc newm1(mp *m) {\n    ... ...\n\tnewosproc(mp)\n    ... ...\n}\n\nfunc newosproc(mp *m) {\n\tstk := unsafe.Pointer(mp.g0.stack.hi)\n    ... ...\n\tvar oset sigset\n\tsigprocmask(_SIG_SETMASK, &sigset_all, &oset)\n\tret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))\n\tsigprocmask(_SIG_SETMASK, &oset, nil)\n    ... ...\n}\n```\n\n### 关于Processor\n\n每一个运行的M都必须绑定一个P，就像线程必须在么一个CPU核上执行一样，由P来调度G在M上的运行，P的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改；\n\nprocessor的字段可以分为以下几类：\n\n1. 内存管理相关：mcache、pcache、mspancache、palloc\n2. 调度计数相关：schedtick、syscalltick、sysmontick\n3. cache相关：deferpool、deferpoolbuf、gFree、sudogcache、sudogbuf\n4. g调度相关：runqhead、runqtail、runq、runnext\n5. 定时器相关：timer0When、timersLock、timers、numTimers、adjustTimers、deletedTimers、\n6. gc相关：gcAssistTime、gcFractionalMarkTime、gcBgMarkWorker、gcMarkWorkerMode、gcMarkWorkerStartTime、gcw、wbBuf、runSafePointFn\n\n这几大方面主要是由于p本身的定位是执行器有关，当执行用户代码时，需要在效率和性能方面做到兼容，\n\np的创建流程代码并不难懂，方法由procresize来执行，也就是平时大家设置GOMAXPROCS计数，其中涉及到扩容和缩容操作。\n\n### 关于Goroutine\n\ngorountine也就是平时的协程，每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息\n\ngorountine的字段可以分为以下几类：\n\n1. 上下文信息：startpc、gopc、sigpc、sched、syscallsp、syscallpc、stktopsp、param\n2. 抢占相关：preempt、preemptStop、preemptShrink\n3. 栈相关：stack、stackguard0、stackguard1\n4. defer相关：\\_panic、\\_defer\n5. 锁相关：waiting、timer、selectDone、\n6. 信号相关：sigcode0、sigcode1、sigpc\n\n当然，gorountine不仅仅是上述的字段，还有大量的pprof的计数字段，本次暂时不做讨论。\n\n可以看出，g和m的字段中，都有信号、锁、抢占相关的字段，但是，为什么m中却没有栈信息，难道不需要栈信息？这就是g0协程的重要性，golang中为了做权限隔离，避免用户代码影响runtime的运行，专门抽象了g0协程执行。既然无法向操作系统中通过中断实现内核态切换，就考虑使用特殊协程，这样相关上下文切换逻辑是完全复用，所以，g0是一个只做权限隔离的协程，同时所有m都拥有一个g0。\n\n#### 创建Gorountine\n\n创建gorountine就是平时大家使用的`go func()`关键字。在编译阶段，关键字会变编译为`runtime.newproc`方法，同时会传入参数大小和函数指针fn。然后从堆栈中获取参数并调用`runtime.newproc1`方法。\n```\nfunc newproc(siz int32, fn *funcval) {\n\targp := add(unsafe.Pointer(&fn), sys.PtrSize)\n\tgp := getg()\n\tpc := getcallerpc()\n\tsystemstack(func() {\n\t\tnewproc1(fn, argp, siz, gp, pc)\n\t})\n}\n```\n在`runtime.newproc1`方法中具体可以分为3块逻辑：\n1. gorountine结构体创建\n2. gorountine对象的初始化\n3. 插入调度对象并唤醒p\n\n创建完的gorountine结构体最终会插入p中的runq链表中。\n\n## 调度实现\n\n从m的创建流程中，可以看到`newosproc`方法是第四个参数，也就是系统线程的入口函数。线程创建完成后，操作系统会根据系统调度算法运行线程，`runtime.mstart`也就是线程的初始化方法。\n\n### 线程初始化\n\n`runtime.mstart`方法中，优先将栈的检查地址更新，这是因为如果是操作系统自动生成的堆栈，线程运行前是无法确定的。之后会调用`runtime.mstart1`方法执行进一步的初始化方法。最后，针对特殊的线程（被lockg的线程），会执行`runtime.mexit`方法。\n```\nfunc mstart() {\n\t_g_ := getg()\n\n\tosStack := _g_.stack.lo == 0\n\tif osStack {\n\t\tsize := _g_.stack.hi\n\t\tif size == 0 {\n\t\t\tsize = 8192 * sys.StackGuardMultiplier\n\t\t}\n\t\t_g_.stack.hi = uintptr(noescape(unsafe.Pointer(&size)))\n\t\t_g_.stack.lo = _g_.stack.hi - size + 1024\n\t}\n\t_g_.stackguard0 = _g_.stack.lo + _StackGuard\n\t_g_.stackguard1 = _g_.stackguard0\n\tmstart1()\n\n\tmexit(osStack)\n}\n```\n继续看`runtime.mstart1`方法，也还是一系列的初始化方法：\n1. 保存调用寄存器信息，主要用于当用户g切换至g0时，需要恢复的上下文\n2. 初始化信号处理方法，因为每个线程都需要自己的信号处理g\n3. 执行mstartfn方法，这个方法是针对sysmon这类的特殊线程实现的功能，使当前线程不进入调度循环中。\n\n执行完上述的初始化操作后，当前线程就将`nextp`字段转正进行绑定，并进入`runtime.schedule`方法中调度。\n\n### 线程循环\n\n在调用循环中，存在3个因素影响调度：当前是否需要stw、当前是否获取到g、当前m是否被g绑定。三者中获取g是调度循环的主流程，其他2者也是golang的特殊功能。所以先抽离出获取g的整体流程。\n\n#### 获取Gorountine\n\n在获取gorountine流程中，可以分为3部分：\n1. 若当前p不存在g，或者调度计数满足61次，则从全局中获取g运行\n2. 产生从p本地队列中获取g\n3. 本地和全局都获取不到时，则在`findrunable`方法中阻塞获取g\n\n```\nfunc schedule() {\n    ... ... \ntop:\n\tif gp == nil {\n\t\tif _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {\n\t\t\tlock(&sched.lock)\n\t\t\tgp = globrunqget(_g_.m.p.ptr(), 1)\n\t\t\tunlock(&sched.lock)\n\t\t}\n\t}\n\tif gp == nil {\n\t\tgp, inheritTime = runqget(_g_.m.p.ptr())\n\t\t// We can see gp != nil here even if the M is spinning,\n\t\t// if checkTimers added a local goroutine via goready.\n\t}\n\t// 如果实在没找到，那就强行找一个可用的\n\tif gp == nil {\n\t\tgp, inheritTime = findrunnable() // blocks until work is available\n\t}\n    execute(gp, inheritTime)\n}\n```\n\n##### globrunqget方法\n在从全局队列中获取g时，会从全局队列中获取g，并同时迁移`1/len(allp)`个数的g到本地队列中。\n```\nfunc globrunqget(_p_ *p, max int32) *g {\n\tn := sched.runqsize/gomaxprocs + 1\n\tif n > int32(len(_p_.runq))/2 {\n\t\tn = int32(len(_p_.runq)) / 2\n\t}\n\n\tsched.runqsize -= n\n\n\tgp := sched.runq.pop()\n\tn--\n\tfor ; n > 0; n-- {\n\t\tgp1 := sched.runq.pop()\n\t\trunqput(_p_, gp1, false)\n\t}\n\treturn gp\n}\n```\n\n##### runqget方法\n而在获取本地队列g的时候，优先会尝试获取`runnext`字段的g，在从`runq`中获取头部的g对象。当然由于`runq`是通过循环队列实现，所以gp是通过下标取余获取。\n```\nfunc runqget(_p_ *p) (gp *g, inheritTime bool) {\n\tfor {\n\t\tnext := _p_.runnext\n\t\tif next == 0 {\n\t\t\tbreak\n\t\t}\n\t\tif _p_.runnext.cas(next, 0) {\n\t\t\treturn next.ptr(), true\n\t\t}\n\t}\n\n\tfor {\n\t\th := atomic.LoadAcq(&_p_.runqhead) // load-acquire, synchronize with other consumers\n\t\tt := _p_.runqtail\n\t\tif t == h {\n\t\t\treturn nil, false\n\t\t}\n\t\tgp := _p_.runq[h%uint32(len(_p_.runq))].ptr()\n\t\tif atomic.CasRel(&_p_.runqhead, h, h+1) { // cas-release, commits consume\n\t\t\treturn gp, false\n\t\t}\n\t}\n}\n```\n##### findrunnable方法\n\n由于前2个方法实在获取不到可运行的g，所以在`findrunnable`方法中会不断的在各个可能存在可运行g的地方查询。具体的查询流程如下：\n1. 检查finalizer是否存在析构对象\n2. 检查本地对象是否存在可用g\n3. 查询全局队列是否存在可用g\n4. 非阻塞检查netpoll\n5. 如果大家都空闲中，或者自旋的m超过了忙碌的p，则进入强制查询阶段\n6. 再不济，随机4次去其他的p中窃取g\n\n上述流程实在找不到，m就不在持有p，然后开始特殊判断阶段。m开始循环判断是否存在可运行的g。判断区域还是从全局队列中、所有p的本地队列中以及netpoll三个方面。最终如果实在获取不到，则休眠当前m，等待有可用的p来唤醒。\n\n\n#### 执行Gorountine\n\n获取到可执行的g之后，就需要调用`runtime.execute`方法，主要针对g做一些变量赋值：\n```\n\tcasgstatus(gp, _Grunnable, _Grunning)\n\tgp.waitsince = 0\n\tgp.preempt = false\n\tgp.stackguard0 = gp.stack.lo + _StackGuard\n\tif !inheritTime {\n\t\t_g_.m.p.ptr().schedtick++\n\t}\n\t_g_.m.curg = gp\n\tgp.m = _g_.m\n```\n赋值完后，会调用`runtime.gogo`方法进行协程的上下文切换，将原有的g0协程，切换至gp协程。\n\n## 调度工具\n\n- trace\n- pprof\n\n## 相关主题\n- lock ranking\n\n\n## 相关链接\nhttps://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html\nhttps://www.linuxjournal.com/article/3184\n\n","source":"_posts/golang-gmp.md","raw":"---\ntitle: Golang-GMP模型\ndate: 2020-07-19 18:04:28\ntags:\n---\n\n## 前言\n\n\n## GMP模型\n\n### 关于线程和协程\n\n在计算机操作系统中,轻量级进程（LWP）是一种实现多任务的方法。与普通进程相比，LWP与其他进程共享所有（或大部分）它的逻辑地址空间和系统资源；与线程相比，LWP有它自己的进程标识符，优先级，状态，以及栈和局部存储区，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。另外，线程既可由应用程序管理，又可由内核管理，而LWP只能由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。\n\n![img](1767848-9c4b06362907280d.webp)\n\n### Golang中的模型\n\n有2个支持高并发的模型：CSP和Actor（erlang）。Go选择了CSP，Go为了提供更容易的并发使用方法，提供了2个重要的概念`goroutine`和`channel`。\n\n**goroutine**来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被`runtime`调度，转移到其他可运行的线程上。\n\n![img](3184f3.jpg)\n\n其实**老调度器**有4个缺点：详见[Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!)\n\n1. 创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争\n2. M转移G会造成延迟和额外的系统开销。\n3. M中的mcache是用来存放小对象的，mcache和栈都和M关联造成了大量的内存开销和差的局部性\n4. 系统调用导致频繁的线程阻塞和取消阻塞操作增加了系统开销。\n\n所以Go语言在2012年重新设计了调度器方案（[Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!)，[设计方案](https://golang.org/s/go11sched)）。\n\n![img](567399-d400f4b192f3dc48.webp)\n\n## 关于GMP模型\n\n### 关于Machine\n \nmachine代表一个线程，每次创建一个M的时候，都会有一个底层线程创建；所有的G任务，最终还是在M上执行。\n\nmachine的字段多达几十个，但将其进行粗劣的分类是可以明确m的具体职责：\n\n1. 特殊g的管理：g0、gsignal、curg\n2. p的管理：p、nextp、oldp\n3. 状态管理：locks、preemptoff、mallocing、throwing、dying、incgo、signalPending、blocked\n4. 锁的管理：lockedg、lockedExt、lockedInt、nextwaitm、waitlock\n5. cgo运行相关：ncgocall、ncgo、cgoCallersUse、cgoCallers\n\n从字段中可以看出，在m层，主要方向有几个关键词：锁、抢占、cgo、g与p的管理、信号。主要原因还是由于m是一个贴近操作系统的结构体，而操作系统的调度的核心问题也是锁、信号，阻塞等。\n\n> 如何解决m和m的绑定问题？\n\n#### 创建Machine\n\n创建m的时机有3类：sysmon抢占线程、templateThread模板线程、运行p。前2者是特殊的线程，不会进入调度系统中。创建m的方法是直接调用`runtime.newm`方法：\n```\nfunc newm(fn func(), _p_ *p) {\n\t// 分配一个m对象\n\tmp := allocm(_p_, fn)\n\t// 设置下一个执行的p\n\tmp.nextp.set(_p_)\n\t// 初始化系统信号拦截\n\tmp.sigmask = initSigmask\n    ... ...\n\tnewm1(mp)\n}\n```\n可以看出在m的创建流程中，具体分为2步：结构体的创建、线程的创建。在`allocm`方法中，核心是需要申请一个m的对象以及相关的g0空间，而针对不同的操作系统，g0的内存空间又区分为是使用系统分配，还是go指定。\n```\nfunc allocm(_p_ *p, fn func()) *m {\n\n    ... ...\n\tmp := new(m)\n\tmp.mstartfn = fn\n\tmcommoninit(mp)\n\n\tif iscgo || GOOS == \"solaris\" || GOOS == \"illumos\" || GOOS == \"windows\" || GOOS == \"plan9\" || GOOS == \"darwin\" {\n\t\tmp.g0 = malg(-1)\n\t} else {\n\t\tmp.g0 = malg(8192 * sys.StackGuardMultiplier)\n\t}\n\tmp.g0.m = mp\n\n\treturn mp\n}\n```\n而在`runtime.newm1`方法中，主要是直接调用`runtime.newosproc`方法，正如其名，就是用于创建一个系统的线程。\n```\nfunc newm1(mp *m) {\n    ... ...\n\tnewosproc(mp)\n    ... ...\n}\n\nfunc newosproc(mp *m) {\n\tstk := unsafe.Pointer(mp.g0.stack.hi)\n    ... ...\n\tvar oset sigset\n\tsigprocmask(_SIG_SETMASK, &sigset_all, &oset)\n\tret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))\n\tsigprocmask(_SIG_SETMASK, &oset, nil)\n    ... ...\n}\n```\n\n### 关于Processor\n\n每一个运行的M都必须绑定一个P，就像线程必须在么一个CPU核上执行一样，由P来调度G在M上的运行，P的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改；\n\nprocessor的字段可以分为以下几类：\n\n1. 内存管理相关：mcache、pcache、mspancache、palloc\n2. 调度计数相关：schedtick、syscalltick、sysmontick\n3. cache相关：deferpool、deferpoolbuf、gFree、sudogcache、sudogbuf\n4. g调度相关：runqhead、runqtail、runq、runnext\n5. 定时器相关：timer0When、timersLock、timers、numTimers、adjustTimers、deletedTimers、\n6. gc相关：gcAssistTime、gcFractionalMarkTime、gcBgMarkWorker、gcMarkWorkerMode、gcMarkWorkerStartTime、gcw、wbBuf、runSafePointFn\n\n这几大方面主要是由于p本身的定位是执行器有关，当执行用户代码时，需要在效率和性能方面做到兼容，\n\np的创建流程代码并不难懂，方法由procresize来执行，也就是平时大家设置GOMAXPROCS计数，其中涉及到扩容和缩容操作。\n\n### 关于Goroutine\n\ngorountine也就是平时的协程，每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息\n\ngorountine的字段可以分为以下几类：\n\n1. 上下文信息：startpc、gopc、sigpc、sched、syscallsp、syscallpc、stktopsp、param\n2. 抢占相关：preempt、preemptStop、preemptShrink\n3. 栈相关：stack、stackguard0、stackguard1\n4. defer相关：\\_panic、\\_defer\n5. 锁相关：waiting、timer、selectDone、\n6. 信号相关：sigcode0、sigcode1、sigpc\n\n当然，gorountine不仅仅是上述的字段，还有大量的pprof的计数字段，本次暂时不做讨论。\n\n可以看出，g和m的字段中，都有信号、锁、抢占相关的字段，但是，为什么m中却没有栈信息，难道不需要栈信息？这就是g0协程的重要性，golang中为了做权限隔离，避免用户代码影响runtime的运行，专门抽象了g0协程执行。既然无法向操作系统中通过中断实现内核态切换，就考虑使用特殊协程，这样相关上下文切换逻辑是完全复用，所以，g0是一个只做权限隔离的协程，同时所有m都拥有一个g0。\n\n#### 创建Gorountine\n\n创建gorountine就是平时大家使用的`go func()`关键字。在编译阶段，关键字会变编译为`runtime.newproc`方法，同时会传入参数大小和函数指针fn。然后从堆栈中获取参数并调用`runtime.newproc1`方法。\n```\nfunc newproc(siz int32, fn *funcval) {\n\targp := add(unsafe.Pointer(&fn), sys.PtrSize)\n\tgp := getg()\n\tpc := getcallerpc()\n\tsystemstack(func() {\n\t\tnewproc1(fn, argp, siz, gp, pc)\n\t})\n}\n```\n在`runtime.newproc1`方法中具体可以分为3块逻辑：\n1. gorountine结构体创建\n2. gorountine对象的初始化\n3. 插入调度对象并唤醒p\n\n创建完的gorountine结构体最终会插入p中的runq链表中。\n\n## 调度实现\n\n从m的创建流程中，可以看到`newosproc`方法是第四个参数，也就是系统线程的入口函数。线程创建完成后，操作系统会根据系统调度算法运行线程，`runtime.mstart`也就是线程的初始化方法。\n\n### 线程初始化\n\n`runtime.mstart`方法中，优先将栈的检查地址更新，这是因为如果是操作系统自动生成的堆栈，线程运行前是无法确定的。之后会调用`runtime.mstart1`方法执行进一步的初始化方法。最后，针对特殊的线程（被lockg的线程），会执行`runtime.mexit`方法。\n```\nfunc mstart() {\n\t_g_ := getg()\n\n\tosStack := _g_.stack.lo == 0\n\tif osStack {\n\t\tsize := _g_.stack.hi\n\t\tif size == 0 {\n\t\t\tsize = 8192 * sys.StackGuardMultiplier\n\t\t}\n\t\t_g_.stack.hi = uintptr(noescape(unsafe.Pointer(&size)))\n\t\t_g_.stack.lo = _g_.stack.hi - size + 1024\n\t}\n\t_g_.stackguard0 = _g_.stack.lo + _StackGuard\n\t_g_.stackguard1 = _g_.stackguard0\n\tmstart1()\n\n\tmexit(osStack)\n}\n```\n继续看`runtime.mstart1`方法，也还是一系列的初始化方法：\n1. 保存调用寄存器信息，主要用于当用户g切换至g0时，需要恢复的上下文\n2. 初始化信号处理方法，因为每个线程都需要自己的信号处理g\n3. 执行mstartfn方法，这个方法是针对sysmon这类的特殊线程实现的功能，使当前线程不进入调度循环中。\n\n执行完上述的初始化操作后，当前线程就将`nextp`字段转正进行绑定，并进入`runtime.schedule`方法中调度。\n\n### 线程循环\n\n在调用循环中，存在3个因素影响调度：当前是否需要stw、当前是否获取到g、当前m是否被g绑定。三者中获取g是调度循环的主流程，其他2者也是golang的特殊功能。所以先抽离出获取g的整体流程。\n\n#### 获取Gorountine\n\n在获取gorountine流程中，可以分为3部分：\n1. 若当前p不存在g，或者调度计数满足61次，则从全局中获取g运行\n2. 产生从p本地队列中获取g\n3. 本地和全局都获取不到时，则在`findrunable`方法中阻塞获取g\n\n```\nfunc schedule() {\n    ... ... \ntop:\n\tif gp == nil {\n\t\tif _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {\n\t\t\tlock(&sched.lock)\n\t\t\tgp = globrunqget(_g_.m.p.ptr(), 1)\n\t\t\tunlock(&sched.lock)\n\t\t}\n\t}\n\tif gp == nil {\n\t\tgp, inheritTime = runqget(_g_.m.p.ptr())\n\t\t// We can see gp != nil here even if the M is spinning,\n\t\t// if checkTimers added a local goroutine via goready.\n\t}\n\t// 如果实在没找到，那就强行找一个可用的\n\tif gp == nil {\n\t\tgp, inheritTime = findrunnable() // blocks until work is available\n\t}\n    execute(gp, inheritTime)\n}\n```\n\n##### globrunqget方法\n在从全局队列中获取g时，会从全局队列中获取g，并同时迁移`1/len(allp)`个数的g到本地队列中。\n```\nfunc globrunqget(_p_ *p, max int32) *g {\n\tn := sched.runqsize/gomaxprocs + 1\n\tif n > int32(len(_p_.runq))/2 {\n\t\tn = int32(len(_p_.runq)) / 2\n\t}\n\n\tsched.runqsize -= n\n\n\tgp := sched.runq.pop()\n\tn--\n\tfor ; n > 0; n-- {\n\t\tgp1 := sched.runq.pop()\n\t\trunqput(_p_, gp1, false)\n\t}\n\treturn gp\n}\n```\n\n##### runqget方法\n而在获取本地队列g的时候，优先会尝试获取`runnext`字段的g，在从`runq`中获取头部的g对象。当然由于`runq`是通过循环队列实现，所以gp是通过下标取余获取。\n```\nfunc runqget(_p_ *p) (gp *g, inheritTime bool) {\n\tfor {\n\t\tnext := _p_.runnext\n\t\tif next == 0 {\n\t\t\tbreak\n\t\t}\n\t\tif _p_.runnext.cas(next, 0) {\n\t\t\treturn next.ptr(), true\n\t\t}\n\t}\n\n\tfor {\n\t\th := atomic.LoadAcq(&_p_.runqhead) // load-acquire, synchronize with other consumers\n\t\tt := _p_.runqtail\n\t\tif t == h {\n\t\t\treturn nil, false\n\t\t}\n\t\tgp := _p_.runq[h%uint32(len(_p_.runq))].ptr()\n\t\tif atomic.CasRel(&_p_.runqhead, h, h+1) { // cas-release, commits consume\n\t\t\treturn gp, false\n\t\t}\n\t}\n}\n```\n##### findrunnable方法\n\n由于前2个方法实在获取不到可运行的g，所以在`findrunnable`方法中会不断的在各个可能存在可运行g的地方查询。具体的查询流程如下：\n1. 检查finalizer是否存在析构对象\n2. 检查本地对象是否存在可用g\n3. 查询全局队列是否存在可用g\n4. 非阻塞检查netpoll\n5. 如果大家都空闲中，或者自旋的m超过了忙碌的p，则进入强制查询阶段\n6. 再不济，随机4次去其他的p中窃取g\n\n上述流程实在找不到，m就不在持有p，然后开始特殊判断阶段。m开始循环判断是否存在可运行的g。判断区域还是从全局队列中、所有p的本地队列中以及netpoll三个方面。最终如果实在获取不到，则休眠当前m，等待有可用的p来唤醒。\n\n\n#### 执行Gorountine\n\n获取到可执行的g之后，就需要调用`runtime.execute`方法，主要针对g做一些变量赋值：\n```\n\tcasgstatus(gp, _Grunnable, _Grunning)\n\tgp.waitsince = 0\n\tgp.preempt = false\n\tgp.stackguard0 = gp.stack.lo + _StackGuard\n\tif !inheritTime {\n\t\t_g_.m.p.ptr().schedtick++\n\t}\n\t_g_.m.curg = gp\n\tgp.m = _g_.m\n```\n赋值完后，会调用`runtime.gogo`方法进行协程的上下文切换，将原有的g0协程，切换至gp协程。\n\n## 调度工具\n\n- trace\n- pprof\n\n## 相关主题\n- lock ranking\n\n\n## 相关链接\nhttps://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html\nhttps://www.linuxjournal.com/article/3184\n\n","slug":"golang-gmp","published":1,"updated":"2022-04-28T11:36:46.339Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg57r0002mauyf5217bft","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><h2 id=\"GMP模型\"><a href=\"#GMP模型\" class=\"headerlink\" title=\"GMP模型\"></a>GMP模型</h2><h3 id=\"关于线程和协程\"><a href=\"#关于线程和协程\" class=\"headerlink\" title=\"关于线程和协程\"></a>关于线程和协程</h3><p>在计算机操作系统中,轻量级进程（LWP）是一种实现多任务的方法。与普通进程相比，LWP与其他进程共享所有（或大部分）它的逻辑地址空间和系统资源；与线程相比，LWP有它自己的进程标识符，优先级，状态，以及栈和局部存储区，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。另外，线程既可由应用程序管理，又可由内核管理，而LWP只能由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。</p>\n<p><img src=\"1767848-9c4b06362907280d.webp\" alt=\"img\"></p>\n<h3 id=\"Golang中的模型\"><a href=\"#Golang中的模型\" class=\"headerlink\" title=\"Golang中的模型\"></a>Golang中的模型</h3><p>有2个支持高并发的模型：CSP和Actor（erlang）。Go选择了CSP，Go为了提供更容易的并发使用方法，提供了2个重要的概念<code>goroutine</code>和<code>channel</code>。</p>\n<p><strong>goroutine</strong>来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被<code>runtime</code>调度，转移到其他可运行的线程上。</p>\n<p><img src=\"3184f3.jpg\" alt=\"img\"></p>\n<p>其实<strong>老调度器</strong>有4个缺点：详见<a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!\" target=\"_blank\" rel=\"noopener\">Scalable Go Scheduler Design Doc</a></p>\n<ol>\n<li>创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争</li>\n<li>M转移G会造成延迟和额外的系统开销。</li>\n<li>M中的mcache是用来存放小对象的，mcache和栈都和M关联造成了大量的内存开销和差的局部性</li>\n<li>系统调用导致频繁的线程阻塞和取消阻塞操作增加了系统开销。</li>\n</ol>\n<p>所以Go语言在2012年重新设计了调度器方案（<a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!\" target=\"_blank\" rel=\"noopener\">Scalable Go Scheduler Design Doc</a>，<a href=\"https://golang.org/s/go11sched\" target=\"_blank\" rel=\"noopener\">设计方案</a>）。</p>\n<p><img src=\"567399-d400f4b192f3dc48.webp\" alt=\"img\"></p>\n<h2 id=\"关于GMP模型\"><a href=\"#关于GMP模型\" class=\"headerlink\" title=\"关于GMP模型\"></a>关于GMP模型</h2><h3 id=\"关于Machine\"><a href=\"#关于Machine\" class=\"headerlink\" title=\"关于Machine\"></a>关于Machine</h3><p>machine代表一个线程，每次创建一个M的时候，都会有一个底层线程创建；所有的G任务，最终还是在M上执行。</p>\n<p>machine的字段多达几十个，但将其进行粗劣的分类是可以明确m的具体职责：</p>\n<ol>\n<li>特殊g的管理：g0、gsignal、curg</li>\n<li>p的管理：p、nextp、oldp</li>\n<li>状态管理：locks、preemptoff、mallocing、throwing、dying、incgo、signalPending、blocked</li>\n<li>锁的管理：lockedg、lockedExt、lockedInt、nextwaitm、waitlock</li>\n<li>cgo运行相关：ncgocall、ncgo、cgoCallersUse、cgoCallers</li>\n</ol>\n<p>从字段中可以看出，在m层，主要方向有几个关键词：锁、抢占、cgo、g与p的管理、信号。主要原因还是由于m是一个贴近操作系统的结构体，而操作系统的调度的核心问题也是锁、信号，阻塞等。</p>\n<blockquote>\n<p>如何解决m和m的绑定问题？</p>\n</blockquote>\n<h4 id=\"创建Machine\"><a href=\"#创建Machine\" class=\"headerlink\" title=\"创建Machine\"></a>创建Machine</h4><p>创建m的时机有3类：sysmon抢占线程、templateThread模板线程、运行p。前2者是特殊的线程，不会进入调度系统中。创建m的方法是直接调用<code>runtime.newm</code>方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newm(fn func(), _p_ *p) &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; 分配一个m对象</span><br><span class=\"line\">\tmp :&#x3D; allocm(_p_, fn)</span><br><span class=\"line\">\t&#x2F;&#x2F; 设置下一个执行的p</span><br><span class=\"line\">\tmp.nextp.set(_p_)</span><br><span class=\"line\">\t&#x2F;&#x2F; 初始化系统信号拦截</span><br><span class=\"line\">\tmp.sigmask &#x3D; initSigmask</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tnewm1(mp)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出在m的创建流程中，具体分为2步：结构体的创建、线程的创建。在<code>allocm</code>方法中，核心是需要申请一个m的对象以及相关的g0空间，而针对不同的操作系统，g0的内存空间又区分为是使用系统分配，还是go指定。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func allocm(_p_ *p, fn func()) *m &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tmp :&#x3D; new(m)</span><br><span class=\"line\">\tmp.mstartfn &#x3D; fn</span><br><span class=\"line\">\tmcommoninit(mp)</span><br><span class=\"line\"></span><br><span class=\"line\">\tif iscgo || GOOS &#x3D;&#x3D; &quot;solaris&quot; || GOOS &#x3D;&#x3D; &quot;illumos&quot; || GOOS &#x3D;&#x3D; &quot;windows&quot; || GOOS &#x3D;&#x3D; &quot;plan9&quot; || GOOS &#x3D;&#x3D; &quot;darwin&quot; &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(-1)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(8192 * sys.StackGuardMultiplier)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tmp.g0.m &#x3D; mp</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn mp</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而在<code>runtime.newm1</code>方法中，主要是直接调用<code>runtime.newosproc</code>方法，正如其名，就是用于创建一个系统的线程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newm1(mp *m) &#123;</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tnewosproc(mp)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func newosproc(mp *m) &#123;</span><br><span class=\"line\">\tstk :&#x3D; unsafe.Pointer(mp.g0.stack.hi)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tvar oset sigset</span><br><span class=\"line\">\tsigprocmask(_SIG_SETMASK, &amp;sigset_all, &amp;oset)</span><br><span class=\"line\">\tret :&#x3D; clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))</span><br><span class=\"line\">\tsigprocmask(_SIG_SETMASK, &amp;oset, nil)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"关于Processor\"><a href=\"#关于Processor\" class=\"headerlink\" title=\"关于Processor\"></a>关于Processor</h3><p>每一个运行的M都必须绑定一个P，就像线程必须在么一个CPU核上执行一样，由P来调度G在M上的运行，P的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改；</p>\n<p>processor的字段可以分为以下几类：</p>\n<ol>\n<li>内存管理相关：mcache、pcache、mspancache、palloc</li>\n<li>调度计数相关：schedtick、syscalltick、sysmontick</li>\n<li>cache相关：deferpool、deferpoolbuf、gFree、sudogcache、sudogbuf</li>\n<li>g调度相关：runqhead、runqtail、runq、runnext</li>\n<li>定时器相关：timer0When、timersLock、timers、numTimers、adjustTimers、deletedTimers、</li>\n<li>gc相关：gcAssistTime、gcFractionalMarkTime、gcBgMarkWorker、gcMarkWorkerMode、gcMarkWorkerStartTime、gcw、wbBuf、runSafePointFn</li>\n</ol>\n<p>这几大方面主要是由于p本身的定位是执行器有关，当执行用户代码时，需要在效率和性能方面做到兼容，</p>\n<p>p的创建流程代码并不难懂，方法由procresize来执行，也就是平时大家设置GOMAXPROCS计数，其中涉及到扩容和缩容操作。</p>\n<h3 id=\"关于Goroutine\"><a href=\"#关于Goroutine\" class=\"headerlink\" title=\"关于Goroutine\"></a>关于Goroutine</h3><p>gorountine也就是平时的协程，每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息</p>\n<p>gorountine的字段可以分为以下几类：</p>\n<ol>\n<li>上下文信息：startpc、gopc、sigpc、sched、syscallsp、syscallpc、stktopsp、param</li>\n<li>抢占相关：preempt、preemptStop、preemptShrink</li>\n<li>栈相关：stack、stackguard0、stackguard1</li>\n<li>defer相关：_panic、_defer</li>\n<li>锁相关：waiting、timer、selectDone、</li>\n<li>信号相关：sigcode0、sigcode1、sigpc</li>\n</ol>\n<p>当然，gorountine不仅仅是上述的字段，还有大量的pprof的计数字段，本次暂时不做讨论。</p>\n<p>可以看出，g和m的字段中，都有信号、锁、抢占相关的字段，但是，为什么m中却没有栈信息，难道不需要栈信息？这就是g0协程的重要性，golang中为了做权限隔离，避免用户代码影响runtime的运行，专门抽象了g0协程执行。既然无法向操作系统中通过中断实现内核态切换，就考虑使用特殊协程，这样相关上下文切换逻辑是完全复用，所以，g0是一个只做权限隔离的协程，同时所有m都拥有一个g0。</p>\n<h4 id=\"创建Gorountine\"><a href=\"#创建Gorountine\" class=\"headerlink\" title=\"创建Gorountine\"></a>创建Gorountine</h4><p>创建gorountine就是平时大家使用的<code>go func()</code>关键字。在编译阶段，关键字会变编译为<code>runtime.newproc</code>方法，同时会传入参数大小和函数指针fn。然后从堆栈中获取参数并调用<code>runtime.newproc1</code>方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newproc(siz int32, fn *funcval) &#123;</span><br><span class=\"line\">\targp :&#x3D; add(unsafe.Pointer(&amp;fn), sys.PtrSize)</span><br><span class=\"line\">\tgp :&#x3D; getg()</span><br><span class=\"line\">\tpc :&#x3D; getcallerpc()</span><br><span class=\"line\">\tsystemstack(func() &#123;</span><br><span class=\"line\">\t\tnewproc1(fn, argp, siz, gp, pc)</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在<code>runtime.newproc1</code>方法中具体可以分为3块逻辑：</p>\n<ol>\n<li>gorountine结构体创建</li>\n<li>gorountine对象的初始化</li>\n<li>插入调度对象并唤醒p</li>\n</ol>\n<p>创建完的gorountine结构体最终会插入p中的runq链表中。</p>\n<h2 id=\"调度实现\"><a href=\"#调度实现\" class=\"headerlink\" title=\"调度实现\"></a>调度实现</h2><p>从m的创建流程中，可以看到<code>newosproc</code>方法是第四个参数，也就是系统线程的入口函数。线程创建完成后，操作系统会根据系统调度算法运行线程，<code>runtime.mstart</code>也就是线程的初始化方法。</p>\n<h3 id=\"线程初始化\"><a href=\"#线程初始化\" class=\"headerlink\" title=\"线程初始化\"></a>线程初始化</h3><p><code>runtime.mstart</code>方法中，优先将栈的检查地址更新，这是因为如果是操作系统自动生成的堆栈，线程运行前是无法确定的。之后会调用<code>runtime.mstart1</code>方法执行进一步的初始化方法。最后，针对特殊的线程（被lockg的线程），会执行<code>runtime.mexit</code>方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func mstart() &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tosStack :&#x3D; _g_.stack.lo &#x3D;&#x3D; 0</span><br><span class=\"line\">\tif osStack &#123;</span><br><span class=\"line\">\t\tsize :&#x3D; _g_.stack.hi</span><br><span class=\"line\">\t\tif size &#x3D;&#x3D; 0 &#123;</span><br><span class=\"line\">\t\t\tsize &#x3D; 8192 * sys.StackGuardMultiplier</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t_g_.stack.hi &#x3D; uintptr(noescape(unsafe.Pointer(&amp;size)))</span><br><span class=\"line\">\t\t_g_.stack.lo &#x3D; _g_.stack.hi - size + 1024</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t_g_.stackguard0 &#x3D; _g_.stack.lo + _StackGuard</span><br><span class=\"line\">\t_g_.stackguard1 &#x3D; _g_.stackguard0</span><br><span class=\"line\">\tmstart1()</span><br><span class=\"line\"></span><br><span class=\"line\">\tmexit(osStack)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>继续看<code>runtime.mstart1</code>方法，也还是一系列的初始化方法：</p>\n<ol>\n<li>保存调用寄存器信息，主要用于当用户g切换至g0时，需要恢复的上下文</li>\n<li>初始化信号处理方法，因为每个线程都需要自己的信号处理g</li>\n<li>执行mstartfn方法，这个方法是针对sysmon这类的特殊线程实现的功能，使当前线程不进入调度循环中。</li>\n</ol>\n<p>执行完上述的初始化操作后，当前线程就将<code>nextp</code>字段转正进行绑定，并进入<code>runtime.schedule</code>方法中调度。</p>\n<h3 id=\"线程循环\"><a href=\"#线程循环\" class=\"headerlink\" title=\"线程循环\"></a>线程循环</h3><p>在调用循环中，存在3个因素影响调度：当前是否需要stw、当前是否获取到g、当前m是否被g绑定。三者中获取g是调度循环的主流程，其他2者也是golang的特殊功能。所以先抽离出获取g的整体流程。</p>\n<h4 id=\"获取Gorountine\"><a href=\"#获取Gorountine\" class=\"headerlink\" title=\"获取Gorountine\"></a>获取Gorountine</h4><p>在获取gorountine流程中，可以分为3部分：</p>\n<ol>\n<li>若当前p不存在g，或者调度计数满足61次，则从全局中获取g运行</li>\n<li>产生从p本地队列中获取g</li>\n<li>本地和全局都获取不到时，则在<code>findrunable</code>方法中阻塞获取g</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func schedule() &#123;</span><br><span class=\"line\">    ... ... </span><br><span class=\"line\">top:</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tif _g_.m.p.ptr().schedtick%61 &#x3D;&#x3D; 0 &amp;&amp; sched.runqsize &gt; 0 &#123;</span><br><span class=\"line\">\t\t\tlock(&amp;sched.lock)</span><br><span class=\"line\">\t\t\tgp &#x3D; globrunqget(_g_.m.p.ptr(), 1)</span><br><span class=\"line\">\t\t\tunlock(&amp;sched.lock)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tgp, inheritTime &#x3D; runqget(_g_.m.p.ptr())</span><br><span class=\"line\">\t\t&#x2F;&#x2F; We can see gp !&#x3D; nil here even if the M is spinning,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; if checkTimers added a local goroutine via goready.</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t&#x2F;&#x2F; 如果实在没找到，那就强行找一个可用的</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tgp, inheritTime &#x3D; findrunnable() &#x2F;&#x2F; blocks until work is available</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    execute(gp, inheritTime)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"globrunqget方法\"><a href=\"#globrunqget方法\" class=\"headerlink\" title=\"globrunqget方法\"></a>globrunqget方法</h5><p>在从全局队列中获取g时，会从全局队列中获取g，并同时迁移<code>1/len(allp)</code>个数的g到本地队列中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func globrunqget(_p_ *p, max int32) *g &#123;</span><br><span class=\"line\">\tn :&#x3D; sched.runqsize&#x2F;gomaxprocs + 1</span><br><span class=\"line\">\tif n &gt; int32(len(_p_.runq))&#x2F;2 &#123;</span><br><span class=\"line\">\t\tn &#x3D; int32(len(_p_.runq)) &#x2F; 2</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.runqsize -&#x3D; n</span><br><span class=\"line\"></span><br><span class=\"line\">\tgp :&#x3D; sched.runq.pop()</span><br><span class=\"line\">\tn--</span><br><span class=\"line\">\tfor ; n &gt; 0; n-- &#123;</span><br><span class=\"line\">\t\tgp1 :&#x3D; sched.runq.pop()</span><br><span class=\"line\">\t\trunqput(_p_, gp1, false)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn gp</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"runqget方法\"><a href=\"#runqget方法\" class=\"headerlink\" title=\"runqget方法\"></a>runqget方法</h5><p>而在获取本地队列g的时候，优先会尝试获取<code>runnext</code>字段的g，在从<code>runq</code>中获取头部的g对象。当然由于<code>runq</code>是通过循环队列实现，所以gp是通过下标取余获取。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func runqget(_p_ *p) (gp *g, inheritTime bool) &#123;</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tnext :&#x3D; _p_.runnext</span><br><span class=\"line\">\t\tif next &#x3D;&#x3D; 0 &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif _p_.runnext.cas(next, 0) &#123;</span><br><span class=\"line\">\t\t\treturn next.ptr(), true</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\th :&#x3D; atomic.LoadAcq(&amp;_p_.runqhead) &#x2F;&#x2F; load-acquire, synchronize with other consumers</span><br><span class=\"line\">\t\tt :&#x3D; _p_.runqtail</span><br><span class=\"line\">\t\tif t &#x3D;&#x3D; h &#123;</span><br><span class=\"line\">\t\t\treturn nil, false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tgp :&#x3D; _p_.runq[h%uint32(len(_p_.runq))].ptr()</span><br><span class=\"line\">\t\tif atomic.CasRel(&amp;_p_.runqhead, h, h+1) &#123; &#x2F;&#x2F; cas-release, commits consume</span><br><span class=\"line\">\t\t\treturn gp, false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"findrunnable方法\"><a href=\"#findrunnable方法\" class=\"headerlink\" title=\"findrunnable方法\"></a>findrunnable方法</h5><p>由于前2个方法实在获取不到可运行的g，所以在<code>findrunnable</code>方法中会不断的在各个可能存在可运行g的地方查询。具体的查询流程如下：</p>\n<ol>\n<li>检查finalizer是否存在析构对象</li>\n<li>检查本地对象是否存在可用g</li>\n<li>查询全局队列是否存在可用g</li>\n<li>非阻塞检查netpoll</li>\n<li>如果大家都空闲中，或者自旋的m超过了忙碌的p，则进入强制查询阶段</li>\n<li>再不济，随机4次去其他的p中窃取g</li>\n</ol>\n<p>上述流程实在找不到，m就不在持有p，然后开始特殊判断阶段。m开始循环判断是否存在可运行的g。判断区域还是从全局队列中、所有p的本地队列中以及netpoll三个方面。最终如果实在获取不到，则休眠当前m，等待有可用的p来唤醒。</p>\n<h4 id=\"执行Gorountine\"><a href=\"#执行Gorountine\" class=\"headerlink\" title=\"执行Gorountine\"></a>执行Gorountine</h4><p>获取到可执行的g之后，就需要调用<code>runtime.execute</code>方法，主要针对g做一些变量赋值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">casgstatus(gp, _Grunnable, _Grunning)</span><br><span class=\"line\">gp.waitsince &#x3D; 0</span><br><span class=\"line\">gp.preempt &#x3D; false</span><br><span class=\"line\">gp.stackguard0 &#x3D; gp.stack.lo + _StackGuard</span><br><span class=\"line\">if !inheritTime &#123;</span><br><span class=\"line\">\t_g_.m.p.ptr().schedtick++</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">_g_.m.curg &#x3D; gp</span><br><span class=\"line\">gp.m &#x3D; _g_.m</span><br></pre></td></tr></table></figure>\n<p>赋值完后，会调用<code>runtime.gogo</code>方法进行协程的上下文切换，将原有的g0协程，切换至gp协程。</p>\n<h2 id=\"调度工具\"><a href=\"#调度工具\" class=\"headerlink\" title=\"调度工具\"></a>调度工具</h2><ul>\n<li>trace</li>\n<li>pprof</li>\n</ul>\n<h2 id=\"相关主题\"><a href=\"#相关主题\" class=\"headerlink\" title=\"相关主题\"></a>相关主题</h2><ul>\n<li>lock ranking</li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html\" target=\"_blank\" rel=\"noopener\">https://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html</a><br><a href=\"https://www.linuxjournal.com/article/3184\" target=\"_blank\" rel=\"noopener\">https://www.linuxjournal.com/article/3184</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><h2 id=\"GMP模型\"><a href=\"#GMP模型\" class=\"headerlink\" title=\"GMP模型\"></a>GMP模型</h2><h3 id=\"关于线程和协程\"><a href=\"#关于线程和协程\" class=\"headerlink\" title=\"关于线程和协程\"></a>关于线程和协程</h3><p>在计算机操作系统中,轻量级进程（LWP）是一种实现多任务的方法。与普通进程相比，LWP与其他进程共享所有（或大部分）它的逻辑地址空间和系统资源；与线程相比，LWP有它自己的进程标识符，优先级，状态，以及栈和局部存储区，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。另外，线程既可由应用程序管理，又可由内核管理，而LWP只能由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。</p>\n<p><img src=\"1767848-9c4b06362907280d.webp\" alt=\"img\"></p>\n<h3 id=\"Golang中的模型\"><a href=\"#Golang中的模型\" class=\"headerlink\" title=\"Golang中的模型\"></a>Golang中的模型</h3><p>有2个支持高并发的模型：CSP和Actor（erlang）。Go选择了CSP，Go为了提供更容易的并发使用方法，提供了2个重要的概念<code>goroutine</code>和<code>channel</code>。</p>\n<p><strong>goroutine</strong>来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被<code>runtime</code>调度，转移到其他可运行的线程上。</p>\n<p><img src=\"3184f3.jpg\" alt=\"img\"></p>\n<p>其实<strong>老调度器</strong>有4个缺点：详见<a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!\" target=\"_blank\" rel=\"noopener\">Scalable Go Scheduler Design Doc</a></p>\n<ol>\n<li>创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争</li>\n<li>M转移G会造成延迟和额外的系统开销。</li>\n<li>M中的mcache是用来存放小对象的，mcache和栈都和M关联造成了大量的内存开销和差的局部性</li>\n<li>系统调用导致频繁的线程阻塞和取消阻塞操作增加了系统开销。</li>\n</ol>\n<p>所以Go语言在2012年重新设计了调度器方案（<a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#!\" target=\"_blank\" rel=\"noopener\">Scalable Go Scheduler Design Doc</a>，<a href=\"https://golang.org/s/go11sched\" target=\"_blank\" rel=\"noopener\">设计方案</a>）。</p>\n<p><img src=\"567399-d400f4b192f3dc48.webp\" alt=\"img\"></p>\n<h2 id=\"关于GMP模型\"><a href=\"#关于GMP模型\" class=\"headerlink\" title=\"关于GMP模型\"></a>关于GMP模型</h2><h3 id=\"关于Machine\"><a href=\"#关于Machine\" class=\"headerlink\" title=\"关于Machine\"></a>关于Machine</h3><p>machine代表一个线程，每次创建一个M的时候，都会有一个底层线程创建；所有的G任务，最终还是在M上执行。</p>\n<p>machine的字段多达几十个，但将其进行粗劣的分类是可以明确m的具体职责：</p>\n<ol>\n<li>特殊g的管理：g0、gsignal、curg</li>\n<li>p的管理：p、nextp、oldp</li>\n<li>状态管理：locks、preemptoff、mallocing、throwing、dying、incgo、signalPending、blocked</li>\n<li>锁的管理：lockedg、lockedExt、lockedInt、nextwaitm、waitlock</li>\n<li>cgo运行相关：ncgocall、ncgo、cgoCallersUse、cgoCallers</li>\n</ol>\n<p>从字段中可以看出，在m层，主要方向有几个关键词：锁、抢占、cgo、g与p的管理、信号。主要原因还是由于m是一个贴近操作系统的结构体，而操作系统的调度的核心问题也是锁、信号，阻塞等。</p>\n<blockquote>\n<p>如何解决m和m的绑定问题？</p>\n</blockquote>\n<h4 id=\"创建Machine\"><a href=\"#创建Machine\" class=\"headerlink\" title=\"创建Machine\"></a>创建Machine</h4><p>创建m的时机有3类：sysmon抢占线程、templateThread模板线程、运行p。前2者是特殊的线程，不会进入调度系统中。创建m的方法是直接调用<code>runtime.newm</code>方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newm(fn func(), _p_ *p) &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; 分配一个m对象</span><br><span class=\"line\">\tmp :&#x3D; allocm(_p_, fn)</span><br><span class=\"line\">\t&#x2F;&#x2F; 设置下一个执行的p</span><br><span class=\"line\">\tmp.nextp.set(_p_)</span><br><span class=\"line\">\t&#x2F;&#x2F; 初始化系统信号拦截</span><br><span class=\"line\">\tmp.sigmask &#x3D; initSigmask</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tnewm1(mp)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出在m的创建流程中，具体分为2步：结构体的创建、线程的创建。在<code>allocm</code>方法中，核心是需要申请一个m的对象以及相关的g0空间，而针对不同的操作系统，g0的内存空间又区分为是使用系统分配，还是go指定。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func allocm(_p_ *p, fn func()) *m &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tmp :&#x3D; new(m)</span><br><span class=\"line\">\tmp.mstartfn &#x3D; fn</span><br><span class=\"line\">\tmcommoninit(mp)</span><br><span class=\"line\"></span><br><span class=\"line\">\tif iscgo || GOOS &#x3D;&#x3D; &quot;solaris&quot; || GOOS &#x3D;&#x3D; &quot;illumos&quot; || GOOS &#x3D;&#x3D; &quot;windows&quot; || GOOS &#x3D;&#x3D; &quot;plan9&quot; || GOOS &#x3D;&#x3D; &quot;darwin&quot; &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(-1)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tmp.g0 &#x3D; malg(8192 * sys.StackGuardMultiplier)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tmp.g0.m &#x3D; mp</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn mp</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而在<code>runtime.newm1</code>方法中，主要是直接调用<code>runtime.newosproc</code>方法，正如其名，就是用于创建一个系统的线程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newm1(mp *m) &#123;</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tnewosproc(mp)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func newosproc(mp *m) &#123;</span><br><span class=\"line\">\tstk :&#x3D; unsafe.Pointer(mp.g0.stack.hi)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">\tvar oset sigset</span><br><span class=\"line\">\tsigprocmask(_SIG_SETMASK, &amp;sigset_all, &amp;oset)</span><br><span class=\"line\">\tret :&#x3D; clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))</span><br><span class=\"line\">\tsigprocmask(_SIG_SETMASK, &amp;oset, nil)</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"关于Processor\"><a href=\"#关于Processor\" class=\"headerlink\" title=\"关于Processor\"></a>关于Processor</h3><p>每一个运行的M都必须绑定一个P，就像线程必须在么一个CPU核上执行一样，由P来调度G在M上的运行，P的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改；</p>\n<p>processor的字段可以分为以下几类：</p>\n<ol>\n<li>内存管理相关：mcache、pcache、mspancache、palloc</li>\n<li>调度计数相关：schedtick、syscalltick、sysmontick</li>\n<li>cache相关：deferpool、deferpoolbuf、gFree、sudogcache、sudogbuf</li>\n<li>g调度相关：runqhead、runqtail、runq、runnext</li>\n<li>定时器相关：timer0When、timersLock、timers、numTimers、adjustTimers、deletedTimers、</li>\n<li>gc相关：gcAssistTime、gcFractionalMarkTime、gcBgMarkWorker、gcMarkWorkerMode、gcMarkWorkerStartTime、gcw、wbBuf、runSafePointFn</li>\n</ol>\n<p>这几大方面主要是由于p本身的定位是执行器有关，当执行用户代码时，需要在效率和性能方面做到兼容，</p>\n<p>p的创建流程代码并不难懂，方法由procresize来执行，也就是平时大家设置GOMAXPROCS计数，其中涉及到扩容和缩容操作。</p>\n<h3 id=\"关于Goroutine\"><a href=\"#关于Goroutine\" class=\"headerlink\" title=\"关于Goroutine\"></a>关于Goroutine</h3><p>gorountine也就是平时的协程，每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息</p>\n<p>gorountine的字段可以分为以下几类：</p>\n<ol>\n<li>上下文信息：startpc、gopc、sigpc、sched、syscallsp、syscallpc、stktopsp、param</li>\n<li>抢占相关：preempt、preemptStop、preemptShrink</li>\n<li>栈相关：stack、stackguard0、stackguard1</li>\n<li>defer相关：_panic、_defer</li>\n<li>锁相关：waiting、timer、selectDone、</li>\n<li>信号相关：sigcode0、sigcode1、sigpc</li>\n</ol>\n<p>当然，gorountine不仅仅是上述的字段，还有大量的pprof的计数字段，本次暂时不做讨论。</p>\n<p>可以看出，g和m的字段中，都有信号、锁、抢占相关的字段，但是，为什么m中却没有栈信息，难道不需要栈信息？这就是g0协程的重要性，golang中为了做权限隔离，避免用户代码影响runtime的运行，专门抽象了g0协程执行。既然无法向操作系统中通过中断实现内核态切换，就考虑使用特殊协程，这样相关上下文切换逻辑是完全复用，所以，g0是一个只做权限隔离的协程，同时所有m都拥有一个g0。</p>\n<h4 id=\"创建Gorountine\"><a href=\"#创建Gorountine\" class=\"headerlink\" title=\"创建Gorountine\"></a>创建Gorountine</h4><p>创建gorountine就是平时大家使用的<code>go func()</code>关键字。在编译阶段，关键字会变编译为<code>runtime.newproc</code>方法，同时会传入参数大小和函数指针fn。然后从堆栈中获取参数并调用<code>runtime.newproc1</code>方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func newproc(siz int32, fn *funcval) &#123;</span><br><span class=\"line\">\targp :&#x3D; add(unsafe.Pointer(&amp;fn), sys.PtrSize)</span><br><span class=\"line\">\tgp :&#x3D; getg()</span><br><span class=\"line\">\tpc :&#x3D; getcallerpc()</span><br><span class=\"line\">\tsystemstack(func() &#123;</span><br><span class=\"line\">\t\tnewproc1(fn, argp, siz, gp, pc)</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在<code>runtime.newproc1</code>方法中具体可以分为3块逻辑：</p>\n<ol>\n<li>gorountine结构体创建</li>\n<li>gorountine对象的初始化</li>\n<li>插入调度对象并唤醒p</li>\n</ol>\n<p>创建完的gorountine结构体最终会插入p中的runq链表中。</p>\n<h2 id=\"调度实现\"><a href=\"#调度实现\" class=\"headerlink\" title=\"调度实现\"></a>调度实现</h2><p>从m的创建流程中，可以看到<code>newosproc</code>方法是第四个参数，也就是系统线程的入口函数。线程创建完成后，操作系统会根据系统调度算法运行线程，<code>runtime.mstart</code>也就是线程的初始化方法。</p>\n<h3 id=\"线程初始化\"><a href=\"#线程初始化\" class=\"headerlink\" title=\"线程初始化\"></a>线程初始化</h3><p><code>runtime.mstart</code>方法中，优先将栈的检查地址更新，这是因为如果是操作系统自动生成的堆栈，线程运行前是无法确定的。之后会调用<code>runtime.mstart1</code>方法执行进一步的初始化方法。最后，针对特殊的线程（被lockg的线程），会执行<code>runtime.mexit</code>方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func mstart() &#123;</span><br><span class=\"line\">\t_g_ :&#x3D; getg()</span><br><span class=\"line\"></span><br><span class=\"line\">\tosStack :&#x3D; _g_.stack.lo &#x3D;&#x3D; 0</span><br><span class=\"line\">\tif osStack &#123;</span><br><span class=\"line\">\t\tsize :&#x3D; _g_.stack.hi</span><br><span class=\"line\">\t\tif size &#x3D;&#x3D; 0 &#123;</span><br><span class=\"line\">\t\t\tsize &#x3D; 8192 * sys.StackGuardMultiplier</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t_g_.stack.hi &#x3D; uintptr(noescape(unsafe.Pointer(&amp;size)))</span><br><span class=\"line\">\t\t_g_.stack.lo &#x3D; _g_.stack.hi - size + 1024</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t_g_.stackguard0 &#x3D; _g_.stack.lo + _StackGuard</span><br><span class=\"line\">\t_g_.stackguard1 &#x3D; _g_.stackguard0</span><br><span class=\"line\">\tmstart1()</span><br><span class=\"line\"></span><br><span class=\"line\">\tmexit(osStack)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>继续看<code>runtime.mstart1</code>方法，也还是一系列的初始化方法：</p>\n<ol>\n<li>保存调用寄存器信息，主要用于当用户g切换至g0时，需要恢复的上下文</li>\n<li>初始化信号处理方法，因为每个线程都需要自己的信号处理g</li>\n<li>执行mstartfn方法，这个方法是针对sysmon这类的特殊线程实现的功能，使当前线程不进入调度循环中。</li>\n</ol>\n<p>执行完上述的初始化操作后，当前线程就将<code>nextp</code>字段转正进行绑定，并进入<code>runtime.schedule</code>方法中调度。</p>\n<h3 id=\"线程循环\"><a href=\"#线程循环\" class=\"headerlink\" title=\"线程循环\"></a>线程循环</h3><p>在调用循环中，存在3个因素影响调度：当前是否需要stw、当前是否获取到g、当前m是否被g绑定。三者中获取g是调度循环的主流程，其他2者也是golang的特殊功能。所以先抽离出获取g的整体流程。</p>\n<h4 id=\"获取Gorountine\"><a href=\"#获取Gorountine\" class=\"headerlink\" title=\"获取Gorountine\"></a>获取Gorountine</h4><p>在获取gorountine流程中，可以分为3部分：</p>\n<ol>\n<li>若当前p不存在g，或者调度计数满足61次，则从全局中获取g运行</li>\n<li>产生从p本地队列中获取g</li>\n<li>本地和全局都获取不到时，则在<code>findrunable</code>方法中阻塞获取g</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func schedule() &#123;</span><br><span class=\"line\">    ... ... </span><br><span class=\"line\">top:</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tif _g_.m.p.ptr().schedtick%61 &#x3D;&#x3D; 0 &amp;&amp; sched.runqsize &gt; 0 &#123;</span><br><span class=\"line\">\t\t\tlock(&amp;sched.lock)</span><br><span class=\"line\">\t\t\tgp &#x3D; globrunqget(_g_.m.p.ptr(), 1)</span><br><span class=\"line\">\t\t\tunlock(&amp;sched.lock)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tgp, inheritTime &#x3D; runqget(_g_.m.p.ptr())</span><br><span class=\"line\">\t\t&#x2F;&#x2F; We can see gp !&#x3D; nil here even if the M is spinning,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; if checkTimers added a local goroutine via goready.</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t&#x2F;&#x2F; 如果实在没找到，那就强行找一个可用的</span><br><span class=\"line\">\tif gp &#x3D;&#x3D; nil &#123;</span><br><span class=\"line\">\t\tgp, inheritTime &#x3D; findrunnable() &#x2F;&#x2F; blocks until work is available</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    execute(gp, inheritTime)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"globrunqget方法\"><a href=\"#globrunqget方法\" class=\"headerlink\" title=\"globrunqget方法\"></a>globrunqget方法</h5><p>在从全局队列中获取g时，会从全局队列中获取g，并同时迁移<code>1/len(allp)</code>个数的g到本地队列中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func globrunqget(_p_ *p, max int32) *g &#123;</span><br><span class=\"line\">\tn :&#x3D; sched.runqsize&#x2F;gomaxprocs + 1</span><br><span class=\"line\">\tif n &gt; int32(len(_p_.runq))&#x2F;2 &#123;</span><br><span class=\"line\">\t\tn &#x3D; int32(len(_p_.runq)) &#x2F; 2</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.runqsize -&#x3D; n</span><br><span class=\"line\"></span><br><span class=\"line\">\tgp :&#x3D; sched.runq.pop()</span><br><span class=\"line\">\tn--</span><br><span class=\"line\">\tfor ; n &gt; 0; n-- &#123;</span><br><span class=\"line\">\t\tgp1 :&#x3D; sched.runq.pop()</span><br><span class=\"line\">\t\trunqput(_p_, gp1, false)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn gp</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"runqget方法\"><a href=\"#runqget方法\" class=\"headerlink\" title=\"runqget方法\"></a>runqget方法</h5><p>而在获取本地队列g的时候，优先会尝试获取<code>runnext</code>字段的g，在从<code>runq</code>中获取头部的g对象。当然由于<code>runq</code>是通过循环队列实现，所以gp是通过下标取余获取。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func runqget(_p_ *p) (gp *g, inheritTime bool) &#123;</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tnext :&#x3D; _p_.runnext</span><br><span class=\"line\">\t\tif next &#x3D;&#x3D; 0 &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif _p_.runnext.cas(next, 0) &#123;</span><br><span class=\"line\">\t\t\treturn next.ptr(), true</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\th :&#x3D; atomic.LoadAcq(&amp;_p_.runqhead) &#x2F;&#x2F; load-acquire, synchronize with other consumers</span><br><span class=\"line\">\t\tt :&#x3D; _p_.runqtail</span><br><span class=\"line\">\t\tif t &#x3D;&#x3D; h &#123;</span><br><span class=\"line\">\t\t\treturn nil, false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tgp :&#x3D; _p_.runq[h%uint32(len(_p_.runq))].ptr()</span><br><span class=\"line\">\t\tif atomic.CasRel(&amp;_p_.runqhead, h, h+1) &#123; &#x2F;&#x2F; cas-release, commits consume</span><br><span class=\"line\">\t\t\treturn gp, false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"findrunnable方法\"><a href=\"#findrunnable方法\" class=\"headerlink\" title=\"findrunnable方法\"></a>findrunnable方法</h5><p>由于前2个方法实在获取不到可运行的g，所以在<code>findrunnable</code>方法中会不断的在各个可能存在可运行g的地方查询。具体的查询流程如下：</p>\n<ol>\n<li>检查finalizer是否存在析构对象</li>\n<li>检查本地对象是否存在可用g</li>\n<li>查询全局队列是否存在可用g</li>\n<li>非阻塞检查netpoll</li>\n<li>如果大家都空闲中，或者自旋的m超过了忙碌的p，则进入强制查询阶段</li>\n<li>再不济，随机4次去其他的p中窃取g</li>\n</ol>\n<p>上述流程实在找不到，m就不在持有p，然后开始特殊判断阶段。m开始循环判断是否存在可运行的g。判断区域还是从全局队列中、所有p的本地队列中以及netpoll三个方面。最终如果实在获取不到，则休眠当前m，等待有可用的p来唤醒。</p>\n<h4 id=\"执行Gorountine\"><a href=\"#执行Gorountine\" class=\"headerlink\" title=\"执行Gorountine\"></a>执行Gorountine</h4><p>获取到可执行的g之后，就需要调用<code>runtime.execute</code>方法，主要针对g做一些变量赋值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">casgstatus(gp, _Grunnable, _Grunning)</span><br><span class=\"line\">gp.waitsince &#x3D; 0</span><br><span class=\"line\">gp.preempt &#x3D; false</span><br><span class=\"line\">gp.stackguard0 &#x3D; gp.stack.lo + _StackGuard</span><br><span class=\"line\">if !inheritTime &#123;</span><br><span class=\"line\">\t_g_.m.p.ptr().schedtick++</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">_g_.m.curg &#x3D; gp</span><br><span class=\"line\">gp.m &#x3D; _g_.m</span><br></pre></td></tr></table></figure>\n<p>赋值完后，会调用<code>runtime.gogo</code>方法进行协程的上下文切换，将原有的g0协程，切换至gp协程。</p>\n<h2 id=\"调度工具\"><a href=\"#调度工具\" class=\"headerlink\" title=\"调度工具\"></a>调度工具</h2><ul>\n<li>trace</li>\n<li>pprof</li>\n</ul>\n<h2 id=\"相关主题\"><a href=\"#相关主题\" class=\"headerlink\" title=\"相关主题\"></a>相关主题</h2><ul>\n<li>lock ranking</li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html\" target=\"_blank\" rel=\"noopener\">https://docs.oracle.com/cd/E19683-01/806-6867/guide-60747/index.html</a><br><a href=\"https://www.linuxjournal.com/article/3184\" target=\"_blank\" rel=\"noopener\">https://www.linuxjournal.com/article/3184</a></p>\n"},{"title":"关于JVM的垃圾收集（2）","_content":"\n关于垃圾收集，上文已经提到了2类算法：引用计数、可达性计算。而针对可达性算法，为了提高垃圾收集效率，将内存分为新生代和老年代，并演化出3类假说：大部分对象朝生夕灭、熬过多次的垃圾收集越难消亡、跨代引用相对于同代引用是极少的。\n\n在这些基础上，java本身也会对gc进行分类处理，而非每次都是全内存进行垃圾清理。其中的分类为Minor GC、Major GC，分别为新生代GC和老年代GC，Mixed GC，表示对新生代和部分老年代的GC、Full GC，收集整个Java堆和方法区的垃圾。\n\n而在不同的GC阶段，自然也有不同的实现方式\n\n## 标记清理算法\n\n所谓标记清理当然分为标记和清理2个阶段：标记出所有需要收集的对象，而后统一进行回收。标记阶段负责判断垃圾，而清理阶段则直接处理相关垃圾对象。\n\n该方法的实际实现便是Golang中的三色标记。其主要确定在于执行效率不稳定，若存在大量对象，且大部分对象都需要回溯，则需要进行大规模的标记和清理动作，其次是内存空间碎片化问题，标记清理会导致大量的空间碎片，而当分配大对象时找不到足够的连续内存，则会提前触发下一次垃圾回收。\n\n## 标记复制算法\n\n为了解决标记清理算法面对大量可回收对象时执行效率低的问题，便产生出了半区复制的GC算法。原理是将可用内存按容量划分为大小相等的两块，每次只使用其中一块，当一块用完后将存活的对象复制到另外一块上面。而后再直接将旧有的一半空间清理。\n\n这类算法缺点则是会产生大量的内存间复制的开销，同时空间浪费相对比较严重。而在IBM公司的实验中发现，新生代98%的对象都熬不过第一轮收集，那也可以佐证并不需要进行半区1：1的空间分配。\n\n于是也就产生了经典的8：1：1的分区关系，划分为Eden（8）、Survivor0（1）、Survivor1（1），在对象申请时，只使用Eden+Survivor0区域，而当进行GC时，就将对象复制到Survivor1区域，并直接清空内存。这样只有10%的空间会浪费，同时，当存活的对象大于10%，那就需要启用老年代空间来存放对象。\n\n## 标记整理算法\n\n标记复制算法的问题则是在存活对象过多的情况下，需要进行较多的对象复制操作，效率极低。同时，如果出现100%的对象存活，那还需要额外的空间来保证算法稳定。那针对老年代的对象特征，那就是需要新的一类算法来保证空间的利用率。\n\n而标记整理便是当前的实际算法，这算法与标记清理的差异在于，前者在回收后需要对存活的对象进行移动。\n\n移动对象的确定在于，需要小心的维护对象的连接关系，保证在移动的过程中，不会直接导致进程崩坏。而如果不进行整理，那么空间碎片化会导致需要类似的内存分配器和访问器来解决。\n\n是否移动对象在实践中都存在利弊，那考虑整体老年代的特征而言，并不需要频繁的GC，更多的是空间利用率的提升，那选择移动对象那必然是较优的选择。","source":"_posts/java-gc-2.md","raw":"---\ntitle: 关于JVM的垃圾收集（2）\n---\n\n关于垃圾收集，上文已经提到了2类算法：引用计数、可达性计算。而针对可达性算法，为了提高垃圾收集效率，将内存分为新生代和老年代，并演化出3类假说：大部分对象朝生夕灭、熬过多次的垃圾收集越难消亡、跨代引用相对于同代引用是极少的。\n\n在这些基础上，java本身也会对gc进行分类处理，而非每次都是全内存进行垃圾清理。其中的分类为Minor GC、Major GC，分别为新生代GC和老年代GC，Mixed GC，表示对新生代和部分老年代的GC、Full GC，收集整个Java堆和方法区的垃圾。\n\n而在不同的GC阶段，自然也有不同的实现方式\n\n## 标记清理算法\n\n所谓标记清理当然分为标记和清理2个阶段：标记出所有需要收集的对象，而后统一进行回收。标记阶段负责判断垃圾，而清理阶段则直接处理相关垃圾对象。\n\n该方法的实际实现便是Golang中的三色标记。其主要确定在于执行效率不稳定，若存在大量对象，且大部分对象都需要回溯，则需要进行大规模的标记和清理动作，其次是内存空间碎片化问题，标记清理会导致大量的空间碎片，而当分配大对象时找不到足够的连续内存，则会提前触发下一次垃圾回收。\n\n## 标记复制算法\n\n为了解决标记清理算法面对大量可回收对象时执行效率低的问题，便产生出了半区复制的GC算法。原理是将可用内存按容量划分为大小相等的两块，每次只使用其中一块，当一块用完后将存活的对象复制到另外一块上面。而后再直接将旧有的一半空间清理。\n\n这类算法缺点则是会产生大量的内存间复制的开销，同时空间浪费相对比较严重。而在IBM公司的实验中发现，新生代98%的对象都熬不过第一轮收集，那也可以佐证并不需要进行半区1：1的空间分配。\n\n于是也就产生了经典的8：1：1的分区关系，划分为Eden（8）、Survivor0（1）、Survivor1（1），在对象申请时，只使用Eden+Survivor0区域，而当进行GC时，就将对象复制到Survivor1区域，并直接清空内存。这样只有10%的空间会浪费，同时，当存活的对象大于10%，那就需要启用老年代空间来存放对象。\n\n## 标记整理算法\n\n标记复制算法的问题则是在存活对象过多的情况下，需要进行较多的对象复制操作，效率极低。同时，如果出现100%的对象存活，那还需要额外的空间来保证算法稳定。那针对老年代的对象特征，那就是需要新的一类算法来保证空间的利用率。\n\n而标记整理便是当前的实际算法，这算法与标记清理的差异在于，前者在回收后需要对存活的对象进行移动。\n\n移动对象的确定在于，需要小心的维护对象的连接关系，保证在移动的过程中，不会直接导致进程崩坏。而如果不进行整理，那么空间碎片化会导致需要类似的内存分配器和访问器来解决。\n\n是否移动对象在实践中都存在利弊，那考虑整体老年代的特征而言，并不需要频繁的GC，更多的是空间利用率的提升，那选择移动对象那必然是较优的选择。","slug":"java-gc-2","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.465Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5800003mauyfo8ecx1b","content":"<p>关于垃圾收集，上文已经提到了2类算法：引用计数、可达性计算。而针对可达性算法，为了提高垃圾收集效率，将内存分为新生代和老年代，并演化出3类假说：大部分对象朝生夕灭、熬过多次的垃圾收集越难消亡、跨代引用相对于同代引用是极少的。</p>\n<p>在这些基础上，java本身也会对gc进行分类处理，而非每次都是全内存进行垃圾清理。其中的分类为Minor GC、Major GC，分别为新生代GC和老年代GC，Mixed GC，表示对新生代和部分老年代的GC、Full GC，收集整个Java堆和方法区的垃圾。</p>\n<p>而在不同的GC阶段，自然也有不同的实现方式</p>\n<h2 id=\"标记清理算法\"><a href=\"#标记清理算法\" class=\"headerlink\" title=\"标记清理算法\"></a>标记清理算法</h2><p>所谓标记清理当然分为标记和清理2个阶段：标记出所有需要收集的对象，而后统一进行回收。标记阶段负责判断垃圾，而清理阶段则直接处理相关垃圾对象。</p>\n<p>该方法的实际实现便是Golang中的三色标记。其主要确定在于执行效率不稳定，若存在大量对象，且大部分对象都需要回溯，则需要进行大规模的标记和清理动作，其次是内存空间碎片化问题，标记清理会导致大量的空间碎片，而当分配大对象时找不到足够的连续内存，则会提前触发下一次垃圾回收。</p>\n<h2 id=\"标记复制算法\"><a href=\"#标记复制算法\" class=\"headerlink\" title=\"标记复制算法\"></a>标记复制算法</h2><p>为了解决标记清理算法面对大量可回收对象时执行效率低的问题，便产生出了半区复制的GC算法。原理是将可用内存按容量划分为大小相等的两块，每次只使用其中一块，当一块用完后将存活的对象复制到另外一块上面。而后再直接将旧有的一半空间清理。</p>\n<p>这类算法缺点则是会产生大量的内存间复制的开销，同时空间浪费相对比较严重。而在IBM公司的实验中发现，新生代98%的对象都熬不过第一轮收集，那也可以佐证并不需要进行半区1：1的空间分配。</p>\n<p>于是也就产生了经典的8：1：1的分区关系，划分为Eden（8）、Survivor0（1）、Survivor1（1），在对象申请时，只使用Eden+Survivor0区域，而当进行GC时，就将对象复制到Survivor1区域，并直接清空内存。这样只有10%的空间会浪费，同时，当存活的对象大于10%，那就需要启用老年代空间来存放对象。</p>\n<h2 id=\"标记整理算法\"><a href=\"#标记整理算法\" class=\"headerlink\" title=\"标记整理算法\"></a>标记整理算法</h2><p>标记复制算法的问题则是在存活对象过多的情况下，需要进行较多的对象复制操作，效率极低。同时，如果出现100%的对象存活，那还需要额外的空间来保证算法稳定。那针对老年代的对象特征，那就是需要新的一类算法来保证空间的利用率。</p>\n<p>而标记整理便是当前的实际算法，这算法与标记清理的差异在于，前者在回收后需要对存活的对象进行移动。</p>\n<p>移动对象的确定在于，需要小心的维护对象的连接关系，保证在移动的过程中，不会直接导致进程崩坏。而如果不进行整理，那么空间碎片化会导致需要类似的内存分配器和访问器来解决。</p>\n<p>是否移动对象在实践中都存在利弊，那考虑整体老年代的特征而言，并不需要频繁的GC，更多的是空间利用率的提升，那选择移动对象那必然是较优的选择。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>关于垃圾收集，上文已经提到了2类算法：引用计数、可达性计算。而针对可达性算法，为了提高垃圾收集效率，将内存分为新生代和老年代，并演化出3类假说：大部分对象朝生夕灭、熬过多次的垃圾收集越难消亡、跨代引用相对于同代引用是极少的。</p>\n<p>在这些基础上，java本身也会对gc进行分类处理，而非每次都是全内存进行垃圾清理。其中的分类为Minor GC、Major GC，分别为新生代GC和老年代GC，Mixed GC，表示对新生代和部分老年代的GC、Full GC，收集整个Java堆和方法区的垃圾。</p>\n<p>而在不同的GC阶段，自然也有不同的实现方式</p>\n<h2 id=\"标记清理算法\"><a href=\"#标记清理算法\" class=\"headerlink\" title=\"标记清理算法\"></a>标记清理算法</h2><p>所谓标记清理当然分为标记和清理2个阶段：标记出所有需要收集的对象，而后统一进行回收。标记阶段负责判断垃圾，而清理阶段则直接处理相关垃圾对象。</p>\n<p>该方法的实际实现便是Golang中的三色标记。其主要确定在于执行效率不稳定，若存在大量对象，且大部分对象都需要回溯，则需要进行大规模的标记和清理动作，其次是内存空间碎片化问题，标记清理会导致大量的空间碎片，而当分配大对象时找不到足够的连续内存，则会提前触发下一次垃圾回收。</p>\n<h2 id=\"标记复制算法\"><a href=\"#标记复制算法\" class=\"headerlink\" title=\"标记复制算法\"></a>标记复制算法</h2><p>为了解决标记清理算法面对大量可回收对象时执行效率低的问题，便产生出了半区复制的GC算法。原理是将可用内存按容量划分为大小相等的两块，每次只使用其中一块，当一块用完后将存活的对象复制到另外一块上面。而后再直接将旧有的一半空间清理。</p>\n<p>这类算法缺点则是会产生大量的内存间复制的开销，同时空间浪费相对比较严重。而在IBM公司的实验中发现，新生代98%的对象都熬不过第一轮收集，那也可以佐证并不需要进行半区1：1的空间分配。</p>\n<p>于是也就产生了经典的8：1：1的分区关系，划分为Eden（8）、Survivor0（1）、Survivor1（1），在对象申请时，只使用Eden+Survivor0区域，而当进行GC时，就将对象复制到Survivor1区域，并直接清空内存。这样只有10%的空间会浪费，同时，当存活的对象大于10%，那就需要启用老年代空间来存放对象。</p>\n<h2 id=\"标记整理算法\"><a href=\"#标记整理算法\" class=\"headerlink\" title=\"标记整理算法\"></a>标记整理算法</h2><p>标记复制算法的问题则是在存活对象过多的情况下，需要进行较多的对象复制操作，效率极低。同时，如果出现100%的对象存活，那还需要额外的空间来保证算法稳定。那针对老年代的对象特征，那就是需要新的一类算法来保证空间的利用率。</p>\n<p>而标记整理便是当前的实际算法，这算法与标记清理的差异在于，前者在回收后需要对存活的对象进行移动。</p>\n<p>移动对象的确定在于，需要小心的维护对象的连接关系，保证在移动的过程中，不会直接导致进程崩坏。而如果不进行整理，那么空间碎片化会导致需要类似的内存分配器和访问器来解决。</p>\n<p>是否移动对象在实践中都存在利弊，那考虑整体老年代的特征而言，并不需要频繁的GC，更多的是空间利用率的提升，那选择移动对象那必然是较优的选择。</p>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.430Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5810004mauy386b8ifb","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"LevelDB实践","_content":"\n关于LevelDB，众所周知就是google基于lsm不断演化出来的一种kv存储库。而中间有各种语言的不同版本，今天则直接介绍一下golang版本中的一下实例。\n\n### 基本功能\n作为kv存储库，本身leveldb并不是和redis以及mysql一样拥有自己的独立服务，它本身是作为一个三方库，支持各个服务直接使用，这更像sqllite的能力，这中间就需要指定一个路径作为数据库的基本空间。\n\n```\ndb, err := leveldb.OpenFile(\"path/to/db\", nil)\n...\ndefer db.Close()\n```\n通过OpenFile方法，便可以指定对应的数据库路径，第二个参数则是当前数据库的相关属性，例如过滤器类型、缓存大小、压缩属性相关，这块就放在后面细说\n\n当打开数据库后，kv存储基本上就是3类操作：插入和查询、删除，只不过删除在最底层实现也还是插入逻辑。具体使用也是如下：\n```\nerr = db.Put([]byte(\"key\"), []byte(\"value\"), nil)\n\nif err != nil {\n\tpanic(err)\n}\n\ndata, err := db.Get([]byte(\"key\"), nil)\n\nif err != nil {\n\tpanic(err)\n}\n\nfmt.Println(data)\n\nerr = db.Delete([]byte(\"key\"), nil)\n\nif err != nil {\n\tpanic(err)\n}  \n```\n方法基本上没有什么特殊之处，而第二个参数都是操作中基本上需要的一下配置化信息：插入和更新操作关心**是否强制落库**以及**是否支持合并写入**、而查询所关心的则是**是否不走缓存**。\n\n当然，为了高性能，leveldb本身也支持批量插入\n```\nbatch := new(leveldb.Batch)\nbatch.Put([]byte(\"foo\"), []byte(\"value\"))\nbatch.Put([]byte(\"bar\"), []byte(\"another value\"))\nbatch.Delete([]byte(\"baz\"))\nerr = db.Write(batch, nil)\n```\n\b批量插入的核心优点就是会打开一个事务保证此次的插入原子性。关于本身事务的实现，这也是后续的一个课题。\n\n### 遍历\n\n当数据的存储已经给出实例，那这块还需要有检索能力，才能支持更丰富的应用场景。\n而关于遍历。由于本身是一个高性能的并发数据库，当并行时出现变更，则会导致遍历异常，而若直接加锁，则会导致性能的大规模损坏。这也映射了mysql中的mvcc实现。\n在leveldb中，直接使用的是迭代器+快照的方法来实现遍历能力。而遍历本身也就分为全局遍历、部分遍历、范围遍历、匹配遍历。这块也暂时举几个🌰，让人有直观的印象。\n```\n\tfor i := 0; i < 5; i++ {\n\t\tdb.Put([]byte(gofakeit.Name()), []byte(gofakeit.Address().Address), nil)\n\t}\n\n\titer := db.NewIterator(nil, nil)\n\tfor iter.Next() {\n\t\t// Remember that the contents of the returned slice should not be modified, and\n\t\t// only valid until the next call to Next.\n\t\tkey := iter.Key()\n\t\tvalue := iter.Value()\n\t\tfmt.Println(\"all date: \", string(key), \" -> \", string(value))\n\t}\n\titer.Release()\n```\n> 生成数据本身使用的是`github.com/brianvoe/gofakeit`\n而针对范围遍历。我们只需要更改一下迭代器的生成即可：\n```\niter = db.NewIterator(&util.Range{Start: []byte(\"Trinity Runte\"), Limit: []byte(\"Vito Gulgowski\")}, nil)\n```\n部分遍历。则是通过迭代器本身的seek方法来找到偏移量：\n```\niter.Seek([]byte(\"Trinity Runte\"))\n```\n还有一个有趣的点是，遍历能支持前缀匹配：\n```\niter := db.NewIterator(util.BytesPrefix([]byte(\"foo-\")), nil)\n```\n关于遍历本身，其实么有特别多好讲的，更多的是遍历对性能上是一个较大的损失，因为本身leveldb是分层文件，遍历则表示需要将所有数据全部查询，其中也就包括热点和非热点数据，这样会变现导致io的压力增加。\n","source":"_posts/level-db-demo.md","raw":"---\ntitle: LevelDB实践\n---\n\n关于LevelDB，众所周知就是google基于lsm不断演化出来的一种kv存储库。而中间有各种语言的不同版本，今天则直接介绍一下golang版本中的一下实例。\n\n### 基本功能\n作为kv存储库，本身leveldb并不是和redis以及mysql一样拥有自己的独立服务，它本身是作为一个三方库，支持各个服务直接使用，这更像sqllite的能力，这中间就需要指定一个路径作为数据库的基本空间。\n\n```\ndb, err := leveldb.OpenFile(\"path/to/db\", nil)\n...\ndefer db.Close()\n```\n通过OpenFile方法，便可以指定对应的数据库路径，第二个参数则是当前数据库的相关属性，例如过滤器类型、缓存大小、压缩属性相关，这块就放在后面细说\n\n当打开数据库后，kv存储基本上就是3类操作：插入和查询、删除，只不过删除在最底层实现也还是插入逻辑。具体使用也是如下：\n```\nerr = db.Put([]byte(\"key\"), []byte(\"value\"), nil)\n\nif err != nil {\n\tpanic(err)\n}\n\ndata, err := db.Get([]byte(\"key\"), nil)\n\nif err != nil {\n\tpanic(err)\n}\n\nfmt.Println(data)\n\nerr = db.Delete([]byte(\"key\"), nil)\n\nif err != nil {\n\tpanic(err)\n}  \n```\n方法基本上没有什么特殊之处，而第二个参数都是操作中基本上需要的一下配置化信息：插入和更新操作关心**是否强制落库**以及**是否支持合并写入**、而查询所关心的则是**是否不走缓存**。\n\n当然，为了高性能，leveldb本身也支持批量插入\n```\nbatch := new(leveldb.Batch)\nbatch.Put([]byte(\"foo\"), []byte(\"value\"))\nbatch.Put([]byte(\"bar\"), []byte(\"another value\"))\nbatch.Delete([]byte(\"baz\"))\nerr = db.Write(batch, nil)\n```\n\b批量插入的核心优点就是会打开一个事务保证此次的插入原子性。关于本身事务的实现，这也是后续的一个课题。\n\n### 遍历\n\n当数据的存储已经给出实例，那这块还需要有检索能力，才能支持更丰富的应用场景。\n而关于遍历。由于本身是一个高性能的并发数据库，当并行时出现变更，则会导致遍历异常，而若直接加锁，则会导致性能的大规模损坏。这也映射了mysql中的mvcc实现。\n在leveldb中，直接使用的是迭代器+快照的方法来实现遍历能力。而遍历本身也就分为全局遍历、部分遍历、范围遍历、匹配遍历。这块也暂时举几个🌰，让人有直观的印象。\n```\n\tfor i := 0; i < 5; i++ {\n\t\tdb.Put([]byte(gofakeit.Name()), []byte(gofakeit.Address().Address), nil)\n\t}\n\n\titer := db.NewIterator(nil, nil)\n\tfor iter.Next() {\n\t\t// Remember that the contents of the returned slice should not be modified, and\n\t\t// only valid until the next call to Next.\n\t\tkey := iter.Key()\n\t\tvalue := iter.Value()\n\t\tfmt.Println(\"all date: \", string(key), \" -> \", string(value))\n\t}\n\titer.Release()\n```\n> 生成数据本身使用的是`github.com/brianvoe/gofakeit`\n而针对范围遍历。我们只需要更改一下迭代器的生成即可：\n```\niter = db.NewIterator(&util.Range{Start: []byte(\"Trinity Runte\"), Limit: []byte(\"Vito Gulgowski\")}, nil)\n```\n部分遍历。则是通过迭代器本身的seek方法来找到偏移量：\n```\niter.Seek([]byte(\"Trinity Runte\"))\n```\n还有一个有趣的点是，遍历能支持前缀匹配：\n```\niter := db.NewIterator(util.BytesPrefix([]byte(\"foo-\")), nil)\n```\n关于遍历本身，其实么有特别多好讲的，更多的是遍历对性能上是一个较大的损失，因为本身leveldb是分层文件，遍历则表示需要将所有数据全部查询，其中也就包括热点和非热点数据，这样会变现导致io的压力增加。\n","slug":"level-db-demo","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.487Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5830005mauyere72leq","content":"<p>关于LevelDB，众所周知就是google基于lsm不断演化出来的一种kv存储库。而中间有各种语言的不同版本，今天则直接介绍一下golang版本中的一下实例。</p>\n<h3 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h3><p>作为kv存储库，本身leveldb并不是和redis以及mysql一样拥有自己的独立服务，它本身是作为一个三方库，支持各个服务直接使用，这更像sqllite的能力，这中间就需要指定一个路径作为数据库的基本空间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db, err :&#x3D; leveldb.OpenFile(&quot;path&#x2F;to&#x2F;db&quot;, nil)</span><br><span class=\"line\">...</span><br><span class=\"line\">defer db.Close()</span><br></pre></td></tr></table></figure>\n<p>通过OpenFile方法，便可以指定对应的数据库路径，第二个参数则是当前数据库的相关属性，例如过滤器类型、缓存大小、压缩属性相关，这块就放在后面细说</p>\n<p>当打开数据库后，kv存储基本上就是3类操作：插入和查询、删除，只不过删除在最底层实现也还是插入逻辑。具体使用也是如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">err &#x3D; db.Put([]byte(&quot;key&quot;), []byte(&quot;value&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">data, err :&#x3D; db.Get([]byte(&quot;key&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">fmt.Println(data)</span><br><span class=\"line\"></span><br><span class=\"line\">err &#x3D; db.Delete([]byte(&quot;key&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>方法基本上没有什么特殊之处，而第二个参数都是操作中基本上需要的一下配置化信息：插入和更新操作关心<strong>是否强制落库</strong>以及<strong>是否支持合并写入</strong>、而查询所关心的则是<strong>是否不走缓存</strong>。</p>\n<p>当然，为了高性能，leveldb本身也支持批量插入</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">batch :&#x3D; new(leveldb.Batch)</span><br><span class=\"line\">batch.Put([]byte(&quot;foo&quot;), []byte(&quot;value&quot;))</span><br><span class=\"line\">batch.Put([]byte(&quot;bar&quot;), []byte(&quot;another value&quot;))</span><br><span class=\"line\">batch.Delete([]byte(&quot;baz&quot;))</span><br><span class=\"line\">err &#x3D; db.Write(batch, nil)</span><br></pre></td></tr></table></figure>\n<p>\b批量插入的核心优点就是会打开一个事务保证此次的插入原子性。关于本身事务的实现，这也是后续的一个课题。</p>\n<h3 id=\"遍历\"><a href=\"#遍历\" class=\"headerlink\" title=\"遍历\"></a>遍历</h3><p>当数据的存储已经给出实例，那这块还需要有检索能力，才能支持更丰富的应用场景。<br>而关于遍历。由于本身是一个高性能的并发数据库，当并行时出现变更，则会导致遍历异常，而若直接加锁，则会导致性能的大规模损坏。这也映射了mysql中的mvcc实现。<br>在leveldb中，直接使用的是迭代器+快照的方法来实现遍历能力。而遍历本身也就分为全局遍历、部分遍历、范围遍历、匹配遍历。这块也暂时举几个🌰，让人有直观的印象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for i :&#x3D; 0; i &lt; 5; i++ &#123;</span><br><span class=\"line\">\tdb.Put([]byte(gofakeit.Name()), []byte(gofakeit.Address().Address), nil)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">iter :&#x3D; db.NewIterator(nil, nil)</span><br><span class=\"line\">for iter.Next() &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; Remember that the contents of the returned slice should not be modified, and</span><br><span class=\"line\">\t&#x2F;&#x2F; only valid until the next call to Next.</span><br><span class=\"line\">\tkey :&#x3D; iter.Key()</span><br><span class=\"line\">\tvalue :&#x3D; iter.Value()</span><br><span class=\"line\">\tfmt.Println(&quot;all date: &quot;, string(key), &quot; -&gt; &quot;, string(value))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">iter.Release()</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>生成数据本身使用的是<code>github.com/brianvoe/gofakeit</code><br>而针对范围遍历。我们只需要更改一下迭代器的生成即可：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter &#x3D; db.NewIterator(&amp;util.Range&#123;Start: []byte(&quot;Trinity Runte&quot;), Limit: []byte(&quot;Vito Gulgowski&quot;)&#125;, nil)</span><br></pre></td></tr></table></figure>\n<p>部分遍历。则是通过迭代器本身的seek方法来找到偏移量：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter.Seek([]byte(&quot;Trinity Runte&quot;))</span><br></pre></td></tr></table></figure>\n<p>还有一个有趣的点是，遍历能支持前缀匹配：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter :&#x3D; db.NewIterator(util.BytesPrefix([]byte(&quot;foo-&quot;)), nil)</span><br></pre></td></tr></table></figure>\n<p>关于遍历本身，其实么有特别多好讲的，更多的是遍历对性能上是一个较大的损失，因为本身leveldb是分层文件，遍历则表示需要将所有数据全部查询，其中也就包括热点和非热点数据，这样会变现导致io的压力增加。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>关于LevelDB，众所周知就是google基于lsm不断演化出来的一种kv存储库。而中间有各种语言的不同版本，今天则直接介绍一下golang版本中的一下实例。</p>\n<h3 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h3><p>作为kv存储库，本身leveldb并不是和redis以及mysql一样拥有自己的独立服务，它本身是作为一个三方库，支持各个服务直接使用，这更像sqllite的能力，这中间就需要指定一个路径作为数据库的基本空间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db, err :&#x3D; leveldb.OpenFile(&quot;path&#x2F;to&#x2F;db&quot;, nil)</span><br><span class=\"line\">...</span><br><span class=\"line\">defer db.Close()</span><br></pre></td></tr></table></figure>\n<p>通过OpenFile方法，便可以指定对应的数据库路径，第二个参数则是当前数据库的相关属性，例如过滤器类型、缓存大小、压缩属性相关，这块就放在后面细说</p>\n<p>当打开数据库后，kv存储基本上就是3类操作：插入和查询、删除，只不过删除在最底层实现也还是插入逻辑。具体使用也是如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">err &#x3D; db.Put([]byte(&quot;key&quot;), []byte(&quot;value&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">data, err :&#x3D; db.Get([]byte(&quot;key&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">fmt.Println(data)</span><br><span class=\"line\"></span><br><span class=\"line\">err &#x3D; db.Delete([]byte(&quot;key&quot;), nil)</span><br><span class=\"line\"></span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\tpanic(err)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>方法基本上没有什么特殊之处，而第二个参数都是操作中基本上需要的一下配置化信息：插入和更新操作关心<strong>是否强制落库</strong>以及<strong>是否支持合并写入</strong>、而查询所关心的则是<strong>是否不走缓存</strong>。</p>\n<p>当然，为了高性能，leveldb本身也支持批量插入</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">batch :&#x3D; new(leveldb.Batch)</span><br><span class=\"line\">batch.Put([]byte(&quot;foo&quot;), []byte(&quot;value&quot;))</span><br><span class=\"line\">batch.Put([]byte(&quot;bar&quot;), []byte(&quot;another value&quot;))</span><br><span class=\"line\">batch.Delete([]byte(&quot;baz&quot;))</span><br><span class=\"line\">err &#x3D; db.Write(batch, nil)</span><br></pre></td></tr></table></figure>\n<p>\b批量插入的核心优点就是会打开一个事务保证此次的插入原子性。关于本身事务的实现，这也是后续的一个课题。</p>\n<h3 id=\"遍历\"><a href=\"#遍历\" class=\"headerlink\" title=\"遍历\"></a>遍历</h3><p>当数据的存储已经给出实例，那这块还需要有检索能力，才能支持更丰富的应用场景。<br>而关于遍历。由于本身是一个高性能的并发数据库，当并行时出现变更，则会导致遍历异常，而若直接加锁，则会导致性能的大规模损坏。这也映射了mysql中的mvcc实现。<br>在leveldb中，直接使用的是迭代器+快照的方法来实现遍历能力。而遍历本身也就分为全局遍历、部分遍历、范围遍历、匹配遍历。这块也暂时举几个🌰，让人有直观的印象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for i :&#x3D; 0; i &lt; 5; i++ &#123;</span><br><span class=\"line\">\tdb.Put([]byte(gofakeit.Name()), []byte(gofakeit.Address().Address), nil)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">iter :&#x3D; db.NewIterator(nil, nil)</span><br><span class=\"line\">for iter.Next() &#123;</span><br><span class=\"line\">\t&#x2F;&#x2F; Remember that the contents of the returned slice should not be modified, and</span><br><span class=\"line\">\t&#x2F;&#x2F; only valid until the next call to Next.</span><br><span class=\"line\">\tkey :&#x3D; iter.Key()</span><br><span class=\"line\">\tvalue :&#x3D; iter.Value()</span><br><span class=\"line\">\tfmt.Println(&quot;all date: &quot;, string(key), &quot; -&gt; &quot;, string(value))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">iter.Release()</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>生成数据本身使用的是<code>github.com/brianvoe/gofakeit</code><br>而针对范围遍历。我们只需要更改一下迭代器的生成即可：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter &#x3D; db.NewIterator(&amp;util.Range&#123;Start: []byte(&quot;Trinity Runte&quot;), Limit: []byte(&quot;Vito Gulgowski&quot;)&#125;, nil)</span><br></pre></td></tr></table></figure>\n<p>部分遍历。则是通过迭代器本身的seek方法来找到偏移量：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter.Seek([]byte(&quot;Trinity Runte&quot;))</span><br></pre></td></tr></table></figure>\n<p>还有一个有趣的点是，遍历能支持前缀匹配：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iter :&#x3D; db.NewIterator(util.BytesPrefix([]byte(&quot;foo-&quot;)), nil)</span><br></pre></td></tr></table></figure>\n<p>关于遍历本身，其实么有特别多好讲的，更多的是遍历对性能上是一个较大的损失，因为本身leveldb是分层文件，遍历则表示需要将所有数据全部查询，其中也就包括热点和非热点数据，这样会变现导致io的压力增加。</p>\n"},{"title":"Golang-Lockg学习","date":"2020-07-12T15:51:41.000Z","_content":"## 前言\n\n## GMP的关系\n\n## G的调度\n\n## 抢占逻辑\n\n## 锁协程\n\n## GMP清理","source":"_posts/golang-lockg.md","raw":"---\ntitle: Golang-Lockg学习\ndate: 2020-07-12 23:51:41\ntags:\n---\n## 前言\n\n## GMP的关系\n\n## G的调度\n\n## 抢占逻辑\n\n## 锁协程\n\n## GMP清理","slug":"golang-lockg","published":1,"updated":"2022-04-28T11:36:46.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5840006mauy89hdc9tr","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><h2 id=\"GMP的关系\"><a href=\"#GMP的关系\" class=\"headerlink\" title=\"GMP的关系\"></a>GMP的关系</h2><h2 id=\"G的调度\"><a href=\"#G的调度\" class=\"headerlink\" title=\"G的调度\"></a>G的调度</h2><h2 id=\"抢占逻辑\"><a href=\"#抢占逻辑\" class=\"headerlink\" title=\"抢占逻辑\"></a>抢占逻辑</h2><h2 id=\"锁协程\"><a href=\"#锁协程\" class=\"headerlink\" title=\"锁协程\"></a>锁协程</h2><h2 id=\"GMP清理\"><a href=\"#GMP清理\" class=\"headerlink\" title=\"GMP清理\"></a>GMP清理</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><h2 id=\"GMP的关系\"><a href=\"#GMP的关系\" class=\"headerlink\" title=\"GMP的关系\"></a>GMP的关系</h2><h2 id=\"G的调度\"><a href=\"#G的调度\" class=\"headerlink\" title=\"G的调度\"></a>G的调度</h2><h2 id=\"抢占逻辑\"><a href=\"#抢占逻辑\" class=\"headerlink\" title=\"抢占逻辑\"></a>抢占逻辑</h2><h2 id=\"锁协程\"><a href=\"#锁协程\" class=\"headerlink\" title=\"锁协程\"></a>锁协程</h2><h2 id=\"GMP清理\"><a href=\"#GMP清理\" class=\"headerlink\" title=\"GMP清理\"></a>GMP清理</h2>"},{"title":"Golang-GMP模型","date":"2020-07-19T10:04:28.000Z","_content":"","source":"_posts/hello.md","raw":"---\ntitle: Golang-GMP模型\ndate: 2020-07-19 18:04:28\ntags:\n---","slug":"hello","published":1,"updated":"2022-04-28T11:36:46.446Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5850007mauy3kmu62nw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"关于LevelDB中的管道","_content":"\n在开源项目https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。\n\n## 管道汇总\n\n#### 写相关管道\n\nwriteMergeC/writeMergedC\n\n这是一对通信方式，当写入时，判断writeMergeC是能够写入，能写入表示抢到了锁操作，并继续往下执行，等待拿到writeMergedC消息，说明自己的写入已经被人合并，并不需要处理。\n\n当然如果当前处理未成功，则会继续往下处理，由另外一个协程进行合并操作。\n\nwriteLockC\n\n这个管道和上述的writeMerge是并集操作，当写入成功该管道，则认为抢锁成功，继续往下执行写入操作。当写入完成后，则会释放锁资源。\n\nwriteAckC\n\nack的管道则是表示当前的操作结果，前2者表示的当前处理流程是否成功。\n\n三者使用了管道来完成了一个队列的功能\n\n### 压缩相关管道\n\ntcompCmdC\n\n该管道表示写入一个cCmd，用于触发压缩操作，这个是由于压缩是一个单独的协程来循环处理，所以需要管道通信\n\ntcompPauseC\n\n这个则是为了快速暂停table的压缩流程，通过管道传入一个管道来让压缩流程停止。当然，如果已经开始进行实际的压缩操作，这个流程是无法终止的。\n\nmcompCmdC\n\n这个管道和tcompCmdC同理，也是用于触发压缩操作，只不过，这个操作是用于mem落入table文件时触发。\n\n## 错误相关管道\n\ncompErrC\\compPerErrC\\compErrSetC\n\n这三者构成了一个错误升级的结构，在压缩时，如果出现异常，则会写入compErrSetC，\n\n而如果当前compErrSetC管道堵住，且已经有compPerErrC产生，那直接panic，主要是因为compPerErrC是由于多次的compErrSetC错误导致写入。\n\n当然，如果compErrSetC成功过一次，则会降级等待，否则连续失败，且compErrC一直没人处理，则表示错误无法处理，并需要终止服务。\n\ncloseC\n\n这个管道则是在db调用关闭操作时触发，在等待操作中都有监听。\n\n## 总结\n\n可以看出，Golang管道不仅仅是一个通信工具，还能实现各类的加锁操作，包括锁升级。","source":"_posts/level-db-chan.md","raw":"---\ntitle: 关于LevelDB中的管道\n---\n\n在开源项目https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。\n\n## 管道汇总\n\n#### 写相关管道\n\nwriteMergeC/writeMergedC\n\n这是一对通信方式，当写入时，判断writeMergeC是能够写入，能写入表示抢到了锁操作，并继续往下执行，等待拿到writeMergedC消息，说明自己的写入已经被人合并，并不需要处理。\n\n当然如果当前处理未成功，则会继续往下处理，由另外一个协程进行合并操作。\n\nwriteLockC\n\n这个管道和上述的writeMerge是并集操作，当写入成功该管道，则认为抢锁成功，继续往下执行写入操作。当写入完成后，则会释放锁资源。\n\nwriteAckC\n\nack的管道则是表示当前的操作结果，前2者表示的当前处理流程是否成功。\n\n三者使用了管道来完成了一个队列的功能\n\n### 压缩相关管道\n\ntcompCmdC\n\n该管道表示写入一个cCmd，用于触发压缩操作，这个是由于压缩是一个单独的协程来循环处理，所以需要管道通信\n\ntcompPauseC\n\n这个则是为了快速暂停table的压缩流程，通过管道传入一个管道来让压缩流程停止。当然，如果已经开始进行实际的压缩操作，这个流程是无法终止的。\n\nmcompCmdC\n\n这个管道和tcompCmdC同理，也是用于触发压缩操作，只不过，这个操作是用于mem落入table文件时触发。\n\n## 错误相关管道\n\ncompErrC\\compPerErrC\\compErrSetC\n\n这三者构成了一个错误升级的结构，在压缩时，如果出现异常，则会写入compErrSetC，\n\n而如果当前compErrSetC管道堵住，且已经有compPerErrC产生，那直接panic，主要是因为compPerErrC是由于多次的compErrSetC错误导致写入。\n\n当然，如果compErrSetC成功过一次，则会降级等待，否则连续失败，且compErrC一直没人处理，则表示错误无法处理，并需要终止服务。\n\ncloseC\n\n这个管道则是在db调用关闭操作时触发，在等待操作中都有监听。\n\n## 总结\n\n可以看出，Golang管道不仅仅是一个通信工具，还能实现各类的加锁操作，包括锁升级。","slug":"level-db-chan","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.475Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5860008mauy9e1j2zkc","content":"<p>在开源项目<a href=\"https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。\" target=\"_blank\" rel=\"noopener\">https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。</a></p>\n<h2 id=\"管道汇总\"><a href=\"#管道汇总\" class=\"headerlink\" title=\"管道汇总\"></a>管道汇总</h2><h4 id=\"写相关管道\"><a href=\"#写相关管道\" class=\"headerlink\" title=\"写相关管道\"></a>写相关管道</h4><p>writeMergeC/writeMergedC</p>\n<p>这是一对通信方式，当写入时，判断writeMergeC是能够写入，能写入表示抢到了锁操作，并继续往下执行，等待拿到writeMergedC消息，说明自己的写入已经被人合并，并不需要处理。</p>\n<p>当然如果当前处理未成功，则会继续往下处理，由另外一个协程进行合并操作。</p>\n<p>writeLockC</p>\n<p>这个管道和上述的writeMerge是并集操作，当写入成功该管道，则认为抢锁成功，继续往下执行写入操作。当写入完成后，则会释放锁资源。</p>\n<p>writeAckC</p>\n<p>ack的管道则是表示当前的操作结果，前2者表示的当前处理流程是否成功。</p>\n<p>三者使用了管道来完成了一个队列的功能</p>\n<h3 id=\"压缩相关管道\"><a href=\"#压缩相关管道\" class=\"headerlink\" title=\"压缩相关管道\"></a>压缩相关管道</h3><p>tcompCmdC</p>\n<p>该管道表示写入一个cCmd，用于触发压缩操作，这个是由于压缩是一个单独的协程来循环处理，所以需要管道通信</p>\n<p>tcompPauseC</p>\n<p>这个则是为了快速暂停table的压缩流程，通过管道传入一个管道来让压缩流程停止。当然，如果已经开始进行实际的压缩操作，这个流程是无法终止的。</p>\n<p>mcompCmdC</p>\n<p>这个管道和tcompCmdC同理，也是用于触发压缩操作，只不过，这个操作是用于mem落入table文件时触发。</p>\n<h2 id=\"错误相关管道\"><a href=\"#错误相关管道\" class=\"headerlink\" title=\"错误相关管道\"></a>错误相关管道</h2><p>compErrC\\compPerErrC\\compErrSetC</p>\n<p>这三者构成了一个错误升级的结构，在压缩时，如果出现异常，则会写入compErrSetC，</p>\n<p>而如果当前compErrSetC管道堵住，且已经有compPerErrC产生，那直接panic，主要是因为compPerErrC是由于多次的compErrSetC错误导致写入。</p>\n<p>当然，如果compErrSetC成功过一次，则会降级等待，否则连续失败，且compErrC一直没人处理，则表示错误无法处理，并需要终止服务。</p>\n<p>closeC</p>\n<p>这个管道则是在db调用关闭操作时触发，在等待操作中都有监听。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>可以看出，Golang管道不仅仅是一个通信工具，还能实现各类的加锁操作，包括锁升级。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在开源项目<a href=\"https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。\" target=\"_blank\" rel=\"noopener\">https://github.com/syndtr/goleveldb中，存在大量的管道通信，而没有使用类似于锁之类的操作，在写法上是一件特别麻烦的事情。不过这也是项目高性能的一大原因。</a></p>\n<h2 id=\"管道汇总\"><a href=\"#管道汇总\" class=\"headerlink\" title=\"管道汇总\"></a>管道汇总</h2><h4 id=\"写相关管道\"><a href=\"#写相关管道\" class=\"headerlink\" title=\"写相关管道\"></a>写相关管道</h4><p>writeMergeC/writeMergedC</p>\n<p>这是一对通信方式，当写入时，判断writeMergeC是能够写入，能写入表示抢到了锁操作，并继续往下执行，等待拿到writeMergedC消息，说明自己的写入已经被人合并，并不需要处理。</p>\n<p>当然如果当前处理未成功，则会继续往下处理，由另外一个协程进行合并操作。</p>\n<p>writeLockC</p>\n<p>这个管道和上述的writeMerge是并集操作，当写入成功该管道，则认为抢锁成功，继续往下执行写入操作。当写入完成后，则会释放锁资源。</p>\n<p>writeAckC</p>\n<p>ack的管道则是表示当前的操作结果，前2者表示的当前处理流程是否成功。</p>\n<p>三者使用了管道来完成了一个队列的功能</p>\n<h3 id=\"压缩相关管道\"><a href=\"#压缩相关管道\" class=\"headerlink\" title=\"压缩相关管道\"></a>压缩相关管道</h3><p>tcompCmdC</p>\n<p>该管道表示写入一个cCmd，用于触发压缩操作，这个是由于压缩是一个单独的协程来循环处理，所以需要管道通信</p>\n<p>tcompPauseC</p>\n<p>这个则是为了快速暂停table的压缩流程，通过管道传入一个管道来让压缩流程停止。当然，如果已经开始进行实际的压缩操作，这个流程是无法终止的。</p>\n<p>mcompCmdC</p>\n<p>这个管道和tcompCmdC同理，也是用于触发压缩操作，只不过，这个操作是用于mem落入table文件时触发。</p>\n<h2 id=\"错误相关管道\"><a href=\"#错误相关管道\" class=\"headerlink\" title=\"错误相关管道\"></a>错误相关管道</h2><p>compErrC\\compPerErrC\\compErrSetC</p>\n<p>这三者构成了一个错误升级的结构，在压缩时，如果出现异常，则会写入compErrSetC，</p>\n<p>而如果当前compErrSetC管道堵住，且已经有compPerErrC产生，那直接panic，主要是因为compPerErrC是由于多次的compErrSetC错误导致写入。</p>\n<p>当然，如果compErrSetC成功过一次，则会降级等待，否则连续失败，且compErrC一直没人处理，则表示错误无法处理，并需要终止服务。</p>\n<p>closeC</p>\n<p>这个管道则是在db调用关闭操作时触发，在等待操作中都有监听。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>可以看出，Golang管道不仅仅是一个通信工具，还能实现各类的加锁操作，包括锁升级。</p>\n"},{"title":"关于JVM的垃圾收集（1）","_content":"\n## 前言\n\n在java中，存在大量的设计概念，在概念中衍生出了很多理论基础，这类的学习对其他语言的深入理解有很大的帮助，因为本身java就是一个很大的知识库，于是，在飞机上，抽空下载了《深入理解JAVA虚拟机》，并学习了其中几张，发现了很多知识点在之前学习Golang时常常是没有提及的，也坚定了后续继续深入阅读java书籍的目标。\n\n### 关于垃圾收集\n\n垃圾收集主要还是针对堆内存中的对象，因为在栈中的对象，是随着线程的执行，会自动消逝，而堆中的对象，则是没有维护上级，对于C、C++来说，需要开发者自身通过free方法来释放，也衍生出了内存池的概念，而在更多编程语言中，例如最初的lisp、近期的golang，为了开发效率，不再提倡手动维护这类对象，而且交由应用程序运行时来管理对象的生命周期，这样也可以避免出现大量对象释放后，导致进程core的bug。\n\n而在整体的垃圾收集算法中，核心还是，如何判断一个对象是否已死？最初的死亡定义是：当一个对象不再有另一个对象引用时，便认为其已死亡。这样也就衍生出引用计数算法，这类算法在最初的PHP有实现，包括在redis中也是有简易的实现。该算法原理简单，效率高，对于简单场景是十分适用，但是该算法并解决不了最困难的问题：循环引用。\n\n所谓循环引用，就是2个对象互相引用，但是不在被其他对象引用，按理说，这类孤岛对象，算是僵尸对象，有人引用，但是不会再被使用，所以也应该被当做垃圾清理。而针对这类case，也衍生出了可达性分析算法，通过一个GC Roots的根对象来进行广度优先搜索，最终判断对象是否可达。这样也就可以解决循环引用的问题，而针对可达性分析算法，也衍生出各种各样的实现，其中也就包括golang的三色标记、php的n色标记、java的分代算法。\n\n## 分代垃圾收集算法 \n\n分代收集的核心理论是建立2个假说：\n\n1）弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。\n\n2）强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。\n\n因此，在java中，会分开新生代和老年代2块区域，针对新生代而言，大部分的对象都在垃圾收集时直接消亡，而剩余的对象逐步晋升为老年代中。这样就可以针对新生代和老年代进行分别垃圾清理。但中间还存在一个问题是当一个新生代对象被老年代引用时，原本只需要在新生代做垃圾收集算法，却必须要同时对老年代进行，这样完全没有达到分代的效果。于是，又引入了一个假说：\n\n3）跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。\n\n即存在互相引用的2个对象，最终肯定是同时生存、死亡，所以，应该同时晋升为老年代，这样跨代的问题便消失了。","source":"_posts/java-gc-1.md","raw":"---\ntitle: 关于JVM的垃圾收集（1）\n---\n\n## 前言\n\n在java中，存在大量的设计概念，在概念中衍生出了很多理论基础，这类的学习对其他语言的深入理解有很大的帮助，因为本身java就是一个很大的知识库，于是，在飞机上，抽空下载了《深入理解JAVA虚拟机》，并学习了其中几张，发现了很多知识点在之前学习Golang时常常是没有提及的，也坚定了后续继续深入阅读java书籍的目标。\n\n### 关于垃圾收集\n\n垃圾收集主要还是针对堆内存中的对象，因为在栈中的对象，是随着线程的执行，会自动消逝，而堆中的对象，则是没有维护上级，对于C、C++来说，需要开发者自身通过free方法来释放，也衍生出了内存池的概念，而在更多编程语言中，例如最初的lisp、近期的golang，为了开发效率，不再提倡手动维护这类对象，而且交由应用程序运行时来管理对象的生命周期，这样也可以避免出现大量对象释放后，导致进程core的bug。\n\n而在整体的垃圾收集算法中，核心还是，如何判断一个对象是否已死？最初的死亡定义是：当一个对象不再有另一个对象引用时，便认为其已死亡。这样也就衍生出引用计数算法，这类算法在最初的PHP有实现，包括在redis中也是有简易的实现。该算法原理简单，效率高，对于简单场景是十分适用，但是该算法并解决不了最困难的问题：循环引用。\n\n所谓循环引用，就是2个对象互相引用，但是不在被其他对象引用，按理说，这类孤岛对象，算是僵尸对象，有人引用，但是不会再被使用，所以也应该被当做垃圾清理。而针对这类case，也衍生出了可达性分析算法，通过一个GC Roots的根对象来进行广度优先搜索，最终判断对象是否可达。这样也就可以解决循环引用的问题，而针对可达性分析算法，也衍生出各种各样的实现，其中也就包括golang的三色标记、php的n色标记、java的分代算法。\n\n## 分代垃圾收集算法 \n\n分代收集的核心理论是建立2个假说：\n\n1）弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。\n\n2）强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。\n\n因此，在java中，会分开新生代和老年代2块区域，针对新生代而言，大部分的对象都在垃圾收集时直接消亡，而剩余的对象逐步晋升为老年代中。这样就可以针对新生代和老年代进行分别垃圾清理。但中间还存在一个问题是当一个新生代对象被老年代引用时，原本只需要在新生代做垃圾收集算法，却必须要同时对老年代进行，这样完全没有达到分代的效果。于是，又引入了一个假说：\n\n3）跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。\n\n即存在互相引用的2个对象，最终肯定是同时生存、死亡，所以，应该同时晋升为老年代，这样跨代的问题便消失了。","slug":"java-gc-1","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.456Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5860009mauy9orm0lce","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在java中，存在大量的设计概念，在概念中衍生出了很多理论基础，这类的学习对其他语言的深入理解有很大的帮助，因为本身java就是一个很大的知识库，于是，在飞机上，抽空下载了《深入理解JAVA虚拟机》，并学习了其中几张，发现了很多知识点在之前学习Golang时常常是没有提及的，也坚定了后续继续深入阅读java书籍的目标。</p>\n<h3 id=\"关于垃圾收集\"><a href=\"#关于垃圾收集\" class=\"headerlink\" title=\"关于垃圾收集\"></a>关于垃圾收集</h3><p>垃圾收集主要还是针对堆内存中的对象，因为在栈中的对象，是随着线程的执行，会自动消逝，而堆中的对象，则是没有维护上级，对于C、C++来说，需要开发者自身通过free方法来释放，也衍生出了内存池的概念，而在更多编程语言中，例如最初的lisp、近期的golang，为了开发效率，不再提倡手动维护这类对象，而且交由应用程序运行时来管理对象的生命周期，这样也可以避免出现大量对象释放后，导致进程core的bug。</p>\n<p>而在整体的垃圾收集算法中，核心还是，如何判断一个对象是否已死？最初的死亡定义是：当一个对象不再有另一个对象引用时，便认为其已死亡。这样也就衍生出引用计数算法，这类算法在最初的PHP有实现，包括在redis中也是有简易的实现。该算法原理简单，效率高，对于简单场景是十分适用，但是该算法并解决不了最困难的问题：循环引用。</p>\n<p>所谓循环引用，就是2个对象互相引用，但是不在被其他对象引用，按理说，这类孤岛对象，算是僵尸对象，有人引用，但是不会再被使用，所以也应该被当做垃圾清理。而针对这类case，也衍生出了可达性分析算法，通过一个GC Roots的根对象来进行广度优先搜索，最终判断对象是否可达。这样也就可以解决循环引用的问题，而针对可达性分析算法，也衍生出各种各样的实现，其中也就包括golang的三色标记、php的n色标记、java的分代算法。</p>\n<h2 id=\"分代垃圾收集算法\"><a href=\"#分代垃圾收集算法\" class=\"headerlink\" title=\"分代垃圾收集算法\"></a>分代垃圾收集算法</h2><p>分代收集的核心理论是建立2个假说：</p>\n<p>1）弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。</p>\n<p>2）强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。</p>\n<p>因此，在java中，会分开新生代和老年代2块区域，针对新生代而言，大部分的对象都在垃圾收集时直接消亡，而剩余的对象逐步晋升为老年代中。这样就可以针对新生代和老年代进行分别垃圾清理。但中间还存在一个问题是当一个新生代对象被老年代引用时，原本只需要在新生代做垃圾收集算法，却必须要同时对老年代进行，这样完全没有达到分代的效果。于是，又引入了一个假说：</p>\n<p>3）跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。</p>\n<p>即存在互相引用的2个对象，最终肯定是同时生存、死亡，所以，应该同时晋升为老年代，这样跨代的问题便消失了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在java中，存在大量的设计概念，在概念中衍生出了很多理论基础，这类的学习对其他语言的深入理解有很大的帮助，因为本身java就是一个很大的知识库，于是，在飞机上，抽空下载了《深入理解JAVA虚拟机》，并学习了其中几张，发现了很多知识点在之前学习Golang时常常是没有提及的，也坚定了后续继续深入阅读java书籍的目标。</p>\n<h3 id=\"关于垃圾收集\"><a href=\"#关于垃圾收集\" class=\"headerlink\" title=\"关于垃圾收集\"></a>关于垃圾收集</h3><p>垃圾收集主要还是针对堆内存中的对象，因为在栈中的对象，是随着线程的执行，会自动消逝，而堆中的对象，则是没有维护上级，对于C、C++来说，需要开发者自身通过free方法来释放，也衍生出了内存池的概念，而在更多编程语言中，例如最初的lisp、近期的golang，为了开发效率，不再提倡手动维护这类对象，而且交由应用程序运行时来管理对象的生命周期，这样也可以避免出现大量对象释放后，导致进程core的bug。</p>\n<p>而在整体的垃圾收集算法中，核心还是，如何判断一个对象是否已死？最初的死亡定义是：当一个对象不再有另一个对象引用时，便认为其已死亡。这样也就衍生出引用计数算法，这类算法在最初的PHP有实现，包括在redis中也是有简易的实现。该算法原理简单，效率高，对于简单场景是十分适用，但是该算法并解决不了最困难的问题：循环引用。</p>\n<p>所谓循环引用，就是2个对象互相引用，但是不在被其他对象引用，按理说，这类孤岛对象，算是僵尸对象，有人引用，但是不会再被使用，所以也应该被当做垃圾清理。而针对这类case，也衍生出了可达性分析算法，通过一个GC Roots的根对象来进行广度优先搜索，最终判断对象是否可达。这样也就可以解决循环引用的问题，而针对可达性分析算法，也衍生出各种各样的实现，其中也就包括golang的三色标记、php的n色标记、java的分代算法。</p>\n<h2 id=\"分代垃圾收集算法\"><a href=\"#分代垃圾收集算法\" class=\"headerlink\" title=\"分代垃圾收集算法\"></a>分代垃圾收集算法</h2><p>分代收集的核心理论是建立2个假说：</p>\n<p>1）弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。</p>\n<p>2）强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。</p>\n<p>因此，在java中，会分开新生代和老年代2块区域，针对新生代而言，大部分的对象都在垃圾收集时直接消亡，而剩余的对象逐步晋升为老年代中。这样就可以针对新生代和老年代进行分别垃圾清理。但中间还存在一个问题是当一个新生代对象被老年代引用时，原本只需要在新生代做垃圾收集算法，却必须要同时对老年代进行，这样完全没有达到分代的效果。于是，又引入了一个假说：</p>\n<p>3）跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。</p>\n<p>即存在互相引用的2个对象，最终肯定是同时生存、死亡，所以，应该同时晋升为老年代，这样跨代的问题便消失了。</p>\n"},{"title":"浅析levelDB流程（打开流程）","_content":"\n## 前言\n核心是逐步学习leveldb的实现，而其中一步步从读写开始学习相关实现\n\n## 打开的方法\n从上文的demo，我们可以看出常见的打开方式是传入一个文件夹目录，方法是`OpenFile`，而针对各种常见，leveldb也提供了多种方法，例如可以自身传入一个存储方式的`Open(stor storage.Storage, o *opt.Options)`、直接从目录中恢复数据的`RecoverFile(path string, o *opt.Options)`等。而此次，我们核心从基础的OpenFile方法中入手，看看在打开leveldb时，是如何进行初始化操作。\n\n## 数据的获取\n```\nstor, err := storage.OpenFile(path, o.GetReadOnly())\n```\n最初引入眼帘的便是通过`storage.OpenFile`去持有一个存储对象。这其中可以使用内存作为存储，当然大部分情况还是使用文件存储。\n在打开文件后，需要开始检查路径是否存在、检查文件锁是否存在。\b检查完这2项后，还有就是确定当前是否只读，如果只读，则不需要新建Log文件，因为Log文件是用于支持AOF能力，否则则需要重建。\n当检查完成后，便会得到以下的结构体：\n```\n\tfs := &fileStorage{\n\t\tpath:     path,\n\t\treadOnly: readOnly,\n\t\tflock:    flock,\n\t\tlogw:     logw,\n\t\tlogSize:  logSize,\n\t}\n```\n结构体中核心包含路径、是否只读、是否锁，以及log文件相关数据\n当然，还有有趣的一行代码是：\n```\nruntime.SetFinalizer(fs, (*fileStorage).Close)\n```\n这行代码的目的和析构函数类似，当对象销毁时，进行善后处理。\n\n## 会话的构建\n当已经持有存储对象时，第一步就开始针对存储对象构建会话session信息。\n```\ns, err := newSession(stor, o)\n\ts = &session{\n\t\tstor:      newIStorage(stor),\n\t\tstorLock:  storLock,\n\t\trefCh:     make(chan *vTask),\n\t\trelCh:     make(chan *vTask),\n\t\tdeltaCh:   make(chan *vDelta),\n\t\tabandon:   make(chan int64),\n\t\tfileRefCh: make(chan chan map[int64]int),\n\t\tcloseC:    make(chan struct{}),\n\t}\n```\n会话中一个大的属性便是管道信息，可以见得session持有了多类管道，中间的能力简单来说就是，当leveldb中文件存在变更，都是通过session来进行异步操作。例如文件的删除和添加。而后会启动一个协程来辅助处理：\n```\ngo s.refLoop()\n```\n得到session对象后，则需要用version对象来管理各个版本的文件信息，这也是保证leveldb中并发安全的基础\n```\ns.setVersion(nil, newVersion(s))\n--- \n\nfunc newVersion(s *session) *version {\n\tid := atomic.AddInt64(&s.ntVersionId, 1)\n\tnv := &version{s: s, id: id - 1}\n\treturn nv\n}\n```\n当在初始化时，仅仅只是将version和session进行绑定。\n\n\n## 奔溃恢复\n初始化完基本信息，leveldb就进入了奔溃恢复流程，这也是所有存储不可避免的一个机制，包括mysql。而崩溃恢复也是针对session而已，最终核心也是恢复出上一次存储的version信息。\n```\nerr = s.recover()\n```\n首先第一步恢复就是恢复当前的存储基本信息，这也映射到了leveldb中的current文件中对应的Manifest文件\n```\n\tfd, err := s.stor.GetMeta()\n\tif err != nil {\n\t\treturn\n\t}\n\n\treader, err := s.stor.Open(fd)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer reader.Close()\n```\n得到Current文件后，就会生成一个记事本journal对象，这个对象管理着Log文件内容，而Manifest文件本书也是Log文件格式存储，所以，直接复用即可。\n文件格式本文暂时不仔细描述，而从Manifest文件中，可以解析出，当前数据库使用的对比方法、压缩格式、各层级的文件信息，至此，我们就可以产生出一个新的version对象。\n\n## 数据库对象构建\nsession本身是管理此次底层version的变更，而再上一层则需要一个db层来管理对外接口以及内存和文件的事件管理。所以，这一层更多的是压缩、和写入的管理：\n```\ndb := &DB{\n\t\ts: s,\n\t\t// Initial sequence\n\t\tseq: s.stSeqNum,\n\t\t// MemDB\n\t\tmemPool: make(chan *memdb.DB, 1),\n\t\t// Snapshot\n\t\tsnapsList: list.New(),\n\t\t// Write\n\t\tbatchPool:    sync.Pool{New: newBatch},\n\t\twriteMergeC:  make(chan writeMerge),\n\t\twriteMergedC: make(chan bool),\n\t\twriteLockC:   make(chan struct{}, 1),\n\t\twriteAckC:    make(chan error),\n\t\t// Compaction\n\t\ttcompCmdC:   make(chan cCmd),\n\t\ttcompPauseC: make(chan chan<- struct{}),\n\t\tmcompCmdC:   make(chan cCmd),\n\t\tcompErrC:    make(chan error),\n\t\tcompPerErrC: make(chan error),\n\t\tcompErrSetC: make(chan error),\n\t\t// Close\n\t\tcloseC: make(chan struct{}),\n\t}\n```\n由结构体可见大部分是针对压缩和写入合并使用的管道对象。\n而生成完session后，仅仅只是吧以及落磁盘的level文件加载，而在崩溃前的内存数据还在丢失的，这些数据则需要从Log文件中恢复，这些则是在DB生成后恢复，当然恢复也是直接入memDB中，当做写入执行。中间必然也就触发了压缩和version的变更。\n\n当Log文件恢复后，最终就是启动各类的管道来执行相关的异步操作：\n```\n\tgo db.compactionError()\n\tgo db.mpoolDrain()\n\n\tif readOnly {\n\t\tdb.SetReadOnly()\n\t} else {\n\t\tdb.closeW.Add(2)\n\t\tgo db.tCompaction()\n\t\tgo db.mCompaction()\n\t\t// go db.jWriter()\n\t}\n```\n## 总结\n由此可见，leveldb中，使用了大量的异步逻辑来保证存储的高性能。同时也是利用了AOF原理来提高高可用性。","source":"_posts/level-db-start.md","raw":"---\ntitle: 浅析levelDB流程（打开流程）\n---\n\n## 前言\n核心是逐步学习leveldb的实现，而其中一步步从读写开始学习相关实现\n\n## 打开的方法\n从上文的demo，我们可以看出常见的打开方式是传入一个文件夹目录，方法是`OpenFile`，而针对各种常见，leveldb也提供了多种方法，例如可以自身传入一个存储方式的`Open(stor storage.Storage, o *opt.Options)`、直接从目录中恢复数据的`RecoverFile(path string, o *opt.Options)`等。而此次，我们核心从基础的OpenFile方法中入手，看看在打开leveldb时，是如何进行初始化操作。\n\n## 数据的获取\n```\nstor, err := storage.OpenFile(path, o.GetReadOnly())\n```\n最初引入眼帘的便是通过`storage.OpenFile`去持有一个存储对象。这其中可以使用内存作为存储，当然大部分情况还是使用文件存储。\n在打开文件后，需要开始检查路径是否存在、检查文件锁是否存在。\b检查完这2项后，还有就是确定当前是否只读，如果只读，则不需要新建Log文件，因为Log文件是用于支持AOF能力，否则则需要重建。\n当检查完成后，便会得到以下的结构体：\n```\n\tfs := &fileStorage{\n\t\tpath:     path,\n\t\treadOnly: readOnly,\n\t\tflock:    flock,\n\t\tlogw:     logw,\n\t\tlogSize:  logSize,\n\t}\n```\n结构体中核心包含路径、是否只读、是否锁，以及log文件相关数据\n当然，还有有趣的一行代码是：\n```\nruntime.SetFinalizer(fs, (*fileStorage).Close)\n```\n这行代码的目的和析构函数类似，当对象销毁时，进行善后处理。\n\n## 会话的构建\n当已经持有存储对象时，第一步就开始针对存储对象构建会话session信息。\n```\ns, err := newSession(stor, o)\n\ts = &session{\n\t\tstor:      newIStorage(stor),\n\t\tstorLock:  storLock,\n\t\trefCh:     make(chan *vTask),\n\t\trelCh:     make(chan *vTask),\n\t\tdeltaCh:   make(chan *vDelta),\n\t\tabandon:   make(chan int64),\n\t\tfileRefCh: make(chan chan map[int64]int),\n\t\tcloseC:    make(chan struct{}),\n\t}\n```\n会话中一个大的属性便是管道信息，可以见得session持有了多类管道，中间的能力简单来说就是，当leveldb中文件存在变更，都是通过session来进行异步操作。例如文件的删除和添加。而后会启动一个协程来辅助处理：\n```\ngo s.refLoop()\n```\n得到session对象后，则需要用version对象来管理各个版本的文件信息，这也是保证leveldb中并发安全的基础\n```\ns.setVersion(nil, newVersion(s))\n--- \n\nfunc newVersion(s *session) *version {\n\tid := atomic.AddInt64(&s.ntVersionId, 1)\n\tnv := &version{s: s, id: id - 1}\n\treturn nv\n}\n```\n当在初始化时，仅仅只是将version和session进行绑定。\n\n\n## 奔溃恢复\n初始化完基本信息，leveldb就进入了奔溃恢复流程，这也是所有存储不可避免的一个机制，包括mysql。而崩溃恢复也是针对session而已，最终核心也是恢复出上一次存储的version信息。\n```\nerr = s.recover()\n```\n首先第一步恢复就是恢复当前的存储基本信息，这也映射到了leveldb中的current文件中对应的Manifest文件\n```\n\tfd, err := s.stor.GetMeta()\n\tif err != nil {\n\t\treturn\n\t}\n\n\treader, err := s.stor.Open(fd)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer reader.Close()\n```\n得到Current文件后，就会生成一个记事本journal对象，这个对象管理着Log文件内容，而Manifest文件本书也是Log文件格式存储，所以，直接复用即可。\n文件格式本文暂时不仔细描述，而从Manifest文件中，可以解析出，当前数据库使用的对比方法、压缩格式、各层级的文件信息，至此，我们就可以产生出一个新的version对象。\n\n## 数据库对象构建\nsession本身是管理此次底层version的变更，而再上一层则需要一个db层来管理对外接口以及内存和文件的事件管理。所以，这一层更多的是压缩、和写入的管理：\n```\ndb := &DB{\n\t\ts: s,\n\t\t// Initial sequence\n\t\tseq: s.stSeqNum,\n\t\t// MemDB\n\t\tmemPool: make(chan *memdb.DB, 1),\n\t\t// Snapshot\n\t\tsnapsList: list.New(),\n\t\t// Write\n\t\tbatchPool:    sync.Pool{New: newBatch},\n\t\twriteMergeC:  make(chan writeMerge),\n\t\twriteMergedC: make(chan bool),\n\t\twriteLockC:   make(chan struct{}, 1),\n\t\twriteAckC:    make(chan error),\n\t\t// Compaction\n\t\ttcompCmdC:   make(chan cCmd),\n\t\ttcompPauseC: make(chan chan<- struct{}),\n\t\tmcompCmdC:   make(chan cCmd),\n\t\tcompErrC:    make(chan error),\n\t\tcompPerErrC: make(chan error),\n\t\tcompErrSetC: make(chan error),\n\t\t// Close\n\t\tcloseC: make(chan struct{}),\n\t}\n```\n由结构体可见大部分是针对压缩和写入合并使用的管道对象。\n而生成完session后，仅仅只是吧以及落磁盘的level文件加载，而在崩溃前的内存数据还在丢失的，这些数据则需要从Log文件中恢复，这些则是在DB生成后恢复，当然恢复也是直接入memDB中，当做写入执行。中间必然也就触发了压缩和version的变更。\n\n当Log文件恢复后，最终就是启动各类的管道来执行相关的异步操作：\n```\n\tgo db.compactionError()\n\tgo db.mpoolDrain()\n\n\tif readOnly {\n\t\tdb.SetReadOnly()\n\t} else {\n\t\tdb.closeW.Add(2)\n\t\tgo db.tCompaction()\n\t\tgo db.mCompaction()\n\t\t// go db.jWriter()\n\t}\n```\n## 总结\n由此可见，leveldb中，使用了大量的异步逻辑来保证存储的高性能。同时也是利用了AOF原理来提高高可用性。","slug":"level-db-start","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.525Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58g000amauy9y47fsnc","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>核心是逐步学习leveldb的实现，而其中一步步从读写开始学习相关实现</p>\n<h2 id=\"打开的方法\"><a href=\"#打开的方法\" class=\"headerlink\" title=\"打开的方法\"></a>打开的方法</h2><p>从上文的demo，我们可以看出常见的打开方式是传入一个文件夹目录，方法是<code>OpenFile</code>，而针对各种常见，leveldb也提供了多种方法，例如可以自身传入一个存储方式的<code>Open(stor storage.Storage, o *opt.Options)</code>、直接从目录中恢复数据的<code>RecoverFile(path string, o *opt.Options)</code>等。而此次，我们核心从基础的OpenFile方法中入手，看看在打开leveldb时，是如何进行初始化操作。</p>\n<h2 id=\"数据的获取\"><a href=\"#数据的获取\" class=\"headerlink\" title=\"数据的获取\"></a>数据的获取</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stor, err :&#x3D; storage.OpenFile(path, o.GetReadOnly())</span><br></pre></td></tr></table></figure>\n<p>最初引入眼帘的便是通过<code>storage.OpenFile</code>去持有一个存储对象。这其中可以使用内存作为存储，当然大部分情况还是使用文件存储。<br>在打开文件后，需要开始检查路径是否存在、检查文件锁是否存在。\b检查完这2项后，还有就是确定当前是否只读，如果只读，则不需要新建Log文件，因为Log文件是用于支持AOF能力，否则则需要重建。<br>当检查完成后，便会得到以下的结构体：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fs :&#x3D; &amp;fileStorage&#123;</span><br><span class=\"line\">\tpath:     path,</span><br><span class=\"line\">\treadOnly: readOnly,</span><br><span class=\"line\">\tflock:    flock,</span><br><span class=\"line\">\tlogw:     logw,</span><br><span class=\"line\">\tlogSize:  logSize,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结构体中核心包含路径、是否只读、是否锁，以及log文件相关数据<br>当然，还有有趣的一行代码是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">runtime.SetFinalizer(fs, (*fileStorage).Close)</span><br></pre></td></tr></table></figure>\n<p>这行代码的目的和析构函数类似，当对象销毁时，进行善后处理。</p>\n<h2 id=\"会话的构建\"><a href=\"#会话的构建\" class=\"headerlink\" title=\"会话的构建\"></a>会话的构建</h2><p>当已经持有存储对象时，第一步就开始针对存储对象构建会话session信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s, err :&#x3D; newSession(stor, o)</span><br><span class=\"line\">\ts &#x3D; &amp;session&#123;</span><br><span class=\"line\">\t\tstor:      newIStorage(stor),</span><br><span class=\"line\">\t\tstorLock:  storLock,</span><br><span class=\"line\">\t\trefCh:     make(chan *vTask),</span><br><span class=\"line\">\t\trelCh:     make(chan *vTask),</span><br><span class=\"line\">\t\tdeltaCh:   make(chan *vDelta),</span><br><span class=\"line\">\t\tabandon:   make(chan int64),</span><br><span class=\"line\">\t\tfileRefCh: make(chan chan map[int64]int),</span><br><span class=\"line\">\t\tcloseC:    make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>会话中一个大的属性便是管道信息，可以见得session持有了多类管道，中间的能力简单来说就是，当leveldb中文件存在变更，都是通过session来进行异步操作。例如文件的删除和添加。而后会启动一个协程来辅助处理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go s.refLoop()</span><br></pre></td></tr></table></figure>\n<p>得到session对象后，则需要用version对象来管理各个版本的文件信息，这也是保证leveldb中并发安全的基础</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.setVersion(nil, newVersion(s))</span><br><span class=\"line\">--- </span><br><span class=\"line\"></span><br><span class=\"line\">func newVersion(s *session) *version &#123;</span><br><span class=\"line\">\tid :&#x3D; atomic.AddInt64(&amp;s.ntVersionId, 1)</span><br><span class=\"line\">\tnv :&#x3D; &amp;version&#123;s: s, id: id - 1&#125;</span><br><span class=\"line\">\treturn nv</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当在初始化时，仅仅只是将version和session进行绑定。</p>\n<h2 id=\"奔溃恢复\"><a href=\"#奔溃恢复\" class=\"headerlink\" title=\"奔溃恢复\"></a>奔溃恢复</h2><p>初始化完基本信息，leveldb就进入了奔溃恢复流程，这也是所有存储不可避免的一个机制，包括mysql。而崩溃恢复也是针对session而已，最终核心也是恢复出上一次存储的version信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">err &#x3D; s.recover()</span><br></pre></td></tr></table></figure>\n<p>首先第一步恢复就是恢复当前的存储基本信息，这也映射到了leveldb中的current文件中对应的Manifest文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fd, err :&#x3D; s.stor.GetMeta()</span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">reader, err :&#x3D; s.stor.Open(fd)</span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">defer reader.Close()</span><br></pre></td></tr></table></figure>\n<p>得到Current文件后，就会生成一个记事本journal对象，这个对象管理着Log文件内容，而Manifest文件本书也是Log文件格式存储，所以，直接复用即可。<br>文件格式本文暂时不仔细描述，而从Manifest文件中，可以解析出，当前数据库使用的对比方法、压缩格式、各层级的文件信息，至此，我们就可以产生出一个新的version对象。</p>\n<h2 id=\"数据库对象构建\"><a href=\"#数据库对象构建\" class=\"headerlink\" title=\"数据库对象构建\"></a>数据库对象构建</h2><p>session本身是管理此次底层version的变更，而再上一层则需要一个db层来管理对外接口以及内存和文件的事件管理。所以，这一层更多的是压缩、和写入的管理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db :&#x3D; &amp;DB&#123;</span><br><span class=\"line\">\t\ts: s,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Initial sequence</span><br><span class=\"line\">\t\tseq: s.stSeqNum,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; MemDB</span><br><span class=\"line\">\t\tmemPool: make(chan *memdb.DB, 1),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Snapshot</span><br><span class=\"line\">\t\tsnapsList: list.New(),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Write</span><br><span class=\"line\">\t\tbatchPool:    sync.Pool&#123;New: newBatch&#125;,</span><br><span class=\"line\">\t\twriteMergeC:  make(chan writeMerge),</span><br><span class=\"line\">\t\twriteMergedC: make(chan bool),</span><br><span class=\"line\">\t\twriteLockC:   make(chan struct&#123;&#125;, 1),</span><br><span class=\"line\">\t\twriteAckC:    make(chan error),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Compaction</span><br><span class=\"line\">\t\ttcompCmdC:   make(chan cCmd),</span><br><span class=\"line\">\t\ttcompPauseC: make(chan chan&lt;- struct&#123;&#125;),</span><br><span class=\"line\">\t\tmcompCmdC:   make(chan cCmd),</span><br><span class=\"line\">\t\tcompErrC:    make(chan error),</span><br><span class=\"line\">\t\tcompPerErrC: make(chan error),</span><br><span class=\"line\">\t\tcompErrSetC: make(chan error),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Close</span><br><span class=\"line\">\t\tcloseC: make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>由结构体可见大部分是针对压缩和写入合并使用的管道对象。<br>而生成完session后，仅仅只是吧以及落磁盘的level文件加载，而在崩溃前的内存数据还在丢失的，这些数据则需要从Log文件中恢复，这些则是在DB生成后恢复，当然恢复也是直接入memDB中，当做写入执行。中间必然也就触发了压缩和version的变更。</p>\n<p>当Log文件恢复后，最终就是启动各类的管道来执行相关的异步操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go db.compactionError()</span><br><span class=\"line\">go db.mpoolDrain()</span><br><span class=\"line\"></span><br><span class=\"line\">if readOnly &#123;</span><br><span class=\"line\">\tdb.SetReadOnly()</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">\tdb.closeW.Add(2)</span><br><span class=\"line\">\tgo db.tCompaction()</span><br><span class=\"line\">\tgo db.mCompaction()</span><br><span class=\"line\">\t&#x2F;&#x2F; go db.jWriter()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>由此可见，leveldb中，使用了大量的异步逻辑来保证存储的高性能。同时也是利用了AOF原理来提高高可用性。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>核心是逐步学习leveldb的实现，而其中一步步从读写开始学习相关实现</p>\n<h2 id=\"打开的方法\"><a href=\"#打开的方法\" class=\"headerlink\" title=\"打开的方法\"></a>打开的方法</h2><p>从上文的demo，我们可以看出常见的打开方式是传入一个文件夹目录，方法是<code>OpenFile</code>，而针对各种常见，leveldb也提供了多种方法，例如可以自身传入一个存储方式的<code>Open(stor storage.Storage, o *opt.Options)</code>、直接从目录中恢复数据的<code>RecoverFile(path string, o *opt.Options)</code>等。而此次，我们核心从基础的OpenFile方法中入手，看看在打开leveldb时，是如何进行初始化操作。</p>\n<h2 id=\"数据的获取\"><a href=\"#数据的获取\" class=\"headerlink\" title=\"数据的获取\"></a>数据的获取</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stor, err :&#x3D; storage.OpenFile(path, o.GetReadOnly())</span><br></pre></td></tr></table></figure>\n<p>最初引入眼帘的便是通过<code>storage.OpenFile</code>去持有一个存储对象。这其中可以使用内存作为存储，当然大部分情况还是使用文件存储。<br>在打开文件后，需要开始检查路径是否存在、检查文件锁是否存在。\b检查完这2项后，还有就是确定当前是否只读，如果只读，则不需要新建Log文件，因为Log文件是用于支持AOF能力，否则则需要重建。<br>当检查完成后，便会得到以下的结构体：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fs :&#x3D; &amp;fileStorage&#123;</span><br><span class=\"line\">\tpath:     path,</span><br><span class=\"line\">\treadOnly: readOnly,</span><br><span class=\"line\">\tflock:    flock,</span><br><span class=\"line\">\tlogw:     logw,</span><br><span class=\"line\">\tlogSize:  logSize,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结构体中核心包含路径、是否只读、是否锁，以及log文件相关数据<br>当然，还有有趣的一行代码是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">runtime.SetFinalizer(fs, (*fileStorage).Close)</span><br></pre></td></tr></table></figure>\n<p>这行代码的目的和析构函数类似，当对象销毁时，进行善后处理。</p>\n<h2 id=\"会话的构建\"><a href=\"#会话的构建\" class=\"headerlink\" title=\"会话的构建\"></a>会话的构建</h2><p>当已经持有存储对象时，第一步就开始针对存储对象构建会话session信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s, err :&#x3D; newSession(stor, o)</span><br><span class=\"line\">\ts &#x3D; &amp;session&#123;</span><br><span class=\"line\">\t\tstor:      newIStorage(stor),</span><br><span class=\"line\">\t\tstorLock:  storLock,</span><br><span class=\"line\">\t\trefCh:     make(chan *vTask),</span><br><span class=\"line\">\t\trelCh:     make(chan *vTask),</span><br><span class=\"line\">\t\tdeltaCh:   make(chan *vDelta),</span><br><span class=\"line\">\t\tabandon:   make(chan int64),</span><br><span class=\"line\">\t\tfileRefCh: make(chan chan map[int64]int),</span><br><span class=\"line\">\t\tcloseC:    make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>会话中一个大的属性便是管道信息，可以见得session持有了多类管道，中间的能力简单来说就是，当leveldb中文件存在变更，都是通过session来进行异步操作。例如文件的删除和添加。而后会启动一个协程来辅助处理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go s.refLoop()</span><br></pre></td></tr></table></figure>\n<p>得到session对象后，则需要用version对象来管理各个版本的文件信息，这也是保证leveldb中并发安全的基础</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.setVersion(nil, newVersion(s))</span><br><span class=\"line\">--- </span><br><span class=\"line\"></span><br><span class=\"line\">func newVersion(s *session) *version &#123;</span><br><span class=\"line\">\tid :&#x3D; atomic.AddInt64(&amp;s.ntVersionId, 1)</span><br><span class=\"line\">\tnv :&#x3D; &amp;version&#123;s: s, id: id - 1&#125;</span><br><span class=\"line\">\treturn nv</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当在初始化时，仅仅只是将version和session进行绑定。</p>\n<h2 id=\"奔溃恢复\"><a href=\"#奔溃恢复\" class=\"headerlink\" title=\"奔溃恢复\"></a>奔溃恢复</h2><p>初始化完基本信息，leveldb就进入了奔溃恢复流程，这也是所有存储不可避免的一个机制，包括mysql。而崩溃恢复也是针对session而已，最终核心也是恢复出上一次存储的version信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">err &#x3D; s.recover()</span><br></pre></td></tr></table></figure>\n<p>首先第一步恢复就是恢复当前的存储基本信息，这也映射到了leveldb中的current文件中对应的Manifest文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fd, err :&#x3D; s.stor.GetMeta()</span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">reader, err :&#x3D; s.stor.Open(fd)</span><br><span class=\"line\">if err !&#x3D; nil &#123;</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">defer reader.Close()</span><br></pre></td></tr></table></figure>\n<p>得到Current文件后，就会生成一个记事本journal对象，这个对象管理着Log文件内容，而Manifest文件本书也是Log文件格式存储，所以，直接复用即可。<br>文件格式本文暂时不仔细描述，而从Manifest文件中，可以解析出，当前数据库使用的对比方法、压缩格式、各层级的文件信息，至此，我们就可以产生出一个新的version对象。</p>\n<h2 id=\"数据库对象构建\"><a href=\"#数据库对象构建\" class=\"headerlink\" title=\"数据库对象构建\"></a>数据库对象构建</h2><p>session本身是管理此次底层version的变更，而再上一层则需要一个db层来管理对外接口以及内存和文件的事件管理。所以，这一层更多的是压缩、和写入的管理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db :&#x3D; &amp;DB&#123;</span><br><span class=\"line\">\t\ts: s,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Initial sequence</span><br><span class=\"line\">\t\tseq: s.stSeqNum,</span><br><span class=\"line\">\t\t&#x2F;&#x2F; MemDB</span><br><span class=\"line\">\t\tmemPool: make(chan *memdb.DB, 1),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Snapshot</span><br><span class=\"line\">\t\tsnapsList: list.New(),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Write</span><br><span class=\"line\">\t\tbatchPool:    sync.Pool&#123;New: newBatch&#125;,</span><br><span class=\"line\">\t\twriteMergeC:  make(chan writeMerge),</span><br><span class=\"line\">\t\twriteMergedC: make(chan bool),</span><br><span class=\"line\">\t\twriteLockC:   make(chan struct&#123;&#125;, 1),</span><br><span class=\"line\">\t\twriteAckC:    make(chan error),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Compaction</span><br><span class=\"line\">\t\ttcompCmdC:   make(chan cCmd),</span><br><span class=\"line\">\t\ttcompPauseC: make(chan chan&lt;- struct&#123;&#125;),</span><br><span class=\"line\">\t\tmcompCmdC:   make(chan cCmd),</span><br><span class=\"line\">\t\tcompErrC:    make(chan error),</span><br><span class=\"line\">\t\tcompPerErrC: make(chan error),</span><br><span class=\"line\">\t\tcompErrSetC: make(chan error),</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Close</span><br><span class=\"line\">\t\tcloseC: make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>由结构体可见大部分是针对压缩和写入合并使用的管道对象。<br>而生成完session后，仅仅只是吧以及落磁盘的level文件加载，而在崩溃前的内存数据还在丢失的，这些数据则需要从Log文件中恢复，这些则是在DB生成后恢复，当然恢复也是直接入memDB中，当做写入执行。中间必然也就触发了压缩和version的变更。</p>\n<p>当Log文件恢复后，最终就是启动各类的管道来执行相关的异步操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go db.compactionError()</span><br><span class=\"line\">go db.mpoolDrain()</span><br><span class=\"line\"></span><br><span class=\"line\">if readOnly &#123;</span><br><span class=\"line\">\tdb.SetReadOnly()</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">\tdb.closeW.Add(2)</span><br><span class=\"line\">\tgo db.tCompaction()</span><br><span class=\"line\">\tgo db.mCompaction()</span><br><span class=\"line\">\t&#x2F;&#x2F; go db.jWriter()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>由此可见，leveldb中，使用了大量的异步逻辑来保证存储的高性能。同时也是利用了AOF原理来提高高可用性。</p>\n"},{"title":"浅析levelDB流程（读流程）","_content":"\n## 前言\n\n前文描述完写流程，此时就需要描述一下大体的数据读取流程。\n\n## 命令封装\n\n读取的时候，由于是kv数据库，当然只会有一个参数，那就是key的值，同时还有一个读取时的选型，当前是包含是否读取缓存、是否严格查询。两者含义挖坑之后再填\n\n同时，在得到key的数据后，为了避免读写冲突，所以会在db层面生成一个快照，保证读取的数据不会被后来的写入所影响，这也是变现的实现了一下可重复读？\n\n而具体的快照，则只是当前数据库中的唯一递增序号。这也避免了在读取时，数据被销毁，导致数据丢失。\n\n进入读取方法后，leveldb还会将读取命令生成一个internalKey对象，其中包含`key`、`seq`、`keyType`三个属性。\n\n\n## 读取MEM流程\n\n`get`方法里面，还支持传入memDB和tFile对象，目的是支持事务操作，这块逻辑暂不考虑。\n\n拿到数据后，则优先从`memDB`中获取数据，当然，在leveldb中，memDB一直存在2个：`mem`和`frozenMem`。在读取时，为了避免内存变更，则将2者进行引用增加。\n\n获取到memDB后,则直接从跳表中获取,\b\b如果获取到后，则直接返回，此时，引用并没有清理，且引用清理时机过长，完全可能导致引用一直不释放。\n\n## 读取FILE流程\n\nfile中，则涉及到version的概念，因为之前讲过，version中保存了整个leveldb的文件信息，所以，在数据读取时，还是需要保证version不会被销毁，同理还是增加引用。\n\n其次则就会传入key信息，此时，则需要对leveldb每一次文件进行遍历。\n\n第一遍历level0文件，全部遍历，第二则遍历levle0+的文件，则只需要对比最大key信息即可，\n\n\n\n","source":"_posts/level-db-read.md","raw":"---\ntitle: 浅析levelDB流程（读流程）\n---\n\n## 前言\n\n前文描述完写流程，此时就需要描述一下大体的数据读取流程。\n\n## 命令封装\n\n读取的时候，由于是kv数据库，当然只会有一个参数，那就是key的值，同时还有一个读取时的选型，当前是包含是否读取缓存、是否严格查询。两者含义挖坑之后再填\n\n同时，在得到key的数据后，为了避免读写冲突，所以会在db层面生成一个快照，保证读取的数据不会被后来的写入所影响，这也是变现的实现了一下可重复读？\n\n而具体的快照，则只是当前数据库中的唯一递增序号。这也避免了在读取时，数据被销毁，导致数据丢失。\n\n进入读取方法后，leveldb还会将读取命令生成一个internalKey对象，其中包含`key`、`seq`、`keyType`三个属性。\n\n\n## 读取MEM流程\n\n`get`方法里面，还支持传入memDB和tFile对象，目的是支持事务操作，这块逻辑暂不考虑。\n\n拿到数据后，则优先从`memDB`中获取数据，当然，在leveldb中，memDB一直存在2个：`mem`和`frozenMem`。在读取时，为了避免内存变更，则将2者进行引用增加。\n\n获取到memDB后,则直接从跳表中获取,\b\b如果获取到后，则直接返回，此时，引用并没有清理，且引用清理时机过长，完全可能导致引用一直不释放。\n\n## 读取FILE流程\n\nfile中，则涉及到version的概念，因为之前讲过，version中保存了整个leveldb的文件信息，所以，在数据读取时，还是需要保证version不会被销毁，同理还是增加引用。\n\n其次则就会传入key信息，此时，则需要对leveldb每一次文件进行遍历。\n\n第一遍历level0文件，全部遍历，第二则遍历levle0+的文件，则只需要对比最大key信息即可，\n\n\n\n","slug":"level-db-read","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58i000cmauyhg6v82va","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>前文描述完写流程，此时就需要描述一下大体的数据读取流程。</p>\n<h2 id=\"命令封装\"><a href=\"#命令封装\" class=\"headerlink\" title=\"命令封装\"></a>命令封装</h2><p>读取的时候，由于是kv数据库，当然只会有一个参数，那就是key的值，同时还有一个读取时的选型，当前是包含是否读取缓存、是否严格查询。两者含义挖坑之后再填</p>\n<p>同时，在得到key的数据后，为了避免读写冲突，所以会在db层面生成一个快照，保证读取的数据不会被后来的写入所影响，这也是变现的实现了一下可重复读？</p>\n<p>而具体的快照，则只是当前数据库中的唯一递增序号。这也避免了在读取时，数据被销毁，导致数据丢失。</p>\n<p>进入读取方法后，leveldb还会将读取命令生成一个internalKey对象，其中包含<code>key</code>、<code>seq</code>、<code>keyType</code>三个属性。</p>\n<h2 id=\"读取MEM流程\"><a href=\"#读取MEM流程\" class=\"headerlink\" title=\"读取MEM流程\"></a>读取MEM流程</h2><p><code>get</code>方法里面，还支持传入memDB和tFile对象，目的是支持事务操作，这块逻辑暂不考虑。</p>\n<p>拿到数据后，则优先从<code>memDB</code>中获取数据，当然，在leveldb中，memDB一直存在2个：<code>mem</code>和<code>frozenMem</code>。在读取时，为了避免内存变更，则将2者进行引用增加。</p>\n<p>获取到memDB后,则直接从跳表中获取,\b\b如果获取到后，则直接返回，此时，引用并没有清理，且引用清理时机过长，完全可能导致引用一直不释放。</p>\n<h2 id=\"读取FILE流程\"><a href=\"#读取FILE流程\" class=\"headerlink\" title=\"读取FILE流程\"></a>读取FILE流程</h2><p>file中，则涉及到version的概念，因为之前讲过，version中保存了整个leveldb的文件信息，所以，在数据读取时，还是需要保证version不会被销毁，同理还是增加引用。</p>\n<p>其次则就会传入key信息，此时，则需要对leveldb每一次文件进行遍历。</p>\n<p>第一遍历level0文件，全部遍历，第二则遍历levle0+的文件，则只需要对比最大key信息即可，</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>前文描述完写流程，此时就需要描述一下大体的数据读取流程。</p>\n<h2 id=\"命令封装\"><a href=\"#命令封装\" class=\"headerlink\" title=\"命令封装\"></a>命令封装</h2><p>读取的时候，由于是kv数据库，当然只会有一个参数，那就是key的值，同时还有一个读取时的选型，当前是包含是否读取缓存、是否严格查询。两者含义挖坑之后再填</p>\n<p>同时，在得到key的数据后，为了避免读写冲突，所以会在db层面生成一个快照，保证读取的数据不会被后来的写入所影响，这也是变现的实现了一下可重复读？</p>\n<p>而具体的快照，则只是当前数据库中的唯一递增序号。这也避免了在读取时，数据被销毁，导致数据丢失。</p>\n<p>进入读取方法后，leveldb还会将读取命令生成一个internalKey对象，其中包含<code>key</code>、<code>seq</code>、<code>keyType</code>三个属性。</p>\n<h2 id=\"读取MEM流程\"><a href=\"#读取MEM流程\" class=\"headerlink\" title=\"读取MEM流程\"></a>读取MEM流程</h2><p><code>get</code>方法里面，还支持传入memDB和tFile对象，目的是支持事务操作，这块逻辑暂不考虑。</p>\n<p>拿到数据后，则优先从<code>memDB</code>中获取数据，当然，在leveldb中，memDB一直存在2个：<code>mem</code>和<code>frozenMem</code>。在读取时，为了避免内存变更，则将2者进行引用增加。</p>\n<p>获取到memDB后,则直接从跳表中获取,\b\b如果获取到后，则直接返回，此时，引用并没有清理，且引用清理时机过长，完全可能导致引用一直不释放。</p>\n<h2 id=\"读取FILE流程\"><a href=\"#读取FILE流程\" class=\"headerlink\" title=\"读取FILE流程\"></a>读取FILE流程</h2><p>file中，则涉及到version的概念，因为之前讲过，version中保存了整个leveldb的文件信息，所以，在数据读取时，还是需要保证version不会被销毁，同理还是增加引用。</p>\n<p>其次则就会传入key信息，此时，则需要对leveldb每一次文件进行遍历。</p>\n<p>第一遍历level0文件，全部遍历，第二则遍历levle0+的文件，则只需要对比最大key信息即可，</p>\n"},{"title":"浅析levelDB文件格式","_content":"\n## 前言\n\nleveldb本身是基于文件来实现的高速kv数据库，期间涉及到了多种文件格式\n\n## 文件介绍\n\n### CURRENT文件\n\n此文件是针对奔溃恢复时，定位MANIFEST文件使用，其中的存储内容就是MANIFEST文件的文件名。\n\n### LOCK文件\n\n此文件控制多进程访问数据库的关键。当一个进程打开了数据库时，会在这个文件上加上互斥文件锁，进程结束时，锁就会自动释放。\n\n### MANIFEST文件\n\n所有文件的 Key 取值范围、层级和其它元信息会存储在数据库目录里面的 MANIFEST 文件中。数据库打开时，读取一下这个文件就知道了所有文件的层级和 Key 取值范围。\n\nMANIFEST 文件也有版本号，它的版本号体现在文件名上如 MANIFEST-000361。每一次重新打开数据库，都会生成一个新的 MANIFEST 文件，具有不同的版本号，然后还需要将老的 MANIFEST 文件删除。\n\n数据库目录中还有另外一个文件 CURRENT，它里面的内容很简单，就是当前 MANIFEST 的文件名。LevelDB 首先读取 CURRENT 文件才知道哪个 MANIFEST 文件是有效文件。在遇到断电时，会存在一个小概率中间状态，新旧 MANIFEST 文件共存于数据库目录中。\n\n### LOG文件\n\n在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据.\n\nLog文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位\n\n### SST文件\n\n同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，红色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。\n\n从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型：紫色的Meta Block，红色的MetaBlock 索引和蓝色的数据索引块以及一个文件尾部块。\n\n## 相关链接\n\n[LevelDB SSTable文件 - Tekkaman - 博客园](https://www.cnblogs.com/tekkaman/p/4877100.html)","source":"_posts/level-db-file.md","raw":"---\ntitle: 浅析levelDB文件格式\n---\n\n## 前言\n\nleveldb本身是基于文件来实现的高速kv数据库，期间涉及到了多种文件格式\n\n## 文件介绍\n\n### CURRENT文件\n\n此文件是针对奔溃恢复时，定位MANIFEST文件使用，其中的存储内容就是MANIFEST文件的文件名。\n\n### LOCK文件\n\n此文件控制多进程访问数据库的关键。当一个进程打开了数据库时，会在这个文件上加上互斥文件锁，进程结束时，锁就会自动释放。\n\n### MANIFEST文件\n\n所有文件的 Key 取值范围、层级和其它元信息会存储在数据库目录里面的 MANIFEST 文件中。数据库打开时，读取一下这个文件就知道了所有文件的层级和 Key 取值范围。\n\nMANIFEST 文件也有版本号，它的版本号体现在文件名上如 MANIFEST-000361。每一次重新打开数据库，都会生成一个新的 MANIFEST 文件，具有不同的版本号，然后还需要将老的 MANIFEST 文件删除。\n\n数据库目录中还有另外一个文件 CURRENT，它里面的内容很简单，就是当前 MANIFEST 的文件名。LevelDB 首先读取 CURRENT 文件才知道哪个 MANIFEST 文件是有效文件。在遇到断电时，会存在一个小概率中间状态，新旧 MANIFEST 文件共存于数据库目录中。\n\n### LOG文件\n\n在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据.\n\nLog文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位\n\n### SST文件\n\n同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，红色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。\n\n从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型：紫色的Meta Block，红色的MetaBlock 索引和蓝色的数据索引块以及一个文件尾部块。\n\n## 相关链接\n\n[LevelDB SSTable文件 - Tekkaman - 博客园](https://www.cnblogs.com/tekkaman/p/4877100.html)","slug":"level-db-file","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.495Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58j000dmauy5b5lefjt","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>leveldb本身是基于文件来实现的高速kv数据库，期间涉及到了多种文件格式</p>\n<h2 id=\"文件介绍\"><a href=\"#文件介绍\" class=\"headerlink\" title=\"文件介绍\"></a>文件介绍</h2><h3 id=\"CURRENT文件\"><a href=\"#CURRENT文件\" class=\"headerlink\" title=\"CURRENT文件\"></a>CURRENT文件</h3><p>此文件是针对奔溃恢复时，定位MANIFEST文件使用，其中的存储内容就是MANIFEST文件的文件名。</p>\n<h3 id=\"LOCK文件\"><a href=\"#LOCK文件\" class=\"headerlink\" title=\"LOCK文件\"></a>LOCK文件</h3><p>此文件控制多进程访问数据库的关键。当一个进程打开了数据库时，会在这个文件上加上互斥文件锁，进程结束时，锁就会自动释放。</p>\n<h3 id=\"MANIFEST文件\"><a href=\"#MANIFEST文件\" class=\"headerlink\" title=\"MANIFEST文件\"></a>MANIFEST文件</h3><p>所有文件的 Key 取值范围、层级和其它元信息会存储在数据库目录里面的 MANIFEST 文件中。数据库打开时，读取一下这个文件就知道了所有文件的层级和 Key 取值范围。</p>\n<p>MANIFEST 文件也有版本号，它的版本号体现在文件名上如 MANIFEST-000361。每一次重新打开数据库，都会生成一个新的 MANIFEST 文件，具有不同的版本号，然后还需要将老的 MANIFEST 文件删除。</p>\n<p>数据库目录中还有另外一个文件 CURRENT，它里面的内容很简单，就是当前 MANIFEST 的文件名。LevelDB 首先读取 CURRENT 文件才知道哪个 MANIFEST 文件是有效文件。在遇到断电时，会存在一个小概率中间状态，新旧 MANIFEST 文件共存于数据库目录中。</p>\n<h3 id=\"LOG文件\"><a href=\"#LOG文件\" class=\"headerlink\" title=\"LOG文件\"></a>LOG文件</h3><p>在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据.</p>\n<p>Log文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位</p>\n<h3 id=\"SST文件\"><a href=\"#SST文件\" class=\"headerlink\" title=\"SST文件\"></a>SST文件</h3><p>同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，红色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。</p>\n<p>从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型：紫色的Meta Block，红色的MetaBlock 索引和蓝色的数据索引块以及一个文件尾部块。</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://www.cnblogs.com/tekkaman/p/4877100.html\" target=\"_blank\" rel=\"noopener\">LevelDB SSTable文件 - Tekkaman - 博客园</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>leveldb本身是基于文件来实现的高速kv数据库，期间涉及到了多种文件格式</p>\n<h2 id=\"文件介绍\"><a href=\"#文件介绍\" class=\"headerlink\" title=\"文件介绍\"></a>文件介绍</h2><h3 id=\"CURRENT文件\"><a href=\"#CURRENT文件\" class=\"headerlink\" title=\"CURRENT文件\"></a>CURRENT文件</h3><p>此文件是针对奔溃恢复时，定位MANIFEST文件使用，其中的存储内容就是MANIFEST文件的文件名。</p>\n<h3 id=\"LOCK文件\"><a href=\"#LOCK文件\" class=\"headerlink\" title=\"LOCK文件\"></a>LOCK文件</h3><p>此文件控制多进程访问数据库的关键。当一个进程打开了数据库时，会在这个文件上加上互斥文件锁，进程结束时，锁就会自动释放。</p>\n<h3 id=\"MANIFEST文件\"><a href=\"#MANIFEST文件\" class=\"headerlink\" title=\"MANIFEST文件\"></a>MANIFEST文件</h3><p>所有文件的 Key 取值范围、层级和其它元信息会存储在数据库目录里面的 MANIFEST 文件中。数据库打开时，读取一下这个文件就知道了所有文件的层级和 Key 取值范围。</p>\n<p>MANIFEST 文件也有版本号，它的版本号体现在文件名上如 MANIFEST-000361。每一次重新打开数据库，都会生成一个新的 MANIFEST 文件，具有不同的版本号，然后还需要将老的 MANIFEST 文件删除。</p>\n<p>数据库目录中还有另外一个文件 CURRENT，它里面的内容很简单，就是当前 MANIFEST 的文件名。LevelDB 首先读取 CURRENT 文件才知道哪个 MANIFEST 文件是有效文件。在遇到断电时，会存在一个小概率中间状态，新旧 MANIFEST 文件共存于数据库目录中。</p>\n<h3 id=\"LOG文件\"><a href=\"#LOG文件\" class=\"headerlink\" title=\"LOG文件\"></a>LOG文件</h3><p>在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据.</p>\n<p>Log文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位</p>\n<h3 id=\"SST文件\"><a href=\"#SST文件\" class=\"headerlink\" title=\"SST文件\"></a>SST文件</h3><p>同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，红色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。</p>\n<p>从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型：紫色的Meta Block，红色的MetaBlock 索引和蓝色的数据索引块以及一个文件尾部块。</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://www.cnblogs.com/tekkaman/p/4877100.html\" target=\"_blank\" rel=\"noopener\">LevelDB SSTable文件 - Tekkaman - 博客园</a></p>\n"},{"title":"浅析levelDB流程（写流程）","_content":"\n## 前言\n\n打开流程完成了整个db的初始化，而后就是整个level对比的存储流程，如何读写db是核心业务。当然读写自然会触发压缩流程，但本文单纯只会串联整个的读写过程，保证内容的简洁，至于压缩则另开一篇详解。\n\n\n## 写流程\n\n### 命令封装\n\n之前文章中，我们有提过更新的2个操作，在最后底层其实是一个操作：\n\n```\nfunc (db *DB) Put(key, value []byte, wo *opt.WriteOptions) error {\n\treturn db.putRec(keyTypeVal, key, value, wo)\n}\n\nfunc (db *DB) Delete(key []byte, wo *opt.WriteOptions) error {\n\treturn db.putRec(keyTypeDel, key, nil, wo)\n}\n```\n\n可以看出，在`Put`和`Delete`命令中，最终会直接调用`putRec`方法，而在此方法中，做的核心逻辑就是，抢锁，并等待信息，其中抢锁的逻辑还是由`channel`实现，逻辑后续再理，先了解一下写入流程`writeLocked`方法：\n```\nbatch := db.batchPool.Get().(*Batch)\nbatch.Reset()\nbatch.appendRec(kt, key, value)\nreturn db.writeLocked(batch, batch, merge, sync)\n```\n调用该方法后，则就是AOF写入以及落入`memdb`跳表数据库中：\n```\n\t// Seq number.\n\tseq := db.seq + 1\n\n\t// Write journal.\n\tif err := db.writeJournal(batches, seq, sync); err != nil {\n\t\tdb.unlockWrite(overflow, merged, err)\n\t\treturn err\n\t}\n\n\t// Put batches.\n\tfor _, batch := range batches {\n\t\tif err := batch.putMem(seq, mdb.DB); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tseq += uint64(batch.Len())\n\t}\n```\n至此，数据已经落入存储中，并返回告知请求处理正常。那么，这一套流程，中间还存在哪些问题呢？\n其中提高吞吐、提高内存空间利用率则是中间的优化点。\n\n### 合并写\n\n关于吞吐量的计算逻辑可以参考：https://zhuanlan.zhihu.com/p/337708438\n\n由于本身leveldb会写入内存，所以中间存在锁的抢占，而在golang中，leveldb使用的是channel进行锁争抢，当你能写入writeLockC管道时，便可以继续写入操作。然而，锁的争抢必定会导致性能下降，那么，合并写就成为了提供性能的一个解决方案。\n\n合并锁的逻辑就是，优先尝试写入writeMergeC管道中，如果写入成功，则等待合并写的结果返回\n```\ncase db.writeMergeC <- writeMerge{sync: sync, keyType: kt, key: key, value: value}:\n    if <-db.writeMergedC {\n        // Write is merged.\n        return <-db.writeAckC\n    }\n    // Write is not merged, the write lock is handed to us. Continue.\ncase db.writeLockC <- struct{}{}:\n    // Write lock acquired.\ncase err := <-db.compPerErrC:\n    // Compaction error.\n    return err\ncase <-db.closeC:\n    // Closed\n    return ErrClosed\n}\n```\n而如果合并锁写入不成功，则尝试去抢写入锁，如果当前写入锁还是没有释放，那其中有可能导致异常出现（猜测）。\n而在抢到写入锁的协程中，则会不断的等待合并写的请求达到上限\n```\nmerge: \n\nfor mergeLimit > 0 {\n    select {\n    case incoming := <-db.writeMergeC:\n        ... ...\n    default:\n        break merge\n    }\n}\n```\n由此可见，当一次写入异常时，常常会阻塞所有的合并写异常，所有，合并写其实是针对大数据量的变更。\n\n当然，如果处理完成后，则会写入writeAckC管道告知等待的写入，但是如果此次合并写并没有写入完成写入，则会使其抢锁成功，并自身去进行写入，这块逻辑便是之前的writeMergeC和writeLockC逻辑。\n```\nfunc (db *DB) unlockWrite(overflow bool, merged int, err error) {\n\tfor i := 0; i < merged; i++ {\n\t\tdb.writeAckC <- err\n\t}\n\tif overflow {\n\t\t// Pass lock to the next write (that failed to merge).\n\t\tdb.writeMergedC <- false\n\t} else {\n\t\t// Release lock.\n\t\t<-db.writeLockC\n\t}\n}\n```\n\n","source":"_posts/level-db-write.md","raw":"---\ntitle: 浅析levelDB流程（写流程）\n---\n\n## 前言\n\n打开流程完成了整个db的初始化，而后就是整个level对比的存储流程，如何读写db是核心业务。当然读写自然会触发压缩流程，但本文单纯只会串联整个的读写过程，保证内容的简洁，至于压缩则另开一篇详解。\n\n\n## 写流程\n\n### 命令封装\n\n之前文章中，我们有提过更新的2个操作，在最后底层其实是一个操作：\n\n```\nfunc (db *DB) Put(key, value []byte, wo *opt.WriteOptions) error {\n\treturn db.putRec(keyTypeVal, key, value, wo)\n}\n\nfunc (db *DB) Delete(key []byte, wo *opt.WriteOptions) error {\n\treturn db.putRec(keyTypeDel, key, nil, wo)\n}\n```\n\n可以看出，在`Put`和`Delete`命令中，最终会直接调用`putRec`方法，而在此方法中，做的核心逻辑就是，抢锁，并等待信息，其中抢锁的逻辑还是由`channel`实现，逻辑后续再理，先了解一下写入流程`writeLocked`方法：\n```\nbatch := db.batchPool.Get().(*Batch)\nbatch.Reset()\nbatch.appendRec(kt, key, value)\nreturn db.writeLocked(batch, batch, merge, sync)\n```\n调用该方法后，则就是AOF写入以及落入`memdb`跳表数据库中：\n```\n\t// Seq number.\n\tseq := db.seq + 1\n\n\t// Write journal.\n\tif err := db.writeJournal(batches, seq, sync); err != nil {\n\t\tdb.unlockWrite(overflow, merged, err)\n\t\treturn err\n\t}\n\n\t// Put batches.\n\tfor _, batch := range batches {\n\t\tif err := batch.putMem(seq, mdb.DB); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tseq += uint64(batch.Len())\n\t}\n```\n至此，数据已经落入存储中，并返回告知请求处理正常。那么，这一套流程，中间还存在哪些问题呢？\n其中提高吞吐、提高内存空间利用率则是中间的优化点。\n\n### 合并写\n\n关于吞吐量的计算逻辑可以参考：https://zhuanlan.zhihu.com/p/337708438\n\n由于本身leveldb会写入内存，所以中间存在锁的抢占，而在golang中，leveldb使用的是channel进行锁争抢，当你能写入writeLockC管道时，便可以继续写入操作。然而，锁的争抢必定会导致性能下降，那么，合并写就成为了提供性能的一个解决方案。\n\n合并锁的逻辑就是，优先尝试写入writeMergeC管道中，如果写入成功，则等待合并写的结果返回\n```\ncase db.writeMergeC <- writeMerge{sync: sync, keyType: kt, key: key, value: value}:\n    if <-db.writeMergedC {\n        // Write is merged.\n        return <-db.writeAckC\n    }\n    // Write is not merged, the write lock is handed to us. Continue.\ncase db.writeLockC <- struct{}{}:\n    // Write lock acquired.\ncase err := <-db.compPerErrC:\n    // Compaction error.\n    return err\ncase <-db.closeC:\n    // Closed\n    return ErrClosed\n}\n```\n而如果合并锁写入不成功，则尝试去抢写入锁，如果当前写入锁还是没有释放，那其中有可能导致异常出现（猜测）。\n而在抢到写入锁的协程中，则会不断的等待合并写的请求达到上限\n```\nmerge: \n\nfor mergeLimit > 0 {\n    select {\n    case incoming := <-db.writeMergeC:\n        ... ...\n    default:\n        break merge\n    }\n}\n```\n由此可见，当一次写入异常时，常常会阻塞所有的合并写异常，所有，合并写其实是针对大数据量的变更。\n\n当然，如果处理完成后，则会写入writeAckC管道告知等待的写入，但是如果此次合并写并没有写入完成写入，则会使其抢锁成功，并自身去进行写入，这块逻辑便是之前的writeMergeC和writeLockC逻辑。\n```\nfunc (db *DB) unlockWrite(overflow bool, merged int, err error) {\n\tfor i := 0; i < merged; i++ {\n\t\tdb.writeAckC <- err\n\t}\n\tif overflow {\n\t\t// Pass lock to the next write (that failed to merge).\n\t\tdb.writeMergedC <- false\n\t} else {\n\t\t// Release lock.\n\t\t<-db.writeLockC\n\t}\n}\n```\n\n","slug":"level-db-write","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.539Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58k000emauy2feu84h6","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>打开流程完成了整个db的初始化，而后就是整个level对比的存储流程，如何读写db是核心业务。当然读写自然会触发压缩流程，但本文单纯只会串联整个的读写过程，保证内容的简洁，至于压缩则另开一篇详解。</p>\n<h2 id=\"写流程\"><a href=\"#写流程\" class=\"headerlink\" title=\"写流程\"></a>写流程</h2><h3 id=\"命令封装\"><a href=\"#命令封装\" class=\"headerlink\" title=\"命令封装\"></a>命令封装</h3><p>之前文章中，我们有提过更新的2个操作，在最后底层其实是一个操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (db *DB) Put(key, value []byte, wo *opt.WriteOptions) error &#123;</span><br><span class=\"line\">\treturn db.putRec(keyTypeVal, key, value, wo)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (db *DB) Delete(key []byte, wo *opt.WriteOptions) error &#123;</span><br><span class=\"line\">\treturn db.putRec(keyTypeDel, key, nil, wo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，在<code>Put</code>和<code>Delete</code>命令中，最终会直接调用<code>putRec</code>方法，而在此方法中，做的核心逻辑就是，抢锁，并等待信息，其中抢锁的逻辑还是由<code>channel</code>实现，逻辑后续再理，先了解一下写入流程<code>writeLocked</code>方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">batch :&#x3D; db.batchPool.Get().(*Batch)</span><br><span class=\"line\">batch.Reset()</span><br><span class=\"line\">batch.appendRec(kt, key, value)</span><br><span class=\"line\">return db.writeLocked(batch, batch, merge, sync)</span><br></pre></td></tr></table></figure>\n<p>调用该方法后，则就是AOF写入以及落入<code>memdb</code>跳表数据库中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; Seq number.</span><br><span class=\"line\">seq :&#x3D; db.seq + 1</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Write journal.</span><br><span class=\"line\">if err :&#x3D; db.writeJournal(batches, seq, sync); err !&#x3D; nil &#123;</span><br><span class=\"line\">\tdb.unlockWrite(overflow, merged, err)</span><br><span class=\"line\">\treturn err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Put batches.</span><br><span class=\"line\">for _, batch :&#x3D; range batches &#123;</span><br><span class=\"line\">\tif err :&#x3D; batch.putMem(seq, mdb.DB); err !&#x3D; nil &#123;</span><br><span class=\"line\">\t\tpanic(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tseq +&#x3D; uint64(batch.Len())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>至此，数据已经落入存储中，并返回告知请求处理正常。那么，这一套流程，中间还存在哪些问题呢？<br>其中提高吞吐、提高内存空间利用率则是中间的优化点。</p>\n<h3 id=\"合并写\"><a href=\"#合并写\" class=\"headerlink\" title=\"合并写\"></a>合并写</h3><p>关于吞吐量的计算逻辑可以参考：<a href=\"https://zhuanlan.zhihu.com/p/337708438\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/337708438</a></p>\n<p>由于本身leveldb会写入内存，所以中间存在锁的抢占，而在golang中，leveldb使用的是channel进行锁争抢，当你能写入writeLockC管道时，便可以继续写入操作。然而，锁的争抢必定会导致性能下降，那么，合并写就成为了提供性能的一个解决方案。</p>\n<p>合并锁的逻辑就是，优先尝试写入writeMergeC管道中，如果写入成功，则等待合并写的结果返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case db.writeMergeC &lt;- writeMerge&#123;sync: sync, keyType: kt, key: key, value: value&#125;:</span><br><span class=\"line\">    if &lt;-db.writeMergedC &#123;</span><br><span class=\"line\">        &#x2F;&#x2F; Write is merged.</span><br><span class=\"line\">        return &lt;-db.writeAckC</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;&#x2F; Write is not merged, the write lock is handed to us. Continue.</span><br><span class=\"line\">case db.writeLockC &lt;- struct&#123;&#125;&#123;&#125;:</span><br><span class=\"line\">    &#x2F;&#x2F; Write lock acquired.</span><br><span class=\"line\">case err :&#x3D; &lt;-db.compPerErrC:</span><br><span class=\"line\">    &#x2F;&#x2F; Compaction error.</span><br><span class=\"line\">    return err</span><br><span class=\"line\">case &lt;-db.closeC:</span><br><span class=\"line\">    &#x2F;&#x2F; Closed</span><br><span class=\"line\">    return ErrClosed</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而如果合并锁写入不成功，则尝试去抢写入锁，如果当前写入锁还是没有释放，那其中有可能导致异常出现（猜测）。<br>而在抢到写入锁的协程中，则会不断的等待合并写的请求达到上限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">merge: </span><br><span class=\"line\"></span><br><span class=\"line\">for mergeLimit &gt; 0 &#123;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case incoming :&#x3D; &lt;-db.writeMergeC:</span><br><span class=\"line\">        ... ...</span><br><span class=\"line\">    default:</span><br><span class=\"line\">        break merge</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由此可见，当一次写入异常时，常常会阻塞所有的合并写异常，所有，合并写其实是针对大数据量的变更。</p>\n<p>当然，如果处理完成后，则会写入writeAckC管道告知等待的写入，但是如果此次合并写并没有写入完成写入，则会使其抢锁成功，并自身去进行写入，这块逻辑便是之前的writeMergeC和writeLockC逻辑。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (db *DB) unlockWrite(overflow bool, merged int, err error) &#123;</span><br><span class=\"line\">\tfor i :&#x3D; 0; i &lt; merged; i++ &#123;</span><br><span class=\"line\">\t\tdb.writeAckC &lt;- err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif overflow &#123;</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Pass lock to the next write (that failed to merge).</span><br><span class=\"line\">\t\tdb.writeMergedC &lt;- false</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Release lock.</span><br><span class=\"line\">\t\t&lt;-db.writeLockC</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>打开流程完成了整个db的初始化，而后就是整个level对比的存储流程，如何读写db是核心业务。当然读写自然会触发压缩流程，但本文单纯只会串联整个的读写过程，保证内容的简洁，至于压缩则另开一篇详解。</p>\n<h2 id=\"写流程\"><a href=\"#写流程\" class=\"headerlink\" title=\"写流程\"></a>写流程</h2><h3 id=\"命令封装\"><a href=\"#命令封装\" class=\"headerlink\" title=\"命令封装\"></a>命令封装</h3><p>之前文章中，我们有提过更新的2个操作，在最后底层其实是一个操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (db *DB) Put(key, value []byte, wo *opt.WriteOptions) error &#123;</span><br><span class=\"line\">\treturn db.putRec(keyTypeVal, key, value, wo)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (db *DB) Delete(key []byte, wo *opt.WriteOptions) error &#123;</span><br><span class=\"line\">\treturn db.putRec(keyTypeDel, key, nil, wo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，在<code>Put</code>和<code>Delete</code>命令中，最终会直接调用<code>putRec</code>方法，而在此方法中，做的核心逻辑就是，抢锁，并等待信息，其中抢锁的逻辑还是由<code>channel</code>实现，逻辑后续再理，先了解一下写入流程<code>writeLocked</code>方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">batch :&#x3D; db.batchPool.Get().(*Batch)</span><br><span class=\"line\">batch.Reset()</span><br><span class=\"line\">batch.appendRec(kt, key, value)</span><br><span class=\"line\">return db.writeLocked(batch, batch, merge, sync)</span><br></pre></td></tr></table></figure>\n<p>调用该方法后，则就是AOF写入以及落入<code>memdb</code>跳表数据库中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; Seq number.</span><br><span class=\"line\">seq :&#x3D; db.seq + 1</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Write journal.</span><br><span class=\"line\">if err :&#x3D; db.writeJournal(batches, seq, sync); err !&#x3D; nil &#123;</span><br><span class=\"line\">\tdb.unlockWrite(overflow, merged, err)</span><br><span class=\"line\">\treturn err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#x2F;&#x2F; Put batches.</span><br><span class=\"line\">for _, batch :&#x3D; range batches &#123;</span><br><span class=\"line\">\tif err :&#x3D; batch.putMem(seq, mdb.DB); err !&#x3D; nil &#123;</span><br><span class=\"line\">\t\tpanic(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tseq +&#x3D; uint64(batch.Len())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>至此，数据已经落入存储中，并返回告知请求处理正常。那么，这一套流程，中间还存在哪些问题呢？<br>其中提高吞吐、提高内存空间利用率则是中间的优化点。</p>\n<h3 id=\"合并写\"><a href=\"#合并写\" class=\"headerlink\" title=\"合并写\"></a>合并写</h3><p>关于吞吐量的计算逻辑可以参考：<a href=\"https://zhuanlan.zhihu.com/p/337708438\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/337708438</a></p>\n<p>由于本身leveldb会写入内存，所以中间存在锁的抢占，而在golang中，leveldb使用的是channel进行锁争抢，当你能写入writeLockC管道时，便可以继续写入操作。然而，锁的争抢必定会导致性能下降，那么，合并写就成为了提供性能的一个解决方案。</p>\n<p>合并锁的逻辑就是，优先尝试写入writeMergeC管道中，如果写入成功，则等待合并写的结果返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case db.writeMergeC &lt;- writeMerge&#123;sync: sync, keyType: kt, key: key, value: value&#125;:</span><br><span class=\"line\">    if &lt;-db.writeMergedC &#123;</span><br><span class=\"line\">        &#x2F;&#x2F; Write is merged.</span><br><span class=\"line\">        return &lt;-db.writeAckC</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;&#x2F; Write is not merged, the write lock is handed to us. Continue.</span><br><span class=\"line\">case db.writeLockC &lt;- struct&#123;&#125;&#123;&#125;:</span><br><span class=\"line\">    &#x2F;&#x2F; Write lock acquired.</span><br><span class=\"line\">case err :&#x3D; &lt;-db.compPerErrC:</span><br><span class=\"line\">    &#x2F;&#x2F; Compaction error.</span><br><span class=\"line\">    return err</span><br><span class=\"line\">case &lt;-db.closeC:</span><br><span class=\"line\">    &#x2F;&#x2F; Closed</span><br><span class=\"line\">    return ErrClosed</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而如果合并锁写入不成功，则尝试去抢写入锁，如果当前写入锁还是没有释放，那其中有可能导致异常出现（猜测）。<br>而在抢到写入锁的协程中，则会不断的等待合并写的请求达到上限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">merge: </span><br><span class=\"line\"></span><br><span class=\"line\">for mergeLimit &gt; 0 &#123;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case incoming :&#x3D; &lt;-db.writeMergeC:</span><br><span class=\"line\">        ... ...</span><br><span class=\"line\">    default:</span><br><span class=\"line\">        break merge</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由此可见，当一次写入异常时，常常会阻塞所有的合并写异常，所有，合并写其实是针对大数据量的变更。</p>\n<p>当然，如果处理完成后，则会写入writeAckC管道告知等待的写入，但是如果此次合并写并没有写入完成写入，则会使其抢锁成功，并自身去进行写入，这块逻辑便是之前的writeMergeC和writeLockC逻辑。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (db *DB) unlockWrite(overflow bool, merged int, err error) &#123;</span><br><span class=\"line\">\tfor i :&#x3D; 0; i &lt; merged; i++ &#123;</span><br><span class=\"line\">\t\tdb.writeAckC &lt;- err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif overflow &#123;</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Pass lock to the next write (that failed to merge).</span><br><span class=\"line\">\t\tdb.writeMergedC &lt;- false</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t&#x2F;&#x2F; Release lock.</span><br><span class=\"line\">\t\t&lt;-db.writeLockC</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"读书笔记：从0开始学框架","date":"2021-09-27T01:34:56.000Z","_content":"\n## 目录\n\n- 基础架构\n- 高性能架构模式\n- 高可用架构模式\n- 可扩展架构模式\n- 架构实战\n\n---\n\n## 基础架构\n\n什么是架构？\n\n架构是如何产生的？\n\n架构的目的是什么？\n\n架构设计有什么原则？\n\n---\n\n### 什么是架构？\n\n架构包含以下几个关键词：\n\n1. 系统与子系统\n2. 模块与组件\n3. 框架与架构\n\n---\n\n### 什么是架构？\n\n参考维基百科的定义，我将架构重新定义为：**软件架构指软件系统的顶层结构**。\n\n- 首先，“系统是一群关联个体组成”，这些“个体”可以是“子系统”“模块”“组件”等；架构需要明确系统包含哪些“个体”。\n- 其次，系统中的个体需要“根据某种规则”运作，架构需要明确个体运作和协作的规则。\n- 第三，维基百科定义的架构用到了“基础结构”这个说法，我改为“顶层结构”，可以更好地区分系统和子系统，避免将系统架构和子系统架构混淆在一起导致架构层次混乱。\n\n---\n\n### 架构的背景\n\n- 机器语言（**1940 年之前**）：太难写、太难读、太难改！\n- 汇编语言（**20 世纪 40 年代**）：解决了机器语言读写复杂的问题，但本质上还是面向机器的\n- 高级语言（**20 世纪 50 年代**）：软件的规模和复杂度的大大增加，软件质量低下、项目无法如期完成、项目严重超支等\n- 第一次软件危机与结构化程序设计（**20 世纪 60 年代~20 世纪 70 年代**）：软件生产力远远跟不上硬件和业务的发展\n- 第二次软件危机与面向对象（**20 世纪 80 年代**）：软件的“扩展”变得非常复杂。\n\n---\n\n### 软件架构的历史背景\n\n> “When systems are constructed from many components, the organization of the overall system-the software architecture-presents a new set of design problems.”\n\n简单翻译一下：随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。\n\n---\n\n### 架构设计的误区\n\n1. 因为架构很重要，所以要做架构设计\n2. 不是每个系统都要做架构设计吗\n3. 公司流程要求系统开发过程中必须有架构设计\n4. 为了高性能、高可用、可扩展，所以要做架构设计\n\n---\n\n### 架构设计的真正目的\n\n> 架构设计的主要目的是为了解决软件系统复杂度带来的问题。\n\n有的放矢，而不是贪大求全。\n\n---\n\n### 复杂度来源\n\n1. 高性能\n2. 高可用\n3. 可扩展\n4. 低成本、安全、规模\n\n---\n\n### 高性能复杂度\n\n- 单机复杂度：多进程、多线程的协作\n- 集群复杂度：任务分配和任务拆解\n\n---\n\n### 高可用复杂度\n\n> 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。\n\n**“冗余”**是高可用的最终解决方案\n\n高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元。\n\n---\n\n### 高可用复杂度\n\n- **计算高可用**：无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的\n- **存储高可用**：如何减少或者规避数据不一致对业务造成的影响。\n- **高可用状态决策**：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确\n\n**决策手段**：独裁式、协商式、民主式\n\n---\n\n### 可扩展性复杂度\n\n设计具备良好可扩展性的系统，有两个基本条件：**正确预测变化**、**完美封装变化**。\n\n预测变化的复杂性在于：\n\n- 不能每个设计点**都考虑**可扩展性。\n- 不能完全**不考虑**可扩展性。\n- 所有的预测都**存在出错**的可能性。\n\n---\n\n### 可扩展性复杂度\n\n唯一不变的是变化，而应对变化的手段就是将变化和不变的分离开：\n\n1. 将“变化”封装在一个“变化层”，将不变的部分封装在一个独立的“稳定层”：**ORM的实现**\n2. 提炼出一个“抽象层”和一个“实现层”：**规则引擎和设计模式**\n\n---\n\n### 复杂度来源：低成本、安全、规模\n\n- 新技术带动低成本\n  - 存储侧：NoSQL、全文搜索引擎、Hadoop\n  - 系统侧：HipHop PHP、Redis/MC + SSD Cache + MySQL、Kafka、\n- 安全需要多方考虑\n  - 功能安全：就是“防小偷”。\n  - 架构安全：就是“防强盗”\n- 量变引起质变\n  - 功能越来越多，导致系统复杂度指数级上升\n  - 数据越来越多，系统复杂度发生质变\n\n---\n\n### 架构设计原则\n\n- 合适原则宣言：“合适优于业界领先”。\n- 简单原则宣言：“简单优于复杂”。\n- 演化原则宣言：“演化优于一步到位”。\n\n---\n\n### 架构设计流程\n\n- 识别复杂度：架构设计的本质目的是为了解决软件系统的复杂性\n- 设计备选方案、评估和选择备选方案\n- 详细方案设计：将方案涉及的关键技术细节给确定下来\n\n---\n\n### 总结\n\n1. 随着软件系统规模的增加，引发了架构设计\n2. 架构设计是为了解决复杂度而产生\n3. 架构设计遵循适合、简单、演变三原则\n4. 架构需要从目的、方案、完善逐步进行\n\n---\n\n## 高性能架构模式\n\n高性能复杂度前文中是从单机到多机的复杂度增加，而将架构拆解开来，可以分为计算高性能和存储高性能。毕竟程序是存储+计算来实现。\n\n存储高性能\n\n- 数据库高性能\n- Nosql高性能\n- 缓存高性能\n\n计算高性能\n\n- 服务器高性能\n- 多机负载均衡\n\n---\n\n### 存储高性能（数据库高性能）\n\n高性能数据库集群的第一种方式是“**读写分离**”，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力；\n\n第二种方式是“**分库分表**”，既可以分散访问压力，又可以分散存储压力。\n\n---\n\n### 读写分离\n\n读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度：**主从复制延迟**和**分配机制**。\n\n- 复制延迟\n  - 写操作后的读操作指定发给数据库主服务器\n  - 读从机失败后再读一次主机\n  - 关键业务读写操作全部指向主机，非关键业务采用读写分离\n- 分配机制\n  - 程序代码封装：实现简单、无法通用\n  - 中间件封装\n\n---\n\n### 分库分表\n\n**核心问题**：数据量太大，读写的性能会下降、数据库备份和恢复需要耗费很长时间、极端情况下丢失数据的风险越高\n\n业务分库：业务分库指的是按照业务模块将数据分散到不同的数据库服务器\n\n- join 操作问题\n- 事务问题\n- 成本问题\n\n数据分表：同一业务的单表数据也会达到单台数据库服务器的处理瓶颈，需要进行垂直分表和水平分表\n\n- 垂直分表\n- 水平分表\n- 路由\n\n---\n\n### 高性能NoSQL起源\n\n关系数据库存在如下缺点：\n\n1. 关系数据库存储的是行记录，无法存储数据结构\n2. 关系数据库的 schema 扩展很不方便\n3. 关系数据库在大数据场景下 I/O 较高\n4. 关系数据库的全文搜索功能比较弱\n\n---\n\n### 高性能NoSQL分类\n\n- K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。\n\n- 文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。\n- 列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。\n- 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。\n\n---\n\n### 高性能缓存架构\n\n虽然我们可以通过各种手段来提升存储系统的性能，但在某些复杂的业务场景下，单纯依靠存储系统的性能提升不够的，典型的场景有：\n\n1. 需要经过复杂运算后得出的数据，存储系统无能为力\n2. 读多写少的数据，存储系统有心无力\n\n缓存虽然能够大大减轻存储系统的压力，但同时也给架构引入了更多复杂性。\n\n----\n\n### 高性能缓存架构的问题\n\n- 缓存穿透：\n- 缓存雪崩：\n- 缓存热点：\n\n---\n\n### 单服务器的高性能\n\n单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：\n\n- 服务器如何管理连接。\n\n- 服务器如何处理请求。\n\n以上两个设计点最终都和操作系统的 I/O 模型及进程模型相关。\n\n- I/O 模型：阻塞、非阻塞、同步、异步。\n- 进程模型：单进程、多进程、多线程。\n\n其中对应的网络编程模型有：PPC、TPC、Reactor、Proactor。\n\n---\n\n#### PPC和TPC\n\nPPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。\n\n- fork 代价高\n- 父子进程通信复杂\n- 支持的并发连接数量有限\n\nTPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。\n\n- 代价低，但并不是没有代价\n- 线程间的互斥和共享又引入了复杂度\n- 多线程会出现互相影响的情况\n\n---\n\nPPC和TPC其实是很大的浪费\n\n引入资源池的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？\n\n解决这个问题的最简单的方式是将 read 操作改为非阻塞，然后进程不断地轮询多个连接。\n\n如果一个进程处理几千上万的连接，则轮询的效率是很低的。\n\n---\n\n### Reactor模式\n\n为了能够更好地解决上述问题，很容易可以想到，只有当连接上有数据的时候进程才去处理，这就是 I/O 多路复用技术的来源。\n\n- 当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的实现方式有 select、epoll、kqueue 等。\n\n- 当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。\n\nI/O 多路复用结合线程池，完美地解决了 PPC 和 TPC 的问题，而且“大神们”给它取了一个很牛的名字：Reactor，中文是“反应堆”。\n\nReactor 模式的核心组成部分包括 Reactor 和处理资源池（进程池或线程池），其中 Reactor 负责监听和分配事件，处理资源池负责处理事件。\n\n---\n\n### Proactor模式\n\nReactor 是非阻塞同步网络模型，因为真正的 read 和 send 操作都需要用户进程同步操作。\n\n如果把 I/O 操作改为异步就能够进一步提升性能，这就是异步网络模型 Proactor。\n\nProactor 中文翻译为“前摄器”比较难理解，与其类似的单词是 proactive，含义为“主动的”，因此我们照猫画虎翻译为“主动器”反而更好理解。\n\n理论上 Proactor 比 Reactor 效率要高一些，异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠，但要实现真正的异步 I/O，操作系统需要做大量的工作。\n\n---\n\n### 集群负载均衡\n\n高性能集群的本质很简单，通过增加更多的服务器来提升系统整体的计算能力。\n\n高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法\n\n负载均衡分类\n\n- DNS 负载均衡\n- 硬件负载均衡\n- 软件负载均衡\n\n---\n\n#### DNS 负载均衡\n\n优点有：\n\n- 简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。\n- 就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。\n\n缺点有：\n\n- 更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。\n- 扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。\n- 分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。\n\n针对 DNS 负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了 HTTP-DNS 的功能，即使用 HTTP 协议实现一个私有的 DNS 系统。这样的方案和通用的 DNS 优缺点正好相反。\n\n---\n\n#### 硬件负载均衡\n\n优点是：\n\n- 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。\n- 性能强大：对比一下，软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。\n- 稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。\n- 支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。\n\n缺点是：\n\n- 价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。\n- 扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。\n\n---\n\n#### 软件负载均衡\n\n常见的有 Nginx 和 LVS，其中 Nginx 是软件的 7 层负载均衡，LVS 是 Linux 内核的 4 层负载均衡。4 层和 7 层的区别就在于协议和灵活性\n\n优点：\n\n- 简单：无论是部署还是维护都比较简单。\n- 便宜：只要买个 Linux 服务器，装上软件即可。\n- 灵活：4 层和 7 层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过 Nginx 的插件来实现业务的定制化功能。\n\n缺点：\n\n- 性能一般：一个 Nginx 大约能支撑 5 万并发。\n- 功能没有硬件负载均衡那么强大。\n- 一般不具备防火墙和防 DDoS 攻击等安全功能。\n\n---\n\n### 负载均衡典型架构\n\n基本原则：DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。\n\n---\n\n### 负载均衡算法\n\n- **任务平分类**：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。\n- **负载均衡类**：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。\n- **性能最优类**：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。\n- **Hash 类**：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。\n\n---\n\n## 高可用架构模式\n\n高可用架构更多核心是探讨高可用状态决策方式。\n\n---\n\n#### CAP模型\n\n第一版解释：\n\n> 对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三个设计约束。\n\n第二版解释：\n\n> 在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。\n\n差异点：属于需要共享数据，且只关注与读写功能\n\n---\n\n### CAP模型细节\n\n#### 一致性（Consistency）\n\n第一版解释：\n\n> 所有节点在同一时刻都能看到相同的数据。\n\n第二版解释：\n\n> 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。\n\n角色从node变成了client，只需要保证观察者能读取到最新数据即可。\n\n---\n\n#### 可用性（Availability）\n\n第一版解释：\n\n> 每个请求都能得到成功或者失败的响应。\n\n第二版解释：\n\n> 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。\n\n第二版明确了不能超时、不能出错，结果是合理的，注意没有说“正确”的结果\n\n---\n\n#### 分区容忍性（Partition Tolerance）\n\n第一版解释：\n\n> 出现消息丢失或者分区错误时系统能够继续运行。\n\n第二版解释：\n\n> 当出现网络分区后，系统能够继续“履行职责”。\n\n第二版描述了更多的异常情况，而非消息丢失。同时强调履行职责，而非运行。\n\n---\n\n#### 三者冲突关系\n\nP是分布式系统的基础，因为如果P无法实现，那C就无法保证写入，必然导致A无法保证。\n\n---\n\n### CAP模型细节\n\n参考文献：[CAP 理论十二年回顾：\"规则\"变了](https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/)\n\n1. “三选二”的公式一直存在着误导性，它会过分简单化各性质之间的相互关系。\n2. 因为分区很少出现，CAP 在大多数时候允许完美的 C 和 A\n3. 当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响\n\n策略应分为三个步骤：探知分区发生，进入显式的分区模式以限制某些操作，启动恢复过程以恢复数据一致性并补偿分区期间发生的错误。\n\n---\n\n### ACID、BASE、CAP\n\nACID 和 BASE 代表了两种截然相反的设计哲学，分处一致性 - 可用性分布图谱的两极。ACID 注重一致性，是数据库的传统设计思路。\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：\n\n- CAP 理论是忽略延时的，而实际应用中延时是无法避免的。\n- AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。\n\n综合上面的分析，ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。\n\n---\n\n### 高可用存储架构：双机架构\n\n存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用\n\n其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。因此，对任何一个高可用存储方案，我们需要从以下几个方面去进行思考和分析：\n\n- 数据如何复制？\n- 各个节点的职责是什么？\n- 如何应对复制延迟？\n- 如何应对复制中断？\n\n常见的高可用存储架构有主备、主从、主主、集群、分区，每一种又可以根据业务的需求进行一些特殊的定制化功能，由此衍生出更多的变种\n\n---\n\n#### 主备复制\n\n主备复制架构的优点就是简单，表现有：\n\n- 对于客户端来说，不需要感知备机的存在，即使灾难恢复后，原来的备机被人工修改为主机后，对于客户端来说，只是认为主机的地址换了而已，无须知道是原来的备机升级为主机。\n- 对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。\n\n主备复制架构的缺点主要有：\n\n- 备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费。\n- 故障后需要人工干预，无法自动恢复。人工处理的效率是很低的，可能打电话找到能够操作的人就耗费了 10 分钟，甚至如果是深更半夜，出了故障都没人知道。人工在执行恢复操作的过程中也容易出错，因为这类操作并不常见，可能 1 年就 2、3 次，实际操作的时候很可能遇到各种意想不到的问题。\n\n---\n\n#### 主从复制\n\n主从复制与主备复制相比，优点有：\n\n- 主从复制在主机故障时，读操作相关的业务可以继续运行。\n- 主从复制架构的从机提供读操作，发挥了硬件的性能。\n\n缺点有：\n\n- 主从复制架构中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备复制要高。\n- 主从复制架构中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题。\n- 故障时需要人工干预。\n\n---\n\n### 双机切换\n\n1. 主备间状态判断：状态传递的渠道、状态检测的内容\n2. 切换决策：切换时机、切换策略、自动程度。\n3. 数据冲突解决\n\n---\n\n#### 状态传递渠道\n\n根据状态传递渠道的不同，常见的主备切换架构有三种形式：互连式、中介式和模拟式。\n\n---\n\n##### 互连式\n\n为了充分利用切换方案能够自动决定主机这个优势，客户端这里也会有一些相应的改变，常见的方式有：\n\n- 为了切换后不影响客户端的访问，主机和备机之间共享一个对客户端来说唯一的地址。例如虚拟 IP，主机需要绑定这个虚拟的 IP。\n- 客户端同时记录主备机的地址，哪个能访问就访问哪个；备机虽然能收到客户端的操作请求，但是会直接拒绝，拒绝的原因就是“备机不对外提供服务”。\n\n互连式主备切换主要的缺点在于：\n\n- 如果状态传递的通道本身有故障（例如，网线被人不小心踢掉了），那么备机也会认为主机故障了从而将自己升级为主机，而此时主机并没有故障，最终就可能出现两个主机。\n- 虽然可以通过增加多个通道来增强状态传递的可靠性，但这样做只是降低了通道故障概率而已，不能从根本上解决这个缺点，而且通道越多，后续的状态决策会更加复杂，因为对备机来说，可能从不同的通道收到了不同甚至矛盾的状态信息。\n\n---\n\n##### 中介式\n\n中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息\n\n- **连接管理更简单**：主备机无须再建立和管理多种类型的状态传递连接通道，只要连接到中介即可，实际上是降低了主备机的连接管理复杂度。\n- **状态决策更简单**：主备机的状态决策简单了，无须考虑多种类型的连接通道获取的状态信息如何决策的问题，只需要按照下面简单的算法即可完成状态决策。\n\n缺点：为了实现高可用，我们引入中介，但中介本身又要求高可用，于是又要设计中介的高可用方案\n\n---\n\n##### 模拟式\n\n模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作\n\n模拟式切换与互连式切换相比，优点是实现更加简单，因为省去了状态传递通道的建立和管理工作。\n\n简单既是优点，同时也是缺点。因为模拟式读写操作获取的状态信息只有响应信息，没有互连式那样多样，基于有限的状态来做状态决策，可能出现偏差。\n\n---\n\n#### 主主复制\n\n相比主备切换架构，主主复制架构具有如下特点：\n\n- 两台都是主机，不存在切换的概念。\n- 客户端无须区分不同角色的主机，随便将读写操作发送给哪台主机都可以。\n\n主主复制架构对数据的设计有严格的要求，一般适合于那些临时性、可丢失、可覆盖的数据场景。\n\n---\n\n### 集群和分区\n\n高可用存储架构也分为2类：数据集群和数据分区。\n\n---\n\n#### 数据集群\n\n- 数据集中集群\n  - 主机如何将数据复制给备机\n  - 备机如何检测主机状态\n  - 主机故障后，如何决定新的主机\n- 数据分散集群\n  - 均衡性\n  - 容错性\n  - 可伸缩性\n\n---\n\n#### 数据分区\n\n需要考虑的核心点：数据量、分区规则、复制规则\n\n常见的分区复制规则有三种：集中式、互备式和独立式。\n\n---\n\n##### 集中式\n\n集中式备份架构的优缺点是：\n\n- 设计简单，各分区之间并无直接联系，可以做到互不影响。\n- 扩展容易，如果要增加第四个分区（例如，武汉分区），只需要将武汉分区的数据复制到西安备份中心即可，其他分区不受影响。\n- 成本较高，需要建设一个独立的备份中心。\n\n---\n\n##### 互备式\n\n互备式备份架构的优缺点是：\n\n- 设计比较复杂，各个分区除了要承担业务数据存储，还需要承担备份功能，相互之间互相关联和影响。\n- 扩展麻烦，如果增加一个武汉分区，则需要修改广州分区的复制指向武汉分区，然后将武汉分区的复制指向北京分区。而原有北京分区已经备份了的广州分区的数据怎么处理也是个难题，不管是做数据迁移，还是广州分区历史数据保留在北京分区，新数据备份到武汉分区，无论哪种方式都很麻烦。\n- 成本低，直接利用已有的设备。\n\n---\n\n##### 独立式\n\n独立式备份架构的优缺点是：\n\n- 设计简单，各分区互不影响。\n- 扩展容易，新增加的分区只需要搭建自己的备份中心即可。\n- 成本高，每个分区需要独立的备份中心，备份中心的场地成本是主要成本，因此独立式比集中式成本要高很多。\n\n---\n\n#### 计算高可用\n\n计算高可用架构的设计复杂度主要体现在**任务管理**方面，即当任务在某台服务器上执行失败后，如何将任务重新分配到新的服务器进行执行。\n\n1. 哪些服务器可以执行任务，\n2. 任务如何重新执行\n\n计算高可用框架也分为三类：\n\n1. 主备架构，备机在故障时才进行启用\n2. 主从架构，备机会参与任务执行\n3. 集群架构：对称集群、非对称集群。减少人工介入，更多的由机器来进行任务分发。\n\n---\n\n### 异地多活\n\n1. 同城异区\n\n2. 跨城异地\n3. 跨国异地\n\n---\n\n#### 异地多活设计4大技巧\n\n1. 同城异区\n\n   关键在于搭建高速网络将两个机房连接起来，达到近似一个本地机房的效果。架构设计上可以将两个机房当作本地机房来设计，无须额外考虑。\n\n2. 跨城异地\n\n   关键在于数据不一致的情况下，业务不受影响或者影响很小，这从逻辑的角度上来说其实是矛盾的，架构设计的主要目的就是为了解决这个矛盾。\n\n3. 跨国异地\n\n   主要是面向不同地区用户提供业务，或者提供只读业务，对架构设计要求不高。\n\n---\n\n#### 异地多活设计4大技巧\n\n技巧 1：保证核心业务的异地多活\n\n技巧 2：保证核心数据最终一致性\n\n技巧 3：采用多种手段同步数据（队列、二次读取、存储同步、回源读取、重新生成）\n\n技巧 4：只保证绝大部分用户的异地多活\n\n---\n\n#### 异地多活设计4步走\n\n第 1 步：业务分级（访问量大的业务、核心业务、产生大量收入的业务）\n\n第 2 步：数据分类（数据量、唯一性、实时性、可丢失性、可恢复性）\n\n第 3 步：数据同步（存储系统、消息队列、重复生成）\n\n第 4 步：异常处理（多通道同步、同步和访问结合、日志记录、用户补偿）\n\n---\n\n### 接口级的故障\n\n降级：系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能\n\n熔断：降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况。\n\n限流：只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。\n\n排队：临时缓存大量的业务请求\n\n---\n\n## 可扩展的基本思想\n\n所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆！\n\n1. 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。（TCP）\n2. 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。（京东的支付和商城）\n3. 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。（京东用户系统里面的查询和注册）\n\n> 不同的拆分方式，本质上决定了系统的扩展方式。\n\n---\n\n### 可扩展方式\n\n**面向流程拆分：**分层架构。\n\n**特点：**扩展时大部分情况只需要修改某一层，少部分情况可能修改关联的两层\n\n**面向服务拆分：**SOA、微服务。\n\n**特点：**对某个服务扩展，或者要增加新的服务时，只需要扩展相关服务即可，无须修改所有的服务。\n\n**面向功能拆分：**微内核架构。\n\n**特点：**对某个功能扩展，或者要增加新的功能时，只需要扩展相关功能即可，无须修改所有的服务。\n\n---\n\n#### 微服务架构最佳实践\n\n实施微服务需要避免踩的陷阱，简单提炼为：\n\n1. 微服务拆分过细，过分强调“small”。\n2. 微服务基础设施不健全，忽略了“automated”。\n3. 微服务并不轻量级，规模大了后，“lightweight”不再适应。\n\n---\n\n#### 微服务架构基础设施\n\n自动化部署：包括版本管理、资源管理（例如，机器管理、虚拟机管理）、部署操作、回退操作等功能。\n\n配置中心：配置版本管理、增删改查配置、节点管理、配置同步、配置推送等功能。\n\n接口框架：以库或者包的形式提供给所有微服务调用\n\nAPI 网关：接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。\n\n服务发现：需要一套服务发现的系统来支撑微服务的自动注册和发现\n\n服务路由：从所有符合条件的可用微服务节点中挑选出一个具体的节点发起请求\n\n服务容错：请求重试、流控和服务隔离\n\n服务监控：实时搜集信息并进行分析、监控预警\n\n服务跟踪：在大量微服务系统中快速定位问题\n\n服务安全：接入安全、数据安全、传输安全\n\n---\n\n#### 微内核架构详解\n\n>  微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构\n\n微内核的核心系统设计的关键技术有：插件管理、插件连接和插件通信。\n\n1. 插件管理\n\n2. 插件连接\n\n3. 插件通信","source":"_posts/note-framework-0.md","raw":"---\ntitle: 读书笔记：从0开始学框架\ndate: 2021-09-27 09:34:56\ntags: 读书笔记\n---\n\n## 目录\n\n- 基础架构\n- 高性能架构模式\n- 高可用架构模式\n- 可扩展架构模式\n- 架构实战\n\n---\n\n## 基础架构\n\n什么是架构？\n\n架构是如何产生的？\n\n架构的目的是什么？\n\n架构设计有什么原则？\n\n---\n\n### 什么是架构？\n\n架构包含以下几个关键词：\n\n1. 系统与子系统\n2. 模块与组件\n3. 框架与架构\n\n---\n\n### 什么是架构？\n\n参考维基百科的定义，我将架构重新定义为：**软件架构指软件系统的顶层结构**。\n\n- 首先，“系统是一群关联个体组成”，这些“个体”可以是“子系统”“模块”“组件”等；架构需要明确系统包含哪些“个体”。\n- 其次，系统中的个体需要“根据某种规则”运作，架构需要明确个体运作和协作的规则。\n- 第三，维基百科定义的架构用到了“基础结构”这个说法，我改为“顶层结构”，可以更好地区分系统和子系统，避免将系统架构和子系统架构混淆在一起导致架构层次混乱。\n\n---\n\n### 架构的背景\n\n- 机器语言（**1940 年之前**）：太难写、太难读、太难改！\n- 汇编语言（**20 世纪 40 年代**）：解决了机器语言读写复杂的问题，但本质上还是面向机器的\n- 高级语言（**20 世纪 50 年代**）：软件的规模和复杂度的大大增加，软件质量低下、项目无法如期完成、项目严重超支等\n- 第一次软件危机与结构化程序设计（**20 世纪 60 年代~20 世纪 70 年代**）：软件生产力远远跟不上硬件和业务的发展\n- 第二次软件危机与面向对象（**20 世纪 80 年代**）：软件的“扩展”变得非常复杂。\n\n---\n\n### 软件架构的历史背景\n\n> “When systems are constructed from many components, the organization of the overall system-the software architecture-presents a new set of design problems.”\n\n简单翻译一下：随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。\n\n---\n\n### 架构设计的误区\n\n1. 因为架构很重要，所以要做架构设计\n2. 不是每个系统都要做架构设计吗\n3. 公司流程要求系统开发过程中必须有架构设计\n4. 为了高性能、高可用、可扩展，所以要做架构设计\n\n---\n\n### 架构设计的真正目的\n\n> 架构设计的主要目的是为了解决软件系统复杂度带来的问题。\n\n有的放矢，而不是贪大求全。\n\n---\n\n### 复杂度来源\n\n1. 高性能\n2. 高可用\n3. 可扩展\n4. 低成本、安全、规模\n\n---\n\n### 高性能复杂度\n\n- 单机复杂度：多进程、多线程的协作\n- 集群复杂度：任务分配和任务拆解\n\n---\n\n### 高可用复杂度\n\n> 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。\n\n**“冗余”**是高可用的最终解决方案\n\n高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元。\n\n---\n\n### 高可用复杂度\n\n- **计算高可用**：无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的\n- **存储高可用**：如何减少或者规避数据不一致对业务造成的影响。\n- **高可用状态决策**：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确\n\n**决策手段**：独裁式、协商式、民主式\n\n---\n\n### 可扩展性复杂度\n\n设计具备良好可扩展性的系统，有两个基本条件：**正确预测变化**、**完美封装变化**。\n\n预测变化的复杂性在于：\n\n- 不能每个设计点**都考虑**可扩展性。\n- 不能完全**不考虑**可扩展性。\n- 所有的预测都**存在出错**的可能性。\n\n---\n\n### 可扩展性复杂度\n\n唯一不变的是变化，而应对变化的手段就是将变化和不变的分离开：\n\n1. 将“变化”封装在一个“变化层”，将不变的部分封装在一个独立的“稳定层”：**ORM的实现**\n2. 提炼出一个“抽象层”和一个“实现层”：**规则引擎和设计模式**\n\n---\n\n### 复杂度来源：低成本、安全、规模\n\n- 新技术带动低成本\n  - 存储侧：NoSQL、全文搜索引擎、Hadoop\n  - 系统侧：HipHop PHP、Redis/MC + SSD Cache + MySQL、Kafka、\n- 安全需要多方考虑\n  - 功能安全：就是“防小偷”。\n  - 架构安全：就是“防强盗”\n- 量变引起质变\n  - 功能越来越多，导致系统复杂度指数级上升\n  - 数据越来越多，系统复杂度发生质变\n\n---\n\n### 架构设计原则\n\n- 合适原则宣言：“合适优于业界领先”。\n- 简单原则宣言：“简单优于复杂”。\n- 演化原则宣言：“演化优于一步到位”。\n\n---\n\n### 架构设计流程\n\n- 识别复杂度：架构设计的本质目的是为了解决软件系统的复杂性\n- 设计备选方案、评估和选择备选方案\n- 详细方案设计：将方案涉及的关键技术细节给确定下来\n\n---\n\n### 总结\n\n1. 随着软件系统规模的增加，引发了架构设计\n2. 架构设计是为了解决复杂度而产生\n3. 架构设计遵循适合、简单、演变三原则\n4. 架构需要从目的、方案、完善逐步进行\n\n---\n\n## 高性能架构模式\n\n高性能复杂度前文中是从单机到多机的复杂度增加，而将架构拆解开来，可以分为计算高性能和存储高性能。毕竟程序是存储+计算来实现。\n\n存储高性能\n\n- 数据库高性能\n- Nosql高性能\n- 缓存高性能\n\n计算高性能\n\n- 服务器高性能\n- 多机负载均衡\n\n---\n\n### 存储高性能（数据库高性能）\n\n高性能数据库集群的第一种方式是“**读写分离**”，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力；\n\n第二种方式是“**分库分表**”，既可以分散访问压力，又可以分散存储压力。\n\n---\n\n### 读写分离\n\n读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度：**主从复制延迟**和**分配机制**。\n\n- 复制延迟\n  - 写操作后的读操作指定发给数据库主服务器\n  - 读从机失败后再读一次主机\n  - 关键业务读写操作全部指向主机，非关键业务采用读写分离\n- 分配机制\n  - 程序代码封装：实现简单、无法通用\n  - 中间件封装\n\n---\n\n### 分库分表\n\n**核心问题**：数据量太大，读写的性能会下降、数据库备份和恢复需要耗费很长时间、极端情况下丢失数据的风险越高\n\n业务分库：业务分库指的是按照业务模块将数据分散到不同的数据库服务器\n\n- join 操作问题\n- 事务问题\n- 成本问题\n\n数据分表：同一业务的单表数据也会达到单台数据库服务器的处理瓶颈，需要进行垂直分表和水平分表\n\n- 垂直分表\n- 水平分表\n- 路由\n\n---\n\n### 高性能NoSQL起源\n\n关系数据库存在如下缺点：\n\n1. 关系数据库存储的是行记录，无法存储数据结构\n2. 关系数据库的 schema 扩展很不方便\n3. 关系数据库在大数据场景下 I/O 较高\n4. 关系数据库的全文搜索功能比较弱\n\n---\n\n### 高性能NoSQL分类\n\n- K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。\n\n- 文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。\n- 列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。\n- 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。\n\n---\n\n### 高性能缓存架构\n\n虽然我们可以通过各种手段来提升存储系统的性能，但在某些复杂的业务场景下，单纯依靠存储系统的性能提升不够的，典型的场景有：\n\n1. 需要经过复杂运算后得出的数据，存储系统无能为力\n2. 读多写少的数据，存储系统有心无力\n\n缓存虽然能够大大减轻存储系统的压力，但同时也给架构引入了更多复杂性。\n\n----\n\n### 高性能缓存架构的问题\n\n- 缓存穿透：\n- 缓存雪崩：\n- 缓存热点：\n\n---\n\n### 单服务器的高性能\n\n单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：\n\n- 服务器如何管理连接。\n\n- 服务器如何处理请求。\n\n以上两个设计点最终都和操作系统的 I/O 模型及进程模型相关。\n\n- I/O 模型：阻塞、非阻塞、同步、异步。\n- 进程模型：单进程、多进程、多线程。\n\n其中对应的网络编程模型有：PPC、TPC、Reactor、Proactor。\n\n---\n\n#### PPC和TPC\n\nPPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。\n\n- fork 代价高\n- 父子进程通信复杂\n- 支持的并发连接数量有限\n\nTPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。\n\n- 代价低，但并不是没有代价\n- 线程间的互斥和共享又引入了复杂度\n- 多线程会出现互相影响的情况\n\n---\n\nPPC和TPC其实是很大的浪费\n\n引入资源池的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？\n\n解决这个问题的最简单的方式是将 read 操作改为非阻塞，然后进程不断地轮询多个连接。\n\n如果一个进程处理几千上万的连接，则轮询的效率是很低的。\n\n---\n\n### Reactor模式\n\n为了能够更好地解决上述问题，很容易可以想到，只有当连接上有数据的时候进程才去处理，这就是 I/O 多路复用技术的来源。\n\n- 当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的实现方式有 select、epoll、kqueue 等。\n\n- 当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。\n\nI/O 多路复用结合线程池，完美地解决了 PPC 和 TPC 的问题，而且“大神们”给它取了一个很牛的名字：Reactor，中文是“反应堆”。\n\nReactor 模式的核心组成部分包括 Reactor 和处理资源池（进程池或线程池），其中 Reactor 负责监听和分配事件，处理资源池负责处理事件。\n\n---\n\n### Proactor模式\n\nReactor 是非阻塞同步网络模型，因为真正的 read 和 send 操作都需要用户进程同步操作。\n\n如果把 I/O 操作改为异步就能够进一步提升性能，这就是异步网络模型 Proactor。\n\nProactor 中文翻译为“前摄器”比较难理解，与其类似的单词是 proactive，含义为“主动的”，因此我们照猫画虎翻译为“主动器”反而更好理解。\n\n理论上 Proactor 比 Reactor 效率要高一些，异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠，但要实现真正的异步 I/O，操作系统需要做大量的工作。\n\n---\n\n### 集群负载均衡\n\n高性能集群的本质很简单，通过增加更多的服务器来提升系统整体的计算能力。\n\n高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法\n\n负载均衡分类\n\n- DNS 负载均衡\n- 硬件负载均衡\n- 软件负载均衡\n\n---\n\n#### DNS 负载均衡\n\n优点有：\n\n- 简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。\n- 就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。\n\n缺点有：\n\n- 更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。\n- 扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。\n- 分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。\n\n针对 DNS 负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了 HTTP-DNS 的功能，即使用 HTTP 协议实现一个私有的 DNS 系统。这样的方案和通用的 DNS 优缺点正好相反。\n\n---\n\n#### 硬件负载均衡\n\n优点是：\n\n- 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。\n- 性能强大：对比一下，软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。\n- 稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。\n- 支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。\n\n缺点是：\n\n- 价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。\n- 扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。\n\n---\n\n#### 软件负载均衡\n\n常见的有 Nginx 和 LVS，其中 Nginx 是软件的 7 层负载均衡，LVS 是 Linux 内核的 4 层负载均衡。4 层和 7 层的区别就在于协议和灵活性\n\n优点：\n\n- 简单：无论是部署还是维护都比较简单。\n- 便宜：只要买个 Linux 服务器，装上软件即可。\n- 灵活：4 层和 7 层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过 Nginx 的插件来实现业务的定制化功能。\n\n缺点：\n\n- 性能一般：一个 Nginx 大约能支撑 5 万并发。\n- 功能没有硬件负载均衡那么强大。\n- 一般不具备防火墙和防 DDoS 攻击等安全功能。\n\n---\n\n### 负载均衡典型架构\n\n基本原则：DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。\n\n---\n\n### 负载均衡算法\n\n- **任务平分类**：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。\n- **负载均衡类**：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。\n- **性能最优类**：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。\n- **Hash 类**：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。\n\n---\n\n## 高可用架构模式\n\n高可用架构更多核心是探讨高可用状态决策方式。\n\n---\n\n#### CAP模型\n\n第一版解释：\n\n> 对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三个设计约束。\n\n第二版解释：\n\n> 在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。\n\n差异点：属于需要共享数据，且只关注与读写功能\n\n---\n\n### CAP模型细节\n\n#### 一致性（Consistency）\n\n第一版解释：\n\n> 所有节点在同一时刻都能看到相同的数据。\n\n第二版解释：\n\n> 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。\n\n角色从node变成了client，只需要保证观察者能读取到最新数据即可。\n\n---\n\n#### 可用性（Availability）\n\n第一版解释：\n\n> 每个请求都能得到成功或者失败的响应。\n\n第二版解释：\n\n> 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。\n\n第二版明确了不能超时、不能出错，结果是合理的，注意没有说“正确”的结果\n\n---\n\n#### 分区容忍性（Partition Tolerance）\n\n第一版解释：\n\n> 出现消息丢失或者分区错误时系统能够继续运行。\n\n第二版解释：\n\n> 当出现网络分区后，系统能够继续“履行职责”。\n\n第二版描述了更多的异常情况，而非消息丢失。同时强调履行职责，而非运行。\n\n---\n\n#### 三者冲突关系\n\nP是分布式系统的基础，因为如果P无法实现，那C就无法保证写入，必然导致A无法保证。\n\n---\n\n### CAP模型细节\n\n参考文献：[CAP 理论十二年回顾：\"规则\"变了](https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/)\n\n1. “三选二”的公式一直存在着误导性，它会过分简单化各性质之间的相互关系。\n2. 因为分区很少出现，CAP 在大多数时候允许完美的 C 和 A\n3. 当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响\n\n策略应分为三个步骤：探知分区发生，进入显式的分区模式以限制某些操作，启动恢复过程以恢复数据一致性并补偿分区期间发生的错误。\n\n---\n\n### ACID、BASE、CAP\n\nACID 和 BASE 代表了两种截然相反的设计哲学，分处一致性 - 可用性分布图谱的两极。ACID 注重一致性，是数据库的传统设计思路。\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：\n\n- CAP 理论是忽略延时的，而实际应用中延时是无法避免的。\n- AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。\n\n综合上面的分析，ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。\n\n---\n\n### 高可用存储架构：双机架构\n\n存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用\n\n其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。因此，对任何一个高可用存储方案，我们需要从以下几个方面去进行思考和分析：\n\n- 数据如何复制？\n- 各个节点的职责是什么？\n- 如何应对复制延迟？\n- 如何应对复制中断？\n\n常见的高可用存储架构有主备、主从、主主、集群、分区，每一种又可以根据业务的需求进行一些特殊的定制化功能，由此衍生出更多的变种\n\n---\n\n#### 主备复制\n\n主备复制架构的优点就是简单，表现有：\n\n- 对于客户端来说，不需要感知备机的存在，即使灾难恢复后，原来的备机被人工修改为主机后，对于客户端来说，只是认为主机的地址换了而已，无须知道是原来的备机升级为主机。\n- 对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。\n\n主备复制架构的缺点主要有：\n\n- 备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费。\n- 故障后需要人工干预，无法自动恢复。人工处理的效率是很低的，可能打电话找到能够操作的人就耗费了 10 分钟，甚至如果是深更半夜，出了故障都没人知道。人工在执行恢复操作的过程中也容易出错，因为这类操作并不常见，可能 1 年就 2、3 次，实际操作的时候很可能遇到各种意想不到的问题。\n\n---\n\n#### 主从复制\n\n主从复制与主备复制相比，优点有：\n\n- 主从复制在主机故障时，读操作相关的业务可以继续运行。\n- 主从复制架构的从机提供读操作，发挥了硬件的性能。\n\n缺点有：\n\n- 主从复制架构中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备复制要高。\n- 主从复制架构中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题。\n- 故障时需要人工干预。\n\n---\n\n### 双机切换\n\n1. 主备间状态判断：状态传递的渠道、状态检测的内容\n2. 切换决策：切换时机、切换策略、自动程度。\n3. 数据冲突解决\n\n---\n\n#### 状态传递渠道\n\n根据状态传递渠道的不同，常见的主备切换架构有三种形式：互连式、中介式和模拟式。\n\n---\n\n##### 互连式\n\n为了充分利用切换方案能够自动决定主机这个优势，客户端这里也会有一些相应的改变，常见的方式有：\n\n- 为了切换后不影响客户端的访问，主机和备机之间共享一个对客户端来说唯一的地址。例如虚拟 IP，主机需要绑定这个虚拟的 IP。\n- 客户端同时记录主备机的地址，哪个能访问就访问哪个；备机虽然能收到客户端的操作请求，但是会直接拒绝，拒绝的原因就是“备机不对外提供服务”。\n\n互连式主备切换主要的缺点在于：\n\n- 如果状态传递的通道本身有故障（例如，网线被人不小心踢掉了），那么备机也会认为主机故障了从而将自己升级为主机，而此时主机并没有故障，最终就可能出现两个主机。\n- 虽然可以通过增加多个通道来增强状态传递的可靠性，但这样做只是降低了通道故障概率而已，不能从根本上解决这个缺点，而且通道越多，后续的状态决策会更加复杂，因为对备机来说，可能从不同的通道收到了不同甚至矛盾的状态信息。\n\n---\n\n##### 中介式\n\n中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息\n\n- **连接管理更简单**：主备机无须再建立和管理多种类型的状态传递连接通道，只要连接到中介即可，实际上是降低了主备机的连接管理复杂度。\n- **状态决策更简单**：主备机的状态决策简单了，无须考虑多种类型的连接通道获取的状态信息如何决策的问题，只需要按照下面简单的算法即可完成状态决策。\n\n缺点：为了实现高可用，我们引入中介，但中介本身又要求高可用，于是又要设计中介的高可用方案\n\n---\n\n##### 模拟式\n\n模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作\n\n模拟式切换与互连式切换相比，优点是实现更加简单，因为省去了状态传递通道的建立和管理工作。\n\n简单既是优点，同时也是缺点。因为模拟式读写操作获取的状态信息只有响应信息，没有互连式那样多样，基于有限的状态来做状态决策，可能出现偏差。\n\n---\n\n#### 主主复制\n\n相比主备切换架构，主主复制架构具有如下特点：\n\n- 两台都是主机，不存在切换的概念。\n- 客户端无须区分不同角色的主机，随便将读写操作发送给哪台主机都可以。\n\n主主复制架构对数据的设计有严格的要求，一般适合于那些临时性、可丢失、可覆盖的数据场景。\n\n---\n\n### 集群和分区\n\n高可用存储架构也分为2类：数据集群和数据分区。\n\n---\n\n#### 数据集群\n\n- 数据集中集群\n  - 主机如何将数据复制给备机\n  - 备机如何检测主机状态\n  - 主机故障后，如何决定新的主机\n- 数据分散集群\n  - 均衡性\n  - 容错性\n  - 可伸缩性\n\n---\n\n#### 数据分区\n\n需要考虑的核心点：数据量、分区规则、复制规则\n\n常见的分区复制规则有三种：集中式、互备式和独立式。\n\n---\n\n##### 集中式\n\n集中式备份架构的优缺点是：\n\n- 设计简单，各分区之间并无直接联系，可以做到互不影响。\n- 扩展容易，如果要增加第四个分区（例如，武汉分区），只需要将武汉分区的数据复制到西安备份中心即可，其他分区不受影响。\n- 成本较高，需要建设一个独立的备份中心。\n\n---\n\n##### 互备式\n\n互备式备份架构的优缺点是：\n\n- 设计比较复杂，各个分区除了要承担业务数据存储，还需要承担备份功能，相互之间互相关联和影响。\n- 扩展麻烦，如果增加一个武汉分区，则需要修改广州分区的复制指向武汉分区，然后将武汉分区的复制指向北京分区。而原有北京分区已经备份了的广州分区的数据怎么处理也是个难题，不管是做数据迁移，还是广州分区历史数据保留在北京分区，新数据备份到武汉分区，无论哪种方式都很麻烦。\n- 成本低，直接利用已有的设备。\n\n---\n\n##### 独立式\n\n独立式备份架构的优缺点是：\n\n- 设计简单，各分区互不影响。\n- 扩展容易，新增加的分区只需要搭建自己的备份中心即可。\n- 成本高，每个分区需要独立的备份中心，备份中心的场地成本是主要成本，因此独立式比集中式成本要高很多。\n\n---\n\n#### 计算高可用\n\n计算高可用架构的设计复杂度主要体现在**任务管理**方面，即当任务在某台服务器上执行失败后，如何将任务重新分配到新的服务器进行执行。\n\n1. 哪些服务器可以执行任务，\n2. 任务如何重新执行\n\n计算高可用框架也分为三类：\n\n1. 主备架构，备机在故障时才进行启用\n2. 主从架构，备机会参与任务执行\n3. 集群架构：对称集群、非对称集群。减少人工介入，更多的由机器来进行任务分发。\n\n---\n\n### 异地多活\n\n1. 同城异区\n\n2. 跨城异地\n3. 跨国异地\n\n---\n\n#### 异地多活设计4大技巧\n\n1. 同城异区\n\n   关键在于搭建高速网络将两个机房连接起来，达到近似一个本地机房的效果。架构设计上可以将两个机房当作本地机房来设计，无须额外考虑。\n\n2. 跨城异地\n\n   关键在于数据不一致的情况下，业务不受影响或者影响很小，这从逻辑的角度上来说其实是矛盾的，架构设计的主要目的就是为了解决这个矛盾。\n\n3. 跨国异地\n\n   主要是面向不同地区用户提供业务，或者提供只读业务，对架构设计要求不高。\n\n---\n\n#### 异地多活设计4大技巧\n\n技巧 1：保证核心业务的异地多活\n\n技巧 2：保证核心数据最终一致性\n\n技巧 3：采用多种手段同步数据（队列、二次读取、存储同步、回源读取、重新生成）\n\n技巧 4：只保证绝大部分用户的异地多活\n\n---\n\n#### 异地多活设计4步走\n\n第 1 步：业务分级（访问量大的业务、核心业务、产生大量收入的业务）\n\n第 2 步：数据分类（数据量、唯一性、实时性、可丢失性、可恢复性）\n\n第 3 步：数据同步（存储系统、消息队列、重复生成）\n\n第 4 步：异常处理（多通道同步、同步和访问结合、日志记录、用户补偿）\n\n---\n\n### 接口级的故障\n\n降级：系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能\n\n熔断：降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况。\n\n限流：只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。\n\n排队：临时缓存大量的业务请求\n\n---\n\n## 可扩展的基本思想\n\n所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆！\n\n1. 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。（TCP）\n2. 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。（京东的支付和商城）\n3. 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。（京东用户系统里面的查询和注册）\n\n> 不同的拆分方式，本质上决定了系统的扩展方式。\n\n---\n\n### 可扩展方式\n\n**面向流程拆分：**分层架构。\n\n**特点：**扩展时大部分情况只需要修改某一层，少部分情况可能修改关联的两层\n\n**面向服务拆分：**SOA、微服务。\n\n**特点：**对某个服务扩展，或者要增加新的服务时，只需要扩展相关服务即可，无须修改所有的服务。\n\n**面向功能拆分：**微内核架构。\n\n**特点：**对某个功能扩展，或者要增加新的功能时，只需要扩展相关功能即可，无须修改所有的服务。\n\n---\n\n#### 微服务架构最佳实践\n\n实施微服务需要避免踩的陷阱，简单提炼为：\n\n1. 微服务拆分过细，过分强调“small”。\n2. 微服务基础设施不健全，忽略了“automated”。\n3. 微服务并不轻量级，规模大了后，“lightweight”不再适应。\n\n---\n\n#### 微服务架构基础设施\n\n自动化部署：包括版本管理、资源管理（例如，机器管理、虚拟机管理）、部署操作、回退操作等功能。\n\n配置中心：配置版本管理、增删改查配置、节点管理、配置同步、配置推送等功能。\n\n接口框架：以库或者包的形式提供给所有微服务调用\n\nAPI 网关：接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。\n\n服务发现：需要一套服务发现的系统来支撑微服务的自动注册和发现\n\n服务路由：从所有符合条件的可用微服务节点中挑选出一个具体的节点发起请求\n\n服务容错：请求重试、流控和服务隔离\n\n服务监控：实时搜集信息并进行分析、监控预警\n\n服务跟踪：在大量微服务系统中快速定位问题\n\n服务安全：接入安全、数据安全、传输安全\n\n---\n\n#### 微内核架构详解\n\n>  微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构\n\n微内核的核心系统设计的关键技术有：插件管理、插件连接和插件通信。\n\n1. 插件管理\n\n2. 插件连接\n\n3. 插件通信","slug":"note-framework-0","published":1,"updated":"2022-04-28T11:36:46.553Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58l000fmauy2w7d8emp","content":"<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li>基础架构</li>\n<li>高性能架构模式</li>\n<li>高可用架构模式</li>\n<li>可扩展架构模式</li>\n<li>架构实战</li>\n</ul>\n<hr>\n<h2 id=\"基础架构\"><a href=\"#基础架构\" class=\"headerlink\" title=\"基础架构\"></a>基础架构</h2><p>什么是架构？</p>\n<p>架构是如何产生的？</p>\n<p>架构的目的是什么？</p>\n<p>架构设计有什么原则？</p>\n<hr>\n<h3 id=\"什么是架构？\"><a href=\"#什么是架构？\" class=\"headerlink\" title=\"什么是架构？\"></a>什么是架构？</h3><p>架构包含以下几个关键词：</p>\n<ol>\n<li>系统与子系统</li>\n<li>模块与组件</li>\n<li>框架与架构</li>\n</ol>\n<hr>\n<h3 id=\"什么是架构？-1\"><a href=\"#什么是架构？-1\" class=\"headerlink\" title=\"什么是架构？\"></a>什么是架构？</h3><p>参考维基百科的定义，我将架构重新定义为：<strong>软件架构指软件系统的顶层结构</strong>。</p>\n<ul>\n<li>首先，“系统是一群关联个体组成”，这些“个体”可以是“子系统”“模块”“组件”等；架构需要明确系统包含哪些“个体”。</li>\n<li>其次，系统中的个体需要“根据某种规则”运作，架构需要明确个体运作和协作的规则。</li>\n<li>第三，维基百科定义的架构用到了“基础结构”这个说法，我改为“顶层结构”，可以更好地区分系统和子系统，避免将系统架构和子系统架构混淆在一起导致架构层次混乱。</li>\n</ul>\n<hr>\n<h3 id=\"架构的背景\"><a href=\"#架构的背景\" class=\"headerlink\" title=\"架构的背景\"></a>架构的背景</h3><ul>\n<li>机器语言（<strong>1940 年之前</strong>）：太难写、太难读、太难改！</li>\n<li>汇编语言（<strong>20 世纪 40 年代</strong>）：解决了机器语言读写复杂的问题，但本质上还是面向机器的</li>\n<li>高级语言（<strong>20 世纪 50 年代</strong>）：软件的规模和复杂度的大大增加，软件质量低下、项目无法如期完成、项目严重超支等</li>\n<li>第一次软件危机与结构化程序设计（<strong>20 世纪 60 年代~20 世纪 70 年代</strong>）：软件生产力远远跟不上硬件和业务的发展</li>\n<li>第二次软件危机与面向对象（<strong>20 世纪 80 年代</strong>）：软件的“扩展”变得非常复杂。</li>\n</ul>\n<hr>\n<h3 id=\"软件架构的历史背景\"><a href=\"#软件架构的历史背景\" class=\"headerlink\" title=\"软件架构的历史背景\"></a>软件架构的历史背景</h3><blockquote>\n<p>“When systems are constructed from many components, the organization of the overall system-the software architecture-presents a new set of design problems.”</p>\n</blockquote>\n<p>简单翻译一下：随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。</p>\n<hr>\n<h3 id=\"架构设计的误区\"><a href=\"#架构设计的误区\" class=\"headerlink\" title=\"架构设计的误区\"></a>架构设计的误区</h3><ol>\n<li>因为架构很重要，所以要做架构设计</li>\n<li>不是每个系统都要做架构设计吗</li>\n<li>公司流程要求系统开发过程中必须有架构设计</li>\n<li>为了高性能、高可用、可扩展，所以要做架构设计</li>\n</ol>\n<hr>\n<h3 id=\"架构设计的真正目的\"><a href=\"#架构设计的真正目的\" class=\"headerlink\" title=\"架构设计的真正目的\"></a>架构设计的真正目的</h3><blockquote>\n<p>架构设计的主要目的是为了解决软件系统复杂度带来的问题。</p>\n</blockquote>\n<p>有的放矢，而不是贪大求全。</p>\n<hr>\n<h3 id=\"复杂度来源\"><a href=\"#复杂度来源\" class=\"headerlink\" title=\"复杂度来源\"></a>复杂度来源</h3><ol>\n<li>高性能</li>\n<li>高可用</li>\n<li>可扩展</li>\n<li>低成本、安全、规模</li>\n</ol>\n<hr>\n<h3 id=\"高性能复杂度\"><a href=\"#高性能复杂度\" class=\"headerlink\" title=\"高性能复杂度\"></a>高性能复杂度</h3><ul>\n<li>单机复杂度：多进程、多线程的协作</li>\n<li>集群复杂度：任务分配和任务拆解</li>\n</ul>\n<hr>\n<h3 id=\"高可用复杂度\"><a href=\"#高可用复杂度\" class=\"headerlink\" title=\"高可用复杂度\"></a>高可用复杂度</h3><blockquote>\n<p>系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。</p>\n</blockquote>\n<p><strong>“冗余”</strong>是高可用的最终解决方案</p>\n<p>高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元。</p>\n<hr>\n<h3 id=\"高可用复杂度-1\"><a href=\"#高可用复杂度-1\" class=\"headerlink\" title=\"高可用复杂度\"></a>高可用复杂度</h3><ul>\n<li><strong>计算高可用</strong>：无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的</li>\n<li><strong>存储高可用</strong>：如何减少或者规避数据不一致对业务造成的影响。</li>\n<li><strong>高可用状态决策</strong>：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确</li>\n</ul>\n<p><strong>决策手段</strong>：独裁式、协商式、民主式</p>\n<hr>\n<h3 id=\"可扩展性复杂度\"><a href=\"#可扩展性复杂度\" class=\"headerlink\" title=\"可扩展性复杂度\"></a>可扩展性复杂度</h3><p>设计具备良好可扩展性的系统，有两个基本条件：<strong>正确预测变化</strong>、<strong>完美封装变化</strong>。</p>\n<p>预测变化的复杂性在于：</p>\n<ul>\n<li>不能每个设计点<strong>都考虑</strong>可扩展性。</li>\n<li>不能完全<strong>不考虑</strong>可扩展性。</li>\n<li>所有的预测都<strong>存在出错</strong>的可能性。</li>\n</ul>\n<hr>\n<h3 id=\"可扩展性复杂度-1\"><a href=\"#可扩展性复杂度-1\" class=\"headerlink\" title=\"可扩展性复杂度\"></a>可扩展性复杂度</h3><p>唯一不变的是变化，而应对变化的手段就是将变化和不变的分离开：</p>\n<ol>\n<li>将“变化”封装在一个“变化层”，将不变的部分封装在一个独立的“稳定层”：<strong>ORM的实现</strong></li>\n<li>提炼出一个“抽象层”和一个“实现层”：<strong>规则引擎和设计模式</strong></li>\n</ol>\n<hr>\n<h3 id=\"复杂度来源：低成本、安全、规模\"><a href=\"#复杂度来源：低成本、安全、规模\" class=\"headerlink\" title=\"复杂度来源：低成本、安全、规模\"></a>复杂度来源：低成本、安全、规模</h3><ul>\n<li>新技术带动低成本<ul>\n<li>存储侧：NoSQL、全文搜索引擎、Hadoop</li>\n<li>系统侧：HipHop PHP、Redis/MC + SSD Cache + MySQL、Kafka、</li>\n</ul>\n</li>\n<li>安全需要多方考虑<ul>\n<li>功能安全：就是“防小偷”。</li>\n<li>架构安全：就是“防强盗”</li>\n</ul>\n</li>\n<li>量变引起质变<ul>\n<li>功能越来越多，导致系统复杂度指数级上升</li>\n<li>数据越来越多，系统复杂度发生质变</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"架构设计原则\"><a href=\"#架构设计原则\" class=\"headerlink\" title=\"架构设计原则\"></a>架构设计原则</h3><ul>\n<li>合适原则宣言：“合适优于业界领先”。</li>\n<li>简单原则宣言：“简单优于复杂”。</li>\n<li>演化原则宣言：“演化优于一步到位”。</li>\n</ul>\n<hr>\n<h3 id=\"架构设计流程\"><a href=\"#架构设计流程\" class=\"headerlink\" title=\"架构设计流程\"></a>架构设计流程</h3><ul>\n<li>识别复杂度：架构设计的本质目的是为了解决软件系统的复杂性</li>\n<li>设计备选方案、评估和选择备选方案</li>\n<li>详细方案设计：将方案涉及的关键技术细节给确定下来</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>随着软件系统规模的增加，引发了架构设计</li>\n<li>架构设计是为了解决复杂度而产生</li>\n<li>架构设计遵循适合、简单、演变三原则</li>\n<li>架构需要从目的、方案、完善逐步进行</li>\n</ol>\n<hr>\n<h2 id=\"高性能架构模式\"><a href=\"#高性能架构模式\" class=\"headerlink\" title=\"高性能架构模式\"></a>高性能架构模式</h2><p>高性能复杂度前文中是从单机到多机的复杂度增加，而将架构拆解开来，可以分为计算高性能和存储高性能。毕竟程序是存储+计算来实现。</p>\n<p>存储高性能</p>\n<ul>\n<li>数据库高性能</li>\n<li>Nosql高性能</li>\n<li>缓存高性能</li>\n</ul>\n<p>计算高性能</p>\n<ul>\n<li>服务器高性能</li>\n<li>多机负载均衡</li>\n</ul>\n<hr>\n<h3 id=\"存储高性能（数据库高性能）\"><a href=\"#存储高性能（数据库高性能）\" class=\"headerlink\" title=\"存储高性能（数据库高性能）\"></a>存储高性能（数据库高性能）</h3><p>高性能数据库集群的第一种方式是“<strong>读写分离</strong>”，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力；</p>\n<p>第二种方式是“<strong>分库分表</strong>”，既可以分散访问压力，又可以分散存储压力。</p>\n<hr>\n<h3 id=\"读写分离\"><a href=\"#读写分离\" class=\"headerlink\" title=\"读写分离\"></a>读写分离</h3><p>读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度：<strong>主从复制延迟</strong>和<strong>分配机制</strong>。</p>\n<ul>\n<li>复制延迟<ul>\n<li>写操作后的读操作指定发给数据库主服务器</li>\n<li>读从机失败后再读一次主机</li>\n<li>关键业务读写操作全部指向主机，非关键业务采用读写分离</li>\n</ul>\n</li>\n<li>分配机制<ul>\n<li>程序代码封装：实现简单、无法通用</li>\n<li>中间件封装</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h3><p><strong>核心问题</strong>：数据量太大，读写的性能会下降、数据库备份和恢复需要耗费很长时间、极端情况下丢失数据的风险越高</p>\n<p>业务分库：业务分库指的是按照业务模块将数据分散到不同的数据库服务器</p>\n<ul>\n<li>join 操作问题</li>\n<li>事务问题</li>\n<li>成本问题</li>\n</ul>\n<p>数据分表：同一业务的单表数据也会达到单台数据库服务器的处理瓶颈，需要进行垂直分表和水平分表</p>\n<ul>\n<li>垂直分表</li>\n<li>水平分表</li>\n<li>路由</li>\n</ul>\n<hr>\n<h3 id=\"高性能NoSQL起源\"><a href=\"#高性能NoSQL起源\" class=\"headerlink\" title=\"高性能NoSQL起源\"></a>高性能NoSQL起源</h3><p>关系数据库存在如下缺点：</p>\n<ol>\n<li>关系数据库存储的是行记录，无法存储数据结构</li>\n<li>关系数据库的 schema 扩展很不方便</li>\n<li>关系数据库在大数据场景下 I/O 较高</li>\n<li>关系数据库的全文搜索功能比较弱</li>\n</ol>\n<hr>\n<h3 id=\"高性能NoSQL分类\"><a href=\"#高性能NoSQL分类\" class=\"headerlink\" title=\"高性能NoSQL分类\"></a>高性能NoSQL分类</h3><ul>\n<li><p>K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。</p>\n</li>\n<li><p>文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。</p>\n</li>\n<li><p>列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。</p>\n</li>\n<li><p>全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"高性能缓存架构\"><a href=\"#高性能缓存架构\" class=\"headerlink\" title=\"高性能缓存架构\"></a>高性能缓存架构</h3><p>虽然我们可以通过各种手段来提升存储系统的性能，但在某些复杂的业务场景下，单纯依靠存储系统的性能提升不够的，典型的场景有：</p>\n<ol>\n<li>需要经过复杂运算后得出的数据，存储系统无能为力</li>\n<li>读多写少的数据，存储系统有心无力</li>\n</ol>\n<p>缓存虽然能够大大减轻存储系统的压力，但同时也给架构引入了更多复杂性。</p>\n<hr>\n<h3 id=\"高性能缓存架构的问题\"><a href=\"#高性能缓存架构的问题\" class=\"headerlink\" title=\"高性能缓存架构的问题\"></a>高性能缓存架构的问题</h3><ul>\n<li>缓存穿透：</li>\n<li>缓存雪崩：</li>\n<li>缓存热点：</li>\n</ul>\n<hr>\n<h3 id=\"单服务器的高性能\"><a href=\"#单服务器的高性能\" class=\"headerlink\" title=\"单服务器的高性能\"></a>单服务器的高性能</h3><p>单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：</p>\n<ul>\n<li><p>服务器如何管理连接。</p>\n</li>\n<li><p>服务器如何处理请求。</p>\n</li>\n</ul>\n<p>以上两个设计点最终都和操作系统的 I/O 模型及进程模型相关。</p>\n<ul>\n<li>I/O 模型：阻塞、非阻塞、同步、异步。</li>\n<li>进程模型：单进程、多进程、多线程。</li>\n</ul>\n<p>其中对应的网络编程模型有：PPC、TPC、Reactor、Proactor。</p>\n<hr>\n<h4 id=\"PPC和TPC\"><a href=\"#PPC和TPC\" class=\"headerlink\" title=\"PPC和TPC\"></a>PPC和TPC</h4><p>PPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。</p>\n<ul>\n<li>fork 代价高</li>\n<li>父子进程通信复杂</li>\n<li>支持的并发连接数量有限</li>\n</ul>\n<p>TPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。</p>\n<ul>\n<li>代价低，但并不是没有代价</li>\n<li>线程间的互斥和共享又引入了复杂度</li>\n<li>多线程会出现互相影响的情况</li>\n</ul>\n<hr>\n<p>PPC和TPC其实是很大的浪费</p>\n<p>引入资源池的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？</p>\n<p>解决这个问题的最简单的方式是将 read 操作改为非阻塞，然后进程不断地轮询多个连接。</p>\n<p>如果一个进程处理几千上万的连接，则轮询的效率是很低的。</p>\n<hr>\n<h3 id=\"Reactor模式\"><a href=\"#Reactor模式\" class=\"headerlink\" title=\"Reactor模式\"></a>Reactor模式</h3><p>为了能够更好地解决上述问题，很容易可以想到，只有当连接上有数据的时候进程才去处理，这就是 I/O 多路复用技术的来源。</p>\n<ul>\n<li><p>当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的实现方式有 select、epoll、kqueue 等。</p>\n</li>\n<li><p>当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。</p>\n</li>\n</ul>\n<p>I/O 多路复用结合线程池，完美地解决了 PPC 和 TPC 的问题，而且“大神们”给它取了一个很牛的名字：Reactor，中文是“反应堆”。</p>\n<p>Reactor 模式的核心组成部分包括 Reactor 和处理资源池（进程池或线程池），其中 Reactor 负责监听和分配事件，处理资源池负责处理事件。</p>\n<hr>\n<h3 id=\"Proactor模式\"><a href=\"#Proactor模式\" class=\"headerlink\" title=\"Proactor模式\"></a>Proactor模式</h3><p>Reactor 是非阻塞同步网络模型，因为真正的 read 和 send 操作都需要用户进程同步操作。</p>\n<p>如果把 I/O 操作改为异步就能够进一步提升性能，这就是异步网络模型 Proactor。</p>\n<p>Proactor 中文翻译为“前摄器”比较难理解，与其类似的单词是 proactive，含义为“主动的”，因此我们照猫画虎翻译为“主动器”反而更好理解。</p>\n<p>理论上 Proactor 比 Reactor 效率要高一些，异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠，但要实现真正的异步 I/O，操作系统需要做大量的工作。</p>\n<hr>\n<h3 id=\"集群负载均衡\"><a href=\"#集群负载均衡\" class=\"headerlink\" title=\"集群负载均衡\"></a>集群负载均衡</h3><p>高性能集群的本质很简单，通过增加更多的服务器来提升系统整体的计算能力。</p>\n<p>高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法</p>\n<p>负载均衡分类</p>\n<ul>\n<li>DNS 负载均衡</li>\n<li>硬件负载均衡</li>\n<li>软件负载均衡</li>\n</ul>\n<hr>\n<h4 id=\"DNS-负载均衡\"><a href=\"#DNS-负载均衡\" class=\"headerlink\" title=\"DNS 负载均衡\"></a>DNS 负载均衡</h4><p>优点有：</p>\n<ul>\n<li>简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。</li>\n<li>就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。</li>\n</ul>\n<p>缺点有：</p>\n<ul>\n<li>更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。</li>\n<li>扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。</li>\n<li>分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。</li>\n</ul>\n<p>针对 DNS 负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了 HTTP-DNS 的功能，即使用 HTTP 协议实现一个私有的 DNS 系统。这样的方案和通用的 DNS 优缺点正好相反。</p>\n<hr>\n<h4 id=\"硬件负载均衡\"><a href=\"#硬件负载均衡\" class=\"headerlink\" title=\"硬件负载均衡\"></a>硬件负载均衡</h4><p>优点是：</p>\n<ul>\n<li>功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。</li>\n<li>性能强大：对比一下，软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。</li>\n<li>稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。</li>\n<li>支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。</li>\n</ul>\n<p>缺点是：</p>\n<ul>\n<li>价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。</li>\n<li>扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。</li>\n</ul>\n<hr>\n<h4 id=\"软件负载均衡\"><a href=\"#软件负载均衡\" class=\"headerlink\" title=\"软件负载均衡\"></a>软件负载均衡</h4><p>常见的有 Nginx 和 LVS，其中 Nginx 是软件的 7 层负载均衡，LVS 是 Linux 内核的 4 层负载均衡。4 层和 7 层的区别就在于协议和灵活性</p>\n<p>优点：</p>\n<ul>\n<li>简单：无论是部署还是维护都比较简单。</li>\n<li>便宜：只要买个 Linux 服务器，装上软件即可。</li>\n<li>灵活：4 层和 7 层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过 Nginx 的插件来实现业务的定制化功能。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>性能一般：一个 Nginx 大约能支撑 5 万并发。</li>\n<li>功能没有硬件负载均衡那么强大。</li>\n<li>一般不具备防火墙和防 DDoS 攻击等安全功能。</li>\n</ul>\n<hr>\n<h3 id=\"负载均衡典型架构\"><a href=\"#负载均衡典型架构\" class=\"headerlink\" title=\"负载均衡典型架构\"></a>负载均衡典型架构</h3><p>基本原则：DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。</p>\n<hr>\n<h3 id=\"负载均衡算法\"><a href=\"#负载均衡算法\" class=\"headerlink\" title=\"负载均衡算法\"></a>负载均衡算法</h3><ul>\n<li><strong>任务平分类</strong>：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。</li>\n<li><strong>负载均衡类</strong>：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。</li>\n<li><strong>性能最优类</strong>：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。</li>\n<li><strong>Hash 类</strong>：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。</li>\n</ul>\n<hr>\n<h2 id=\"高可用架构模式\"><a href=\"#高可用架构模式\" class=\"headerlink\" title=\"高可用架构模式\"></a>高可用架构模式</h2><p>高可用架构更多核心是探讨高可用状态决策方式。</p>\n<hr>\n<h4 id=\"CAP模型\"><a href=\"#CAP模型\" class=\"headerlink\" title=\"CAP模型\"></a>CAP模型</h4><p>第一版解释：</p>\n<blockquote>\n<p>对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三个设计约束。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。</p>\n</blockquote>\n<p>差异点：属于需要共享数据，且只关注与读写功能</p>\n<hr>\n<h3 id=\"CAP模型细节\"><a href=\"#CAP模型细节\" class=\"headerlink\" title=\"CAP模型细节\"></a>CAP模型细节</h3><h4 id=\"一致性（Consistency）\"><a href=\"#一致性（Consistency）\" class=\"headerlink\" title=\"一致性（Consistency）\"></a>一致性（Consistency）</h4><p>第一版解释：</p>\n<blockquote>\n<p>所有节点在同一时刻都能看到相同的数据。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。</p>\n</blockquote>\n<p>角色从node变成了client，只需要保证观察者能读取到最新数据即可。</p>\n<hr>\n<h4 id=\"可用性（Availability）\"><a href=\"#可用性（Availability）\" class=\"headerlink\" title=\"可用性（Availability）\"></a>可用性（Availability）</h4><p>第一版解释：</p>\n<blockquote>\n<p>每个请求都能得到成功或者失败的响应。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。</p>\n</blockquote>\n<p>第二版明确了不能超时、不能出错，结果是合理的，注意没有说“正确”的结果</p>\n<hr>\n<h4 id=\"分区容忍性（Partition-Tolerance）\"><a href=\"#分区容忍性（Partition-Tolerance）\" class=\"headerlink\" title=\"分区容忍性（Partition Tolerance）\"></a>分区容忍性（Partition Tolerance）</h4><p>第一版解释：</p>\n<blockquote>\n<p>出现消息丢失或者分区错误时系统能够继续运行。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>当出现网络分区后，系统能够继续“履行职责”。</p>\n</blockquote>\n<p>第二版描述了更多的异常情况，而非消息丢失。同时强调履行职责，而非运行。</p>\n<hr>\n<h4 id=\"三者冲突关系\"><a href=\"#三者冲突关系\" class=\"headerlink\" title=\"三者冲突关系\"></a>三者冲突关系</h4><p>P是分布式系统的基础，因为如果P无法实现，那C就无法保证写入，必然导致A无法保证。</p>\n<hr>\n<h3 id=\"CAP模型细节-1\"><a href=\"#CAP模型细节-1\" class=\"headerlink\" title=\"CAP模型细节\"></a>CAP模型细节</h3><p>参考文献：<a href=\"https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/\" target=\"_blank\" rel=\"noopener\">CAP 理论十二年回顾：”规则”变了</a></p>\n<ol>\n<li>“三选二”的公式一直存在着误导性，它会过分简单化各性质之间的相互关系。</li>\n<li>因为分区很少出现，CAP 在大多数时候允许完美的 C 和 A</li>\n<li>当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响</li>\n</ol>\n<p>策略应分为三个步骤：探知分区发生，进入显式的分区模式以限制某些操作，启动恢复过程以恢复数据一致性并补偿分区期间发生的错误。</p>\n<hr>\n<h3 id=\"ACID、BASE、CAP\"><a href=\"#ACID、BASE、CAP\" class=\"headerlink\" title=\"ACID、BASE、CAP\"></a>ACID、BASE、CAP</h3><p>ACID 和 BASE 代表了两种截然相反的设计哲学，分处一致性 - 可用性分布图谱的两极。ACID 注重一致性，是数据库的传统设计思路。</p>\n<p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：</p>\n<ul>\n<li>CAP 理论是忽略延时的，而实际应用中延时是无法避免的。</li>\n<li>AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。</li>\n</ul>\n<p>综合上面的分析，ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</p>\n<hr>\n<h3 id=\"高可用存储架构：双机架构\"><a href=\"#高可用存储架构：双机架构\" class=\"headerlink\" title=\"高可用存储架构：双机架构\"></a>高可用存储架构：双机架构</h3><p>存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用</p>\n<p>其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。因此，对任何一个高可用存储方案，我们需要从以下几个方面去进行思考和分析：</p>\n<ul>\n<li>数据如何复制？</li>\n<li>各个节点的职责是什么？</li>\n<li>如何应对复制延迟？</li>\n<li>如何应对复制中断？</li>\n</ul>\n<p>常见的高可用存储架构有主备、主从、主主、集群、分区，每一种又可以根据业务的需求进行一些特殊的定制化功能，由此衍生出更多的变种</p>\n<hr>\n<h4 id=\"主备复制\"><a href=\"#主备复制\" class=\"headerlink\" title=\"主备复制\"></a>主备复制</h4><p>主备复制架构的优点就是简单，表现有：</p>\n<ul>\n<li>对于客户端来说，不需要感知备机的存在，即使灾难恢复后，原来的备机被人工修改为主机后，对于客户端来说，只是认为主机的地址换了而已，无须知道是原来的备机升级为主机。</li>\n<li>对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。</li>\n</ul>\n<p>主备复制架构的缺点主要有：</p>\n<ul>\n<li>备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费。</li>\n<li>故障后需要人工干预，无法自动恢复。人工处理的效率是很低的，可能打电话找到能够操作的人就耗费了 10 分钟，甚至如果是深更半夜，出了故障都没人知道。人工在执行恢复操作的过程中也容易出错，因为这类操作并不常见，可能 1 年就 2、3 次，实际操作的时候很可能遇到各种意想不到的问题。</li>\n</ul>\n<hr>\n<h4 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h4><p>主从复制与主备复制相比，优点有：</p>\n<ul>\n<li>主从复制在主机故障时，读操作相关的业务可以继续运行。</li>\n<li>主从复制架构的从机提供读操作，发挥了硬件的性能。</li>\n</ul>\n<p>缺点有：</p>\n<ul>\n<li>主从复制架构中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备复制要高。</li>\n<li>主从复制架构中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题。</li>\n<li>故障时需要人工干预。</li>\n</ul>\n<hr>\n<h3 id=\"双机切换\"><a href=\"#双机切换\" class=\"headerlink\" title=\"双机切换\"></a>双机切换</h3><ol>\n<li>主备间状态判断：状态传递的渠道、状态检测的内容</li>\n<li>切换决策：切换时机、切换策略、自动程度。</li>\n<li>数据冲突解决</li>\n</ol>\n<hr>\n<h4 id=\"状态传递渠道\"><a href=\"#状态传递渠道\" class=\"headerlink\" title=\"状态传递渠道\"></a>状态传递渠道</h4><p>根据状态传递渠道的不同，常见的主备切换架构有三种形式：互连式、中介式和模拟式。</p>\n<hr>\n<h5 id=\"互连式\"><a href=\"#互连式\" class=\"headerlink\" title=\"互连式\"></a>互连式</h5><p>为了充分利用切换方案能够自动决定主机这个优势，客户端这里也会有一些相应的改变，常见的方式有：</p>\n<ul>\n<li>为了切换后不影响客户端的访问，主机和备机之间共享一个对客户端来说唯一的地址。例如虚拟 IP，主机需要绑定这个虚拟的 IP。</li>\n<li>客户端同时记录主备机的地址，哪个能访问就访问哪个；备机虽然能收到客户端的操作请求，但是会直接拒绝，拒绝的原因就是“备机不对外提供服务”。</li>\n</ul>\n<p>互连式主备切换主要的缺点在于：</p>\n<ul>\n<li>如果状态传递的通道本身有故障（例如，网线被人不小心踢掉了），那么备机也会认为主机故障了从而将自己升级为主机，而此时主机并没有故障，最终就可能出现两个主机。</li>\n<li>虽然可以通过增加多个通道来增强状态传递的可靠性，但这样做只是降低了通道故障概率而已，不能从根本上解决这个缺点，而且通道越多，后续的状态决策会更加复杂，因为对备机来说，可能从不同的通道收到了不同甚至矛盾的状态信息。</li>\n</ul>\n<hr>\n<h5 id=\"中介式\"><a href=\"#中介式\" class=\"headerlink\" title=\"中介式\"></a>中介式</h5><p>中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息</p>\n<ul>\n<li><strong>连接管理更简单</strong>：主备机无须再建立和管理多种类型的状态传递连接通道，只要连接到中介即可，实际上是降低了主备机的连接管理复杂度。</li>\n<li><strong>状态决策更简单</strong>：主备机的状态决策简单了，无须考虑多种类型的连接通道获取的状态信息如何决策的问题，只需要按照下面简单的算法即可完成状态决策。</li>\n</ul>\n<p>缺点：为了实现高可用，我们引入中介，但中介本身又要求高可用，于是又要设计中介的高可用方案</p>\n<hr>\n<h5 id=\"模拟式\"><a href=\"#模拟式\" class=\"headerlink\" title=\"模拟式\"></a>模拟式</h5><p>模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作</p>\n<p>模拟式切换与互连式切换相比，优点是实现更加简单，因为省去了状态传递通道的建立和管理工作。</p>\n<p>简单既是优点，同时也是缺点。因为模拟式读写操作获取的状态信息只有响应信息，没有互连式那样多样，基于有限的状态来做状态决策，可能出现偏差。</p>\n<hr>\n<h4 id=\"主主复制\"><a href=\"#主主复制\" class=\"headerlink\" title=\"主主复制\"></a>主主复制</h4><p>相比主备切换架构，主主复制架构具有如下特点：</p>\n<ul>\n<li>两台都是主机，不存在切换的概念。</li>\n<li>客户端无须区分不同角色的主机，随便将读写操作发送给哪台主机都可以。</li>\n</ul>\n<p>主主复制架构对数据的设计有严格的要求，一般适合于那些临时性、可丢失、可覆盖的数据场景。</p>\n<hr>\n<h3 id=\"集群和分区\"><a href=\"#集群和分区\" class=\"headerlink\" title=\"集群和分区\"></a>集群和分区</h3><p>高可用存储架构也分为2类：数据集群和数据分区。</p>\n<hr>\n<h4 id=\"数据集群\"><a href=\"#数据集群\" class=\"headerlink\" title=\"数据集群\"></a>数据集群</h4><ul>\n<li>数据集中集群<ul>\n<li>主机如何将数据复制给备机</li>\n<li>备机如何检测主机状态</li>\n<li>主机故障后，如何决定新的主机</li>\n</ul>\n</li>\n<li>数据分散集群<ul>\n<li>均衡性</li>\n<li>容错性</li>\n<li>可伸缩性</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"数据分区\"><a href=\"#数据分区\" class=\"headerlink\" title=\"数据分区\"></a>数据分区</h4><p>需要考虑的核心点：数据量、分区规则、复制规则</p>\n<p>常见的分区复制规则有三种：集中式、互备式和独立式。</p>\n<hr>\n<h5 id=\"集中式\"><a href=\"#集中式\" class=\"headerlink\" title=\"集中式\"></a>集中式</h5><p>集中式备份架构的优缺点是：</p>\n<ul>\n<li>设计简单，各分区之间并无直接联系，可以做到互不影响。</li>\n<li>扩展容易，如果要增加第四个分区（例如，武汉分区），只需要将武汉分区的数据复制到西安备份中心即可，其他分区不受影响。</li>\n<li>成本较高，需要建设一个独立的备份中心。</li>\n</ul>\n<hr>\n<h5 id=\"互备式\"><a href=\"#互备式\" class=\"headerlink\" title=\"互备式\"></a>互备式</h5><p>互备式备份架构的优缺点是：</p>\n<ul>\n<li>设计比较复杂，各个分区除了要承担业务数据存储，还需要承担备份功能，相互之间互相关联和影响。</li>\n<li>扩展麻烦，如果增加一个武汉分区，则需要修改广州分区的复制指向武汉分区，然后将武汉分区的复制指向北京分区。而原有北京分区已经备份了的广州分区的数据怎么处理也是个难题，不管是做数据迁移，还是广州分区历史数据保留在北京分区，新数据备份到武汉分区，无论哪种方式都很麻烦。</li>\n<li>成本低，直接利用已有的设备。</li>\n</ul>\n<hr>\n<h5 id=\"独立式\"><a href=\"#独立式\" class=\"headerlink\" title=\"独立式\"></a>独立式</h5><p>独立式备份架构的优缺点是：</p>\n<ul>\n<li>设计简单，各分区互不影响。</li>\n<li>扩展容易，新增加的分区只需要搭建自己的备份中心即可。</li>\n<li>成本高，每个分区需要独立的备份中心，备份中心的场地成本是主要成本，因此独立式比集中式成本要高很多。</li>\n</ul>\n<hr>\n<h4 id=\"计算高可用\"><a href=\"#计算高可用\" class=\"headerlink\" title=\"计算高可用\"></a>计算高可用</h4><p>计算高可用架构的设计复杂度主要体现在<strong>任务管理</strong>方面，即当任务在某台服务器上执行失败后，如何将任务重新分配到新的服务器进行执行。</p>\n<ol>\n<li>哪些服务器可以执行任务，</li>\n<li>任务如何重新执行</li>\n</ol>\n<p>计算高可用框架也分为三类：</p>\n<ol>\n<li>主备架构，备机在故障时才进行启用</li>\n<li>主从架构，备机会参与任务执行</li>\n<li>集群架构：对称集群、非对称集群。减少人工介入，更多的由机器来进行任务分发。</li>\n</ol>\n<hr>\n<h3 id=\"异地多活\"><a href=\"#异地多活\" class=\"headerlink\" title=\"异地多活\"></a>异地多活</h3><ol>\n<li><p>同城异区</p>\n</li>\n<li><p>跨城异地</p>\n</li>\n<li><p>跨国异地</p>\n</li>\n</ol>\n<hr>\n<h4 id=\"异地多活设计4大技巧\"><a href=\"#异地多活设计4大技巧\" class=\"headerlink\" title=\"异地多活设计4大技巧\"></a>异地多活设计4大技巧</h4><ol>\n<li><p>同城异区</p>\n<p>关键在于搭建高速网络将两个机房连接起来，达到近似一个本地机房的效果。架构设计上可以将两个机房当作本地机房来设计，无须额外考虑。</p>\n</li>\n<li><p>跨城异地</p>\n<p>关键在于数据不一致的情况下，业务不受影响或者影响很小，这从逻辑的角度上来说其实是矛盾的，架构设计的主要目的就是为了解决这个矛盾。</p>\n</li>\n<li><p>跨国异地</p>\n<p>主要是面向不同地区用户提供业务，或者提供只读业务，对架构设计要求不高。</p>\n</li>\n</ol>\n<hr>\n<h4 id=\"异地多活设计4大技巧-1\"><a href=\"#异地多活设计4大技巧-1\" class=\"headerlink\" title=\"异地多活设计4大技巧\"></a>异地多活设计4大技巧</h4><p>技巧 1：保证核心业务的异地多活</p>\n<p>技巧 2：保证核心数据最终一致性</p>\n<p>技巧 3：采用多种手段同步数据（队列、二次读取、存储同步、回源读取、重新生成）</p>\n<p>技巧 4：只保证绝大部分用户的异地多活</p>\n<hr>\n<h4 id=\"异地多活设计4步走\"><a href=\"#异地多活设计4步走\" class=\"headerlink\" title=\"异地多活设计4步走\"></a>异地多活设计4步走</h4><p>第 1 步：业务分级（访问量大的业务、核心业务、产生大量收入的业务）</p>\n<p>第 2 步：数据分类（数据量、唯一性、实时性、可丢失性、可恢复性）</p>\n<p>第 3 步：数据同步（存储系统、消息队列、重复生成）</p>\n<p>第 4 步：异常处理（多通道同步、同步和访问结合、日志记录、用户补偿）</p>\n<hr>\n<h3 id=\"接口级的故障\"><a href=\"#接口级的故障\" class=\"headerlink\" title=\"接口级的故障\"></a>接口级的故障</h3><p>降级：系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能</p>\n<p>熔断：降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况。</p>\n<p>限流：只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。</p>\n<p>排队：临时缓存大量的业务请求</p>\n<hr>\n<h2 id=\"可扩展的基本思想\"><a href=\"#可扩展的基本思想\" class=\"headerlink\" title=\"可扩展的基本思想\"></a>可扩展的基本思想</h2><p>所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆！</p>\n<ol>\n<li>面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。（TCP）</li>\n<li>面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。（京东的支付和商城）</li>\n<li>面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。（京东用户系统里面的查询和注册）</li>\n</ol>\n<blockquote>\n<p>不同的拆分方式，本质上决定了系统的扩展方式。</p>\n</blockquote>\n<hr>\n<h3 id=\"可扩展方式\"><a href=\"#可扩展方式\" class=\"headerlink\" title=\"可扩展方式\"></a>可扩展方式</h3><p><strong>面向流程拆分：</strong>分层架构。</p>\n<p><strong>特点：</strong>扩展时大部分情况只需要修改某一层，少部分情况可能修改关联的两层</p>\n<p><strong>面向服务拆分：</strong>SOA、微服务。</p>\n<p><strong>特点：</strong>对某个服务扩展，或者要增加新的服务时，只需要扩展相关服务即可，无须修改所有的服务。</p>\n<p><strong>面向功能拆分：</strong>微内核架构。</p>\n<p><strong>特点：</strong>对某个功能扩展，或者要增加新的功能时，只需要扩展相关功能即可，无须修改所有的服务。</p>\n<hr>\n<h4 id=\"微服务架构最佳实践\"><a href=\"#微服务架构最佳实践\" class=\"headerlink\" title=\"微服务架构最佳实践\"></a>微服务架构最佳实践</h4><p>实施微服务需要避免踩的陷阱，简单提炼为：</p>\n<ol>\n<li>微服务拆分过细，过分强调“small”。</li>\n<li>微服务基础设施不健全，忽略了“automated”。</li>\n<li>微服务并不轻量级，规模大了后，“lightweight”不再适应。</li>\n</ol>\n<hr>\n<h4 id=\"微服务架构基础设施\"><a href=\"#微服务架构基础设施\" class=\"headerlink\" title=\"微服务架构基础设施\"></a>微服务架构基础设施</h4><p>自动化部署：包括版本管理、资源管理（例如，机器管理、虚拟机管理）、部署操作、回退操作等功能。</p>\n<p>配置中心：配置版本管理、增删改查配置、节点管理、配置同步、配置推送等功能。</p>\n<p>接口框架：以库或者包的形式提供给所有微服务调用</p>\n<p>API 网关：接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。</p>\n<p>服务发现：需要一套服务发现的系统来支撑微服务的自动注册和发现</p>\n<p>服务路由：从所有符合条件的可用微服务节点中挑选出一个具体的节点发起请求</p>\n<p>服务容错：请求重试、流控和服务隔离</p>\n<p>服务监控：实时搜集信息并进行分析、监控预警</p>\n<p>服务跟踪：在大量微服务系统中快速定位问题</p>\n<p>服务安全：接入安全、数据安全、传输安全</p>\n<hr>\n<h4 id=\"微内核架构详解\"><a href=\"#微内核架构详解\" class=\"headerlink\" title=\"微内核架构详解\"></a>微内核架构详解</h4><blockquote>\n<p> 微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构</p>\n</blockquote>\n<p>微内核的核心系统设计的关键技术有：插件管理、插件连接和插件通信。</p>\n<ol>\n<li><p>插件管理</p>\n</li>\n<li><p>插件连接</p>\n</li>\n<li><p>插件通信</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li>基础架构</li>\n<li>高性能架构模式</li>\n<li>高可用架构模式</li>\n<li>可扩展架构模式</li>\n<li>架构实战</li>\n</ul>\n<hr>\n<h2 id=\"基础架构\"><a href=\"#基础架构\" class=\"headerlink\" title=\"基础架构\"></a>基础架构</h2><p>什么是架构？</p>\n<p>架构是如何产生的？</p>\n<p>架构的目的是什么？</p>\n<p>架构设计有什么原则？</p>\n<hr>\n<h3 id=\"什么是架构？\"><a href=\"#什么是架构？\" class=\"headerlink\" title=\"什么是架构？\"></a>什么是架构？</h3><p>架构包含以下几个关键词：</p>\n<ol>\n<li>系统与子系统</li>\n<li>模块与组件</li>\n<li>框架与架构</li>\n</ol>\n<hr>\n<h3 id=\"什么是架构？-1\"><a href=\"#什么是架构？-1\" class=\"headerlink\" title=\"什么是架构？\"></a>什么是架构？</h3><p>参考维基百科的定义，我将架构重新定义为：<strong>软件架构指软件系统的顶层结构</strong>。</p>\n<ul>\n<li>首先，“系统是一群关联个体组成”，这些“个体”可以是“子系统”“模块”“组件”等；架构需要明确系统包含哪些“个体”。</li>\n<li>其次，系统中的个体需要“根据某种规则”运作，架构需要明确个体运作和协作的规则。</li>\n<li>第三，维基百科定义的架构用到了“基础结构”这个说法，我改为“顶层结构”，可以更好地区分系统和子系统，避免将系统架构和子系统架构混淆在一起导致架构层次混乱。</li>\n</ul>\n<hr>\n<h3 id=\"架构的背景\"><a href=\"#架构的背景\" class=\"headerlink\" title=\"架构的背景\"></a>架构的背景</h3><ul>\n<li>机器语言（<strong>1940 年之前</strong>）：太难写、太难读、太难改！</li>\n<li>汇编语言（<strong>20 世纪 40 年代</strong>）：解决了机器语言读写复杂的问题，但本质上还是面向机器的</li>\n<li>高级语言（<strong>20 世纪 50 年代</strong>）：软件的规模和复杂度的大大增加，软件质量低下、项目无法如期完成、项目严重超支等</li>\n<li>第一次软件危机与结构化程序设计（<strong>20 世纪 60 年代~20 世纪 70 年代</strong>）：软件生产力远远跟不上硬件和业务的发展</li>\n<li>第二次软件危机与面向对象（<strong>20 世纪 80 年代</strong>）：软件的“扩展”变得非常复杂。</li>\n</ul>\n<hr>\n<h3 id=\"软件架构的历史背景\"><a href=\"#软件架构的历史背景\" class=\"headerlink\" title=\"软件架构的历史背景\"></a>软件架构的历史背景</h3><blockquote>\n<p>“When systems are constructed from many components, the organization of the overall system-the software architecture-presents a new set of design problems.”</p>\n</blockquote>\n<p>简单翻译一下：随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。</p>\n<hr>\n<h3 id=\"架构设计的误区\"><a href=\"#架构设计的误区\" class=\"headerlink\" title=\"架构设计的误区\"></a>架构设计的误区</h3><ol>\n<li>因为架构很重要，所以要做架构设计</li>\n<li>不是每个系统都要做架构设计吗</li>\n<li>公司流程要求系统开发过程中必须有架构设计</li>\n<li>为了高性能、高可用、可扩展，所以要做架构设计</li>\n</ol>\n<hr>\n<h3 id=\"架构设计的真正目的\"><a href=\"#架构设计的真正目的\" class=\"headerlink\" title=\"架构设计的真正目的\"></a>架构设计的真正目的</h3><blockquote>\n<p>架构设计的主要目的是为了解决软件系统复杂度带来的问题。</p>\n</blockquote>\n<p>有的放矢，而不是贪大求全。</p>\n<hr>\n<h3 id=\"复杂度来源\"><a href=\"#复杂度来源\" class=\"headerlink\" title=\"复杂度来源\"></a>复杂度来源</h3><ol>\n<li>高性能</li>\n<li>高可用</li>\n<li>可扩展</li>\n<li>低成本、安全、规模</li>\n</ol>\n<hr>\n<h3 id=\"高性能复杂度\"><a href=\"#高性能复杂度\" class=\"headerlink\" title=\"高性能复杂度\"></a>高性能复杂度</h3><ul>\n<li>单机复杂度：多进程、多线程的协作</li>\n<li>集群复杂度：任务分配和任务拆解</li>\n</ul>\n<hr>\n<h3 id=\"高可用复杂度\"><a href=\"#高可用复杂度\" class=\"headerlink\" title=\"高可用复杂度\"></a>高可用复杂度</h3><blockquote>\n<p>系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。</p>\n</blockquote>\n<p><strong>“冗余”</strong>是高可用的最终解决方案</p>\n<p>高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元。</p>\n<hr>\n<h3 id=\"高可用复杂度-1\"><a href=\"#高可用复杂度-1\" class=\"headerlink\" title=\"高可用复杂度\"></a>高可用复杂度</h3><ul>\n<li><strong>计算高可用</strong>：无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的</li>\n<li><strong>存储高可用</strong>：如何减少或者规避数据不一致对业务造成的影响。</li>\n<li><strong>高可用状态决策</strong>：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确</li>\n</ul>\n<p><strong>决策手段</strong>：独裁式、协商式、民主式</p>\n<hr>\n<h3 id=\"可扩展性复杂度\"><a href=\"#可扩展性复杂度\" class=\"headerlink\" title=\"可扩展性复杂度\"></a>可扩展性复杂度</h3><p>设计具备良好可扩展性的系统，有两个基本条件：<strong>正确预测变化</strong>、<strong>完美封装变化</strong>。</p>\n<p>预测变化的复杂性在于：</p>\n<ul>\n<li>不能每个设计点<strong>都考虑</strong>可扩展性。</li>\n<li>不能完全<strong>不考虑</strong>可扩展性。</li>\n<li>所有的预测都<strong>存在出错</strong>的可能性。</li>\n</ul>\n<hr>\n<h3 id=\"可扩展性复杂度-1\"><a href=\"#可扩展性复杂度-1\" class=\"headerlink\" title=\"可扩展性复杂度\"></a>可扩展性复杂度</h3><p>唯一不变的是变化，而应对变化的手段就是将变化和不变的分离开：</p>\n<ol>\n<li>将“变化”封装在一个“变化层”，将不变的部分封装在一个独立的“稳定层”：<strong>ORM的实现</strong></li>\n<li>提炼出一个“抽象层”和一个“实现层”：<strong>规则引擎和设计模式</strong></li>\n</ol>\n<hr>\n<h3 id=\"复杂度来源：低成本、安全、规模\"><a href=\"#复杂度来源：低成本、安全、规模\" class=\"headerlink\" title=\"复杂度来源：低成本、安全、规模\"></a>复杂度来源：低成本、安全、规模</h3><ul>\n<li>新技术带动低成本<ul>\n<li>存储侧：NoSQL、全文搜索引擎、Hadoop</li>\n<li>系统侧：HipHop PHP、Redis/MC + SSD Cache + MySQL、Kafka、</li>\n</ul>\n</li>\n<li>安全需要多方考虑<ul>\n<li>功能安全：就是“防小偷”。</li>\n<li>架构安全：就是“防强盗”</li>\n</ul>\n</li>\n<li>量变引起质变<ul>\n<li>功能越来越多，导致系统复杂度指数级上升</li>\n<li>数据越来越多，系统复杂度发生质变</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"架构设计原则\"><a href=\"#架构设计原则\" class=\"headerlink\" title=\"架构设计原则\"></a>架构设计原则</h3><ul>\n<li>合适原则宣言：“合适优于业界领先”。</li>\n<li>简单原则宣言：“简单优于复杂”。</li>\n<li>演化原则宣言：“演化优于一步到位”。</li>\n</ul>\n<hr>\n<h3 id=\"架构设计流程\"><a href=\"#架构设计流程\" class=\"headerlink\" title=\"架构设计流程\"></a>架构设计流程</h3><ul>\n<li>识别复杂度：架构设计的本质目的是为了解决软件系统的复杂性</li>\n<li>设计备选方案、评估和选择备选方案</li>\n<li>详细方案设计：将方案涉及的关键技术细节给确定下来</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>随着软件系统规模的增加，引发了架构设计</li>\n<li>架构设计是为了解决复杂度而产生</li>\n<li>架构设计遵循适合、简单、演变三原则</li>\n<li>架构需要从目的、方案、完善逐步进行</li>\n</ol>\n<hr>\n<h2 id=\"高性能架构模式\"><a href=\"#高性能架构模式\" class=\"headerlink\" title=\"高性能架构模式\"></a>高性能架构模式</h2><p>高性能复杂度前文中是从单机到多机的复杂度增加，而将架构拆解开来，可以分为计算高性能和存储高性能。毕竟程序是存储+计算来实现。</p>\n<p>存储高性能</p>\n<ul>\n<li>数据库高性能</li>\n<li>Nosql高性能</li>\n<li>缓存高性能</li>\n</ul>\n<p>计算高性能</p>\n<ul>\n<li>服务器高性能</li>\n<li>多机负载均衡</li>\n</ul>\n<hr>\n<h3 id=\"存储高性能（数据库高性能）\"><a href=\"#存储高性能（数据库高性能）\" class=\"headerlink\" title=\"存储高性能（数据库高性能）\"></a>存储高性能（数据库高性能）</h3><p>高性能数据库集群的第一种方式是“<strong>读写分离</strong>”，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力；</p>\n<p>第二种方式是“<strong>分库分表</strong>”，既可以分散访问压力，又可以分散存储压力。</p>\n<hr>\n<h3 id=\"读写分离\"><a href=\"#读写分离\" class=\"headerlink\" title=\"读写分离\"></a>读写分离</h3><p>读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度：<strong>主从复制延迟</strong>和<strong>分配机制</strong>。</p>\n<ul>\n<li>复制延迟<ul>\n<li>写操作后的读操作指定发给数据库主服务器</li>\n<li>读从机失败后再读一次主机</li>\n<li>关键业务读写操作全部指向主机，非关键业务采用读写分离</li>\n</ul>\n</li>\n<li>分配机制<ul>\n<li>程序代码封装：实现简单、无法通用</li>\n<li>中间件封装</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h3><p><strong>核心问题</strong>：数据量太大，读写的性能会下降、数据库备份和恢复需要耗费很长时间、极端情况下丢失数据的风险越高</p>\n<p>业务分库：业务分库指的是按照业务模块将数据分散到不同的数据库服务器</p>\n<ul>\n<li>join 操作问题</li>\n<li>事务问题</li>\n<li>成本问题</li>\n</ul>\n<p>数据分表：同一业务的单表数据也会达到单台数据库服务器的处理瓶颈，需要进行垂直分表和水平分表</p>\n<ul>\n<li>垂直分表</li>\n<li>水平分表</li>\n<li>路由</li>\n</ul>\n<hr>\n<h3 id=\"高性能NoSQL起源\"><a href=\"#高性能NoSQL起源\" class=\"headerlink\" title=\"高性能NoSQL起源\"></a>高性能NoSQL起源</h3><p>关系数据库存在如下缺点：</p>\n<ol>\n<li>关系数据库存储的是行记录，无法存储数据结构</li>\n<li>关系数据库的 schema 扩展很不方便</li>\n<li>关系数据库在大数据场景下 I/O 较高</li>\n<li>关系数据库的全文搜索功能比较弱</li>\n</ol>\n<hr>\n<h3 id=\"高性能NoSQL分类\"><a href=\"#高性能NoSQL分类\" class=\"headerlink\" title=\"高性能NoSQL分类\"></a>高性能NoSQL分类</h3><ul>\n<li><p>K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。</p>\n</li>\n<li><p>文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。</p>\n</li>\n<li><p>列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。</p>\n</li>\n<li><p>全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"高性能缓存架构\"><a href=\"#高性能缓存架构\" class=\"headerlink\" title=\"高性能缓存架构\"></a>高性能缓存架构</h3><p>虽然我们可以通过各种手段来提升存储系统的性能，但在某些复杂的业务场景下，单纯依靠存储系统的性能提升不够的，典型的场景有：</p>\n<ol>\n<li>需要经过复杂运算后得出的数据，存储系统无能为力</li>\n<li>读多写少的数据，存储系统有心无力</li>\n</ol>\n<p>缓存虽然能够大大减轻存储系统的压力，但同时也给架构引入了更多复杂性。</p>\n<hr>\n<h3 id=\"高性能缓存架构的问题\"><a href=\"#高性能缓存架构的问题\" class=\"headerlink\" title=\"高性能缓存架构的问题\"></a>高性能缓存架构的问题</h3><ul>\n<li>缓存穿透：</li>\n<li>缓存雪崩：</li>\n<li>缓存热点：</li>\n</ul>\n<hr>\n<h3 id=\"单服务器的高性能\"><a href=\"#单服务器的高性能\" class=\"headerlink\" title=\"单服务器的高性能\"></a>单服务器的高性能</h3><p>单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：</p>\n<ul>\n<li><p>服务器如何管理连接。</p>\n</li>\n<li><p>服务器如何处理请求。</p>\n</li>\n</ul>\n<p>以上两个设计点最终都和操作系统的 I/O 模型及进程模型相关。</p>\n<ul>\n<li>I/O 模型：阻塞、非阻塞、同步、异步。</li>\n<li>进程模型：单进程、多进程、多线程。</li>\n</ul>\n<p>其中对应的网络编程模型有：PPC、TPC、Reactor、Proactor。</p>\n<hr>\n<h4 id=\"PPC和TPC\"><a href=\"#PPC和TPC\" class=\"headerlink\" title=\"PPC和TPC\"></a>PPC和TPC</h4><p>PPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。</p>\n<ul>\n<li>fork 代价高</li>\n<li>父子进程通信复杂</li>\n<li>支持的并发连接数量有限</li>\n</ul>\n<p>TPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。</p>\n<ul>\n<li>代价低，但并不是没有代价</li>\n<li>线程间的互斥和共享又引入了复杂度</li>\n<li>多线程会出现互相影响的情况</li>\n</ul>\n<hr>\n<p>PPC和TPC其实是很大的浪费</p>\n<p>引入资源池的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？</p>\n<p>解决这个问题的最简单的方式是将 read 操作改为非阻塞，然后进程不断地轮询多个连接。</p>\n<p>如果一个进程处理几千上万的连接，则轮询的效率是很低的。</p>\n<hr>\n<h3 id=\"Reactor模式\"><a href=\"#Reactor模式\" class=\"headerlink\" title=\"Reactor模式\"></a>Reactor模式</h3><p>为了能够更好地解决上述问题，很容易可以想到，只有当连接上有数据的时候进程才去处理，这就是 I/O 多路复用技术的来源。</p>\n<ul>\n<li><p>当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的实现方式有 select、epoll、kqueue 等。</p>\n</li>\n<li><p>当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。</p>\n</li>\n</ul>\n<p>I/O 多路复用结合线程池，完美地解决了 PPC 和 TPC 的问题，而且“大神们”给它取了一个很牛的名字：Reactor，中文是“反应堆”。</p>\n<p>Reactor 模式的核心组成部分包括 Reactor 和处理资源池（进程池或线程池），其中 Reactor 负责监听和分配事件，处理资源池负责处理事件。</p>\n<hr>\n<h3 id=\"Proactor模式\"><a href=\"#Proactor模式\" class=\"headerlink\" title=\"Proactor模式\"></a>Proactor模式</h3><p>Reactor 是非阻塞同步网络模型，因为真正的 read 和 send 操作都需要用户进程同步操作。</p>\n<p>如果把 I/O 操作改为异步就能够进一步提升性能，这就是异步网络模型 Proactor。</p>\n<p>Proactor 中文翻译为“前摄器”比较难理解，与其类似的单词是 proactive，含义为“主动的”，因此我们照猫画虎翻译为“主动器”反而更好理解。</p>\n<p>理论上 Proactor 比 Reactor 效率要高一些，异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠，但要实现真正的异步 I/O，操作系统需要做大量的工作。</p>\n<hr>\n<h3 id=\"集群负载均衡\"><a href=\"#集群负载均衡\" class=\"headerlink\" title=\"集群负载均衡\"></a>集群负载均衡</h3><p>高性能集群的本质很简单，通过增加更多的服务器来提升系统整体的计算能力。</p>\n<p>高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法</p>\n<p>负载均衡分类</p>\n<ul>\n<li>DNS 负载均衡</li>\n<li>硬件负载均衡</li>\n<li>软件负载均衡</li>\n</ul>\n<hr>\n<h4 id=\"DNS-负载均衡\"><a href=\"#DNS-负载均衡\" class=\"headerlink\" title=\"DNS 负载均衡\"></a>DNS 负载均衡</h4><p>优点有：</p>\n<ul>\n<li>简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。</li>\n<li>就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。</li>\n</ul>\n<p>缺点有：</p>\n<ul>\n<li>更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。</li>\n<li>扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。</li>\n<li>分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。</li>\n</ul>\n<p>针对 DNS 负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了 HTTP-DNS 的功能，即使用 HTTP 协议实现一个私有的 DNS 系统。这样的方案和通用的 DNS 优缺点正好相反。</p>\n<hr>\n<h4 id=\"硬件负载均衡\"><a href=\"#硬件负载均衡\" class=\"headerlink\" title=\"硬件负载均衡\"></a>硬件负载均衡</h4><p>优点是：</p>\n<ul>\n<li>功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。</li>\n<li>性能强大：对比一下，软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。</li>\n<li>稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。</li>\n<li>支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。</li>\n</ul>\n<p>缺点是：</p>\n<ul>\n<li>价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。</li>\n<li>扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。</li>\n</ul>\n<hr>\n<h4 id=\"软件负载均衡\"><a href=\"#软件负载均衡\" class=\"headerlink\" title=\"软件负载均衡\"></a>软件负载均衡</h4><p>常见的有 Nginx 和 LVS，其中 Nginx 是软件的 7 层负载均衡，LVS 是 Linux 内核的 4 层负载均衡。4 层和 7 层的区别就在于协议和灵活性</p>\n<p>优点：</p>\n<ul>\n<li>简单：无论是部署还是维护都比较简单。</li>\n<li>便宜：只要买个 Linux 服务器，装上软件即可。</li>\n<li>灵活：4 层和 7 层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过 Nginx 的插件来实现业务的定制化功能。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>性能一般：一个 Nginx 大约能支撑 5 万并发。</li>\n<li>功能没有硬件负载均衡那么强大。</li>\n<li>一般不具备防火墙和防 DDoS 攻击等安全功能。</li>\n</ul>\n<hr>\n<h3 id=\"负载均衡典型架构\"><a href=\"#负载均衡典型架构\" class=\"headerlink\" title=\"负载均衡典型架构\"></a>负载均衡典型架构</h3><p>基本原则：DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。</p>\n<hr>\n<h3 id=\"负载均衡算法\"><a href=\"#负载均衡算法\" class=\"headerlink\" title=\"负载均衡算法\"></a>负载均衡算法</h3><ul>\n<li><strong>任务平分类</strong>：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。</li>\n<li><strong>负载均衡类</strong>：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。</li>\n<li><strong>性能最优类</strong>：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。</li>\n<li><strong>Hash 类</strong>：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。</li>\n</ul>\n<hr>\n<h2 id=\"高可用架构模式\"><a href=\"#高可用架构模式\" class=\"headerlink\" title=\"高可用架构模式\"></a>高可用架构模式</h2><p>高可用架构更多核心是探讨高可用状态决策方式。</p>\n<hr>\n<h4 id=\"CAP模型\"><a href=\"#CAP模型\" class=\"headerlink\" title=\"CAP模型\"></a>CAP模型</h4><p>第一版解释：</p>\n<blockquote>\n<p>对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三个设计约束。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。</p>\n</blockquote>\n<p>差异点：属于需要共享数据，且只关注与读写功能</p>\n<hr>\n<h3 id=\"CAP模型细节\"><a href=\"#CAP模型细节\" class=\"headerlink\" title=\"CAP模型细节\"></a>CAP模型细节</h3><h4 id=\"一致性（Consistency）\"><a href=\"#一致性（Consistency）\" class=\"headerlink\" title=\"一致性（Consistency）\"></a>一致性（Consistency）</h4><p>第一版解释：</p>\n<blockquote>\n<p>所有节点在同一时刻都能看到相同的数据。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。</p>\n</blockquote>\n<p>角色从node变成了client，只需要保证观察者能读取到最新数据即可。</p>\n<hr>\n<h4 id=\"可用性（Availability）\"><a href=\"#可用性（Availability）\" class=\"headerlink\" title=\"可用性（Availability）\"></a>可用性（Availability）</h4><p>第一版解释：</p>\n<blockquote>\n<p>每个请求都能得到成功或者失败的响应。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。</p>\n</blockquote>\n<p>第二版明确了不能超时、不能出错，结果是合理的，注意没有说“正确”的结果</p>\n<hr>\n<h4 id=\"分区容忍性（Partition-Tolerance）\"><a href=\"#分区容忍性（Partition-Tolerance）\" class=\"headerlink\" title=\"分区容忍性（Partition Tolerance）\"></a>分区容忍性（Partition Tolerance）</h4><p>第一版解释：</p>\n<blockquote>\n<p>出现消息丢失或者分区错误时系统能够继续运行。</p>\n</blockquote>\n<p>第二版解释：</p>\n<blockquote>\n<p>当出现网络分区后，系统能够继续“履行职责”。</p>\n</blockquote>\n<p>第二版描述了更多的异常情况，而非消息丢失。同时强调履行职责，而非运行。</p>\n<hr>\n<h4 id=\"三者冲突关系\"><a href=\"#三者冲突关系\" class=\"headerlink\" title=\"三者冲突关系\"></a>三者冲突关系</h4><p>P是分布式系统的基础，因为如果P无法实现，那C就无法保证写入，必然导致A无法保证。</p>\n<hr>\n<h3 id=\"CAP模型细节-1\"><a href=\"#CAP模型细节-1\" class=\"headerlink\" title=\"CAP模型细节\"></a>CAP模型细节</h3><p>参考文献：<a href=\"https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/\" target=\"_blank\" rel=\"noopener\">CAP 理论十二年回顾：”规则”变了</a></p>\n<ol>\n<li>“三选二”的公式一直存在着误导性，它会过分简单化各性质之间的相互关系。</li>\n<li>因为分区很少出现，CAP 在大多数时候允许完美的 C 和 A</li>\n<li>当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响</li>\n</ol>\n<p>策略应分为三个步骤：探知分区发生，进入显式的分区模式以限制某些操作，启动恢复过程以恢复数据一致性并补偿分区期间发生的错误。</p>\n<hr>\n<h3 id=\"ACID、BASE、CAP\"><a href=\"#ACID、BASE、CAP\" class=\"headerlink\" title=\"ACID、BASE、CAP\"></a>ACID、BASE、CAP</h3><p>ACID 和 BASE 代表了两种截然相反的设计哲学，分处一致性 - 可用性分布图谱的两极。ACID 注重一致性，是数据库的传统设计思路。</p>\n<p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：</p>\n<ul>\n<li>CAP 理论是忽略延时的，而实际应用中延时是无法避免的。</li>\n<li>AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。</li>\n</ul>\n<p>综合上面的分析，ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</p>\n<hr>\n<h3 id=\"高可用存储架构：双机架构\"><a href=\"#高可用存储架构：双机架构\" class=\"headerlink\" title=\"高可用存储架构：双机架构\"></a>高可用存储架构：双机架构</h3><p>存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用</p>\n<p>其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。因此，对任何一个高可用存储方案，我们需要从以下几个方面去进行思考和分析：</p>\n<ul>\n<li>数据如何复制？</li>\n<li>各个节点的职责是什么？</li>\n<li>如何应对复制延迟？</li>\n<li>如何应对复制中断？</li>\n</ul>\n<p>常见的高可用存储架构有主备、主从、主主、集群、分区，每一种又可以根据业务的需求进行一些特殊的定制化功能，由此衍生出更多的变种</p>\n<hr>\n<h4 id=\"主备复制\"><a href=\"#主备复制\" class=\"headerlink\" title=\"主备复制\"></a>主备复制</h4><p>主备复制架构的优点就是简单，表现有：</p>\n<ul>\n<li>对于客户端来说，不需要感知备机的存在，即使灾难恢复后，原来的备机被人工修改为主机后，对于客户端来说，只是认为主机的地址换了而已，无须知道是原来的备机升级为主机。</li>\n<li>对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。</li>\n</ul>\n<p>主备复制架构的缺点主要有：</p>\n<ul>\n<li>备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费。</li>\n<li>故障后需要人工干预，无法自动恢复。人工处理的效率是很低的，可能打电话找到能够操作的人就耗费了 10 分钟，甚至如果是深更半夜，出了故障都没人知道。人工在执行恢复操作的过程中也容易出错，因为这类操作并不常见，可能 1 年就 2、3 次，实际操作的时候很可能遇到各种意想不到的问题。</li>\n</ul>\n<hr>\n<h4 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h4><p>主从复制与主备复制相比，优点有：</p>\n<ul>\n<li>主从复制在主机故障时，读操作相关的业务可以继续运行。</li>\n<li>主从复制架构的从机提供读操作，发挥了硬件的性能。</li>\n</ul>\n<p>缺点有：</p>\n<ul>\n<li>主从复制架构中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备复制要高。</li>\n<li>主从复制架构中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题。</li>\n<li>故障时需要人工干预。</li>\n</ul>\n<hr>\n<h3 id=\"双机切换\"><a href=\"#双机切换\" class=\"headerlink\" title=\"双机切换\"></a>双机切换</h3><ol>\n<li>主备间状态判断：状态传递的渠道、状态检测的内容</li>\n<li>切换决策：切换时机、切换策略、自动程度。</li>\n<li>数据冲突解决</li>\n</ol>\n<hr>\n<h4 id=\"状态传递渠道\"><a href=\"#状态传递渠道\" class=\"headerlink\" title=\"状态传递渠道\"></a>状态传递渠道</h4><p>根据状态传递渠道的不同，常见的主备切换架构有三种形式：互连式、中介式和模拟式。</p>\n<hr>\n<h5 id=\"互连式\"><a href=\"#互连式\" class=\"headerlink\" title=\"互连式\"></a>互连式</h5><p>为了充分利用切换方案能够自动决定主机这个优势，客户端这里也会有一些相应的改变，常见的方式有：</p>\n<ul>\n<li>为了切换后不影响客户端的访问，主机和备机之间共享一个对客户端来说唯一的地址。例如虚拟 IP，主机需要绑定这个虚拟的 IP。</li>\n<li>客户端同时记录主备机的地址，哪个能访问就访问哪个；备机虽然能收到客户端的操作请求，但是会直接拒绝，拒绝的原因就是“备机不对外提供服务”。</li>\n</ul>\n<p>互连式主备切换主要的缺点在于：</p>\n<ul>\n<li>如果状态传递的通道本身有故障（例如，网线被人不小心踢掉了），那么备机也会认为主机故障了从而将自己升级为主机，而此时主机并没有故障，最终就可能出现两个主机。</li>\n<li>虽然可以通过增加多个通道来增强状态传递的可靠性，但这样做只是降低了通道故障概率而已，不能从根本上解决这个缺点，而且通道越多，后续的状态决策会更加复杂，因为对备机来说，可能从不同的通道收到了不同甚至矛盾的状态信息。</li>\n</ul>\n<hr>\n<h5 id=\"中介式\"><a href=\"#中介式\" class=\"headerlink\" title=\"中介式\"></a>中介式</h5><p>中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息</p>\n<ul>\n<li><strong>连接管理更简单</strong>：主备机无须再建立和管理多种类型的状态传递连接通道，只要连接到中介即可，实际上是降低了主备机的连接管理复杂度。</li>\n<li><strong>状态决策更简单</strong>：主备机的状态决策简单了，无须考虑多种类型的连接通道获取的状态信息如何决策的问题，只需要按照下面简单的算法即可完成状态决策。</li>\n</ul>\n<p>缺点：为了实现高可用，我们引入中介，但中介本身又要求高可用，于是又要设计中介的高可用方案</p>\n<hr>\n<h5 id=\"模拟式\"><a href=\"#模拟式\" class=\"headerlink\" title=\"模拟式\"></a>模拟式</h5><p>模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作</p>\n<p>模拟式切换与互连式切换相比，优点是实现更加简单，因为省去了状态传递通道的建立和管理工作。</p>\n<p>简单既是优点，同时也是缺点。因为模拟式读写操作获取的状态信息只有响应信息，没有互连式那样多样，基于有限的状态来做状态决策，可能出现偏差。</p>\n<hr>\n<h4 id=\"主主复制\"><a href=\"#主主复制\" class=\"headerlink\" title=\"主主复制\"></a>主主复制</h4><p>相比主备切换架构，主主复制架构具有如下特点：</p>\n<ul>\n<li>两台都是主机，不存在切换的概念。</li>\n<li>客户端无须区分不同角色的主机，随便将读写操作发送给哪台主机都可以。</li>\n</ul>\n<p>主主复制架构对数据的设计有严格的要求，一般适合于那些临时性、可丢失、可覆盖的数据场景。</p>\n<hr>\n<h3 id=\"集群和分区\"><a href=\"#集群和分区\" class=\"headerlink\" title=\"集群和分区\"></a>集群和分区</h3><p>高可用存储架构也分为2类：数据集群和数据分区。</p>\n<hr>\n<h4 id=\"数据集群\"><a href=\"#数据集群\" class=\"headerlink\" title=\"数据集群\"></a>数据集群</h4><ul>\n<li>数据集中集群<ul>\n<li>主机如何将数据复制给备机</li>\n<li>备机如何检测主机状态</li>\n<li>主机故障后，如何决定新的主机</li>\n</ul>\n</li>\n<li>数据分散集群<ul>\n<li>均衡性</li>\n<li>容错性</li>\n<li>可伸缩性</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"数据分区\"><a href=\"#数据分区\" class=\"headerlink\" title=\"数据分区\"></a>数据分区</h4><p>需要考虑的核心点：数据量、分区规则、复制规则</p>\n<p>常见的分区复制规则有三种：集中式、互备式和独立式。</p>\n<hr>\n<h5 id=\"集中式\"><a href=\"#集中式\" class=\"headerlink\" title=\"集中式\"></a>集中式</h5><p>集中式备份架构的优缺点是：</p>\n<ul>\n<li>设计简单，各分区之间并无直接联系，可以做到互不影响。</li>\n<li>扩展容易，如果要增加第四个分区（例如，武汉分区），只需要将武汉分区的数据复制到西安备份中心即可，其他分区不受影响。</li>\n<li>成本较高，需要建设一个独立的备份中心。</li>\n</ul>\n<hr>\n<h5 id=\"互备式\"><a href=\"#互备式\" class=\"headerlink\" title=\"互备式\"></a>互备式</h5><p>互备式备份架构的优缺点是：</p>\n<ul>\n<li>设计比较复杂，各个分区除了要承担业务数据存储，还需要承担备份功能，相互之间互相关联和影响。</li>\n<li>扩展麻烦，如果增加一个武汉分区，则需要修改广州分区的复制指向武汉分区，然后将武汉分区的复制指向北京分区。而原有北京分区已经备份了的广州分区的数据怎么处理也是个难题，不管是做数据迁移，还是广州分区历史数据保留在北京分区，新数据备份到武汉分区，无论哪种方式都很麻烦。</li>\n<li>成本低，直接利用已有的设备。</li>\n</ul>\n<hr>\n<h5 id=\"独立式\"><a href=\"#独立式\" class=\"headerlink\" title=\"独立式\"></a>独立式</h5><p>独立式备份架构的优缺点是：</p>\n<ul>\n<li>设计简单，各分区互不影响。</li>\n<li>扩展容易，新增加的分区只需要搭建自己的备份中心即可。</li>\n<li>成本高，每个分区需要独立的备份中心，备份中心的场地成本是主要成本，因此独立式比集中式成本要高很多。</li>\n</ul>\n<hr>\n<h4 id=\"计算高可用\"><a href=\"#计算高可用\" class=\"headerlink\" title=\"计算高可用\"></a>计算高可用</h4><p>计算高可用架构的设计复杂度主要体现在<strong>任务管理</strong>方面，即当任务在某台服务器上执行失败后，如何将任务重新分配到新的服务器进行执行。</p>\n<ol>\n<li>哪些服务器可以执行任务，</li>\n<li>任务如何重新执行</li>\n</ol>\n<p>计算高可用框架也分为三类：</p>\n<ol>\n<li>主备架构，备机在故障时才进行启用</li>\n<li>主从架构，备机会参与任务执行</li>\n<li>集群架构：对称集群、非对称集群。减少人工介入，更多的由机器来进行任务分发。</li>\n</ol>\n<hr>\n<h3 id=\"异地多活\"><a href=\"#异地多活\" class=\"headerlink\" title=\"异地多活\"></a>异地多活</h3><ol>\n<li><p>同城异区</p>\n</li>\n<li><p>跨城异地</p>\n</li>\n<li><p>跨国异地</p>\n</li>\n</ol>\n<hr>\n<h4 id=\"异地多活设计4大技巧\"><a href=\"#异地多活设计4大技巧\" class=\"headerlink\" title=\"异地多活设计4大技巧\"></a>异地多活设计4大技巧</h4><ol>\n<li><p>同城异区</p>\n<p>关键在于搭建高速网络将两个机房连接起来，达到近似一个本地机房的效果。架构设计上可以将两个机房当作本地机房来设计，无须额外考虑。</p>\n</li>\n<li><p>跨城异地</p>\n<p>关键在于数据不一致的情况下，业务不受影响或者影响很小，这从逻辑的角度上来说其实是矛盾的，架构设计的主要目的就是为了解决这个矛盾。</p>\n</li>\n<li><p>跨国异地</p>\n<p>主要是面向不同地区用户提供业务，或者提供只读业务，对架构设计要求不高。</p>\n</li>\n</ol>\n<hr>\n<h4 id=\"异地多活设计4大技巧-1\"><a href=\"#异地多活设计4大技巧-1\" class=\"headerlink\" title=\"异地多活设计4大技巧\"></a>异地多活设计4大技巧</h4><p>技巧 1：保证核心业务的异地多活</p>\n<p>技巧 2：保证核心数据最终一致性</p>\n<p>技巧 3：采用多种手段同步数据（队列、二次读取、存储同步、回源读取、重新生成）</p>\n<p>技巧 4：只保证绝大部分用户的异地多活</p>\n<hr>\n<h4 id=\"异地多活设计4步走\"><a href=\"#异地多活设计4步走\" class=\"headerlink\" title=\"异地多活设计4步走\"></a>异地多活设计4步走</h4><p>第 1 步：业务分级（访问量大的业务、核心业务、产生大量收入的业务）</p>\n<p>第 2 步：数据分类（数据量、唯一性、实时性、可丢失性、可恢复性）</p>\n<p>第 3 步：数据同步（存储系统、消息队列、重复生成）</p>\n<p>第 4 步：异常处理（多通道同步、同步和访问结合、日志记录、用户补偿）</p>\n<hr>\n<h3 id=\"接口级的故障\"><a href=\"#接口级的故障\" class=\"headerlink\" title=\"接口级的故障\"></a>接口级的故障</h3><p>降级：系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能</p>\n<p>熔断：降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况。</p>\n<p>限流：只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。</p>\n<p>排队：临时缓存大量的业务请求</p>\n<hr>\n<h2 id=\"可扩展的基本思想\"><a href=\"#可扩展的基本思想\" class=\"headerlink\" title=\"可扩展的基本思想\"></a>可扩展的基本思想</h2><p>所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆！</p>\n<ol>\n<li>面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。（TCP）</li>\n<li>面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。（京东的支付和商城）</li>\n<li>面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。（京东用户系统里面的查询和注册）</li>\n</ol>\n<blockquote>\n<p>不同的拆分方式，本质上决定了系统的扩展方式。</p>\n</blockquote>\n<hr>\n<h3 id=\"可扩展方式\"><a href=\"#可扩展方式\" class=\"headerlink\" title=\"可扩展方式\"></a>可扩展方式</h3><p><strong>面向流程拆分：</strong>分层架构。</p>\n<p><strong>特点：</strong>扩展时大部分情况只需要修改某一层，少部分情况可能修改关联的两层</p>\n<p><strong>面向服务拆分：</strong>SOA、微服务。</p>\n<p><strong>特点：</strong>对某个服务扩展，或者要增加新的服务时，只需要扩展相关服务即可，无须修改所有的服务。</p>\n<p><strong>面向功能拆分：</strong>微内核架构。</p>\n<p><strong>特点：</strong>对某个功能扩展，或者要增加新的功能时，只需要扩展相关功能即可，无须修改所有的服务。</p>\n<hr>\n<h4 id=\"微服务架构最佳实践\"><a href=\"#微服务架构最佳实践\" class=\"headerlink\" title=\"微服务架构最佳实践\"></a>微服务架构最佳实践</h4><p>实施微服务需要避免踩的陷阱，简单提炼为：</p>\n<ol>\n<li>微服务拆分过细，过分强调“small”。</li>\n<li>微服务基础设施不健全，忽略了“automated”。</li>\n<li>微服务并不轻量级，规模大了后，“lightweight”不再适应。</li>\n</ol>\n<hr>\n<h4 id=\"微服务架构基础设施\"><a href=\"#微服务架构基础设施\" class=\"headerlink\" title=\"微服务架构基础设施\"></a>微服务架构基础设施</h4><p>自动化部署：包括版本管理、资源管理（例如，机器管理、虚拟机管理）、部署操作、回退操作等功能。</p>\n<p>配置中心：配置版本管理、增删改查配置、节点管理、配置同步、配置推送等功能。</p>\n<p>接口框架：以库或者包的形式提供给所有微服务调用</p>\n<p>API 网关：接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。</p>\n<p>服务发现：需要一套服务发现的系统来支撑微服务的自动注册和发现</p>\n<p>服务路由：从所有符合条件的可用微服务节点中挑选出一个具体的节点发起请求</p>\n<p>服务容错：请求重试、流控和服务隔离</p>\n<p>服务监控：实时搜集信息并进行分析、监控预警</p>\n<p>服务跟踪：在大量微服务系统中快速定位问题</p>\n<p>服务安全：接入安全、数据安全、传输安全</p>\n<hr>\n<h4 id=\"微内核架构详解\"><a href=\"#微内核架构详解\" class=\"headerlink\" title=\"微内核架构详解\"></a>微内核架构详解</h4><blockquote>\n<p> 微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构</p>\n</blockquote>\n<p>微内核的核心系统设计的关键技术有：插件管理、插件连接和插件通信。</p>\n<ol>\n<li><p>插件管理</p>\n</li>\n<li><p>插件连接</p>\n</li>\n<li><p>插件通信</p>\n</li>\n</ol>\n"},{"title":"从0开始的golang学习","date":"2021-09-15T01:36:34.000Z","_content":"\n- 内存模型\n- 垃圾回收\n- GMP调度\n- 函数调用\n- defer的实现\n- 泛型\n- ","source":"_posts/re0-golang.md","raw":"---\ntitle: 从0开始的golang学习\ndate: 2021-09-15 09:36:34\ntags: 从0开始的golang\n---\n\n- 内存模型\n- 垃圾回收\n- GMP调度\n- 函数调用\n- defer的实现\n- 泛型\n- ","slug":"re0-golang","published":1,"updated":"2022-04-28T11:36:46.564Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58m000gmauy3pvd60lh","content":"<ul>\n<li>内存模型</li>\n<li>垃圾回收</li>\n<li>GMP调度</li>\n<li>函数调用</li>\n<li>defer的实现</li>\n<li>泛型</li>\n<li></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>内存模型</li>\n<li>垃圾回收</li>\n<li>GMP调度</li>\n<li>函数调用</li>\n<li>defer的实现</li>\n<li>泛型</li>\n<li></li>\n</ul>\n"},{"title":"VIM配置分享","date":"2022-04-28T11:50:07.000Z","_content":"\n```\ncall plug#begin('~/.vim/plugged')\nPlug 'itchyny/lightline.vim'\nPlug 'junegunn/fzf'\nPlug 'junegunn/fzf.vim'\nPlug 'terryma/vim-multiple-cursors'\nPlug 'scrooloose/nerdtree'\nPlug 'vim-airline/vim-airline'\nPlug 'vim-airline/vim-airline-themes'\nPlug 'bling/vim-bufferline'\nPlug 'fatih/vim-go', { 'do': ':GoUpdateBinaries' }\nPlug 'Blackrush/vim-gocode'\nPlug 'Valloric/YouCompleteMe'\nPlug 'honza/vim-snippets'\nPlug 'majutsushi/tagbar'\nPlug 'marijnh/tern_for_vim'\nPlug 'Xuyuanp/nerdtree-git-plugin'\nPlug 'SirVer/ultisnips'\nPlug 'vim-scripts/mru.vim'\nPlug 'mhinz/vim-startify'\nPlug 'mhinz/vim-startify'\ncall plug#end()\n\n\n\" Vim 基础设置\nlet mapleader=\" \"\nset number\nset tabstop=4\nset expandtab\nset smartindent\nset fdm=indent\nset list\nset listchars=tab:\\ \\ ,trail:.\nset hlsearch\nhighlight WhitespaceEOL ctermbg=red guibg=red\nmatch WhitespaceEOL /\\s\\+$/\nlet g:airline#extensions#tabline#enabled=1 \"顶部tab显示\"\n\n\" 自定义改键\nmap <leader>w :w<CR>\nmap <leader>q :q<CR>\nmap <leader>wq :wq<CR>\nmap <leader>ws :source ~/.vimrc<CR>\nmap <leader>f /\nmap <leader>fh :noh<CR>\nmap <leader>fp :Files<CR>\nnmap <tab> :bn<cr> \"设置tab键映射\"\nnnoremap <leader>y :call system('nc localhost 8377', @0)<CR>\n\n\" NerdTree 设置\n\" 关闭NERDTree快捷键\nmap <leader>t :NERDTreeToggle<CR>\n\" 显示行号\nlet NERDTreeShowLineNumbers=1\nlet NERDTreeAutoCenter=1\n\" 是否显示隐藏文件\n\" let NERDTreeShowHidden=1\n\" let NERDTreeShowBookmarks=0\n\" 设置宽度\nlet NERDTreeWinSize=31\n\" 在终端启动vim时，共享NERDTree\nlet g:nerdtree_tabs_open_on_console_startup=1\n\" 忽略一下文件的显示\nlet NERDTreeIgnore=['\\.pyc','\\~$','\\.swp']\n\" 显示书签列表\nlet NERDTreeShowBookmarks=1\nset rtp+=~/.fzf\n\n\n\ncommand! -bang -nargs=* Ag call fzf#vim#ag(<q-args>, {'options': '--delimiter : --nth 4..'}, <bang>0)\nnnoremap <silent> <Leader>a :Ag <C-R><C-W><CR>\n```","source":"_posts/my-vim-config.md","raw":"---\ntitle: VIM配置分享\ndate: 2022-04-28 19:50:07\ntags:\n---\n\n```\ncall plug#begin('~/.vim/plugged')\nPlug 'itchyny/lightline.vim'\nPlug 'junegunn/fzf'\nPlug 'junegunn/fzf.vim'\nPlug 'terryma/vim-multiple-cursors'\nPlug 'scrooloose/nerdtree'\nPlug 'vim-airline/vim-airline'\nPlug 'vim-airline/vim-airline-themes'\nPlug 'bling/vim-bufferline'\nPlug 'fatih/vim-go', { 'do': ':GoUpdateBinaries' }\nPlug 'Blackrush/vim-gocode'\nPlug 'Valloric/YouCompleteMe'\nPlug 'honza/vim-snippets'\nPlug 'majutsushi/tagbar'\nPlug 'marijnh/tern_for_vim'\nPlug 'Xuyuanp/nerdtree-git-plugin'\nPlug 'SirVer/ultisnips'\nPlug 'vim-scripts/mru.vim'\nPlug 'mhinz/vim-startify'\nPlug 'mhinz/vim-startify'\ncall plug#end()\n\n\n\" Vim 基础设置\nlet mapleader=\" \"\nset number\nset tabstop=4\nset expandtab\nset smartindent\nset fdm=indent\nset list\nset listchars=tab:\\ \\ ,trail:.\nset hlsearch\nhighlight WhitespaceEOL ctermbg=red guibg=red\nmatch WhitespaceEOL /\\s\\+$/\nlet g:airline#extensions#tabline#enabled=1 \"顶部tab显示\"\n\n\" 自定义改键\nmap <leader>w :w<CR>\nmap <leader>q :q<CR>\nmap <leader>wq :wq<CR>\nmap <leader>ws :source ~/.vimrc<CR>\nmap <leader>f /\nmap <leader>fh :noh<CR>\nmap <leader>fp :Files<CR>\nnmap <tab> :bn<cr> \"设置tab键映射\"\nnnoremap <leader>y :call system('nc localhost 8377', @0)<CR>\n\n\" NerdTree 设置\n\" 关闭NERDTree快捷键\nmap <leader>t :NERDTreeToggle<CR>\n\" 显示行号\nlet NERDTreeShowLineNumbers=1\nlet NERDTreeAutoCenter=1\n\" 是否显示隐藏文件\n\" let NERDTreeShowHidden=1\n\" let NERDTreeShowBookmarks=0\n\" 设置宽度\nlet NERDTreeWinSize=31\n\" 在终端启动vim时，共享NERDTree\nlet g:nerdtree_tabs_open_on_console_startup=1\n\" 忽略一下文件的显示\nlet NERDTreeIgnore=['\\.pyc','\\~$','\\.swp']\n\" 显示书签列表\nlet NERDTreeShowBookmarks=1\nset rtp+=~/.fzf\n\n\n\ncommand! -bang -nargs=* Ag call fzf#vim#ag(<q-args>, {'options': '--delimiter : --nth 4..'}, <bang>0)\nnnoremap <silent> <Leader>a :Ag <C-R><C-W><CR>\n```","slug":"my-vim-config","published":1,"updated":"2022-04-28T11:50:44.738Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58r000imauyg18j0stg","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">call plug#begin(&#39;~&#x2F;.vim&#x2F;plugged&#39;)</span><br><span class=\"line\">Plug &#39;itchyny&#x2F;lightline.vim&#39;</span><br><span class=\"line\">Plug &#39;junegunn&#x2F;fzf&#39;</span><br><span class=\"line\">Plug &#39;junegunn&#x2F;fzf.vim&#39;</span><br><span class=\"line\">Plug &#39;terryma&#x2F;vim-multiple-cursors&#39;</span><br><span class=\"line\">Plug &#39;scrooloose&#x2F;nerdtree&#39;</span><br><span class=\"line\">Plug &#39;vim-airline&#x2F;vim-airline&#39;</span><br><span class=\"line\">Plug &#39;vim-airline&#x2F;vim-airline-themes&#39;</span><br><span class=\"line\">Plug &#39;bling&#x2F;vim-bufferline&#39;</span><br><span class=\"line\">Plug &#39;fatih&#x2F;vim-go&#39;, &#123; &#39;do&#39;: &#39;:GoUpdateBinaries&#39; &#125;</span><br><span class=\"line\">Plug &#39;Blackrush&#x2F;vim-gocode&#39;</span><br><span class=\"line\">Plug &#39;Valloric&#x2F;YouCompleteMe&#39;</span><br><span class=\"line\">Plug &#39;honza&#x2F;vim-snippets&#39;</span><br><span class=\"line\">Plug &#39;majutsushi&#x2F;tagbar&#39;</span><br><span class=\"line\">Plug &#39;marijnh&#x2F;tern_for_vim&#39;</span><br><span class=\"line\">Plug &#39;Xuyuanp&#x2F;nerdtree-git-plugin&#39;</span><br><span class=\"line\">Plug &#39;SirVer&#x2F;ultisnips&#39;</span><br><span class=\"line\">Plug &#39;vim-scripts&#x2F;mru.vim&#39;</span><br><span class=\"line\">Plug &#39;mhinz&#x2F;vim-startify&#39;</span><br><span class=\"line\">Plug &#39;mhinz&#x2F;vim-startify&#39;</span><br><span class=\"line\">call plug#end()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot; Vim 基础设置</span><br><span class=\"line\">let mapleader&#x3D;&quot; &quot;</span><br><span class=\"line\">set number</span><br><span class=\"line\">set tabstop&#x3D;4</span><br><span class=\"line\">set expandtab</span><br><span class=\"line\">set smartindent</span><br><span class=\"line\">set fdm&#x3D;indent</span><br><span class=\"line\">set list</span><br><span class=\"line\">set listchars&#x3D;tab:\\ \\ ,trail:.</span><br><span class=\"line\">set hlsearch</span><br><span class=\"line\">highlight WhitespaceEOL ctermbg&#x3D;red guibg&#x3D;red</span><br><span class=\"line\">match WhitespaceEOL &#x2F;\\s\\+$&#x2F;</span><br><span class=\"line\">let g:airline#extensions#tabline#enabled&#x3D;1 &quot;顶部tab显示&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; 自定义改键</span><br><span class=\"line\">map &lt;leader&gt;w :w&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;q :q&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;wq :wq&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;ws :source ~&#x2F;.vimrc&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;f &#x2F;</span><br><span class=\"line\">map &lt;leader&gt;fh :noh&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;fp :Files&lt;CR&gt;</span><br><span class=\"line\">nmap &lt;tab&gt; :bn&lt;cr&gt; &quot;设置tab键映射&quot;</span><br><span class=\"line\">nnoremap &lt;leader&gt;y :call system(&#39;nc localhost 8377&#39;, @0)&lt;CR&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; NerdTree 设置</span><br><span class=\"line\">&quot; 关闭NERDTree快捷键</span><br><span class=\"line\">map &lt;leader&gt;t :NERDTreeToggle&lt;CR&gt;</span><br><span class=\"line\">&quot; 显示行号</span><br><span class=\"line\">let NERDTreeShowLineNumbers&#x3D;1</span><br><span class=\"line\">let NERDTreeAutoCenter&#x3D;1</span><br><span class=\"line\">&quot; 是否显示隐藏文件</span><br><span class=\"line\">&quot; let NERDTreeShowHidden&#x3D;1</span><br><span class=\"line\">&quot; let NERDTreeShowBookmarks&#x3D;0</span><br><span class=\"line\">&quot; 设置宽度</span><br><span class=\"line\">let NERDTreeWinSize&#x3D;31</span><br><span class=\"line\">&quot; 在终端启动vim时，共享NERDTree</span><br><span class=\"line\">let g:nerdtree_tabs_open_on_console_startup&#x3D;1</span><br><span class=\"line\">&quot; 忽略一下文件的显示</span><br><span class=\"line\">let NERDTreeIgnore&#x3D;[&#39;\\.pyc&#39;,&#39;\\~$&#39;,&#39;\\.swp&#39;]</span><br><span class=\"line\">&quot; 显示书签列表</span><br><span class=\"line\">let NERDTreeShowBookmarks&#x3D;1</span><br><span class=\"line\">set rtp+&#x3D;~&#x2F;.fzf</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">command! -bang -nargs&#x3D;* Ag call fzf#vim#ag(&lt;q-args&gt;, &#123;&#39;options&#39;: &#39;--delimiter : --nth 4..&#39;&#125;, &lt;bang&gt;0)</span><br><span class=\"line\">nnoremap &lt;silent&gt; &lt;Leader&gt;a :Ag &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">call plug#begin(&#39;~&#x2F;.vim&#x2F;plugged&#39;)</span><br><span class=\"line\">Plug &#39;itchyny&#x2F;lightline.vim&#39;</span><br><span class=\"line\">Plug &#39;junegunn&#x2F;fzf&#39;</span><br><span class=\"line\">Plug &#39;junegunn&#x2F;fzf.vim&#39;</span><br><span class=\"line\">Plug &#39;terryma&#x2F;vim-multiple-cursors&#39;</span><br><span class=\"line\">Plug &#39;scrooloose&#x2F;nerdtree&#39;</span><br><span class=\"line\">Plug &#39;vim-airline&#x2F;vim-airline&#39;</span><br><span class=\"line\">Plug &#39;vim-airline&#x2F;vim-airline-themes&#39;</span><br><span class=\"line\">Plug &#39;bling&#x2F;vim-bufferline&#39;</span><br><span class=\"line\">Plug &#39;fatih&#x2F;vim-go&#39;, &#123; &#39;do&#39;: &#39;:GoUpdateBinaries&#39; &#125;</span><br><span class=\"line\">Plug &#39;Blackrush&#x2F;vim-gocode&#39;</span><br><span class=\"line\">Plug &#39;Valloric&#x2F;YouCompleteMe&#39;</span><br><span class=\"line\">Plug &#39;honza&#x2F;vim-snippets&#39;</span><br><span class=\"line\">Plug &#39;majutsushi&#x2F;tagbar&#39;</span><br><span class=\"line\">Plug &#39;marijnh&#x2F;tern_for_vim&#39;</span><br><span class=\"line\">Plug &#39;Xuyuanp&#x2F;nerdtree-git-plugin&#39;</span><br><span class=\"line\">Plug &#39;SirVer&#x2F;ultisnips&#39;</span><br><span class=\"line\">Plug &#39;vim-scripts&#x2F;mru.vim&#39;</span><br><span class=\"line\">Plug &#39;mhinz&#x2F;vim-startify&#39;</span><br><span class=\"line\">Plug &#39;mhinz&#x2F;vim-startify&#39;</span><br><span class=\"line\">call plug#end()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot; Vim 基础设置</span><br><span class=\"line\">let mapleader&#x3D;&quot; &quot;</span><br><span class=\"line\">set number</span><br><span class=\"line\">set tabstop&#x3D;4</span><br><span class=\"line\">set expandtab</span><br><span class=\"line\">set smartindent</span><br><span class=\"line\">set fdm&#x3D;indent</span><br><span class=\"line\">set list</span><br><span class=\"line\">set listchars&#x3D;tab:\\ \\ ,trail:.</span><br><span class=\"line\">set hlsearch</span><br><span class=\"line\">highlight WhitespaceEOL ctermbg&#x3D;red guibg&#x3D;red</span><br><span class=\"line\">match WhitespaceEOL &#x2F;\\s\\+$&#x2F;</span><br><span class=\"line\">let g:airline#extensions#tabline#enabled&#x3D;1 &quot;顶部tab显示&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; 自定义改键</span><br><span class=\"line\">map &lt;leader&gt;w :w&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;q :q&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;wq :wq&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;ws :source ~&#x2F;.vimrc&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;f &#x2F;</span><br><span class=\"line\">map &lt;leader&gt;fh :noh&lt;CR&gt;</span><br><span class=\"line\">map &lt;leader&gt;fp :Files&lt;CR&gt;</span><br><span class=\"line\">nmap &lt;tab&gt; :bn&lt;cr&gt; &quot;设置tab键映射&quot;</span><br><span class=\"line\">nnoremap &lt;leader&gt;y :call system(&#39;nc localhost 8377&#39;, @0)&lt;CR&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; NerdTree 设置</span><br><span class=\"line\">&quot; 关闭NERDTree快捷键</span><br><span class=\"line\">map &lt;leader&gt;t :NERDTreeToggle&lt;CR&gt;</span><br><span class=\"line\">&quot; 显示行号</span><br><span class=\"line\">let NERDTreeShowLineNumbers&#x3D;1</span><br><span class=\"line\">let NERDTreeAutoCenter&#x3D;1</span><br><span class=\"line\">&quot; 是否显示隐藏文件</span><br><span class=\"line\">&quot; let NERDTreeShowHidden&#x3D;1</span><br><span class=\"line\">&quot; let NERDTreeShowBookmarks&#x3D;0</span><br><span class=\"line\">&quot; 设置宽度</span><br><span class=\"line\">let NERDTreeWinSize&#x3D;31</span><br><span class=\"line\">&quot; 在终端启动vim时，共享NERDTree</span><br><span class=\"line\">let g:nerdtree_tabs_open_on_console_startup&#x3D;1</span><br><span class=\"line\">&quot; 忽略一下文件的显示</span><br><span class=\"line\">let NERDTreeIgnore&#x3D;[&#39;\\.pyc&#39;,&#39;\\~$&#39;,&#39;\\.swp&#39;]</span><br><span class=\"line\">&quot; 显示书签列表</span><br><span class=\"line\">let NERDTreeShowBookmarks&#x3D;1</span><br><span class=\"line\">set rtp+&#x3D;~&#x2F;.fzf</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">command! -bang -nargs&#x3D;* Ag call fzf#vim#ag(&lt;q-args&gt;, &#123;&#39;options&#39;: &#39;--delimiter : --nth 4..&#39;&#125;, &lt;bang&gt;0)</span><br><span class=\"line\">nnoremap &lt;silent&gt; &lt;Leader&gt;a :Ag &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br></pre></td></tr></table></figure>"},{"title":"主从复制数据同步","date":"2021-09-15T17:45:15.000Z","_content":"\n## 零、从问题出发\n\n## 一、前言\n\n这篇开始要进入Redis集群的技术研究了，我们按照顺序会至少分四部分来介绍：**主从复制、哨兵模式、Gossip协议和一致性哈希以及Redis集群**。**主从复制**是高可用的基石，**哨兵模式**提供了主从架构中的自动故障恢复能力， **Gossip协议和一致性哈希**提供了集群中新加入节点和退出节点的发现以及节点加入或退出引起的数据重分配，最后基于上述的几个核心技术实现了高可用的**Redis集群**。\n\nRedis作为一个内存数据库，使用主从架构的最核心的目的便是提供数据冗余备份，以防止一个Redis节点Down掉之后其中的数据也被丢失，而作为冗余备份，主从节点最重要的工作便是数据同步。那么本篇着重介绍的便是Redis的数据同步策略，包括主从节点首次建立连接后的**全量复制**以及从节点短暂断连后的数据**部分复制。**主要内容分为\n\n1. **Redis主从复制概述**\n2. **Redis主从数据同步**\n3. **Redis读写分离实现以及过期数据处理**\n4. **结语**\n\n## 二、Redis主从复制概述\n\n主从复制，是指将一台Redis服务器的数据复制到其他的Redis服务器，前者称为主节点(master/leader)，后者称为从节点(slave/follower)。一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点，同时每个从节点也可以是别的从节点的父节点，即主从节点连接形成树结构。\n\n![主从复制过程](https://p.pstatp.com/origin/pgc-image/4ae244e1829440078351db7231a1a9d6)\n\n主从复制的发起都是在子节点发起，当节点127.0.0.1:6380中使用salveof 127.0.0.1 6379后，6380节点与6379节点的数据复制过程如下图所示。\n\n**主从结构中数据的复制是单向的，只能由主节点到从节点**，所有的内存变更，即数据的增删改都只能在主节点上进行，从节点通过同步的方式完成修改。默认情况下，从节点对非Master节点客户端是只读的。Redis使用主从复制的作用有：\n\n1. **数据冗余**：实现数据冗余备份，这样一台节点挂了之后，其上的数据不至于丢失。\n2. **故障恢复**：当主节点出现问题时，其从节点可以被提升为主节点继续提供服务，实现快速的故障恢复；\n3. **负载均衡**：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。\n\n## 三、数据同步\n\n接下来进入本文的重点——Redis主从节点的数据同步。作为内存数据库，Redis主从结构的核心目的在于数据备份。当节点A对节点B发起复制时，最直接的做法就是把节点B的内存数据生成快照文件（RDB）然后发送给节点A，节点A接收到RDB文件后将文件中的数据恢复到内存中，这就是**全量复制**。\n\n\n![img](https://pic1.zhimg.com/80/v2-12a31457508682daabc7ea4f1c2e455c_720w.jpg)\n\n## 四、全量复制\n\n在Redis(1)中我们介绍过为了保障进程挂掉之后数据不至于丢失，Redis采用了RDB持久化和AOF持久化两种策略，这样当Redis重启后便可以从RDB文件或者AOF文件中恢复出数据。**而全量复制的核心就是把Master节点当前的数据全部发送给子节点**，那么显然，只要我们把Master节点的RDB文件或者AOF文件发给Slave节点就可以。这样Slave节点接收到文件之后就可以从文件中恢复出Master节点的数据。当然，为了保证主从节点一致，Slave节点从持久化文件中恢复数据之前首先应该清空自己内存中的所有数据。Redis提供了两种数据同步方式:RDB_CHILD_TYPE_DISK和RDB_CHILD_TYPE_SOCKET。所谓RDB_CHILD_TYPE_DISK就是将内存数据写入磁盘文件中，然后将磁盘文件发送给Slave节点, RDB_CHILD_TYPE_SOCKET即直接把内存数据写入Slave节点的socket文件进行发送而不需要先写入磁盘。由于不需要落盘，RDB_CHILD_TYPE_DISK的方式速度会更快，但是如果Master节点采用RDB_CHILD_TYPE_SOCKET向Slave节点发送数据时有新的节点发起数据同步请求，那么Master节点就需要重新再为新的Slave节点重新同步，而采用RDB_CHILD_TYPE_DISK生成RDB文件时如果有新的Slave节点加入数据复制，并不会引发新的RDB文件生成过程。二者各有利弊，但一般情况下我们会采用基于RDB_CHILD_TYPE_DISK的方式进行数据同步，同时也是限于篇幅，接下来的介绍中以RDB_CHILD_TYPE_DISK为主。\n\n[大龙：Redis详解（1）——为什么我们都需要了解Redis47 赞同 · 2 评论文章![img](https://pic3.zhimg.com/v2-d7454c387a1257b6f819bb251b0a121e_180x120.jpg)](https://zhuanlan.zhihu.com/p/94680529)\n\n在Redis的源码实现中。***replicationCron***函数被每秒调用一次。函数中会每次都会去判断是否有Slave节点处于等待数据同步的状态。如果有，则开始进行全量复制。 全量复制首先fork一个子进程调用***rdbSave***函数生成RDB文件，生成结束后调用回调函数***updateSlavesWaitingBgsave***将RDB文件发送给所有的Slave节点完成了同步过程。由于这部分实现代码非常的多，我就在下面把路径中的每个函数进行了大幅删减，主要展示整个过程中的函数调用关系，方便大家对着源代码阅读，大家从上往下读即可。\n\n```c\n// replication.c\n// replicationCron函数每秒调用一次，代码被删减\nvoid replicationCron(void) {\n    /* Redis至多只允许一个子进程运行，而Master节点进行全量复制时需要fork一个子进程来进行RDB文件的生成*/\n    if (!hasActiveChildProcess()) {\n        time_t idle, max_idle = 0;\n        int slaves_waiting = 0;\n        int mincapa = -1;\n        listNode *ln;\n        listIter li;\n        // 统计子节点中有多少个节点正在等待全量数据复制\n        listRewind(server.slaves,&li);\n        while((ln = listNext(&li))) {\n            client *slave = ln->value;\n            if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {\n                idle = server.unixtime - slave->lastinteraction;\n                if (idle > max_idle) max_idle = idle;\n                slaves_waiting++;\n                mincapa = (mincapa == -1) ? slave->slave_capa :\n                                            (mincapa & slave->slave_capa);\n            }\n        }\n        // 如果有子节点在等待，则开始进行全量复制\n        if (slaves_waiting )\n        {\n            startBgsaveForReplication(mincapa);\n        }\n    }\n}\n\nint startBgsaveForReplication(int mincapa) {\n  \n   int reval = rdbSaveBackground(server.rdb_filename,rsiptr);\n\n}\n\nint rdbSaveBackground(char *filename, rdbSaveInfo *rsi) {\n    pid_t childpid;\n    // fork一个子进程用于生成RDB文件\n    if ((childpid = redisFork()) == 0) {\n        int retval = rdbSave(filename,rsi);\n    } \n}\n\n/* 生成RDB文件*/\nint rdbSave(char *filename, rdbSaveInfo *rsi) {\n    // 省略代码...\n}\n\n/* 当RDB文件生成结束后，根据同步的方式来调用对应的回调函数 */\nvoid backgroundSaveDoneHandler(int exitcode, int bysignal) {\n    switch(server.rdb_child_type) {\n    case RDB_CHILD_TYPE_DISK:\n        backgroundSaveDoneHandlerDisk(exitcode,bysignal);\n        break;\n    case RDB_CHILD_TYPE_SOCKET:\n        backgroundSaveDoneHandlerSocket(exitcode,bysignal);\n        break;\n    default:\n        serverPanic(\"Unknown RDB child type.\");\n        break;\n    }\n}\n\n// 基于RDB_CHILD_TYPE_DISK的回调函数中向所有 Slave节点发送RDB文件。\nvoid backgroundSaveDoneHandlerDisk(int exitcode, int bysignal) {\n   updateSlavesWaitingBgsave((!bysignal && exitcode == 0) ? C_OK : C_ERR, RDB_CHILD_TYPE_DISK);\n}\n```\n\n全量复制的介绍就到这里，那么这里有一个问题是：全量复制只是复制了T1时刻Master节点的数据快照，那么之后客户端向Master节点的写入数据该如何同步给Slave节点？第一种显然的做法就是开启定时任务，每隔T时间就进行一次全量复制，完成一上面的所有操作即可。但是全量复制实际上是个成本很高的操作，大致分为如下几步：\n\n1. Master节点开启子进程进行RDB文件生成\n2. Master节点将RDB文件发送给Slave节点\n3. Slave节点清空内存中的所有数据并删除之前的RDB文件\n4. Slave节点使用从Master接收的RDB文件恢复数据到内存中\n\n整个过程每一步都是耗时间的IO操作，比如Master节点在T1时刻开始RDB文件的生成，一直到T2时刻Slave节点才能完成数据载入。在网络环境较差或者IO能力较弱的情况下，上述的操作不仅耗时久，而且会因此导致主从节点数据延迟比较大（因为耗时，所以T会设置的比较大）。那么Redis为了解决这个问题，提出的解决方案是**命令传播+增量复制。**\n\n## 五、命令传播\n\n所谓命令传播当Master节点每处理完一个命令都会把命令广播给所有的子节点，而每个子节点接收到Master的广播过来的命令后，会在处理完之后继续广播给自己的子节点。需要注意的是，Redis的命令广播是异步的操作。即Master节点处理完客户端的命令之后会立马向客户端返回结果，而不会一直等待所有的子节点都确认完成操作后再返回以保证Redis高效的性能。\n\n```c\nvoid processInputBufferAndReplicate(client *c) {\n    // 处理命令然后广播命令\n    // if this is a slave, we just process the commands\n    if (!(c->flags & CLIENT_MASTER)) {\n        processInputBuffer(c);\n    } else {\n        /* If the client is a master we need to compute the difference\n         * between the applied offset before and after processing the buffer,\n         * to understand how much of the replication stream was actually\n         * applied to the master state: this quantity, and its corresponding\n         * part of the replication stream, will be propagated to the\n         * sub-replicas and to the replication backlog. */\n        size_t prev_offset = c->reploff;\n        processInputBuffer(c);\n        // applied is how much of the replication stream was actually applied to the master state\n        size_t applied = c->reploff - prev_offset;\n        if (applied) {\n\n            replicationFeedSlavesFromMasterStream(server.slaves,\n                    c->pending_querybuf, applied);\n            sdsrange(c->pending_querybuf,applied,-1);\n        }\n    }\n}\n```\n\n那么紧接着的另一个问题是，**如果某一个子节点A短暂的断连了T秒，那么A再次恢复连接之后该如何同步数据呢？**Redis选择的做法是开辟一个缓冲区（默认大小是1M)，每次处理完命令之后，先写入缓冲区repl_backlog, 然后再发送给子节点。这就是增量复制（也叫部分复制）。但是缓冲区能保存的命令有限，只能至多保存的命令长度为repl_backlog_length，如果某个子节点落后当前最新命令的长度大于了repl_backlog_length，那么就会触发全量复制。\n\n## 六、读写分离和过期数据\n\n主从复制的一大用处就是可以拓展单节点的读写性能，但是由于Redis中主从节点的数据复制时单向的，所以从节点对外是只读状态，而主节点是可读可写的状态。在读请求占比比较大的时候，让从节点参与响应读请求可以有效的分摊Master节点的压力。但是需要注意的是，由于主从节点之间可能存在数据的延迟，导致从子节点读到的数据可能是过期数据。其中一个典型的场景就是过期数据未能及时清理。由于数据的单向复制，子节点在Master节点不告知的情况下不会主动进行任何内存变更的操作，涉及到数据过期时，Redis采用的做法是当Master节点判断某个key过期了之后会向子节点发送DEL命令删除掉数据。但是如果期间由于网络环境或其他问题导致DEL命令未及时到达子节点，那么用户此时从子节点读到的数据就是本应已过期被删除的数据。为了解决这个问题，Redis从3.2版本之后，子节点也可以主动判断用户请求的键是否已经过期。如果过期，则就不向用户返回结果，但是并不会直接删除数据。删除数据的操作仍然是只会由Master节点的同步引起。这实际上是对主从的时钟同步是有要求的，绝大部分情况下这个先决条件还是能够被满足的。\n\n## 七、结语\n\n本文介绍了着重介绍了Redis主从复制的全量复制和部分复制，并简单的介绍了Redis主从分离对单点读写性能的扩展以及面临的数据延迟中的典型代表：数据过期问题。希望能对大家有所帮助。\n\n## 八、后记\n\n这篇文章写的真的是一坨翔，回到家专心工作比较艰难，都是零敲碎打的写东西。但是为了能不断更，所以也就硬着头皮往下写了。写之前看了很多资料，都是介绍了原理性的内容，自己不是很满意，于是就想读源码，从实现的角度来更详细的介绍主从复制。读完后才发现，从代码实现上讲并不会增加更多的细节，反而容易让读者抓不住重点。下次写就只写一个聚焦的话题，回北京之前不会再写这种涉及话题比较多的内容了。\n\n## 相关链接\n- [Redis集群——主从复制数据同步 - 知乎](https://zhuanlan.zhihu.com/p/102859170)","source":"_posts/re0-redis-master.md","raw":"---\ntitle: 主从复制数据同步\ndate: 2021-09-16 01:45:15\ntags: 从0开始的Redis\n---\n\n## 零、从问题出发\n\n## 一、前言\n\n这篇开始要进入Redis集群的技术研究了，我们按照顺序会至少分四部分来介绍：**主从复制、哨兵模式、Gossip协议和一致性哈希以及Redis集群**。**主从复制**是高可用的基石，**哨兵模式**提供了主从架构中的自动故障恢复能力， **Gossip协议和一致性哈希**提供了集群中新加入节点和退出节点的发现以及节点加入或退出引起的数据重分配，最后基于上述的几个核心技术实现了高可用的**Redis集群**。\n\nRedis作为一个内存数据库，使用主从架构的最核心的目的便是提供数据冗余备份，以防止一个Redis节点Down掉之后其中的数据也被丢失，而作为冗余备份，主从节点最重要的工作便是数据同步。那么本篇着重介绍的便是Redis的数据同步策略，包括主从节点首次建立连接后的**全量复制**以及从节点短暂断连后的数据**部分复制。**主要内容分为\n\n1. **Redis主从复制概述**\n2. **Redis主从数据同步**\n3. **Redis读写分离实现以及过期数据处理**\n4. **结语**\n\n## 二、Redis主从复制概述\n\n主从复制，是指将一台Redis服务器的数据复制到其他的Redis服务器，前者称为主节点(master/leader)，后者称为从节点(slave/follower)。一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点，同时每个从节点也可以是别的从节点的父节点，即主从节点连接形成树结构。\n\n![主从复制过程](https://p.pstatp.com/origin/pgc-image/4ae244e1829440078351db7231a1a9d6)\n\n主从复制的发起都是在子节点发起，当节点127.0.0.1:6380中使用salveof 127.0.0.1 6379后，6380节点与6379节点的数据复制过程如下图所示。\n\n**主从结构中数据的复制是单向的，只能由主节点到从节点**，所有的内存变更，即数据的增删改都只能在主节点上进行，从节点通过同步的方式完成修改。默认情况下，从节点对非Master节点客户端是只读的。Redis使用主从复制的作用有：\n\n1. **数据冗余**：实现数据冗余备份，这样一台节点挂了之后，其上的数据不至于丢失。\n2. **故障恢复**：当主节点出现问题时，其从节点可以被提升为主节点继续提供服务，实现快速的故障恢复；\n3. **负载均衡**：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。\n\n## 三、数据同步\n\n接下来进入本文的重点——Redis主从节点的数据同步。作为内存数据库，Redis主从结构的核心目的在于数据备份。当节点A对节点B发起复制时，最直接的做法就是把节点B的内存数据生成快照文件（RDB）然后发送给节点A，节点A接收到RDB文件后将文件中的数据恢复到内存中，这就是**全量复制**。\n\n\n![img](https://pic1.zhimg.com/80/v2-12a31457508682daabc7ea4f1c2e455c_720w.jpg)\n\n## 四、全量复制\n\n在Redis(1)中我们介绍过为了保障进程挂掉之后数据不至于丢失，Redis采用了RDB持久化和AOF持久化两种策略，这样当Redis重启后便可以从RDB文件或者AOF文件中恢复出数据。**而全量复制的核心就是把Master节点当前的数据全部发送给子节点**，那么显然，只要我们把Master节点的RDB文件或者AOF文件发给Slave节点就可以。这样Slave节点接收到文件之后就可以从文件中恢复出Master节点的数据。当然，为了保证主从节点一致，Slave节点从持久化文件中恢复数据之前首先应该清空自己内存中的所有数据。Redis提供了两种数据同步方式:RDB_CHILD_TYPE_DISK和RDB_CHILD_TYPE_SOCKET。所谓RDB_CHILD_TYPE_DISK就是将内存数据写入磁盘文件中，然后将磁盘文件发送给Slave节点, RDB_CHILD_TYPE_SOCKET即直接把内存数据写入Slave节点的socket文件进行发送而不需要先写入磁盘。由于不需要落盘，RDB_CHILD_TYPE_DISK的方式速度会更快，但是如果Master节点采用RDB_CHILD_TYPE_SOCKET向Slave节点发送数据时有新的节点发起数据同步请求，那么Master节点就需要重新再为新的Slave节点重新同步，而采用RDB_CHILD_TYPE_DISK生成RDB文件时如果有新的Slave节点加入数据复制，并不会引发新的RDB文件生成过程。二者各有利弊，但一般情况下我们会采用基于RDB_CHILD_TYPE_DISK的方式进行数据同步，同时也是限于篇幅，接下来的介绍中以RDB_CHILD_TYPE_DISK为主。\n\n[大龙：Redis详解（1）——为什么我们都需要了解Redis47 赞同 · 2 评论文章![img](https://pic3.zhimg.com/v2-d7454c387a1257b6f819bb251b0a121e_180x120.jpg)](https://zhuanlan.zhihu.com/p/94680529)\n\n在Redis的源码实现中。***replicationCron***函数被每秒调用一次。函数中会每次都会去判断是否有Slave节点处于等待数据同步的状态。如果有，则开始进行全量复制。 全量复制首先fork一个子进程调用***rdbSave***函数生成RDB文件，生成结束后调用回调函数***updateSlavesWaitingBgsave***将RDB文件发送给所有的Slave节点完成了同步过程。由于这部分实现代码非常的多，我就在下面把路径中的每个函数进行了大幅删减，主要展示整个过程中的函数调用关系，方便大家对着源代码阅读，大家从上往下读即可。\n\n```c\n// replication.c\n// replicationCron函数每秒调用一次，代码被删减\nvoid replicationCron(void) {\n    /* Redis至多只允许一个子进程运行，而Master节点进行全量复制时需要fork一个子进程来进行RDB文件的生成*/\n    if (!hasActiveChildProcess()) {\n        time_t idle, max_idle = 0;\n        int slaves_waiting = 0;\n        int mincapa = -1;\n        listNode *ln;\n        listIter li;\n        // 统计子节点中有多少个节点正在等待全量数据复制\n        listRewind(server.slaves,&li);\n        while((ln = listNext(&li))) {\n            client *slave = ln->value;\n            if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {\n                idle = server.unixtime - slave->lastinteraction;\n                if (idle > max_idle) max_idle = idle;\n                slaves_waiting++;\n                mincapa = (mincapa == -1) ? slave->slave_capa :\n                                            (mincapa & slave->slave_capa);\n            }\n        }\n        // 如果有子节点在等待，则开始进行全量复制\n        if (slaves_waiting )\n        {\n            startBgsaveForReplication(mincapa);\n        }\n    }\n}\n\nint startBgsaveForReplication(int mincapa) {\n  \n   int reval = rdbSaveBackground(server.rdb_filename,rsiptr);\n\n}\n\nint rdbSaveBackground(char *filename, rdbSaveInfo *rsi) {\n    pid_t childpid;\n    // fork一个子进程用于生成RDB文件\n    if ((childpid = redisFork()) == 0) {\n        int retval = rdbSave(filename,rsi);\n    } \n}\n\n/* 生成RDB文件*/\nint rdbSave(char *filename, rdbSaveInfo *rsi) {\n    // 省略代码...\n}\n\n/* 当RDB文件生成结束后，根据同步的方式来调用对应的回调函数 */\nvoid backgroundSaveDoneHandler(int exitcode, int bysignal) {\n    switch(server.rdb_child_type) {\n    case RDB_CHILD_TYPE_DISK:\n        backgroundSaveDoneHandlerDisk(exitcode,bysignal);\n        break;\n    case RDB_CHILD_TYPE_SOCKET:\n        backgroundSaveDoneHandlerSocket(exitcode,bysignal);\n        break;\n    default:\n        serverPanic(\"Unknown RDB child type.\");\n        break;\n    }\n}\n\n// 基于RDB_CHILD_TYPE_DISK的回调函数中向所有 Slave节点发送RDB文件。\nvoid backgroundSaveDoneHandlerDisk(int exitcode, int bysignal) {\n   updateSlavesWaitingBgsave((!bysignal && exitcode == 0) ? C_OK : C_ERR, RDB_CHILD_TYPE_DISK);\n}\n```\n\n全量复制的介绍就到这里，那么这里有一个问题是：全量复制只是复制了T1时刻Master节点的数据快照，那么之后客户端向Master节点的写入数据该如何同步给Slave节点？第一种显然的做法就是开启定时任务，每隔T时间就进行一次全量复制，完成一上面的所有操作即可。但是全量复制实际上是个成本很高的操作，大致分为如下几步：\n\n1. Master节点开启子进程进行RDB文件生成\n2. Master节点将RDB文件发送给Slave节点\n3. Slave节点清空内存中的所有数据并删除之前的RDB文件\n4. Slave节点使用从Master接收的RDB文件恢复数据到内存中\n\n整个过程每一步都是耗时间的IO操作，比如Master节点在T1时刻开始RDB文件的生成，一直到T2时刻Slave节点才能完成数据载入。在网络环境较差或者IO能力较弱的情况下，上述的操作不仅耗时久，而且会因此导致主从节点数据延迟比较大（因为耗时，所以T会设置的比较大）。那么Redis为了解决这个问题，提出的解决方案是**命令传播+增量复制。**\n\n## 五、命令传播\n\n所谓命令传播当Master节点每处理完一个命令都会把命令广播给所有的子节点，而每个子节点接收到Master的广播过来的命令后，会在处理完之后继续广播给自己的子节点。需要注意的是，Redis的命令广播是异步的操作。即Master节点处理完客户端的命令之后会立马向客户端返回结果，而不会一直等待所有的子节点都确认完成操作后再返回以保证Redis高效的性能。\n\n```c\nvoid processInputBufferAndReplicate(client *c) {\n    // 处理命令然后广播命令\n    // if this is a slave, we just process the commands\n    if (!(c->flags & CLIENT_MASTER)) {\n        processInputBuffer(c);\n    } else {\n        /* If the client is a master we need to compute the difference\n         * between the applied offset before and after processing the buffer,\n         * to understand how much of the replication stream was actually\n         * applied to the master state: this quantity, and its corresponding\n         * part of the replication stream, will be propagated to the\n         * sub-replicas and to the replication backlog. */\n        size_t prev_offset = c->reploff;\n        processInputBuffer(c);\n        // applied is how much of the replication stream was actually applied to the master state\n        size_t applied = c->reploff - prev_offset;\n        if (applied) {\n\n            replicationFeedSlavesFromMasterStream(server.slaves,\n                    c->pending_querybuf, applied);\n            sdsrange(c->pending_querybuf,applied,-1);\n        }\n    }\n}\n```\n\n那么紧接着的另一个问题是，**如果某一个子节点A短暂的断连了T秒，那么A再次恢复连接之后该如何同步数据呢？**Redis选择的做法是开辟一个缓冲区（默认大小是1M)，每次处理完命令之后，先写入缓冲区repl_backlog, 然后再发送给子节点。这就是增量复制（也叫部分复制）。但是缓冲区能保存的命令有限，只能至多保存的命令长度为repl_backlog_length，如果某个子节点落后当前最新命令的长度大于了repl_backlog_length，那么就会触发全量复制。\n\n## 六、读写分离和过期数据\n\n主从复制的一大用处就是可以拓展单节点的读写性能，但是由于Redis中主从节点的数据复制时单向的，所以从节点对外是只读状态，而主节点是可读可写的状态。在读请求占比比较大的时候，让从节点参与响应读请求可以有效的分摊Master节点的压力。但是需要注意的是，由于主从节点之间可能存在数据的延迟，导致从子节点读到的数据可能是过期数据。其中一个典型的场景就是过期数据未能及时清理。由于数据的单向复制，子节点在Master节点不告知的情况下不会主动进行任何内存变更的操作，涉及到数据过期时，Redis采用的做法是当Master节点判断某个key过期了之后会向子节点发送DEL命令删除掉数据。但是如果期间由于网络环境或其他问题导致DEL命令未及时到达子节点，那么用户此时从子节点读到的数据就是本应已过期被删除的数据。为了解决这个问题，Redis从3.2版本之后，子节点也可以主动判断用户请求的键是否已经过期。如果过期，则就不向用户返回结果，但是并不会直接删除数据。删除数据的操作仍然是只会由Master节点的同步引起。这实际上是对主从的时钟同步是有要求的，绝大部分情况下这个先决条件还是能够被满足的。\n\n## 七、结语\n\n本文介绍了着重介绍了Redis主从复制的全量复制和部分复制，并简单的介绍了Redis主从分离对单点读写性能的扩展以及面临的数据延迟中的典型代表：数据过期问题。希望能对大家有所帮助。\n\n## 八、后记\n\n这篇文章写的真的是一坨翔，回到家专心工作比较艰难，都是零敲碎打的写东西。但是为了能不断更，所以也就硬着头皮往下写了。写之前看了很多资料，都是介绍了原理性的内容，自己不是很满意，于是就想读源码，从实现的角度来更详细的介绍主从复制。读完后才发现，从代码实现上讲并不会增加更多的细节，反而容易让读者抓不住重点。下次写就只写一个聚焦的话题，回北京之前不会再写这种涉及话题比较多的内容了。\n\n## 相关链接\n- [Redis集群——主从复制数据同步 - 知乎](https://zhuanlan.zhihu.com/p/102859170)","slug":"re0-redis-master","published":1,"updated":"2022-04-28T11:36:46.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58t000jmauy0pria8w4","content":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h2><p>这篇开始要进入Redis集群的技术研究了，我们按照顺序会至少分四部分来介绍：<strong>主从复制、哨兵模式、Gossip协议和一致性哈希以及Redis集群</strong>。<strong>主从复制</strong>是高可用的基石，<strong>哨兵模式</strong>提供了主从架构中的自动故障恢复能力， <strong>Gossip协议和一致性哈希</strong>提供了集群中新加入节点和退出节点的发现以及节点加入或退出引起的数据重分配，最后基于上述的几个核心技术实现了高可用的<strong>Redis集群</strong>。</p>\n<p>Redis作为一个内存数据库，使用主从架构的最核心的目的便是提供数据冗余备份，以防止一个Redis节点Down掉之后其中的数据也被丢失，而作为冗余备份，主从节点最重要的工作便是数据同步。那么本篇着重介绍的便是Redis的数据同步策略，包括主从节点首次建立连接后的<strong>全量复制</strong>以及从节点短暂断连后的数据<strong>部分复制。</strong>主要内容分为</p>\n<ol>\n<li><strong>Redis主从复制概述</strong></li>\n<li><strong>Redis主从数据同步</strong></li>\n<li><strong>Redis读写分离实现以及过期数据处理</strong></li>\n<li><strong>结语</strong></li>\n</ol>\n<h2 id=\"二、Redis主从复制概述\"><a href=\"#二、Redis主从复制概述\" class=\"headerlink\" title=\"二、Redis主从复制概述\"></a>二、Redis主从复制概述</h2><p>主从复制，是指将一台Redis服务器的数据复制到其他的Redis服务器，前者称为主节点(master/leader)，后者称为从节点(slave/follower)。一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点，同时每个从节点也可以是别的从节点的父节点，即主从节点连接形成树结构。</p>\n<p><img src=\"https://p.pstatp.com/origin/pgc-image/4ae244e1829440078351db7231a1a9d6\" alt=\"主从复制过程\"></p>\n<p>主从复制的发起都是在子节点发起，当节点127.0.0.1:6380中使用salveof 127.0.0.1 6379后，6380节点与6379节点的数据复制过程如下图所示。</p>\n<p><strong>主从结构中数据的复制是单向的，只能由主节点到从节点</strong>，所有的内存变更，即数据的增删改都只能在主节点上进行，从节点通过同步的方式完成修改。默认情况下，从节点对非Master节点客户端是只读的。Redis使用主从复制的作用有：</p>\n<ol>\n<li><strong>数据冗余</strong>：实现数据冗余备份，这样一台节点挂了之后，其上的数据不至于丢失。</li>\n<li><strong>故障恢复</strong>：当主节点出现问题时，其从节点可以被提升为主节点继续提供服务，实现快速的故障恢复；</li>\n<li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li>\n</ol>\n<h2 id=\"三、数据同步\"><a href=\"#三、数据同步\" class=\"headerlink\" title=\"三、数据同步\"></a>三、数据同步</h2><p>接下来进入本文的重点——Redis主从节点的数据同步。作为内存数据库，Redis主从结构的核心目的在于数据备份。当节点A对节点B发起复制时，最直接的做法就是把节点B的内存数据生成快照文件（RDB）然后发送给节点A，节点A接收到RDB文件后将文件中的数据恢复到内存中，这就是<strong>全量复制</strong>。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-12a31457508682daabc7ea4f1c2e455c_720w.jpg\" alt=\"img\"></p>\n<h2 id=\"四、全量复制\"><a href=\"#四、全量复制\" class=\"headerlink\" title=\"四、全量复制\"></a>四、全量复制</h2><p>在Redis(1)中我们介绍过为了保障进程挂掉之后数据不至于丢失，Redis采用了RDB持久化和AOF持久化两种策略，这样当Redis重启后便可以从RDB文件或者AOF文件中恢复出数据。<strong>而全量复制的核心就是把Master节点当前的数据全部发送给子节点</strong>，那么显然，只要我们把Master节点的RDB文件或者AOF文件发给Slave节点就可以。这样Slave节点接收到文件之后就可以从文件中恢复出Master节点的数据。当然，为了保证主从节点一致，Slave节点从持久化文件中恢复数据之前首先应该清空自己内存中的所有数据。Redis提供了两种数据同步方式:RDB_CHILD_TYPE_DISK和RDB_CHILD_TYPE_SOCKET。所谓RDB_CHILD_TYPE_DISK就是将内存数据写入磁盘文件中，然后将磁盘文件发送给Slave节点, RDB_CHILD_TYPE_SOCKET即直接把内存数据写入Slave节点的socket文件进行发送而不需要先写入磁盘。由于不需要落盘，RDB_CHILD_TYPE_DISK的方式速度会更快，但是如果Master节点采用RDB_CHILD_TYPE_SOCKET向Slave节点发送数据时有新的节点发起数据同步请求，那么Master节点就需要重新再为新的Slave节点重新同步，而采用RDB_CHILD_TYPE_DISK生成RDB文件时如果有新的Slave节点加入数据复制，并不会引发新的RDB文件生成过程。二者各有利弊，但一般情况下我们会采用基于RDB_CHILD_TYPE_DISK的方式进行数据同步，同时也是限于篇幅，接下来的介绍中以RDB_CHILD_TYPE_DISK为主。</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/94680529\" target=\"_blank\" rel=\"noopener\">大龙：Redis详解（1）——为什么我们都需要了解Redis47 赞同 · 2 评论文章<img src=\"https://pic3.zhimg.com/v2-d7454c387a1257b6f819bb251b0a121e_180x120.jpg\" alt=\"img\"></a></p>\n<p>在Redis的源码实现中。<strong><em>replicationCron</em></strong>函数被每秒调用一次。函数中会每次都会去判断是否有Slave节点处于等待数据同步的状态。如果有，则开始进行全量复制。 全量复制首先fork一个子进程调用<strong><em>rdbSave</em></strong>函数生成RDB文件，生成结束后调用回调函数<strong><em>updateSlavesWaitingBgsave</em></strong>将RDB文件发送给所有的Slave节点完成了同步过程。由于这部分实现代码非常的多，我就在下面把路径中的每个函数进行了大幅删减，主要展示整个过程中的函数调用关系，方便大家对着源代码阅读，大家从上往下读即可。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// replication.c</span></span><br><span class=\"line\"><span class=\"comment\">// replicationCron函数每秒调用一次，代码被删减</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">replicationCron</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/* Redis至多只允许一个子进程运行，而Master节点进行全量复制时需要fork一个子进程来进行RDB文件的生成*/</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!hasActiveChildProcess()) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">time_t</span> idle, max_idle = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> slaves_waiting = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mincapa = <span class=\"number\">-1</span>;</span><br><span class=\"line\">        listNode *ln;</span><br><span class=\"line\">        listIter li;</span><br><span class=\"line\">        <span class=\"comment\">// 统计子节点中有多少个节点正在等待全量数据复制</span></span><br><span class=\"line\">        listRewind(server.slaves,&amp;li);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>((ln = listNext(&amp;li))) &#123;</span><br><span class=\"line\">            client *slave = ln-&gt;value;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) &#123;</span><br><span class=\"line\">                idle = server.unixtime - slave-&gt;lastinteraction;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (idle &gt; max_idle) max_idle = idle;</span><br><span class=\"line\">                slaves_waiting++;</span><br><span class=\"line\">                mincapa = (mincapa == <span class=\"number\">-1</span>) ? slave-&gt;slave_capa :</span><br><span class=\"line\">                                            (mincapa &amp; slave-&gt;slave_capa);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果有子节点在等待，则开始进行全量复制</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (slaves_waiting )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            startBgsaveForReplication(mincapa);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">startBgsaveForReplication</span><span class=\"params\">(<span class=\"keyword\">int</span> mincapa)</span> </span>&#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">   <span class=\"keyword\">int</span> reval = rdbSaveBackground(server.rdb_filename,rsiptr);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rdbSaveBackground</span><span class=\"params\">(<span class=\"keyword\">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> childpid;</span><br><span class=\"line\">    <span class=\"comment\">// fork一个子进程用于生成RDB文件</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((childpid = redisFork()) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> retval = rdbSave(filename,rsi);</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 生成RDB文件*/</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rdbSave</span><span class=\"params\">(<span class=\"keyword\">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 省略代码...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 当RDB文件生成结束后，根据同步的方式来调用对应的回调函数 */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">backgroundSaveDoneHandler</span><span class=\"params\">(<span class=\"keyword\">int</span> exitcode, <span class=\"keyword\">int</span> bysignal)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">switch</span>(server.rdb_child_type) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">case</span> RDB_CHILD_TYPE_DISK:</span><br><span class=\"line\">        backgroundSaveDoneHandlerDisk(exitcode,bysignal);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    <span class=\"keyword\">case</span> RDB_CHILD_TYPE_SOCKET:</span><br><span class=\"line\">        backgroundSaveDoneHandlerSocket(exitcode,bysignal);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    <span class=\"keyword\">default</span>:</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown RDB child type.\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 基于RDB_CHILD_TYPE_DISK的回调函数中向所有 Slave节点发送RDB文件。</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">backgroundSaveDoneHandlerDisk</span><span class=\"params\">(<span class=\"keyword\">int</span> exitcode, <span class=\"keyword\">int</span> bysignal)</span> </span>&#123;</span><br><span class=\"line\">   updateSlavesWaitingBgsave((!bysignal &amp;&amp; exitcode == <span class=\"number\">0</span>) ? C_OK : C_ERR, RDB_CHILD_TYPE_DISK);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>全量复制的介绍就到这里，那么这里有一个问题是：全量复制只是复制了T1时刻Master节点的数据快照，那么之后客户端向Master节点的写入数据该如何同步给Slave节点？第一种显然的做法就是开启定时任务，每隔T时间就进行一次全量复制，完成一上面的所有操作即可。但是全量复制实际上是个成本很高的操作，大致分为如下几步：</p>\n<ol>\n<li>Master节点开启子进程进行RDB文件生成</li>\n<li>Master节点将RDB文件发送给Slave节点</li>\n<li>Slave节点清空内存中的所有数据并删除之前的RDB文件</li>\n<li>Slave节点使用从Master接收的RDB文件恢复数据到内存中</li>\n</ol>\n<p>整个过程每一步都是耗时间的IO操作，比如Master节点在T1时刻开始RDB文件的生成，一直到T2时刻Slave节点才能完成数据载入。在网络环境较差或者IO能力较弱的情况下，上述的操作不仅耗时久，而且会因此导致主从节点数据延迟比较大（因为耗时，所以T会设置的比较大）。那么Redis为了解决这个问题，提出的解决方案是<strong>命令传播+增量复制。</strong></p>\n<h2 id=\"五、命令传播\"><a href=\"#五、命令传播\" class=\"headerlink\" title=\"五、命令传播\"></a>五、命令传播</h2><p>所谓命令传播当Master节点每处理完一个命令都会把命令广播给所有的子节点，而每个子节点接收到Master的广播过来的命令后，会在处理完之后继续广播给自己的子节点。需要注意的是，Redis的命令广播是异步的操作。即Master节点处理完客户端的命令之后会立马向客户端返回结果，而不会一直等待所有的子节点都确认完成操作后再返回以保证Redis高效的性能。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">processInputBufferAndReplicate</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 处理命令然后广播命令</span></span><br><span class=\"line\">    <span class=\"comment\">// if this is a slave, we just process the commands</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!(c-&gt;flags &amp; CLIENT_MASTER)) &#123;</span><br><span class=\"line\">        processInputBuffer(c);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* If the client is a master we need to compute the difference</span></span><br><span class=\"line\"><span class=\"comment\">         * between the applied offset before and after processing the buffer,</span></span><br><span class=\"line\"><span class=\"comment\">         * to understand how much of the replication stream was actually</span></span><br><span class=\"line\"><span class=\"comment\">         * applied to the master state: this quantity, and its corresponding</span></span><br><span class=\"line\"><span class=\"comment\">         * part of the replication stream, will be propagated to the</span></span><br><span class=\"line\"><span class=\"comment\">         * sub-replicas and to the replication backlog. */</span></span><br><span class=\"line\">        <span class=\"keyword\">size_t</span> prev_offset = c-&gt;reploff;</span><br><span class=\"line\">        processInputBuffer(c);</span><br><span class=\"line\">        <span class=\"comment\">// applied is how much of the replication stream was actually applied to the master state</span></span><br><span class=\"line\">        <span class=\"keyword\">size_t</span> applied = c-&gt;reploff - prev_offset;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (applied) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">            replicationFeedSlavesFromMasterStream(server.slaves,</span><br><span class=\"line\">                    c-&gt;pending_querybuf, applied);</span><br><span class=\"line\">            sdsrange(c-&gt;pending_querybuf,applied,<span class=\"number\">-1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么紧接着的另一个问题是，<strong>如果某一个子节点A短暂的断连了T秒，那么A再次恢复连接之后该如何同步数据呢？</strong>Redis选择的做法是开辟一个缓冲区（默认大小是1M)，每次处理完命令之后，先写入缓冲区repl_backlog, 然后再发送给子节点。这就是增量复制（也叫部分复制）。但是缓冲区能保存的命令有限，只能至多保存的命令长度为repl_backlog_length，如果某个子节点落后当前最新命令的长度大于了repl_backlog_length，那么就会触发全量复制。</p>\n<h2 id=\"六、读写分离和过期数据\"><a href=\"#六、读写分离和过期数据\" class=\"headerlink\" title=\"六、读写分离和过期数据\"></a>六、读写分离和过期数据</h2><p>主从复制的一大用处就是可以拓展单节点的读写性能，但是由于Redis中主从节点的数据复制时单向的，所以从节点对外是只读状态，而主节点是可读可写的状态。在读请求占比比较大的时候，让从节点参与响应读请求可以有效的分摊Master节点的压力。但是需要注意的是，由于主从节点之间可能存在数据的延迟，导致从子节点读到的数据可能是过期数据。其中一个典型的场景就是过期数据未能及时清理。由于数据的单向复制，子节点在Master节点不告知的情况下不会主动进行任何内存变更的操作，涉及到数据过期时，Redis采用的做法是当Master节点判断某个key过期了之后会向子节点发送DEL命令删除掉数据。但是如果期间由于网络环境或其他问题导致DEL命令未及时到达子节点，那么用户此时从子节点读到的数据就是本应已过期被删除的数据。为了解决这个问题，Redis从3.2版本之后，子节点也可以主动判断用户请求的键是否已经过期。如果过期，则就不向用户返回结果，但是并不会直接删除数据。删除数据的操作仍然是只会由Master节点的同步引起。这实际上是对主从的时钟同步是有要求的，绝大部分情况下这个先决条件还是能够被满足的。</p>\n<h2 id=\"七、结语\"><a href=\"#七、结语\" class=\"headerlink\" title=\"七、结语\"></a>七、结语</h2><p>本文介绍了着重介绍了Redis主从复制的全量复制和部分复制，并简单的介绍了Redis主从分离对单点读写性能的扩展以及面临的数据延迟中的典型代表：数据过期问题。希望能对大家有所帮助。</p>\n<h2 id=\"八、后记\"><a href=\"#八、后记\" class=\"headerlink\" title=\"八、后记\"></a>八、后记</h2><p>这篇文章写的真的是一坨翔，回到家专心工作比较艰难，都是零敲碎打的写东西。但是为了能不断更，所以也就硬着头皮往下写了。写之前看了很多资料，都是介绍了原理性的内容，自己不是很满意，于是就想读源码，从实现的角度来更详细的介绍主从复制。读完后才发现，从代码实现上讲并不会增加更多的细节，反而容易让读者抓不住重点。下次写就只写一个聚焦的话题，回北京之前不会再写这种涉及话题比较多的内容了。</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/102859170\" target=\"_blank\" rel=\"noopener\">Redis集群——主从复制数据同步 - 知乎</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h2><p>这篇开始要进入Redis集群的技术研究了，我们按照顺序会至少分四部分来介绍：<strong>主从复制、哨兵模式、Gossip协议和一致性哈希以及Redis集群</strong>。<strong>主从复制</strong>是高可用的基石，<strong>哨兵模式</strong>提供了主从架构中的自动故障恢复能力， <strong>Gossip协议和一致性哈希</strong>提供了集群中新加入节点和退出节点的发现以及节点加入或退出引起的数据重分配，最后基于上述的几个核心技术实现了高可用的<strong>Redis集群</strong>。</p>\n<p>Redis作为一个内存数据库，使用主从架构的最核心的目的便是提供数据冗余备份，以防止一个Redis节点Down掉之后其中的数据也被丢失，而作为冗余备份，主从节点最重要的工作便是数据同步。那么本篇着重介绍的便是Redis的数据同步策略，包括主从节点首次建立连接后的<strong>全量复制</strong>以及从节点短暂断连后的数据<strong>部分复制。</strong>主要内容分为</p>\n<ol>\n<li><strong>Redis主从复制概述</strong></li>\n<li><strong>Redis主从数据同步</strong></li>\n<li><strong>Redis读写分离实现以及过期数据处理</strong></li>\n<li><strong>结语</strong></li>\n</ol>\n<h2 id=\"二、Redis主从复制概述\"><a href=\"#二、Redis主从复制概述\" class=\"headerlink\" title=\"二、Redis主从复制概述\"></a>二、Redis主从复制概述</h2><p>主从复制，是指将一台Redis服务器的数据复制到其他的Redis服务器，前者称为主节点(master/leader)，后者称为从节点(slave/follower)。一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点，同时每个从节点也可以是别的从节点的父节点，即主从节点连接形成树结构。</p>\n<p><img src=\"https://p.pstatp.com/origin/pgc-image/4ae244e1829440078351db7231a1a9d6\" alt=\"主从复制过程\"></p>\n<p>主从复制的发起都是在子节点发起，当节点127.0.0.1:6380中使用salveof 127.0.0.1 6379后，6380节点与6379节点的数据复制过程如下图所示。</p>\n<p><strong>主从结构中数据的复制是单向的，只能由主节点到从节点</strong>，所有的内存变更，即数据的增删改都只能在主节点上进行，从节点通过同步的方式完成修改。默认情况下，从节点对非Master节点客户端是只读的。Redis使用主从复制的作用有：</p>\n<ol>\n<li><strong>数据冗余</strong>：实现数据冗余备份，这样一台节点挂了之后，其上的数据不至于丢失。</li>\n<li><strong>故障恢复</strong>：当主节点出现问题时，其从节点可以被提升为主节点继续提供服务，实现快速的故障恢复；</li>\n<li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li>\n</ol>\n<h2 id=\"三、数据同步\"><a href=\"#三、数据同步\" class=\"headerlink\" title=\"三、数据同步\"></a>三、数据同步</h2><p>接下来进入本文的重点——Redis主从节点的数据同步。作为内存数据库，Redis主从结构的核心目的在于数据备份。当节点A对节点B发起复制时，最直接的做法就是把节点B的内存数据生成快照文件（RDB）然后发送给节点A，节点A接收到RDB文件后将文件中的数据恢复到内存中，这就是<strong>全量复制</strong>。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-12a31457508682daabc7ea4f1c2e455c_720w.jpg\" alt=\"img\"></p>\n<h2 id=\"四、全量复制\"><a href=\"#四、全量复制\" class=\"headerlink\" title=\"四、全量复制\"></a>四、全量复制</h2><p>在Redis(1)中我们介绍过为了保障进程挂掉之后数据不至于丢失，Redis采用了RDB持久化和AOF持久化两种策略，这样当Redis重启后便可以从RDB文件或者AOF文件中恢复出数据。<strong>而全量复制的核心就是把Master节点当前的数据全部发送给子节点</strong>，那么显然，只要我们把Master节点的RDB文件或者AOF文件发给Slave节点就可以。这样Slave节点接收到文件之后就可以从文件中恢复出Master节点的数据。当然，为了保证主从节点一致，Slave节点从持久化文件中恢复数据之前首先应该清空自己内存中的所有数据。Redis提供了两种数据同步方式:RDB_CHILD_TYPE_DISK和RDB_CHILD_TYPE_SOCKET。所谓RDB_CHILD_TYPE_DISK就是将内存数据写入磁盘文件中，然后将磁盘文件发送给Slave节点, RDB_CHILD_TYPE_SOCKET即直接把内存数据写入Slave节点的socket文件进行发送而不需要先写入磁盘。由于不需要落盘，RDB_CHILD_TYPE_DISK的方式速度会更快，但是如果Master节点采用RDB_CHILD_TYPE_SOCKET向Slave节点发送数据时有新的节点发起数据同步请求，那么Master节点就需要重新再为新的Slave节点重新同步，而采用RDB_CHILD_TYPE_DISK生成RDB文件时如果有新的Slave节点加入数据复制，并不会引发新的RDB文件生成过程。二者各有利弊，但一般情况下我们会采用基于RDB_CHILD_TYPE_DISK的方式进行数据同步，同时也是限于篇幅，接下来的介绍中以RDB_CHILD_TYPE_DISK为主。</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/94680529\" target=\"_blank\" rel=\"noopener\">大龙：Redis详解（1）——为什么我们都需要了解Redis47 赞同 · 2 评论文章<img src=\"https://pic3.zhimg.com/v2-d7454c387a1257b6f819bb251b0a121e_180x120.jpg\" alt=\"img\"></a></p>\n<p>在Redis的源码实现中。<strong><em>replicationCron</em></strong>函数被每秒调用一次。函数中会每次都会去判断是否有Slave节点处于等待数据同步的状态。如果有，则开始进行全量复制。 全量复制首先fork一个子进程调用<strong><em>rdbSave</em></strong>函数生成RDB文件，生成结束后调用回调函数<strong><em>updateSlavesWaitingBgsave</em></strong>将RDB文件发送给所有的Slave节点完成了同步过程。由于这部分实现代码非常的多，我就在下面把路径中的每个函数进行了大幅删减，主要展示整个过程中的函数调用关系，方便大家对着源代码阅读，大家从上往下读即可。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// replication.c</span></span><br><span class=\"line\"><span class=\"comment\">// replicationCron函数每秒调用一次，代码被删减</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">replicationCron</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/* Redis至多只允许一个子进程运行，而Master节点进行全量复制时需要fork一个子进程来进行RDB文件的生成*/</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!hasActiveChildProcess()) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">time_t</span> idle, max_idle = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> slaves_waiting = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mincapa = <span class=\"number\">-1</span>;</span><br><span class=\"line\">        listNode *ln;</span><br><span class=\"line\">        listIter li;</span><br><span class=\"line\">        <span class=\"comment\">// 统计子节点中有多少个节点正在等待全量数据复制</span></span><br><span class=\"line\">        listRewind(server.slaves,&amp;li);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>((ln = listNext(&amp;li))) &#123;</span><br><span class=\"line\">            client *slave = ln-&gt;value;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) &#123;</span><br><span class=\"line\">                idle = server.unixtime - slave-&gt;lastinteraction;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (idle &gt; max_idle) max_idle = idle;</span><br><span class=\"line\">                slaves_waiting++;</span><br><span class=\"line\">                mincapa = (mincapa == <span class=\"number\">-1</span>) ? slave-&gt;slave_capa :</span><br><span class=\"line\">                                            (mincapa &amp; slave-&gt;slave_capa);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果有子节点在等待，则开始进行全量复制</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (slaves_waiting )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            startBgsaveForReplication(mincapa);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">startBgsaveForReplication</span><span class=\"params\">(<span class=\"keyword\">int</span> mincapa)</span> </span>&#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">   <span class=\"keyword\">int</span> reval = rdbSaveBackground(server.rdb_filename,rsiptr);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rdbSaveBackground</span><span class=\"params\">(<span class=\"keyword\">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">pid_t</span> childpid;</span><br><span class=\"line\">    <span class=\"comment\">// fork一个子进程用于生成RDB文件</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((childpid = redisFork()) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> retval = rdbSave(filename,rsi);</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 生成RDB文件*/</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rdbSave</span><span class=\"params\">(<span class=\"keyword\">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 省略代码...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 当RDB文件生成结束后，根据同步的方式来调用对应的回调函数 */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">backgroundSaveDoneHandler</span><span class=\"params\">(<span class=\"keyword\">int</span> exitcode, <span class=\"keyword\">int</span> bysignal)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">switch</span>(server.rdb_child_type) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">case</span> RDB_CHILD_TYPE_DISK:</span><br><span class=\"line\">        backgroundSaveDoneHandlerDisk(exitcode,bysignal);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    <span class=\"keyword\">case</span> RDB_CHILD_TYPE_SOCKET:</span><br><span class=\"line\">        backgroundSaveDoneHandlerSocket(exitcode,bysignal);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    <span class=\"keyword\">default</span>:</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown RDB child type.\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 基于RDB_CHILD_TYPE_DISK的回调函数中向所有 Slave节点发送RDB文件。</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">backgroundSaveDoneHandlerDisk</span><span class=\"params\">(<span class=\"keyword\">int</span> exitcode, <span class=\"keyword\">int</span> bysignal)</span> </span>&#123;</span><br><span class=\"line\">   updateSlavesWaitingBgsave((!bysignal &amp;&amp; exitcode == <span class=\"number\">0</span>) ? C_OK : C_ERR, RDB_CHILD_TYPE_DISK);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>全量复制的介绍就到这里，那么这里有一个问题是：全量复制只是复制了T1时刻Master节点的数据快照，那么之后客户端向Master节点的写入数据该如何同步给Slave节点？第一种显然的做法就是开启定时任务，每隔T时间就进行一次全量复制，完成一上面的所有操作即可。但是全量复制实际上是个成本很高的操作，大致分为如下几步：</p>\n<ol>\n<li>Master节点开启子进程进行RDB文件生成</li>\n<li>Master节点将RDB文件发送给Slave节点</li>\n<li>Slave节点清空内存中的所有数据并删除之前的RDB文件</li>\n<li>Slave节点使用从Master接收的RDB文件恢复数据到内存中</li>\n</ol>\n<p>整个过程每一步都是耗时间的IO操作，比如Master节点在T1时刻开始RDB文件的生成，一直到T2时刻Slave节点才能完成数据载入。在网络环境较差或者IO能力较弱的情况下，上述的操作不仅耗时久，而且会因此导致主从节点数据延迟比较大（因为耗时，所以T会设置的比较大）。那么Redis为了解决这个问题，提出的解决方案是<strong>命令传播+增量复制。</strong></p>\n<h2 id=\"五、命令传播\"><a href=\"#五、命令传播\" class=\"headerlink\" title=\"五、命令传播\"></a>五、命令传播</h2><p>所谓命令传播当Master节点每处理完一个命令都会把命令广播给所有的子节点，而每个子节点接收到Master的广播过来的命令后，会在处理完之后继续广播给自己的子节点。需要注意的是，Redis的命令广播是异步的操作。即Master节点处理完客户端的命令之后会立马向客户端返回结果，而不会一直等待所有的子节点都确认完成操作后再返回以保证Redis高效的性能。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">processInputBufferAndReplicate</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 处理命令然后广播命令</span></span><br><span class=\"line\">    <span class=\"comment\">// if this is a slave, we just process the commands</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!(c-&gt;flags &amp; CLIENT_MASTER)) &#123;</span><br><span class=\"line\">        processInputBuffer(c);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* If the client is a master we need to compute the difference</span></span><br><span class=\"line\"><span class=\"comment\">         * between the applied offset before and after processing the buffer,</span></span><br><span class=\"line\"><span class=\"comment\">         * to understand how much of the replication stream was actually</span></span><br><span class=\"line\"><span class=\"comment\">         * applied to the master state: this quantity, and its corresponding</span></span><br><span class=\"line\"><span class=\"comment\">         * part of the replication stream, will be propagated to the</span></span><br><span class=\"line\"><span class=\"comment\">         * sub-replicas and to the replication backlog. */</span></span><br><span class=\"line\">        <span class=\"keyword\">size_t</span> prev_offset = c-&gt;reploff;</span><br><span class=\"line\">        processInputBuffer(c);</span><br><span class=\"line\">        <span class=\"comment\">// applied is how much of the replication stream was actually applied to the master state</span></span><br><span class=\"line\">        <span class=\"keyword\">size_t</span> applied = c-&gt;reploff - prev_offset;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (applied) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">            replicationFeedSlavesFromMasterStream(server.slaves,</span><br><span class=\"line\">                    c-&gt;pending_querybuf, applied);</span><br><span class=\"line\">            sdsrange(c-&gt;pending_querybuf,applied,<span class=\"number\">-1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么紧接着的另一个问题是，<strong>如果某一个子节点A短暂的断连了T秒，那么A再次恢复连接之后该如何同步数据呢？</strong>Redis选择的做法是开辟一个缓冲区（默认大小是1M)，每次处理完命令之后，先写入缓冲区repl_backlog, 然后再发送给子节点。这就是增量复制（也叫部分复制）。但是缓冲区能保存的命令有限，只能至多保存的命令长度为repl_backlog_length，如果某个子节点落后当前最新命令的长度大于了repl_backlog_length，那么就会触发全量复制。</p>\n<h2 id=\"六、读写分离和过期数据\"><a href=\"#六、读写分离和过期数据\" class=\"headerlink\" title=\"六、读写分离和过期数据\"></a>六、读写分离和过期数据</h2><p>主从复制的一大用处就是可以拓展单节点的读写性能，但是由于Redis中主从节点的数据复制时单向的，所以从节点对外是只读状态，而主节点是可读可写的状态。在读请求占比比较大的时候，让从节点参与响应读请求可以有效的分摊Master节点的压力。但是需要注意的是，由于主从节点之间可能存在数据的延迟，导致从子节点读到的数据可能是过期数据。其中一个典型的场景就是过期数据未能及时清理。由于数据的单向复制，子节点在Master节点不告知的情况下不会主动进行任何内存变更的操作，涉及到数据过期时，Redis采用的做法是当Master节点判断某个key过期了之后会向子节点发送DEL命令删除掉数据。但是如果期间由于网络环境或其他问题导致DEL命令未及时到达子节点，那么用户此时从子节点读到的数据就是本应已过期被删除的数据。为了解决这个问题，Redis从3.2版本之后，子节点也可以主动判断用户请求的键是否已经过期。如果过期，则就不向用户返回结果，但是并不会直接删除数据。删除数据的操作仍然是只会由Master节点的同步引起。这实际上是对主从的时钟同步是有要求的，绝大部分情况下这个先决条件还是能够被满足的。</p>\n<h2 id=\"七、结语\"><a href=\"#七、结语\" class=\"headerlink\" title=\"七、结语\"></a>七、结语</h2><p>本文介绍了着重介绍了Redis主从复制的全量复制和部分复制，并简单的介绍了Redis主从分离对单点读写性能的扩展以及面临的数据延迟中的典型代表：数据过期问题。希望能对大家有所帮助。</p>\n<h2 id=\"八、后记\"><a href=\"#八、后记\" class=\"headerlink\" title=\"八、后记\"></a>八、后记</h2><p>这篇文章写的真的是一坨翔，回到家专心工作比较艰难，都是零敲碎打的写东西。但是为了能不断更，所以也就硬着头皮往下写了。写之前看了很多资料，都是介绍了原理性的内容，自己不是很满意，于是就想读源码，从实现的角度来更详细的介绍主从复制。读完后才发现，从代码实现上讲并不会增加更多的细节，反而容易让读者抓不住重点。下次写就只写一个聚焦的话题，回北京之前不会再写这种涉及话题比较多的内容了。</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/102859170\" target=\"_blank\" rel=\"noopener\">Redis集群——主从复制数据同步 - 知乎</a></li>\n</ul>\n"},{"title":"Redis淘汰机制","date":"2021-09-16T16:27:56.000Z","_content":"\n# 概述\n\nRedis是基于内存存储，常用于数据的缓存，所以Redis提供了对键的过期时间的设置，实现了几种淘汰机制便于适应各种场景。\n\n------\n\n**设置过期时间**\n我们可以在设置键时设置expire time，也可以在运行时给存在的键设置剩余的生存时间，不设置则默认为-1，设置为-1时表示永久存储。\n\n# Redis清除过期Key的方式\n\n```\n定期删除+惰性删除\n```\n\n## 定期删除\n\nRedis设定每隔100ms`随机`抽取设置了过期时间的key，并对其进行检查，如果已经过期则删除。\n**为什么是随机抽取？** 因为如果存储了大量数据，全部遍历一遍是非常影响性能的！\n\n## 惰性删除\n\n每次获取key时会对key进行判断是否还存活，如果已经过期了则删除。\n\n------\n\n```\n注意：Redis中过期的key并不会马上删除，因为定期删除可能正好没抽取到它，我们也没有访问它触发惰性删除\n```\n\n# Redis内存淘汰机制\n\n思考一下，如果定期删除漏掉了很多过期的key，而我们也没有再去访问它，如果不加处理，很可能导致内存耗尽。\n\n------\n\nRedis配置文件中可以设置maxmemory，内存的最大使用量，到达限度时会执行`内存淘汰机制`。\n\n**Redis中的内存淘汰机制：**\n\n没有配置时，`默认为no-eviction`\n\n| 名称            | 描述                                                     |\n| --------------- | -------------------------------------------------------- |\n| volatile-lru    | 从已设置过期时间的数据集中挑选`最近最少使用`的数据淘汰 |\n| volatile-lfu    | 从已设置过期时间的数据集中挑选`最不经常`使用的数据淘汰   |\n| volatile-ttl    | 从已设置过期时间的数据集中挑选`将要过期`的数据淘汰       |\n| volatile-random | 从已设置过期时间的数据集中挑选`任意数据`淘汰             |\n| allkeys-lru     | 当内存不足写入新数据时淘汰最近最少使用的Key              |\n| allkeys-random  | 当内存不足写入新数据时随机选择key淘汰                    |\n| allkeys-lfu     | 当内存不足写入新数据时移除最不经常使用的Key              |\n| no-eviction     | 当内存不足写入新数据时，写入操作会报错，同时不删除数据   |\n\n- volatile为前缀的策略都是从已过期的数据集中进行淘汰。\n- allkeys为前缀的策略都是面向所有key进行淘汰。\n- LRU（least recently used）最近最少用到的。\n- LFU（Least Frequently Used）最不常用的。\n- 它们的触发条件都是Redis使用的内存达到阈值时。\n\n## 相关链接\n- https://blog.csdn.net/weixin_43184769/article/details/90523923","source":"_posts/re0-redis-expire.md","raw":"---\ntitle: Redis淘汰机制\ndate: 2021-09-17 00:27:56\ntags: 从0开始的Redis\n---\n\n# 概述\n\nRedis是基于内存存储，常用于数据的缓存，所以Redis提供了对键的过期时间的设置，实现了几种淘汰机制便于适应各种场景。\n\n------\n\n**设置过期时间**\n我们可以在设置键时设置expire time，也可以在运行时给存在的键设置剩余的生存时间，不设置则默认为-1，设置为-1时表示永久存储。\n\n# Redis清除过期Key的方式\n\n```\n定期删除+惰性删除\n```\n\n## 定期删除\n\nRedis设定每隔100ms`随机`抽取设置了过期时间的key，并对其进行检查，如果已经过期则删除。\n**为什么是随机抽取？** 因为如果存储了大量数据，全部遍历一遍是非常影响性能的！\n\n## 惰性删除\n\n每次获取key时会对key进行判断是否还存活，如果已经过期了则删除。\n\n------\n\n```\n注意：Redis中过期的key并不会马上删除，因为定期删除可能正好没抽取到它，我们也没有访问它触发惰性删除\n```\n\n# Redis内存淘汰机制\n\n思考一下，如果定期删除漏掉了很多过期的key，而我们也没有再去访问它，如果不加处理，很可能导致内存耗尽。\n\n------\n\nRedis配置文件中可以设置maxmemory，内存的最大使用量，到达限度时会执行`内存淘汰机制`。\n\n**Redis中的内存淘汰机制：**\n\n没有配置时，`默认为no-eviction`\n\n| 名称            | 描述                                                     |\n| --------------- | -------------------------------------------------------- |\n| volatile-lru    | 从已设置过期时间的数据集中挑选`最近最少使用`的数据淘汰 |\n| volatile-lfu    | 从已设置过期时间的数据集中挑选`最不经常`使用的数据淘汰   |\n| volatile-ttl    | 从已设置过期时间的数据集中挑选`将要过期`的数据淘汰       |\n| volatile-random | 从已设置过期时间的数据集中挑选`任意数据`淘汰             |\n| allkeys-lru     | 当内存不足写入新数据时淘汰最近最少使用的Key              |\n| allkeys-random  | 当内存不足写入新数据时随机选择key淘汰                    |\n| allkeys-lfu     | 当内存不足写入新数据时移除最不经常使用的Key              |\n| no-eviction     | 当内存不足写入新数据时，写入操作会报错，同时不删除数据   |\n\n- volatile为前缀的策略都是从已过期的数据集中进行淘汰。\n- allkeys为前缀的策略都是面向所有key进行淘汰。\n- LRU（least recently used）最近最少用到的。\n- LFU（Least Frequently Used）最不常用的。\n- 它们的触发条件都是Redis使用的内存达到阈值时。\n\n## 相关链接\n- https://blog.csdn.net/weixin_43184769/article/details/90523923","slug":"re0-redis-expire","published":1,"updated":"2022-04-28T11:36:46.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58v000kmauygn2a4klt","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>Redis是基于内存存储，常用于数据的缓存，所以Redis提供了对键的过期时间的设置，实现了几种淘汰机制便于适应各种场景。</p>\n<hr>\n<p><strong>设置过期时间</strong><br>我们可以在设置键时设置expire time，也可以在运行时给存在的键设置剩余的生存时间，不设置则默认为-1，设置为-1时表示永久存储。</p>\n<h1 id=\"Redis清除过期Key的方式\"><a href=\"#Redis清除过期Key的方式\" class=\"headerlink\" title=\"Redis清除过期Key的方式\"></a>Redis清除过期Key的方式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">定期删除+惰性删除</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"定期删除\"><a href=\"#定期删除\" class=\"headerlink\" title=\"定期删除\"></a>定期删除</h2><p>Redis设定每隔100ms<code>随机</code>抽取设置了过期时间的key，并对其进行检查，如果已经过期则删除。<br><strong>为什么是随机抽取？</strong> 因为如果存储了大量数据，全部遍历一遍是非常影响性能的！</p>\n<h2 id=\"惰性删除\"><a href=\"#惰性删除\" class=\"headerlink\" title=\"惰性删除\"></a>惰性删除</h2><p>每次获取key时会对key进行判断是否还存活，如果已经过期了则删除。</p>\n<hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">注意：Redis中过期的key并不会马上删除，因为定期删除可能正好没抽取到它，我们也没有访问它触发惰性删除</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Redis内存淘汰机制\"><a href=\"#Redis内存淘汰机制\" class=\"headerlink\" title=\"Redis内存淘汰机制\"></a>Redis内存淘汰机制</h1><p>思考一下，如果定期删除漏掉了很多过期的key，而我们也没有再去访问它，如果不加处理，很可能导致内存耗尽。</p>\n<hr>\n<p>Redis配置文件中可以设置maxmemory，内存的最大使用量，到达限度时会执行<code>内存淘汰机制</code>。</p>\n<p><strong>Redis中的内存淘汰机制：</strong></p>\n<p>没有配置时，<code>默认为no-eviction</code></p>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>volatile-lru</td>\n<td>从已设置过期时间的数据集中挑选<code>最近最少使用</code>的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-lfu</td>\n<td>从已设置过期时间的数据集中挑选<code>最不经常</code>使用的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-ttl</td>\n<td>从已设置过期时间的数据集中挑选<code>将要过期</code>的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-random</td>\n<td>从已设置过期时间的数据集中挑选<code>任意数据</code>淘汰</td>\n</tr>\n<tr>\n<td>allkeys-lru</td>\n<td>当内存不足写入新数据时淘汰最近最少使用的Key</td>\n</tr>\n<tr>\n<td>allkeys-random</td>\n<td>当内存不足写入新数据时随机选择key淘汰</td>\n</tr>\n<tr>\n<td>allkeys-lfu</td>\n<td>当内存不足写入新数据时移除最不经常使用的Key</td>\n</tr>\n<tr>\n<td>no-eviction</td>\n<td>当内存不足写入新数据时，写入操作会报错，同时不删除数据</td>\n</tr>\n</tbody></table>\n<ul>\n<li>volatile为前缀的策略都是从已过期的数据集中进行淘汰。</li>\n<li>allkeys为前缀的策略都是面向所有key进行淘汰。</li>\n<li>LRU（least recently used）最近最少用到的。</li>\n<li>LFU（Least Frequently Used）最不常用的。</li>\n<li>它们的触发条件都是Redis使用的内存达到阈值时。</li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/weixin_43184769/article/details/90523923\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_43184769/article/details/90523923</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>Redis是基于内存存储，常用于数据的缓存，所以Redis提供了对键的过期时间的设置，实现了几种淘汰机制便于适应各种场景。</p>\n<hr>\n<p><strong>设置过期时间</strong><br>我们可以在设置键时设置expire time，也可以在运行时给存在的键设置剩余的生存时间，不设置则默认为-1，设置为-1时表示永久存储。</p>\n<h1 id=\"Redis清除过期Key的方式\"><a href=\"#Redis清除过期Key的方式\" class=\"headerlink\" title=\"Redis清除过期Key的方式\"></a>Redis清除过期Key的方式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">定期删除+惰性删除</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"定期删除\"><a href=\"#定期删除\" class=\"headerlink\" title=\"定期删除\"></a>定期删除</h2><p>Redis设定每隔100ms<code>随机</code>抽取设置了过期时间的key，并对其进行检查，如果已经过期则删除。<br><strong>为什么是随机抽取？</strong> 因为如果存储了大量数据，全部遍历一遍是非常影响性能的！</p>\n<h2 id=\"惰性删除\"><a href=\"#惰性删除\" class=\"headerlink\" title=\"惰性删除\"></a>惰性删除</h2><p>每次获取key时会对key进行判断是否还存活，如果已经过期了则删除。</p>\n<hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">注意：Redis中过期的key并不会马上删除，因为定期删除可能正好没抽取到它，我们也没有访问它触发惰性删除</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Redis内存淘汰机制\"><a href=\"#Redis内存淘汰机制\" class=\"headerlink\" title=\"Redis内存淘汰机制\"></a>Redis内存淘汰机制</h1><p>思考一下，如果定期删除漏掉了很多过期的key，而我们也没有再去访问它，如果不加处理，很可能导致内存耗尽。</p>\n<hr>\n<p>Redis配置文件中可以设置maxmemory，内存的最大使用量，到达限度时会执行<code>内存淘汰机制</code>。</p>\n<p><strong>Redis中的内存淘汰机制：</strong></p>\n<p>没有配置时，<code>默认为no-eviction</code></p>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>volatile-lru</td>\n<td>从已设置过期时间的数据集中挑选<code>最近最少使用</code>的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-lfu</td>\n<td>从已设置过期时间的数据集中挑选<code>最不经常</code>使用的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-ttl</td>\n<td>从已设置过期时间的数据集中挑选<code>将要过期</code>的数据淘汰</td>\n</tr>\n<tr>\n<td>volatile-random</td>\n<td>从已设置过期时间的数据集中挑选<code>任意数据</code>淘汰</td>\n</tr>\n<tr>\n<td>allkeys-lru</td>\n<td>当内存不足写入新数据时淘汰最近最少使用的Key</td>\n</tr>\n<tr>\n<td>allkeys-random</td>\n<td>当内存不足写入新数据时随机选择key淘汰</td>\n</tr>\n<tr>\n<td>allkeys-lfu</td>\n<td>当内存不足写入新数据时移除最不经常使用的Key</td>\n</tr>\n<tr>\n<td>no-eviction</td>\n<td>当内存不足写入新数据时，写入操作会报错，同时不删除数据</td>\n</tr>\n</tbody></table>\n<ul>\n<li>volatile为前缀的策略都是从已过期的数据集中进行淘汰。</li>\n<li>allkeys为前缀的策略都是面向所有key进行淘汰。</li>\n<li>LRU（least recently used）最近最少用到的。</li>\n<li>LFU（Least Frequently Used）最不常用的。</li>\n<li>它们的触发条件都是Redis使用的内存达到阈值时。</li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/weixin_43184769/article/details/90523923\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_43184769/article/details/90523923</a></li>\n</ul>\n"},{"title":"Redis事件模型","date":"2021-09-13T15:21:01.000Z","_content":"## 零、带着问题出发\n\n- 带着问题出发\n\n## 一、关于Reactor\n\n网络编程模型通常有如下几种：Reactor, Proactor, Asynchronous, Completion Token, and Acceptor-Connector. 本文主要对最主流的Reactor模型进行介绍。通常网络编程模型处理的主要流程如下\n\n```\ninitiate => receive => demultiplex => dispatch => process events\n```\n\nI/O多路复用可以用作并发事件驱动(event-driven)程序的基础，即整个事件驱动模型是一个状态机，包含了状态(state), 输入事件(input-event), 状态转移(transition), 状态转移即状态到输入事件的一组映射。通过I/O多路复用的技术检测事件的发生，并根据具体的事件(通常为读写)，进行不同的操作，即状态转移。\n\nReactor模式是一种典型的事件驱动的编程模型，Reactor逆置了程序处理的流程，其基本的思想即为\n> Hollywood Principle — 'Don't call us, we'll call you'.\n\n普通的函数处理机制为：`调用某函数 -> 函数执行， 主程序等待阻塞 -> 函数将结果返回给主程序 -> 主程序继续执行`\n\nReactor事件处理机制为：主程序将事件以及对应事件处理的方法在Reactor上进行注册, 如果相应的事件发生，Reactor将会主动调用事件注册的接口，即 回调函数. libevent即为封装了epoll并注册相应的事件(I/O读写，时间事件，信号事件)以及回调函数，实现的事件驱动的框架。\n\nredis是一个事件驱动的服务程序，在redis的服务程序中存在两种类型的事件，分别是文件事件和时间事件。文件事件是对网络通信操作的统称，时间事件是redis中定时运行的任务或者是周期性的任务（目前redis中只有serverCron这一个周期性时间事件，并没有定时时间事件）。对于事件驱动类的程序，非常适合使用Reactor模式进行设计。redis也不例外，在文件事件处理的设计中采用了Reactor设计模式。\n\nReactor模式包含四部分，分别是\n\n- Handle(对于系统资源的一种抽象，在redis中就是监听描述符或者是连接描述符）\n- Synchronous Event Demultiplexer(同步事件分离器，在redis中对应于IO多路复用程序）\n- Event Handler(事件处理器，在redis中对应于连接应答处理器、命令请求处理器以及命令回复处理器、事件处理器等）\n- Initiation Dispatcher(事件分派器，在redis中对应于ae.c/aeProcessEvents函数）\n\n## 二、redis事件模型概览\n\n对应的流程如下：\n\n- 在redis中将感兴趣的事件及类型(读、写）通过IO多路复用程序注册到内核中并监听每个事件是否发生。\n- 当IO多路复用程序返回的时候，如果有事件发生，redis在封装IO多路复用程序时，将所有已经发生的事件及该事件的类型封装为aeFiredEvent类型，放到aeEventLoop的fired成员中，形成一个队列。\n- 通过这个队列，redis以有序、同步、每次一个套接字事件的方式向文件事件分派器传送套接字，并处理发生的文件事件。\n- redis处理事件（无论是文件事件还是时间事件）都是以原子的方式进行的，中间不存在事件之间的抢占。这很容易理解，redis是单线程模型，不存在处理上的并发操作。\n\n最后需要说明的是redis首先处理发生的文件事件，然后才会处理时间事件，这点我们在介绍redis源码aeProcessEvents的时候会详细注释和介绍。\n\nredis表示事件模型的数据结构是对该事件标识、事件类型和事件处理函数的一种抽象，就是Reactor模式中的`Handle和Event Handle`的集合。redis使用了四种数据结构描述redis中的事件，前三种数据结构是对redis中某种特定类型事件的一种抽象，最后一种数据结构aeEventLoop是redis管理所有事件的一种抽象。\n\n\n## 三、redis事件模型数据结构\n\n\naeTimeEvent中的id成员、aeFiredEvent中的fd成员都是Reactor模式中所说的Handle的具体表现，但是好像aeFileEvents并没有对应的handle。其实，redis在aeEventLoop的events成员中使用每一个描述符fd作为下标，该下标的对应值为aeFileEvent成员，由此将描述符fd与对该fd感兴趣的事件类型以及处理函数相关联，对应于Reactor中Handle与Event Handler的关联。当通过aeEventLoop中的fired获取到已经发生的事件fd及其类型mask的时候，由fd和mask在aeEventLoop的events成员中获取对应的事件处理器，处理已经发生的事件。也就是说，文件事件的处理是联合使用了fired和events两个成员变量；时间事件的处理使用aeTimeEvent变量。\n\n#### 文件事件数据结构。\n```\n/* 文件事件 */\n  typedef struct aeFileEvent {\n      /* 套接字发生的事件，读事件或者写事件其中的一种 */\n      int mask; /* one of AE_(READABLE|WRITABLE) */\n      /* 读事件处理器，回调函数 */\n      aeFileProc *rfileProc;\n      /* 写事件处理器，回调函数 */\n      aeFileProc *wfileProc;\n      /* 客户端数据 */\n      void *clientData;\n  } aeFileEvent;\n```\n#### 时间事件数据结构。\n```\n  typedef struct aeTimeEvent {\n      /* 时间事件，每个时间事件通过id唯一标识 */\n      long long id;\n      /* 时间事件应该触发的时间，单位:s */\n      long when_sec;\n      /* 时间事件被触发的时间,单位:ms */\n      long when_ms;\n      /* 时间事件处理函数 */\n      aeTimeProc *timeProc;\n      aeEventFinalizerProc *finalizerProc;\n      /* 客户端数据 */\n      void *clientData;\n      /* 时间事件形成的链条 */\n      struct aeTimeEvent *next;\n  } aeTimeEvent;\n```\n#### 已经发生的文件事件数据结构。\n```\n  /* 已经发生的文件事件 */\n  typedef struct aeFiredEvent {\n      int fd;\n      int mask;\n  } aeFiredEvent;\n```\n#### redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\n```\n  /* redis中的事件管理结构体 */\n  typedef struct aeEventLoop {\n      /* 当前IO程序追踪的最大的文件描述符，大于此值的setsize范围内的值，没有意义*/\n      int maxfd;\n      /* 当前感兴趣集合的大小, setsize > maxfd */\n      int setsize;\n      /* 下一个时间事件的id */\n      long long timeEventNextId;\n      /* 用于修正系统时钟的偏移，具体参考aeProcessTimeEvents */\n      time_t lastTime;\n      /* 注册的感兴趣的文件事件 */\n      aeFileEvent *events; \n      /* 被触发的文件事件指针，也就是上文所说的已经发生的文件事件形成的队列 */\n      aeFiredEvent *fired;\n      /* 时间事件形成的链表(无序链表) */\n      aeTimeEvent *timeEventHead;\n      /* 事件停止标志 */\n      int stop;\n      /* 针对特定API需要的数据结构, 通过该数据结构屏蔽掉IO多路复用\n       * 不同底层实现的需要的不同数据结构\n       */\n      void *apidata;\n      aeBeforeSleepProc *beforesleep;\n      aeBeforeSleepProc *aftersleep;\n  } aeEventLoop;\n```\n## 三、redis中的IO多路复用机制\n\nredis中的IO多路复用机制对应于Reactor模式中的同步事件分离器。redis考虑到不同系统可能支持不同的的IO多路复用机制，因此实现了select、epoll、kqueue和evport四种不同的IO多路复用，并且每种IO多路复用机制都提供了完全相同的外部接口，根据ae.c中的条件编译语句选择的顺序依次是evport、epoll、kequeue和select，隔离了系统对IO多路复用机制支持的差异。\n\n## redis的事件分派器\n\n在redis中，ae.c文件提供的对外API屏蔽掉了操作系统底层实现的不同，将对文件事件和时间事件的处理通过统一的接口操作。下面我们详细说明一下redis中作为事件分派器的aeProcessEvents函数和时间事件处理函数processTimeEvents。\n\nredis在aeProcessEvents函数中处理文件事件和时间事件，且先处理文件事件再处理时间事件。flags指定redis是处理时间事件还是文件事件又或者是两种事件的并集，这点很容易理解，我们只是想说明一下flags中的另一个标志位---就是获取就绪文件事件的时候是否阻塞的标志位，AE_DONT_WAIT标志。\n\n按照Reactor设计模式，在文件事件分派器上调用同步事件分离器，获取已经就绪的文件事件。调用同步事件分离器就是要调用IO多路复用函数，而IO多路复用函数有可能阻塞（依据传入的时间参数，决定不阻塞、永久阻塞还是阻塞特定的时间段）。\n\n为了防止redis线程长时间阻塞在文件事件等待就绪上而耽误了及时处理到时的时间事件，并且防止redis过多重复性的遍历时间事件形成的无序链表，redis在aeProcessEvents的实现中通过设置flags中的AE_DONT_WAIT标志位达到以上目的。具体参考aeProcessEvents中的注释。\n\n```\n  int aeProcessEvents(aeEventLoop *eventLoop, int flags)\n  {\n      int processed = 0, numevents;\n  \n      /* 所有的事件都不进行处理 */\n      if (!(flags & AE_TIME_EVENTS) && !(flags & AE_FILE_EVENTS)) return 0;\n  \n      /* 首先判断是否存在需要监听的文件事件，如果存在需要监听的文件事件，那么通过IO多路复用程序获取\n       * 准备就绪的文件事件，至于IO多路复用程序是否等待以及等待多久的时间，依发生时间距离现在最近的时间事件确定;\n       * 如果eventLoop->maxfd == -1表示没有需要监听的文件事件，但是时间事件肯定是存在的(serverCron())，\n       * 如果此时没有设置AE_DONT_WAIT标志位，此时调用IO多路复用，其目的就不是为了监听文件事件准备就绪了，\n       * 而是为了使线程休眠到发生时间距离现在最近的时间事件的发生时间(作用类似于unix中的sleep函数),\n       * 这种休眠操作的目的是为了避免线程一直不停的遍历时间事件形成的无序链表，造成不必要的资源浪费\n       */\n      if (eventLoop->maxfd != -1 ||\n          ((flags & AE_TIME_EVENTS) && !(flags & AE_DONT_WAIT))) {\n          int j;\n          aeTimeEvent *shortest = NULL;\n          struct timeval tv, *tvp;\n  \n          /* 寻找发生时间距离现在最近的时间事件,该时间事件的发生时间与当前时间之差就是IO多路复用程序应该等待的时间 */\n          if (flags & AE_TIME_EVENTS && !(flags & AE_DONT_WAIT))\n              shortest = aeSearchNearestTimer(eventLoop);\n          if (shortest) {\n              long now_sec, now_ms;\n  \n              aeGetTime(&now_sec, &now_ms);\n              tvp = &tv;\n  \n              long long ms =\n                  (shortest->when_sec - now_sec)*1000 +\n                  shortest->when_ms - now_ms;\n  \n              /* 如果时间之差大于0，说明时间事件到时时间未到,则等待对应的时间;\n               * 如果时间间隔小于0，说明时间事件已经到时，此时如果没有\n               * 文件事件准备就绪，那么IO多路复用程序应该立即返回，以免\n               * 耽误处理时间事件\n               */\n              if (ms > 0) {\n                  tvp->tv_sec = ms/1000;\n                  tvp->tv_usec = (ms % 1000)*1000;\n              } else {\n                  tvp->tv_sec = 0;\n                  tvp->tv_usec = 0;\n              }   \n          } else {\n              /* 没有找到距离现在最近的时间事件，且设置了AE_DONT_WAIT标志位，\n               * 立即从IO多路复用程序返回\n               */\n              if (flags & AE_DONT_WAIT) {\n                  tv.tv_sec = tv.tv_usec = 0;\n                  tvp = &tv;\n              } else {\n                  /* 没有设置AE_DONT_WAIT标志位，且没有找到发生时间距离现在最近的时间事件，\n                   * IO多路复用程序可以无限等待\n                   */\n                  tvp = NULL;\n              }\n          }\n  \n          /* 典型的reator设计模式。作为事件分派器，\n           * 将已经发生的文件事件交给对应的eventHandle处理\n           */\n          numevents = aeApiPoll(eventLoop, tvp);\n  \n          /* After sleep callback. */\n          if (eventLoop->aftersleep != NULL && flags & AE_CALL_AFTER_SLEEP)\n              eventLoop->aftersleep(eventLoop);\n  \n          for (j = 0; j < numevents; j++) {\n              aeFileEvent *fe = &eventLoop->events[eventLoop->fired[j].fd];\n              /* 按照队列的顺序处理就绪的文件事件 */\n              int mask = eventLoop->fired[j].mask;\n              int fd = eventLoop->fired[j].fd;\n              int rfired = 0;\n  \n              /* 如果IO多路复用程序同时监听fd的读事件和写事件，\n               * 则当该fd对应的读、写事件都返回可用的时候，\n               * 服务器首先处理读套接字、后处理写套接字\n               */\n              if (fe->mask & mask & AE_READABLE) {\n                  rfired = 1;\n                  fe->rfileProc(eventLoop,fd,fe->clientData,mask);\n              }\n              if (fe->mask & mask & AE_WRITABLE) {\n                  if (!rfired || fe->wfileProc != fe->rfileProc)\n                      fe->wfileProc(eventLoop,fd,fe->clientData,mask);\n              }\n              processed++;\n          }\n      }\n      /* 处理时间事件 */\n      if (flags & AE_TIME_EVENTS)\n          processed += processTimeEvents(eventLoop);\n  \n      return processed; /* return the number of processed file/time events */\n  }    \n```\n\n在redis中将对文件事件的处理直接放到了aeProcessEvents中，但是对于时间事件的处理却是存在单独的函数，aeProcessTimeEvents。                \n\n```\n  static int processTimeEvents(aeEventLoop *eventLoop) {\n      int processed = 0;\n      aeTimeEvent *te, *prev;\n      long long maxId;\n      time_t now = time(NULL);\n  \n      /* 系统的始终如果发生了漂移，那么所有的时间事件应该立即被处理;\n       * 将te->when_sec设置为0，表示所有的时间事件都能够被处理。如果时间事件没有到时，\n       * 那么当前立即处理也不存在什么问题;如果时间事件确实已经到时，那确实应该被处理\n       */\n      if (now < eventLoop->lastTime) {\n          te = eventLoop->timeEventHead;\n          while(te) {\n              te->when_sec = 0;\n              te = te->next;\n          }\n      }\n      /* 纠正系统时钟 */\n      eventLoop->lastTime = now;\n  \n      prev = NULL;\n      te = eventLoop->timeEventHead;\n      maxId = eventLoop->timeEventNextId-1;\n      while(te) {\n          long now_sec, now_ms;\n          long long id;\n  \n          /* 在aeDeleteTimeEvent函数中删除掉时间事件只是将时间事件的id置为无效的id值，\n           * 真正的内存释放工作在这里进行\n           */\n          if (te->id == AE_DELETED_EVENT_ID) {\n              aeTimeEvent *next = te->next;\n              if (prev == NULL)\n                  eventLoop->timeEventHead = te->next;\n              else\n                  prev->next = te->next;\n              if (te->finalizerProc)\n                  te->finalizerProc(eventLoop, te->clientData);\n              /* 释放时间事件 */\n              zfree(te);\n              te = next;\n              continue;\n          }\n  \n          /* Make sure we don't process time events created by time events in\n           * this iteration. Note that this check is currently useless: we always\n           * add new timers on the head, however if we change the implementation\n           * detail, this check may be useful again: we keep it here for future\n           * defense. */\n          if (te->id > maxId) {\n              te = te->next;\n              continue;\n          }\n          aeGetTime(&now_sec, &now_ms);\n          if (now_sec > te->when_sec ||\n              (now_sec == te->when_sec && now_ms >= te->when_ms))\n          {\n              int retval;\n  \n              id = te->id;\n              retval = te->timeProc(eventLoop, id, te->clientData);\n              processed++;\n              /* 要求timeProc返回该时间事件是否需要继续，如果不需要再继续那么返回AE_NOMOER;\n               * 如果是周期性的事件，那么需要需要继续，则返回下一次发生的时间距离现在的毫秒数。\n               * 如果是定时事件，则该事件不需要再次执行，返回AE_NOMORE\n               */\n              /* 周期性时间，在处理完这次事件之后，重新设定下一次该事件应该执行的时间，以便周期性进行调度 */\n              if (retval != AE_NOMORE) {\n                  aeAddMillisecondsToNow(retval,&te->when_sec,&te->when_ms);\n              } else {\n                  /* 重新留下了无效的时间事件id，等待下一次调用处理时间事件的函数的时候，删除掉该事件 */\n                  te->id = AE_DELETED_EVENT_ID;\n              }\n          }\n          prev = te;\n          te = te->next;\n      }\n      return processed;\n  }\n```\n\nredis所有的事件都是在aeProcessEvents中处理的，aeProcessEvents被aeMain调用。\n\n```\n  void aeMain(aeEventLoop *eventLoop) {\n      eventLoop->stop = 0;\n      /* 在整个循环中不断地处理时间事件和文件事件，构成了redis运行的主体 */\n      while (!eventLoop->stop) {\n          if (eventLoop->beforesleep != NULL)\n              eventLoop->beforesleep(eventLoop);\n          aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);\n      }\n  }\n```\n        \n\n## 相关链接\n- https://blog.csdn.net/GDJ0001/article/details/80268836\n- https://zhuanlan.zhihu.com/p/93612337","source":"_posts/re0-redis-event.md","raw":"---\ntitle: Redis事件模型\ndate: 2021-09-13 23:21:01\ntags: 从0开始的Redis\n---\n## 零、带着问题出发\n\n- 带着问题出发\n\n## 一、关于Reactor\n\n网络编程模型通常有如下几种：Reactor, Proactor, Asynchronous, Completion Token, and Acceptor-Connector. 本文主要对最主流的Reactor模型进行介绍。通常网络编程模型处理的主要流程如下\n\n```\ninitiate => receive => demultiplex => dispatch => process events\n```\n\nI/O多路复用可以用作并发事件驱动(event-driven)程序的基础，即整个事件驱动模型是一个状态机，包含了状态(state), 输入事件(input-event), 状态转移(transition), 状态转移即状态到输入事件的一组映射。通过I/O多路复用的技术检测事件的发生，并根据具体的事件(通常为读写)，进行不同的操作，即状态转移。\n\nReactor模式是一种典型的事件驱动的编程模型，Reactor逆置了程序处理的流程，其基本的思想即为\n> Hollywood Principle — 'Don't call us, we'll call you'.\n\n普通的函数处理机制为：`调用某函数 -> 函数执行， 主程序等待阻塞 -> 函数将结果返回给主程序 -> 主程序继续执行`\n\nReactor事件处理机制为：主程序将事件以及对应事件处理的方法在Reactor上进行注册, 如果相应的事件发生，Reactor将会主动调用事件注册的接口，即 回调函数. libevent即为封装了epoll并注册相应的事件(I/O读写，时间事件，信号事件)以及回调函数，实现的事件驱动的框架。\n\nredis是一个事件驱动的服务程序，在redis的服务程序中存在两种类型的事件，分别是文件事件和时间事件。文件事件是对网络通信操作的统称，时间事件是redis中定时运行的任务或者是周期性的任务（目前redis中只有serverCron这一个周期性时间事件，并没有定时时间事件）。对于事件驱动类的程序，非常适合使用Reactor模式进行设计。redis也不例外，在文件事件处理的设计中采用了Reactor设计模式。\n\nReactor模式包含四部分，分别是\n\n- Handle(对于系统资源的一种抽象，在redis中就是监听描述符或者是连接描述符）\n- Synchronous Event Demultiplexer(同步事件分离器，在redis中对应于IO多路复用程序）\n- Event Handler(事件处理器，在redis中对应于连接应答处理器、命令请求处理器以及命令回复处理器、事件处理器等）\n- Initiation Dispatcher(事件分派器，在redis中对应于ae.c/aeProcessEvents函数）\n\n## 二、redis事件模型概览\n\n对应的流程如下：\n\n- 在redis中将感兴趣的事件及类型(读、写）通过IO多路复用程序注册到内核中并监听每个事件是否发生。\n- 当IO多路复用程序返回的时候，如果有事件发生，redis在封装IO多路复用程序时，将所有已经发生的事件及该事件的类型封装为aeFiredEvent类型，放到aeEventLoop的fired成员中，形成一个队列。\n- 通过这个队列，redis以有序、同步、每次一个套接字事件的方式向文件事件分派器传送套接字，并处理发生的文件事件。\n- redis处理事件（无论是文件事件还是时间事件）都是以原子的方式进行的，中间不存在事件之间的抢占。这很容易理解，redis是单线程模型，不存在处理上的并发操作。\n\n最后需要说明的是redis首先处理发生的文件事件，然后才会处理时间事件，这点我们在介绍redis源码aeProcessEvents的时候会详细注释和介绍。\n\nredis表示事件模型的数据结构是对该事件标识、事件类型和事件处理函数的一种抽象，就是Reactor模式中的`Handle和Event Handle`的集合。redis使用了四种数据结构描述redis中的事件，前三种数据结构是对redis中某种特定类型事件的一种抽象，最后一种数据结构aeEventLoop是redis管理所有事件的一种抽象。\n\n\n## 三、redis事件模型数据结构\n\n\naeTimeEvent中的id成员、aeFiredEvent中的fd成员都是Reactor模式中所说的Handle的具体表现，但是好像aeFileEvents并没有对应的handle。其实，redis在aeEventLoop的events成员中使用每一个描述符fd作为下标，该下标的对应值为aeFileEvent成员，由此将描述符fd与对该fd感兴趣的事件类型以及处理函数相关联，对应于Reactor中Handle与Event Handler的关联。当通过aeEventLoop中的fired获取到已经发生的事件fd及其类型mask的时候，由fd和mask在aeEventLoop的events成员中获取对应的事件处理器，处理已经发生的事件。也就是说，文件事件的处理是联合使用了fired和events两个成员变量；时间事件的处理使用aeTimeEvent变量。\n\n#### 文件事件数据结构。\n```\n/* 文件事件 */\n  typedef struct aeFileEvent {\n      /* 套接字发生的事件，读事件或者写事件其中的一种 */\n      int mask; /* one of AE_(READABLE|WRITABLE) */\n      /* 读事件处理器，回调函数 */\n      aeFileProc *rfileProc;\n      /* 写事件处理器，回调函数 */\n      aeFileProc *wfileProc;\n      /* 客户端数据 */\n      void *clientData;\n  } aeFileEvent;\n```\n#### 时间事件数据结构。\n```\n  typedef struct aeTimeEvent {\n      /* 时间事件，每个时间事件通过id唯一标识 */\n      long long id;\n      /* 时间事件应该触发的时间，单位:s */\n      long when_sec;\n      /* 时间事件被触发的时间,单位:ms */\n      long when_ms;\n      /* 时间事件处理函数 */\n      aeTimeProc *timeProc;\n      aeEventFinalizerProc *finalizerProc;\n      /* 客户端数据 */\n      void *clientData;\n      /* 时间事件形成的链条 */\n      struct aeTimeEvent *next;\n  } aeTimeEvent;\n```\n#### 已经发生的文件事件数据结构。\n```\n  /* 已经发生的文件事件 */\n  typedef struct aeFiredEvent {\n      int fd;\n      int mask;\n  } aeFiredEvent;\n```\n#### redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\n```\n  /* redis中的事件管理结构体 */\n  typedef struct aeEventLoop {\n      /* 当前IO程序追踪的最大的文件描述符，大于此值的setsize范围内的值，没有意义*/\n      int maxfd;\n      /* 当前感兴趣集合的大小, setsize > maxfd */\n      int setsize;\n      /* 下一个时间事件的id */\n      long long timeEventNextId;\n      /* 用于修正系统时钟的偏移，具体参考aeProcessTimeEvents */\n      time_t lastTime;\n      /* 注册的感兴趣的文件事件 */\n      aeFileEvent *events; \n      /* 被触发的文件事件指针，也就是上文所说的已经发生的文件事件形成的队列 */\n      aeFiredEvent *fired;\n      /* 时间事件形成的链表(无序链表) */\n      aeTimeEvent *timeEventHead;\n      /* 事件停止标志 */\n      int stop;\n      /* 针对特定API需要的数据结构, 通过该数据结构屏蔽掉IO多路复用\n       * 不同底层实现的需要的不同数据结构\n       */\n      void *apidata;\n      aeBeforeSleepProc *beforesleep;\n      aeBeforeSleepProc *aftersleep;\n  } aeEventLoop;\n```\n## 三、redis中的IO多路复用机制\n\nredis中的IO多路复用机制对应于Reactor模式中的同步事件分离器。redis考虑到不同系统可能支持不同的的IO多路复用机制，因此实现了select、epoll、kqueue和evport四种不同的IO多路复用，并且每种IO多路复用机制都提供了完全相同的外部接口，根据ae.c中的条件编译语句选择的顺序依次是evport、epoll、kequeue和select，隔离了系统对IO多路复用机制支持的差异。\n\n## redis的事件分派器\n\n在redis中，ae.c文件提供的对外API屏蔽掉了操作系统底层实现的不同，将对文件事件和时间事件的处理通过统一的接口操作。下面我们详细说明一下redis中作为事件分派器的aeProcessEvents函数和时间事件处理函数processTimeEvents。\n\nredis在aeProcessEvents函数中处理文件事件和时间事件，且先处理文件事件再处理时间事件。flags指定redis是处理时间事件还是文件事件又或者是两种事件的并集，这点很容易理解，我们只是想说明一下flags中的另一个标志位---就是获取就绪文件事件的时候是否阻塞的标志位，AE_DONT_WAIT标志。\n\n按照Reactor设计模式，在文件事件分派器上调用同步事件分离器，获取已经就绪的文件事件。调用同步事件分离器就是要调用IO多路复用函数，而IO多路复用函数有可能阻塞（依据传入的时间参数，决定不阻塞、永久阻塞还是阻塞特定的时间段）。\n\n为了防止redis线程长时间阻塞在文件事件等待就绪上而耽误了及时处理到时的时间事件，并且防止redis过多重复性的遍历时间事件形成的无序链表，redis在aeProcessEvents的实现中通过设置flags中的AE_DONT_WAIT标志位达到以上目的。具体参考aeProcessEvents中的注释。\n\n```\n  int aeProcessEvents(aeEventLoop *eventLoop, int flags)\n  {\n      int processed = 0, numevents;\n  \n      /* 所有的事件都不进行处理 */\n      if (!(flags & AE_TIME_EVENTS) && !(flags & AE_FILE_EVENTS)) return 0;\n  \n      /* 首先判断是否存在需要监听的文件事件，如果存在需要监听的文件事件，那么通过IO多路复用程序获取\n       * 准备就绪的文件事件，至于IO多路复用程序是否等待以及等待多久的时间，依发生时间距离现在最近的时间事件确定;\n       * 如果eventLoop->maxfd == -1表示没有需要监听的文件事件，但是时间事件肯定是存在的(serverCron())，\n       * 如果此时没有设置AE_DONT_WAIT标志位，此时调用IO多路复用，其目的就不是为了监听文件事件准备就绪了，\n       * 而是为了使线程休眠到发生时间距离现在最近的时间事件的发生时间(作用类似于unix中的sleep函数),\n       * 这种休眠操作的目的是为了避免线程一直不停的遍历时间事件形成的无序链表，造成不必要的资源浪费\n       */\n      if (eventLoop->maxfd != -1 ||\n          ((flags & AE_TIME_EVENTS) && !(flags & AE_DONT_WAIT))) {\n          int j;\n          aeTimeEvent *shortest = NULL;\n          struct timeval tv, *tvp;\n  \n          /* 寻找发生时间距离现在最近的时间事件,该时间事件的发生时间与当前时间之差就是IO多路复用程序应该等待的时间 */\n          if (flags & AE_TIME_EVENTS && !(flags & AE_DONT_WAIT))\n              shortest = aeSearchNearestTimer(eventLoop);\n          if (shortest) {\n              long now_sec, now_ms;\n  \n              aeGetTime(&now_sec, &now_ms);\n              tvp = &tv;\n  \n              long long ms =\n                  (shortest->when_sec - now_sec)*1000 +\n                  shortest->when_ms - now_ms;\n  \n              /* 如果时间之差大于0，说明时间事件到时时间未到,则等待对应的时间;\n               * 如果时间间隔小于0，说明时间事件已经到时，此时如果没有\n               * 文件事件准备就绪，那么IO多路复用程序应该立即返回，以免\n               * 耽误处理时间事件\n               */\n              if (ms > 0) {\n                  tvp->tv_sec = ms/1000;\n                  tvp->tv_usec = (ms % 1000)*1000;\n              } else {\n                  tvp->tv_sec = 0;\n                  tvp->tv_usec = 0;\n              }   \n          } else {\n              /* 没有找到距离现在最近的时间事件，且设置了AE_DONT_WAIT标志位，\n               * 立即从IO多路复用程序返回\n               */\n              if (flags & AE_DONT_WAIT) {\n                  tv.tv_sec = tv.tv_usec = 0;\n                  tvp = &tv;\n              } else {\n                  /* 没有设置AE_DONT_WAIT标志位，且没有找到发生时间距离现在最近的时间事件，\n                   * IO多路复用程序可以无限等待\n                   */\n                  tvp = NULL;\n              }\n          }\n  \n          /* 典型的reator设计模式。作为事件分派器，\n           * 将已经发生的文件事件交给对应的eventHandle处理\n           */\n          numevents = aeApiPoll(eventLoop, tvp);\n  \n          /* After sleep callback. */\n          if (eventLoop->aftersleep != NULL && flags & AE_CALL_AFTER_SLEEP)\n              eventLoop->aftersleep(eventLoop);\n  \n          for (j = 0; j < numevents; j++) {\n              aeFileEvent *fe = &eventLoop->events[eventLoop->fired[j].fd];\n              /* 按照队列的顺序处理就绪的文件事件 */\n              int mask = eventLoop->fired[j].mask;\n              int fd = eventLoop->fired[j].fd;\n              int rfired = 0;\n  \n              /* 如果IO多路复用程序同时监听fd的读事件和写事件，\n               * 则当该fd对应的读、写事件都返回可用的时候，\n               * 服务器首先处理读套接字、后处理写套接字\n               */\n              if (fe->mask & mask & AE_READABLE) {\n                  rfired = 1;\n                  fe->rfileProc(eventLoop,fd,fe->clientData,mask);\n              }\n              if (fe->mask & mask & AE_WRITABLE) {\n                  if (!rfired || fe->wfileProc != fe->rfileProc)\n                      fe->wfileProc(eventLoop,fd,fe->clientData,mask);\n              }\n              processed++;\n          }\n      }\n      /* 处理时间事件 */\n      if (flags & AE_TIME_EVENTS)\n          processed += processTimeEvents(eventLoop);\n  \n      return processed; /* return the number of processed file/time events */\n  }    \n```\n\n在redis中将对文件事件的处理直接放到了aeProcessEvents中，但是对于时间事件的处理却是存在单独的函数，aeProcessTimeEvents。                \n\n```\n  static int processTimeEvents(aeEventLoop *eventLoop) {\n      int processed = 0;\n      aeTimeEvent *te, *prev;\n      long long maxId;\n      time_t now = time(NULL);\n  \n      /* 系统的始终如果发生了漂移，那么所有的时间事件应该立即被处理;\n       * 将te->when_sec设置为0，表示所有的时间事件都能够被处理。如果时间事件没有到时，\n       * 那么当前立即处理也不存在什么问题;如果时间事件确实已经到时，那确实应该被处理\n       */\n      if (now < eventLoop->lastTime) {\n          te = eventLoop->timeEventHead;\n          while(te) {\n              te->when_sec = 0;\n              te = te->next;\n          }\n      }\n      /* 纠正系统时钟 */\n      eventLoop->lastTime = now;\n  \n      prev = NULL;\n      te = eventLoop->timeEventHead;\n      maxId = eventLoop->timeEventNextId-1;\n      while(te) {\n          long now_sec, now_ms;\n          long long id;\n  \n          /* 在aeDeleteTimeEvent函数中删除掉时间事件只是将时间事件的id置为无效的id值，\n           * 真正的内存释放工作在这里进行\n           */\n          if (te->id == AE_DELETED_EVENT_ID) {\n              aeTimeEvent *next = te->next;\n              if (prev == NULL)\n                  eventLoop->timeEventHead = te->next;\n              else\n                  prev->next = te->next;\n              if (te->finalizerProc)\n                  te->finalizerProc(eventLoop, te->clientData);\n              /* 释放时间事件 */\n              zfree(te);\n              te = next;\n              continue;\n          }\n  \n          /* Make sure we don't process time events created by time events in\n           * this iteration. Note that this check is currently useless: we always\n           * add new timers on the head, however if we change the implementation\n           * detail, this check may be useful again: we keep it here for future\n           * defense. */\n          if (te->id > maxId) {\n              te = te->next;\n              continue;\n          }\n          aeGetTime(&now_sec, &now_ms);\n          if (now_sec > te->when_sec ||\n              (now_sec == te->when_sec && now_ms >= te->when_ms))\n          {\n              int retval;\n  \n              id = te->id;\n              retval = te->timeProc(eventLoop, id, te->clientData);\n              processed++;\n              /* 要求timeProc返回该时间事件是否需要继续，如果不需要再继续那么返回AE_NOMOER;\n               * 如果是周期性的事件，那么需要需要继续，则返回下一次发生的时间距离现在的毫秒数。\n               * 如果是定时事件，则该事件不需要再次执行，返回AE_NOMORE\n               */\n              /* 周期性时间，在处理完这次事件之后，重新设定下一次该事件应该执行的时间，以便周期性进行调度 */\n              if (retval != AE_NOMORE) {\n                  aeAddMillisecondsToNow(retval,&te->when_sec,&te->when_ms);\n              } else {\n                  /* 重新留下了无效的时间事件id，等待下一次调用处理时间事件的函数的时候，删除掉该事件 */\n                  te->id = AE_DELETED_EVENT_ID;\n              }\n          }\n          prev = te;\n          te = te->next;\n      }\n      return processed;\n  }\n```\n\nredis所有的事件都是在aeProcessEvents中处理的，aeProcessEvents被aeMain调用。\n\n```\n  void aeMain(aeEventLoop *eventLoop) {\n      eventLoop->stop = 0;\n      /* 在整个循环中不断地处理时间事件和文件事件，构成了redis运行的主体 */\n      while (!eventLoop->stop) {\n          if (eventLoop->beforesleep != NULL)\n              eventLoop->beforesleep(eventLoop);\n          aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);\n      }\n  }\n```\n        \n\n## 相关链接\n- https://blog.csdn.net/GDJ0001/article/details/80268836\n- https://zhuanlan.zhihu.com/p/93612337","slug":"re0-redis-event","published":1,"updated":"2022-04-28T11:36:46.597Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58x000nmauy896z705j","content":"<h2 id=\"零、带着问题出发\"><a href=\"#零、带着问题出发\" class=\"headerlink\" title=\"零、带着问题出发\"></a>零、带着问题出发</h2><ul>\n<li>带着问题出发</li>\n</ul>\n<h2 id=\"一、关于Reactor\"><a href=\"#一、关于Reactor\" class=\"headerlink\" title=\"一、关于Reactor\"></a>一、关于Reactor</h2><p>网络编程模型通常有如下几种：Reactor, Proactor, Asynchronous, Completion Token, and Acceptor-Connector. 本文主要对最主流的Reactor模型进行介绍。通常网络编程模型处理的主要流程如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">initiate &#x3D;&gt; receive &#x3D;&gt; demultiplex &#x3D;&gt; dispatch &#x3D;&gt; process events</span><br></pre></td></tr></table></figure>\n\n<p>I/O多路复用可以用作并发事件驱动(event-driven)程序的基础，即整个事件驱动模型是一个状态机，包含了状态(state), 输入事件(input-event), 状态转移(transition), 状态转移即状态到输入事件的一组映射。通过I/O多路复用的技术检测事件的发生，并根据具体的事件(通常为读写)，进行不同的操作，即状态转移。</p>\n<p>Reactor模式是一种典型的事件驱动的编程模型，Reactor逆置了程序处理的流程，其基本的思想即为</p>\n<blockquote>\n<p>Hollywood Principle — ‘Don’t call us, we’ll call you’.</p>\n</blockquote>\n<p>普通的函数处理机制为：<code>调用某函数 -&gt; 函数执行， 主程序等待阻塞 -&gt; 函数将结果返回给主程序 -&gt; 主程序继续执行</code></p>\n<p>Reactor事件处理机制为：主程序将事件以及对应事件处理的方法在Reactor上进行注册, 如果相应的事件发生，Reactor将会主动调用事件注册的接口，即 回调函数. libevent即为封装了epoll并注册相应的事件(I/O读写，时间事件，信号事件)以及回调函数，实现的事件驱动的框架。</p>\n<p>redis是一个事件驱动的服务程序，在redis的服务程序中存在两种类型的事件，分别是文件事件和时间事件。文件事件是对网络通信操作的统称，时间事件是redis中定时运行的任务或者是周期性的任务（目前redis中只有serverCron这一个周期性时间事件，并没有定时时间事件）。对于事件驱动类的程序，非常适合使用Reactor模式进行设计。redis也不例外，在文件事件处理的设计中采用了Reactor设计模式。</p>\n<p>Reactor模式包含四部分，分别是</p>\n<ul>\n<li>Handle(对于系统资源的一种抽象，在redis中就是监听描述符或者是连接描述符）</li>\n<li>Synchronous Event Demultiplexer(同步事件分离器，在redis中对应于IO多路复用程序）</li>\n<li>Event Handler(事件处理器，在redis中对应于连接应答处理器、命令请求处理器以及命令回复处理器、事件处理器等）</li>\n<li>Initiation Dispatcher(事件分派器，在redis中对应于ae.c/aeProcessEvents函数）</li>\n</ul>\n<h2 id=\"二、redis事件模型概览\"><a href=\"#二、redis事件模型概览\" class=\"headerlink\" title=\"二、redis事件模型概览\"></a>二、redis事件模型概览</h2><p>对应的流程如下：</p>\n<ul>\n<li>在redis中将感兴趣的事件及类型(读、写）通过IO多路复用程序注册到内核中并监听每个事件是否发生。</li>\n<li>当IO多路复用程序返回的时候，如果有事件发生，redis在封装IO多路复用程序时，将所有已经发生的事件及该事件的类型封装为aeFiredEvent类型，放到aeEventLoop的fired成员中，形成一个队列。</li>\n<li>通过这个队列，redis以有序、同步、每次一个套接字事件的方式向文件事件分派器传送套接字，并处理发生的文件事件。</li>\n<li>redis处理事件（无论是文件事件还是时间事件）都是以原子的方式进行的，中间不存在事件之间的抢占。这很容易理解，redis是单线程模型，不存在处理上的并发操作。</li>\n</ul>\n<p>最后需要说明的是redis首先处理发生的文件事件，然后才会处理时间事件，这点我们在介绍redis源码aeProcessEvents的时候会详细注释和介绍。</p>\n<p>redis表示事件模型的数据结构是对该事件标识、事件类型和事件处理函数的一种抽象，就是Reactor模式中的<code>Handle和Event Handle</code>的集合。redis使用了四种数据结构描述redis中的事件，前三种数据结构是对redis中某种特定类型事件的一种抽象，最后一种数据结构aeEventLoop是redis管理所有事件的一种抽象。</p>\n<h2 id=\"三、redis事件模型数据结构\"><a href=\"#三、redis事件模型数据结构\" class=\"headerlink\" title=\"三、redis事件模型数据结构\"></a>三、redis事件模型数据结构</h2><p>aeTimeEvent中的id成员、aeFiredEvent中的fd成员都是Reactor模式中所说的Handle的具体表现，但是好像aeFileEvents并没有对应的handle。其实，redis在aeEventLoop的events成员中使用每一个描述符fd作为下标，该下标的对应值为aeFileEvent成员，由此将描述符fd与对该fd感兴趣的事件类型以及处理函数相关联，对应于Reactor中Handle与Event Handler的关联。当通过aeEventLoop中的fired获取到已经发生的事件fd及其类型mask的时候，由fd和mask在aeEventLoop的events成员中获取对应的事件处理器，处理已经发生的事件。也就是说，文件事件的处理是联合使用了fired和events两个成员变量；时间事件的处理使用aeTimeEvent变量。</p>\n<h4 id=\"文件事件数据结构。\"><a href=\"#文件事件数据结构。\" class=\"headerlink\" title=\"文件事件数据结构。\"></a>文件事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* 文件事件 *&#x2F;</span><br><span class=\"line\">  typedef struct aeFileEvent &#123;</span><br><span class=\"line\">      &#x2F;* 套接字发生的事件，读事件或者写事件其中的一种 *&#x2F;</span><br><span class=\"line\">      int mask; &#x2F;* one of AE_(READABLE|WRITABLE) *&#x2F;</span><br><span class=\"line\">      &#x2F;* 读事件处理器，回调函数 *&#x2F;</span><br><span class=\"line\">      aeFileProc *rfileProc;</span><br><span class=\"line\">      &#x2F;* 写事件处理器，回调函数 *&#x2F;</span><br><span class=\"line\">      aeFileProc *wfileProc;</span><br><span class=\"line\">      &#x2F;* 客户端数据 *&#x2F;</span><br><span class=\"line\">      void *clientData;</span><br><span class=\"line\">  &#125; aeFileEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"时间事件数据结构。\"><a href=\"#时间事件数据结构。\" class=\"headerlink\" title=\"时间事件数据结构。\"></a>时间事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef struct aeTimeEvent &#123;</span><br><span class=\"line\">    &#x2F;* 时间事件，每个时间事件通过id唯一标识 *&#x2F;</span><br><span class=\"line\">    long long id;</span><br><span class=\"line\">    &#x2F;* 时间事件应该触发的时间，单位:s *&#x2F;</span><br><span class=\"line\">    long when_sec;</span><br><span class=\"line\">    &#x2F;* 时间事件被触发的时间,单位:ms *&#x2F;</span><br><span class=\"line\">    long when_ms;</span><br><span class=\"line\">    &#x2F;* 时间事件处理函数 *&#x2F;</span><br><span class=\"line\">    aeTimeProc *timeProc;</span><br><span class=\"line\">    aeEventFinalizerProc *finalizerProc;</span><br><span class=\"line\">    &#x2F;* 客户端数据 *&#x2F;</span><br><span class=\"line\">    void *clientData;</span><br><span class=\"line\">    &#x2F;* 时间事件形成的链条 *&#x2F;</span><br><span class=\"line\">    struct aeTimeEvent *next;</span><br><span class=\"line\">&#125; aeTimeEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"已经发生的文件事件数据结构。\"><a href=\"#已经发生的文件事件数据结构。\" class=\"headerlink\" title=\"已经发生的文件事件数据结构。\"></a>已经发生的文件事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* 已经发生的文件事件 *&#x2F;</span><br><span class=\"line\">typedef struct aeFiredEvent &#123;</span><br><span class=\"line\">    int fd;</span><br><span class=\"line\">    int mask;</span><br><span class=\"line\">&#125; aeFiredEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\"><a href=\"#redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\" class=\"headerlink\" title=\"redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\"></a>redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* redis中的事件管理结构体 *&#x2F;</span><br><span class=\"line\">typedef struct aeEventLoop &#123;</span><br><span class=\"line\">    &#x2F;* 当前IO程序追踪的最大的文件描述符，大于此值的setsize范围内的值，没有意义*&#x2F;</span><br><span class=\"line\">    int maxfd;</span><br><span class=\"line\">    &#x2F;* 当前感兴趣集合的大小, setsize &gt; maxfd *&#x2F;</span><br><span class=\"line\">    int setsize;</span><br><span class=\"line\">    &#x2F;* 下一个时间事件的id *&#x2F;</span><br><span class=\"line\">    long long timeEventNextId;</span><br><span class=\"line\">    &#x2F;* 用于修正系统时钟的偏移，具体参考aeProcessTimeEvents *&#x2F;</span><br><span class=\"line\">    time_t lastTime;</span><br><span class=\"line\">    &#x2F;* 注册的感兴趣的文件事件 *&#x2F;</span><br><span class=\"line\">    aeFileEvent *events; </span><br><span class=\"line\">    &#x2F;* 被触发的文件事件指针，也就是上文所说的已经发生的文件事件形成的队列 *&#x2F;</span><br><span class=\"line\">    aeFiredEvent *fired;</span><br><span class=\"line\">    &#x2F;* 时间事件形成的链表(无序链表) *&#x2F;</span><br><span class=\"line\">    aeTimeEvent *timeEventHead;</span><br><span class=\"line\">    &#x2F;* 事件停止标志 *&#x2F;</span><br><span class=\"line\">    int stop;</span><br><span class=\"line\">    &#x2F;* 针对特定API需要的数据结构, 通过该数据结构屏蔽掉IO多路复用</span><br><span class=\"line\">     * 不同底层实现的需要的不同数据结构</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    void *apidata;</span><br><span class=\"line\">    aeBeforeSleepProc *beforesleep;</span><br><span class=\"line\">    aeBeforeSleepProc *aftersleep;</span><br><span class=\"line\">&#125; aeEventLoop;</span><br></pre></td></tr></table></figure>\n<h2 id=\"三、redis中的IO多路复用机制\"><a href=\"#三、redis中的IO多路复用机制\" class=\"headerlink\" title=\"三、redis中的IO多路复用机制\"></a>三、redis中的IO多路复用机制</h2><p>redis中的IO多路复用机制对应于Reactor模式中的同步事件分离器。redis考虑到不同系统可能支持不同的的IO多路复用机制，因此实现了select、epoll、kqueue和evport四种不同的IO多路复用，并且每种IO多路复用机制都提供了完全相同的外部接口，根据ae.c中的条件编译语句选择的顺序依次是evport、epoll、kequeue和select，隔离了系统对IO多路复用机制支持的差异。</p>\n<h2 id=\"redis的事件分派器\"><a href=\"#redis的事件分派器\" class=\"headerlink\" title=\"redis的事件分派器\"></a>redis的事件分派器</h2><p>在redis中，ae.c文件提供的对外API屏蔽掉了操作系统底层实现的不同，将对文件事件和时间事件的处理通过统一的接口操作。下面我们详细说明一下redis中作为事件分派器的aeProcessEvents函数和时间事件处理函数processTimeEvents。</p>\n<p>redis在aeProcessEvents函数中处理文件事件和时间事件，且先处理文件事件再处理时间事件。flags指定redis是处理时间事件还是文件事件又或者是两种事件的并集，这点很容易理解，我们只是想说明一下flags中的另一个标志位—就是获取就绪文件事件的时候是否阻塞的标志位，AE_DONT_WAIT标志。</p>\n<p>按照Reactor设计模式，在文件事件分派器上调用同步事件分离器，获取已经就绪的文件事件。调用同步事件分离器就是要调用IO多路复用函数，而IO多路复用函数有可能阻塞（依据传入的时间参数，决定不阻塞、永久阻塞还是阻塞特定的时间段）。</p>\n<p>为了防止redis线程长时间阻塞在文件事件等待就绪上而耽误了及时处理到时的时间事件，并且防止redis过多重复性的遍历时间事件形成的无序链表，redis在aeProcessEvents的实现中通过设置flags中的AE_DONT_WAIT标志位达到以上目的。具体参考aeProcessEvents中的注释。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int aeProcessEvents(aeEventLoop *eventLoop, int flags)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int processed &#x3D; 0, numevents;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 所有的事件都不进行处理 *&#x2F;</span><br><span class=\"line\">    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 首先判断是否存在需要监听的文件事件，如果存在需要监听的文件事件，那么通过IO多路复用程序获取</span><br><span class=\"line\">     * 准备就绪的文件事件，至于IO多路复用程序是否等待以及等待多久的时间，依发生时间距离现在最近的时间事件确定;</span><br><span class=\"line\">     * 如果eventLoop-&gt;maxfd &#x3D;&#x3D; -1表示没有需要监听的文件事件，但是时间事件肯定是存在的(serverCron())，</span><br><span class=\"line\">     * 如果此时没有设置AE_DONT_WAIT标志位，此时调用IO多路复用，其目的就不是为了监听文件事件准备就绪了，</span><br><span class=\"line\">     * 而是为了使线程休眠到发生时间距离现在最近的时间事件的发生时间(作用类似于unix中的sleep函数),</span><br><span class=\"line\">     * 这种休眠操作的目的是为了避免线程一直不停的遍历时间事件形成的无序链表，造成不必要的资源浪费</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    if (eventLoop-&gt;maxfd !&#x3D; -1 ||</span><br><span class=\"line\">        ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) &#123;</span><br><span class=\"line\">        int j;</span><br><span class=\"line\">        aeTimeEvent *shortest &#x3D; NULL;</span><br><span class=\"line\">        struct timeval tv, *tvp;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 寻找发生时间距离现在最近的时间事件,该时间事件的发生时间与当前时间之差就是IO多路复用程序应该等待的时间 *&#x2F;</span><br><span class=\"line\">        if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT))</span><br><span class=\"line\">            shortest &#x3D; aeSearchNearestTimer(eventLoop);</span><br><span class=\"line\">        if (shortest) &#123;</span><br><span class=\"line\">            long now_sec, now_ms;</span><br><span class=\"line\"></span><br><span class=\"line\">            aeGetTime(&amp;now_sec, &amp;now_ms);</span><br><span class=\"line\">            tvp &#x3D; &amp;tv;</span><br><span class=\"line\"></span><br><span class=\"line\">            long long ms &#x3D;</span><br><span class=\"line\">                (shortest-&gt;when_sec - now_sec)*1000 +</span><br><span class=\"line\">                shortest-&gt;when_ms - now_ms;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#x2F;* 如果时间之差大于0，说明时间事件到时时间未到,则等待对应的时间;</span><br><span class=\"line\">             * 如果时间间隔小于0，说明时间事件已经到时，此时如果没有</span><br><span class=\"line\">             * 文件事件准备就绪，那么IO多路复用程序应该立即返回，以免</span><br><span class=\"line\">             * 耽误处理时间事件</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (ms &gt; 0) &#123;</span><br><span class=\"line\">                tvp-&gt;tv_sec &#x3D; ms&#x2F;1000;</span><br><span class=\"line\">                tvp-&gt;tv_usec &#x3D; (ms % 1000)*1000;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                tvp-&gt;tv_sec &#x3D; 0;</span><br><span class=\"line\">                tvp-&gt;tv_usec &#x3D; 0;</span><br><span class=\"line\">            &#125;   </span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            &#x2F;* 没有找到距离现在最近的时间事件，且设置了AE_DONT_WAIT标志位，</span><br><span class=\"line\">             * 立即从IO多路复用程序返回</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (flags &amp; AE_DONT_WAIT) &#123;</span><br><span class=\"line\">                tv.tv_sec &#x3D; tv.tv_usec &#x3D; 0;</span><br><span class=\"line\">                tvp &#x3D; &amp;tv;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                &#x2F;* 没有设置AE_DONT_WAIT标志位，且没有找到发生时间距离现在最近的时间事件，</span><br><span class=\"line\">                 * IO多路复用程序可以无限等待</span><br><span class=\"line\">                 *&#x2F;</span><br><span class=\"line\">                tvp &#x3D; NULL;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 典型的reator设计模式。作为事件分派器，</span><br><span class=\"line\">         * 将已经发生的文件事件交给对应的eventHandle处理</span><br><span class=\"line\">         *&#x2F;</span><br><span class=\"line\">        numevents &#x3D; aeApiPoll(eventLoop, tvp);</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* After sleep callback. *&#x2F;</span><br><span class=\"line\">        if (eventLoop-&gt;aftersleep !&#x3D; NULL &amp;&amp; flags &amp; AE_CALL_AFTER_SLEEP)</span><br><span class=\"line\">            eventLoop-&gt;aftersleep(eventLoop);</span><br><span class=\"line\"></span><br><span class=\"line\">        for (j &#x3D; 0; j &lt; numevents; j++) &#123;</span><br><span class=\"line\">            aeFileEvent *fe &#x3D; &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];</span><br><span class=\"line\">            &#x2F;* 按照队列的顺序处理就绪的文件事件 *&#x2F;</span><br><span class=\"line\">            int mask &#x3D; eventLoop-&gt;fired[j].mask;</span><br><span class=\"line\">            int fd &#x3D; eventLoop-&gt;fired[j].fd;</span><br><span class=\"line\">            int rfired &#x3D; 0;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#x2F;* 如果IO多路复用程序同时监听fd的读事件和写事件，</span><br><span class=\"line\">             * 则当该fd对应的读、写事件都返回可用的时候，</span><br><span class=\"line\">             * 服务器首先处理读套接字、后处理写套接字</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (fe-&gt;mask &amp; mask &amp; AE_READABLE) &#123;</span><br><span class=\"line\">                rfired &#x3D; 1;</span><br><span class=\"line\">                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) &#123;</span><br><span class=\"line\">                if (!rfired || fe-&gt;wfileProc !&#x3D; fe-&gt;rfileProc)</span><br><span class=\"line\">                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            processed++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;* 处理时间事件 *&#x2F;</span><br><span class=\"line\">    if (flags &amp; AE_TIME_EVENTS)</span><br><span class=\"line\">        processed +&#x3D; processTimeEvents(eventLoop);</span><br><span class=\"line\"></span><br><span class=\"line\">    return processed; &#x2F;* return the number of processed file&#x2F;time events *&#x2F;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在redis中将对文件事件的处理直接放到了aeProcessEvents中，但是对于时间事件的处理却是存在单独的函数，aeProcessTimeEvents。                </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static int processTimeEvents(aeEventLoop *eventLoop) &#123;</span><br><span class=\"line\">    int processed &#x3D; 0;</span><br><span class=\"line\">    aeTimeEvent *te, *prev;</span><br><span class=\"line\">    long long maxId;</span><br><span class=\"line\">    time_t now &#x3D; time(NULL);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 系统的始终如果发生了漂移，那么所有的时间事件应该立即被处理;</span><br><span class=\"line\">     * 将te-&gt;when_sec设置为0，表示所有的时间事件都能够被处理。如果时间事件没有到时，</span><br><span class=\"line\">     * 那么当前立即处理也不存在什么问题;如果时间事件确实已经到时，那确实应该被处理</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    if (now &lt; eventLoop-&gt;lastTime) &#123;</span><br><span class=\"line\">        te &#x3D; eventLoop-&gt;timeEventHead;</span><br><span class=\"line\">        while(te) &#123;</span><br><span class=\"line\">            te-&gt;when_sec &#x3D; 0;</span><br><span class=\"line\">            te &#x3D; te-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;* 纠正系统时钟 *&#x2F;</span><br><span class=\"line\">    eventLoop-&gt;lastTime &#x3D; now;</span><br><span class=\"line\"></span><br><span class=\"line\">    prev &#x3D; NULL;</span><br><span class=\"line\">    te &#x3D; eventLoop-&gt;timeEventHead;</span><br><span class=\"line\">    maxId &#x3D; eventLoop-&gt;timeEventNextId-1;</span><br><span class=\"line\">    while(te) &#123;</span><br><span class=\"line\">        long now_sec, now_ms;</span><br><span class=\"line\">        long long id;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 在aeDeleteTimeEvent函数中删除掉时间事件只是将时间事件的id置为无效的id值，</span><br><span class=\"line\">         * 真正的内存释放工作在这里进行</span><br><span class=\"line\">         *&#x2F;</span><br><span class=\"line\">        if (te-&gt;id &#x3D;&#x3D; AE_DELETED_EVENT_ID) &#123;</span><br><span class=\"line\">            aeTimeEvent *next &#x3D; te-&gt;next;</span><br><span class=\"line\">            if (prev &#x3D;&#x3D; NULL)</span><br><span class=\"line\">                eventLoop-&gt;timeEventHead &#x3D; te-&gt;next;</span><br><span class=\"line\">            else</span><br><span class=\"line\">                prev-&gt;next &#x3D; te-&gt;next;</span><br><span class=\"line\">            if (te-&gt;finalizerProc)</span><br><span class=\"line\">                te-&gt;finalizerProc(eventLoop, te-&gt;clientData);</span><br><span class=\"line\">            &#x2F;* 释放时间事件 *&#x2F;</span><br><span class=\"line\">            zfree(te);</span><br><span class=\"line\">            te &#x3D; next;</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* Make sure we don&#39;t process time events created by time events in</span><br><span class=\"line\">         * this iteration. Note that this check is currently useless: we always</span><br><span class=\"line\">         * add new timers on the head, however if we change the implementation</span><br><span class=\"line\">         * detail, this check may be useful again: we keep it here for future</span><br><span class=\"line\">         * defense. *&#x2F;</span><br><span class=\"line\">        if (te-&gt;id &gt; maxId) &#123;</span><br><span class=\"line\">            te &#x3D; te-&gt;next;</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        aeGetTime(&amp;now_sec, &amp;now_ms);</span><br><span class=\"line\">        if (now_sec &gt; te-&gt;when_sec ||</span><br><span class=\"line\">            (now_sec &#x3D;&#x3D; te-&gt;when_sec &amp;&amp; now_ms &gt;&#x3D; te-&gt;when_ms))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int retval;</span><br><span class=\"line\"></span><br><span class=\"line\">            id &#x3D; te-&gt;id;</span><br><span class=\"line\">            retval &#x3D; te-&gt;timeProc(eventLoop, id, te-&gt;clientData);</span><br><span class=\"line\">            processed++;</span><br><span class=\"line\">            &#x2F;* 要求timeProc返回该时间事件是否需要继续，如果不需要再继续那么返回AE_NOMOER;</span><br><span class=\"line\">             * 如果是周期性的事件，那么需要需要继续，则返回下一次发生的时间距离现在的毫秒数。</span><br><span class=\"line\">             * 如果是定时事件，则该事件不需要再次执行，返回AE_NOMORE</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            &#x2F;* 周期性时间，在处理完这次事件之后，重新设定下一次该事件应该执行的时间，以便周期性进行调度 *&#x2F;</span><br><span class=\"line\">            if (retval !&#x3D; AE_NOMORE) &#123;</span><br><span class=\"line\">                aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                &#x2F;* 重新留下了无效的时间事件id，等待下一次调用处理时间事件的函数的时候，删除掉该事件 *&#x2F;</span><br><span class=\"line\">                te-&gt;id &#x3D; AE_DELETED_EVENT_ID;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        prev &#x3D; te;</span><br><span class=\"line\">        te &#x3D; te-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return processed;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>redis所有的事件都是在aeProcessEvents中处理的，aeProcessEvents被aeMain调用。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void aeMain(aeEventLoop *eventLoop) &#123;</span><br><span class=\"line\">    eventLoop-&gt;stop &#x3D; 0;</span><br><span class=\"line\">    &#x2F;* 在整个循环中不断地处理时间事件和文件事件，构成了redis运行的主体 *&#x2F;</span><br><span class=\"line\">    while (!eventLoop-&gt;stop) &#123;</span><br><span class=\"line\">        if (eventLoop-&gt;beforesleep !&#x3D; NULL)</span><br><span class=\"line\">            eventLoop-&gt;beforesleep(eventLoop);</span><br><span class=\"line\">        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/GDJ0001/article/details/80268836\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/GDJ0001/article/details/80268836</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/93612337\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/93612337</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、带着问题出发\"><a href=\"#零、带着问题出发\" class=\"headerlink\" title=\"零、带着问题出发\"></a>零、带着问题出发</h2><ul>\n<li>带着问题出发</li>\n</ul>\n<h2 id=\"一、关于Reactor\"><a href=\"#一、关于Reactor\" class=\"headerlink\" title=\"一、关于Reactor\"></a>一、关于Reactor</h2><p>网络编程模型通常有如下几种：Reactor, Proactor, Asynchronous, Completion Token, and Acceptor-Connector. 本文主要对最主流的Reactor模型进行介绍。通常网络编程模型处理的主要流程如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">initiate &#x3D;&gt; receive &#x3D;&gt; demultiplex &#x3D;&gt; dispatch &#x3D;&gt; process events</span><br></pre></td></tr></table></figure>\n\n<p>I/O多路复用可以用作并发事件驱动(event-driven)程序的基础，即整个事件驱动模型是一个状态机，包含了状态(state), 输入事件(input-event), 状态转移(transition), 状态转移即状态到输入事件的一组映射。通过I/O多路复用的技术检测事件的发生，并根据具体的事件(通常为读写)，进行不同的操作，即状态转移。</p>\n<p>Reactor模式是一种典型的事件驱动的编程模型，Reactor逆置了程序处理的流程，其基本的思想即为</p>\n<blockquote>\n<p>Hollywood Principle — ‘Don’t call us, we’ll call you’.</p>\n</blockquote>\n<p>普通的函数处理机制为：<code>调用某函数 -&gt; 函数执行， 主程序等待阻塞 -&gt; 函数将结果返回给主程序 -&gt; 主程序继续执行</code></p>\n<p>Reactor事件处理机制为：主程序将事件以及对应事件处理的方法在Reactor上进行注册, 如果相应的事件发生，Reactor将会主动调用事件注册的接口，即 回调函数. libevent即为封装了epoll并注册相应的事件(I/O读写，时间事件，信号事件)以及回调函数，实现的事件驱动的框架。</p>\n<p>redis是一个事件驱动的服务程序，在redis的服务程序中存在两种类型的事件，分别是文件事件和时间事件。文件事件是对网络通信操作的统称，时间事件是redis中定时运行的任务或者是周期性的任务（目前redis中只有serverCron这一个周期性时间事件，并没有定时时间事件）。对于事件驱动类的程序，非常适合使用Reactor模式进行设计。redis也不例外，在文件事件处理的设计中采用了Reactor设计模式。</p>\n<p>Reactor模式包含四部分，分别是</p>\n<ul>\n<li>Handle(对于系统资源的一种抽象，在redis中就是监听描述符或者是连接描述符）</li>\n<li>Synchronous Event Demultiplexer(同步事件分离器，在redis中对应于IO多路复用程序）</li>\n<li>Event Handler(事件处理器，在redis中对应于连接应答处理器、命令请求处理器以及命令回复处理器、事件处理器等）</li>\n<li>Initiation Dispatcher(事件分派器，在redis中对应于ae.c/aeProcessEvents函数）</li>\n</ul>\n<h2 id=\"二、redis事件模型概览\"><a href=\"#二、redis事件模型概览\" class=\"headerlink\" title=\"二、redis事件模型概览\"></a>二、redis事件模型概览</h2><p>对应的流程如下：</p>\n<ul>\n<li>在redis中将感兴趣的事件及类型(读、写）通过IO多路复用程序注册到内核中并监听每个事件是否发生。</li>\n<li>当IO多路复用程序返回的时候，如果有事件发生，redis在封装IO多路复用程序时，将所有已经发生的事件及该事件的类型封装为aeFiredEvent类型，放到aeEventLoop的fired成员中，形成一个队列。</li>\n<li>通过这个队列，redis以有序、同步、每次一个套接字事件的方式向文件事件分派器传送套接字，并处理发生的文件事件。</li>\n<li>redis处理事件（无论是文件事件还是时间事件）都是以原子的方式进行的，中间不存在事件之间的抢占。这很容易理解，redis是单线程模型，不存在处理上的并发操作。</li>\n</ul>\n<p>最后需要说明的是redis首先处理发生的文件事件，然后才会处理时间事件，这点我们在介绍redis源码aeProcessEvents的时候会详细注释和介绍。</p>\n<p>redis表示事件模型的数据结构是对该事件标识、事件类型和事件处理函数的一种抽象，就是Reactor模式中的<code>Handle和Event Handle</code>的集合。redis使用了四种数据结构描述redis中的事件，前三种数据结构是对redis中某种特定类型事件的一种抽象，最后一种数据结构aeEventLoop是redis管理所有事件的一种抽象。</p>\n<h2 id=\"三、redis事件模型数据结构\"><a href=\"#三、redis事件模型数据结构\" class=\"headerlink\" title=\"三、redis事件模型数据结构\"></a>三、redis事件模型数据结构</h2><p>aeTimeEvent中的id成员、aeFiredEvent中的fd成员都是Reactor模式中所说的Handle的具体表现，但是好像aeFileEvents并没有对应的handle。其实，redis在aeEventLoop的events成员中使用每一个描述符fd作为下标，该下标的对应值为aeFileEvent成员，由此将描述符fd与对该fd感兴趣的事件类型以及处理函数相关联，对应于Reactor中Handle与Event Handler的关联。当通过aeEventLoop中的fired获取到已经发生的事件fd及其类型mask的时候，由fd和mask在aeEventLoop的events成员中获取对应的事件处理器，处理已经发生的事件。也就是说，文件事件的处理是联合使用了fired和events两个成员变量；时间事件的处理使用aeTimeEvent变量。</p>\n<h4 id=\"文件事件数据结构。\"><a href=\"#文件事件数据结构。\" class=\"headerlink\" title=\"文件事件数据结构。\"></a>文件事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* 文件事件 *&#x2F;</span><br><span class=\"line\">  typedef struct aeFileEvent &#123;</span><br><span class=\"line\">      &#x2F;* 套接字发生的事件，读事件或者写事件其中的一种 *&#x2F;</span><br><span class=\"line\">      int mask; &#x2F;* one of AE_(READABLE|WRITABLE) *&#x2F;</span><br><span class=\"line\">      &#x2F;* 读事件处理器，回调函数 *&#x2F;</span><br><span class=\"line\">      aeFileProc *rfileProc;</span><br><span class=\"line\">      &#x2F;* 写事件处理器，回调函数 *&#x2F;</span><br><span class=\"line\">      aeFileProc *wfileProc;</span><br><span class=\"line\">      &#x2F;* 客户端数据 *&#x2F;</span><br><span class=\"line\">      void *clientData;</span><br><span class=\"line\">  &#125; aeFileEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"时间事件数据结构。\"><a href=\"#时间事件数据结构。\" class=\"headerlink\" title=\"时间事件数据结构。\"></a>时间事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef struct aeTimeEvent &#123;</span><br><span class=\"line\">    &#x2F;* 时间事件，每个时间事件通过id唯一标识 *&#x2F;</span><br><span class=\"line\">    long long id;</span><br><span class=\"line\">    &#x2F;* 时间事件应该触发的时间，单位:s *&#x2F;</span><br><span class=\"line\">    long when_sec;</span><br><span class=\"line\">    &#x2F;* 时间事件被触发的时间,单位:ms *&#x2F;</span><br><span class=\"line\">    long when_ms;</span><br><span class=\"line\">    &#x2F;* 时间事件处理函数 *&#x2F;</span><br><span class=\"line\">    aeTimeProc *timeProc;</span><br><span class=\"line\">    aeEventFinalizerProc *finalizerProc;</span><br><span class=\"line\">    &#x2F;* 客户端数据 *&#x2F;</span><br><span class=\"line\">    void *clientData;</span><br><span class=\"line\">    &#x2F;* 时间事件形成的链条 *&#x2F;</span><br><span class=\"line\">    struct aeTimeEvent *next;</span><br><span class=\"line\">&#125; aeTimeEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"已经发生的文件事件数据结构。\"><a href=\"#已经发生的文件事件数据结构。\" class=\"headerlink\" title=\"已经发生的文件事件数据结构。\"></a>已经发生的文件事件数据结构。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* 已经发生的文件事件 *&#x2F;</span><br><span class=\"line\">typedef struct aeFiredEvent &#123;</span><br><span class=\"line\">    int fd;</span><br><span class=\"line\">    int mask;</span><br><span class=\"line\">&#125; aeFiredEvent;</span><br></pre></td></tr></table></figure>\n<h4 id=\"redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\"><a href=\"#redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\" class=\"headerlink\" title=\"redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。\"></a>redis中时间管理结构体，包含了文件事件、时间事件、已发生的文件事件等相关信息。</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;* redis中的事件管理结构体 *&#x2F;</span><br><span class=\"line\">typedef struct aeEventLoop &#123;</span><br><span class=\"line\">    &#x2F;* 当前IO程序追踪的最大的文件描述符，大于此值的setsize范围内的值，没有意义*&#x2F;</span><br><span class=\"line\">    int maxfd;</span><br><span class=\"line\">    &#x2F;* 当前感兴趣集合的大小, setsize &gt; maxfd *&#x2F;</span><br><span class=\"line\">    int setsize;</span><br><span class=\"line\">    &#x2F;* 下一个时间事件的id *&#x2F;</span><br><span class=\"line\">    long long timeEventNextId;</span><br><span class=\"line\">    &#x2F;* 用于修正系统时钟的偏移，具体参考aeProcessTimeEvents *&#x2F;</span><br><span class=\"line\">    time_t lastTime;</span><br><span class=\"line\">    &#x2F;* 注册的感兴趣的文件事件 *&#x2F;</span><br><span class=\"line\">    aeFileEvent *events; </span><br><span class=\"line\">    &#x2F;* 被触发的文件事件指针，也就是上文所说的已经发生的文件事件形成的队列 *&#x2F;</span><br><span class=\"line\">    aeFiredEvent *fired;</span><br><span class=\"line\">    &#x2F;* 时间事件形成的链表(无序链表) *&#x2F;</span><br><span class=\"line\">    aeTimeEvent *timeEventHead;</span><br><span class=\"line\">    &#x2F;* 事件停止标志 *&#x2F;</span><br><span class=\"line\">    int stop;</span><br><span class=\"line\">    &#x2F;* 针对特定API需要的数据结构, 通过该数据结构屏蔽掉IO多路复用</span><br><span class=\"line\">     * 不同底层实现的需要的不同数据结构</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    void *apidata;</span><br><span class=\"line\">    aeBeforeSleepProc *beforesleep;</span><br><span class=\"line\">    aeBeforeSleepProc *aftersleep;</span><br><span class=\"line\">&#125; aeEventLoop;</span><br></pre></td></tr></table></figure>\n<h2 id=\"三、redis中的IO多路复用机制\"><a href=\"#三、redis中的IO多路复用机制\" class=\"headerlink\" title=\"三、redis中的IO多路复用机制\"></a>三、redis中的IO多路复用机制</h2><p>redis中的IO多路复用机制对应于Reactor模式中的同步事件分离器。redis考虑到不同系统可能支持不同的的IO多路复用机制，因此实现了select、epoll、kqueue和evport四种不同的IO多路复用，并且每种IO多路复用机制都提供了完全相同的外部接口，根据ae.c中的条件编译语句选择的顺序依次是evport、epoll、kequeue和select，隔离了系统对IO多路复用机制支持的差异。</p>\n<h2 id=\"redis的事件分派器\"><a href=\"#redis的事件分派器\" class=\"headerlink\" title=\"redis的事件分派器\"></a>redis的事件分派器</h2><p>在redis中，ae.c文件提供的对外API屏蔽掉了操作系统底层实现的不同，将对文件事件和时间事件的处理通过统一的接口操作。下面我们详细说明一下redis中作为事件分派器的aeProcessEvents函数和时间事件处理函数processTimeEvents。</p>\n<p>redis在aeProcessEvents函数中处理文件事件和时间事件，且先处理文件事件再处理时间事件。flags指定redis是处理时间事件还是文件事件又或者是两种事件的并集，这点很容易理解，我们只是想说明一下flags中的另一个标志位—就是获取就绪文件事件的时候是否阻塞的标志位，AE_DONT_WAIT标志。</p>\n<p>按照Reactor设计模式，在文件事件分派器上调用同步事件分离器，获取已经就绪的文件事件。调用同步事件分离器就是要调用IO多路复用函数，而IO多路复用函数有可能阻塞（依据传入的时间参数，决定不阻塞、永久阻塞还是阻塞特定的时间段）。</p>\n<p>为了防止redis线程长时间阻塞在文件事件等待就绪上而耽误了及时处理到时的时间事件，并且防止redis过多重复性的遍历时间事件形成的无序链表，redis在aeProcessEvents的实现中通过设置flags中的AE_DONT_WAIT标志位达到以上目的。具体参考aeProcessEvents中的注释。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int aeProcessEvents(aeEventLoop *eventLoop, int flags)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int processed &#x3D; 0, numevents;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 所有的事件都不进行处理 *&#x2F;</span><br><span class=\"line\">    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 首先判断是否存在需要监听的文件事件，如果存在需要监听的文件事件，那么通过IO多路复用程序获取</span><br><span class=\"line\">     * 准备就绪的文件事件，至于IO多路复用程序是否等待以及等待多久的时间，依发生时间距离现在最近的时间事件确定;</span><br><span class=\"line\">     * 如果eventLoop-&gt;maxfd &#x3D;&#x3D; -1表示没有需要监听的文件事件，但是时间事件肯定是存在的(serverCron())，</span><br><span class=\"line\">     * 如果此时没有设置AE_DONT_WAIT标志位，此时调用IO多路复用，其目的就不是为了监听文件事件准备就绪了，</span><br><span class=\"line\">     * 而是为了使线程休眠到发生时间距离现在最近的时间事件的发生时间(作用类似于unix中的sleep函数),</span><br><span class=\"line\">     * 这种休眠操作的目的是为了避免线程一直不停的遍历时间事件形成的无序链表，造成不必要的资源浪费</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    if (eventLoop-&gt;maxfd !&#x3D; -1 ||</span><br><span class=\"line\">        ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) &#123;</span><br><span class=\"line\">        int j;</span><br><span class=\"line\">        aeTimeEvent *shortest &#x3D; NULL;</span><br><span class=\"line\">        struct timeval tv, *tvp;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 寻找发生时间距离现在最近的时间事件,该时间事件的发生时间与当前时间之差就是IO多路复用程序应该等待的时间 *&#x2F;</span><br><span class=\"line\">        if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT))</span><br><span class=\"line\">            shortest &#x3D; aeSearchNearestTimer(eventLoop);</span><br><span class=\"line\">        if (shortest) &#123;</span><br><span class=\"line\">            long now_sec, now_ms;</span><br><span class=\"line\"></span><br><span class=\"line\">            aeGetTime(&amp;now_sec, &amp;now_ms);</span><br><span class=\"line\">            tvp &#x3D; &amp;tv;</span><br><span class=\"line\"></span><br><span class=\"line\">            long long ms &#x3D;</span><br><span class=\"line\">                (shortest-&gt;when_sec - now_sec)*1000 +</span><br><span class=\"line\">                shortest-&gt;when_ms - now_ms;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#x2F;* 如果时间之差大于0，说明时间事件到时时间未到,则等待对应的时间;</span><br><span class=\"line\">             * 如果时间间隔小于0，说明时间事件已经到时，此时如果没有</span><br><span class=\"line\">             * 文件事件准备就绪，那么IO多路复用程序应该立即返回，以免</span><br><span class=\"line\">             * 耽误处理时间事件</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (ms &gt; 0) &#123;</span><br><span class=\"line\">                tvp-&gt;tv_sec &#x3D; ms&#x2F;1000;</span><br><span class=\"line\">                tvp-&gt;tv_usec &#x3D; (ms % 1000)*1000;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                tvp-&gt;tv_sec &#x3D; 0;</span><br><span class=\"line\">                tvp-&gt;tv_usec &#x3D; 0;</span><br><span class=\"line\">            &#125;   </span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            &#x2F;* 没有找到距离现在最近的时间事件，且设置了AE_DONT_WAIT标志位，</span><br><span class=\"line\">             * 立即从IO多路复用程序返回</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (flags &amp; AE_DONT_WAIT) &#123;</span><br><span class=\"line\">                tv.tv_sec &#x3D; tv.tv_usec &#x3D; 0;</span><br><span class=\"line\">                tvp &#x3D; &amp;tv;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                &#x2F;* 没有设置AE_DONT_WAIT标志位，且没有找到发生时间距离现在最近的时间事件，</span><br><span class=\"line\">                 * IO多路复用程序可以无限等待</span><br><span class=\"line\">                 *&#x2F;</span><br><span class=\"line\">                tvp &#x3D; NULL;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 典型的reator设计模式。作为事件分派器，</span><br><span class=\"line\">         * 将已经发生的文件事件交给对应的eventHandle处理</span><br><span class=\"line\">         *&#x2F;</span><br><span class=\"line\">        numevents &#x3D; aeApiPoll(eventLoop, tvp);</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* After sleep callback. *&#x2F;</span><br><span class=\"line\">        if (eventLoop-&gt;aftersleep !&#x3D; NULL &amp;&amp; flags &amp; AE_CALL_AFTER_SLEEP)</span><br><span class=\"line\">            eventLoop-&gt;aftersleep(eventLoop);</span><br><span class=\"line\"></span><br><span class=\"line\">        for (j &#x3D; 0; j &lt; numevents; j++) &#123;</span><br><span class=\"line\">            aeFileEvent *fe &#x3D; &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];</span><br><span class=\"line\">            &#x2F;* 按照队列的顺序处理就绪的文件事件 *&#x2F;</span><br><span class=\"line\">            int mask &#x3D; eventLoop-&gt;fired[j].mask;</span><br><span class=\"line\">            int fd &#x3D; eventLoop-&gt;fired[j].fd;</span><br><span class=\"line\">            int rfired &#x3D; 0;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#x2F;* 如果IO多路复用程序同时监听fd的读事件和写事件，</span><br><span class=\"line\">             * 则当该fd对应的读、写事件都返回可用的时候，</span><br><span class=\"line\">             * 服务器首先处理读套接字、后处理写套接字</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            if (fe-&gt;mask &amp; mask &amp; AE_READABLE) &#123;</span><br><span class=\"line\">                rfired &#x3D; 1;</span><br><span class=\"line\">                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) &#123;</span><br><span class=\"line\">                if (!rfired || fe-&gt;wfileProc !&#x3D; fe-&gt;rfileProc)</span><br><span class=\"line\">                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            processed++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;* 处理时间事件 *&#x2F;</span><br><span class=\"line\">    if (flags &amp; AE_TIME_EVENTS)</span><br><span class=\"line\">        processed +&#x3D; processTimeEvents(eventLoop);</span><br><span class=\"line\"></span><br><span class=\"line\">    return processed; &#x2F;* return the number of processed file&#x2F;time events *&#x2F;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在redis中将对文件事件的处理直接放到了aeProcessEvents中，但是对于时间事件的处理却是存在单独的函数，aeProcessTimeEvents。                </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static int processTimeEvents(aeEventLoop *eventLoop) &#123;</span><br><span class=\"line\">    int processed &#x3D; 0;</span><br><span class=\"line\">    aeTimeEvent *te, *prev;</span><br><span class=\"line\">    long long maxId;</span><br><span class=\"line\">    time_t now &#x3D; time(NULL);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#x2F;* 系统的始终如果发生了漂移，那么所有的时间事件应该立即被处理;</span><br><span class=\"line\">     * 将te-&gt;when_sec设置为0，表示所有的时间事件都能够被处理。如果时间事件没有到时，</span><br><span class=\"line\">     * 那么当前立即处理也不存在什么问题;如果时间事件确实已经到时，那确实应该被处理</span><br><span class=\"line\">     *&#x2F;</span><br><span class=\"line\">    if (now &lt; eventLoop-&gt;lastTime) &#123;</span><br><span class=\"line\">        te &#x3D; eventLoop-&gt;timeEventHead;</span><br><span class=\"line\">        while(te) &#123;</span><br><span class=\"line\">            te-&gt;when_sec &#x3D; 0;</span><br><span class=\"line\">            te &#x3D; te-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#x2F;* 纠正系统时钟 *&#x2F;</span><br><span class=\"line\">    eventLoop-&gt;lastTime &#x3D; now;</span><br><span class=\"line\"></span><br><span class=\"line\">    prev &#x3D; NULL;</span><br><span class=\"line\">    te &#x3D; eventLoop-&gt;timeEventHead;</span><br><span class=\"line\">    maxId &#x3D; eventLoop-&gt;timeEventNextId-1;</span><br><span class=\"line\">    while(te) &#123;</span><br><span class=\"line\">        long now_sec, now_ms;</span><br><span class=\"line\">        long long id;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* 在aeDeleteTimeEvent函数中删除掉时间事件只是将时间事件的id置为无效的id值，</span><br><span class=\"line\">         * 真正的内存释放工作在这里进行</span><br><span class=\"line\">         *&#x2F;</span><br><span class=\"line\">        if (te-&gt;id &#x3D;&#x3D; AE_DELETED_EVENT_ID) &#123;</span><br><span class=\"line\">            aeTimeEvent *next &#x3D; te-&gt;next;</span><br><span class=\"line\">            if (prev &#x3D;&#x3D; NULL)</span><br><span class=\"line\">                eventLoop-&gt;timeEventHead &#x3D; te-&gt;next;</span><br><span class=\"line\">            else</span><br><span class=\"line\">                prev-&gt;next &#x3D; te-&gt;next;</span><br><span class=\"line\">            if (te-&gt;finalizerProc)</span><br><span class=\"line\">                te-&gt;finalizerProc(eventLoop, te-&gt;clientData);</span><br><span class=\"line\">            &#x2F;* 释放时间事件 *&#x2F;</span><br><span class=\"line\">            zfree(te);</span><br><span class=\"line\">            te &#x3D; next;</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#x2F;* Make sure we don&#39;t process time events created by time events in</span><br><span class=\"line\">         * this iteration. Note that this check is currently useless: we always</span><br><span class=\"line\">         * add new timers on the head, however if we change the implementation</span><br><span class=\"line\">         * detail, this check may be useful again: we keep it here for future</span><br><span class=\"line\">         * defense. *&#x2F;</span><br><span class=\"line\">        if (te-&gt;id &gt; maxId) &#123;</span><br><span class=\"line\">            te &#x3D; te-&gt;next;</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        aeGetTime(&amp;now_sec, &amp;now_ms);</span><br><span class=\"line\">        if (now_sec &gt; te-&gt;when_sec ||</span><br><span class=\"line\">            (now_sec &#x3D;&#x3D; te-&gt;when_sec &amp;&amp; now_ms &gt;&#x3D; te-&gt;when_ms))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int retval;</span><br><span class=\"line\"></span><br><span class=\"line\">            id &#x3D; te-&gt;id;</span><br><span class=\"line\">            retval &#x3D; te-&gt;timeProc(eventLoop, id, te-&gt;clientData);</span><br><span class=\"line\">            processed++;</span><br><span class=\"line\">            &#x2F;* 要求timeProc返回该时间事件是否需要继续，如果不需要再继续那么返回AE_NOMOER;</span><br><span class=\"line\">             * 如果是周期性的事件，那么需要需要继续，则返回下一次发生的时间距离现在的毫秒数。</span><br><span class=\"line\">             * 如果是定时事件，则该事件不需要再次执行，返回AE_NOMORE</span><br><span class=\"line\">             *&#x2F;</span><br><span class=\"line\">            &#x2F;* 周期性时间，在处理完这次事件之后，重新设定下一次该事件应该执行的时间，以便周期性进行调度 *&#x2F;</span><br><span class=\"line\">            if (retval !&#x3D; AE_NOMORE) &#123;</span><br><span class=\"line\">                aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                &#x2F;* 重新留下了无效的时间事件id，等待下一次调用处理时间事件的函数的时候，删除掉该事件 *&#x2F;</span><br><span class=\"line\">                te-&gt;id &#x3D; AE_DELETED_EVENT_ID;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        prev &#x3D; te;</span><br><span class=\"line\">        te &#x3D; te-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return processed;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>redis所有的事件都是在aeProcessEvents中处理的，aeProcessEvents被aeMain调用。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void aeMain(aeEventLoop *eventLoop) &#123;</span><br><span class=\"line\">    eventLoop-&gt;stop &#x3D; 0;</span><br><span class=\"line\">    &#x2F;* 在整个循环中不断地处理时间事件和文件事件，构成了redis运行的主体 *&#x2F;</span><br><span class=\"line\">    while (!eventLoop-&gt;stop) &#123;</span><br><span class=\"line\">        if (eventLoop-&gt;beforesleep !&#x3D; NULL)</span><br><span class=\"line\">            eventLoop-&gt;beforesleep(eventLoop);</span><br><span class=\"line\">        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/GDJ0001/article/details/80268836\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/GDJ0001/article/details/80268836</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/93612337\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/93612337</a></li>\n</ul>\n"},{"title":"Redis的Pipeline","date":"2021-09-16T01:30:52.000Z","_content":"## 零、从问题出发\n\n\n## 一、简介\n\nRedis 使用的是客户端-服务器（CS）模型和请求/响应协议的 TCP 服务器。这意味着通常情况下一个请求会遵循以下步骤：\n\n- 客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。\n- 服务端处理命令，并将结果返回给客户端。\n\nRedis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。\n\nredis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，即算redis server端有很强的处理能力，也由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须部分请求放到队列中（使用内存）执行完毕后一次性发送结果；如果发送的命名很多的话，建议对返回的结果加标签，当然这也会增加使用的内存；\n\nPipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，而且对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能,性能提升的原因主要是TCP链接中较少了“交互往返”的时间。不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。\n\n不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。\n\n由于通信会有网络延迟，假如 client 和 server 之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使 redis 每秒能处理100个命令，而我们的 client 也只能一秒钟发出四个命令。这显然没有充分利用 redis 的处理能力。\n\n而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。\n\n需要注意到是用 pipeline 方式打包命令发送，redis 必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。\n\n## 二、适用场景\n\n有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 redis 了，那这种场景就不适合。\n\n还有的系统，可能是批量的将数据写入 redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入 redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用 pipeline 最好了。\n\n## 三、管道（Pipelining） VS 脚本（Scripting）\n\n大量 pipeline 应用场景可通过 Redis 脚本（Redis 版本 >= 2.6）得到更高效的处理，后者在服务器端执行大量工作。脚本的一大优势是可通过最小的延迟读写数据，让读、计算、写等操作变得非常快（pipeline 在这种情况下不能使用，因为客户端在写命令前需要读命令返回的结果）。\n\n应用程序有时可能在 pipeline 中发送 EVAL 或 EVALSHA 命令。Redis 通过 SCRIPT LOAD 命令（保证 EVALSHA 成功被调用）明确支持这种情况。","source":"_posts/re0-redis-pipeline.md","raw":"---\ntitle: Redis的Pipeline\ndate: 2021-09-16 09:30:52\ntags: 从0开始的Redis\n---\n## 零、从问题出发\n\n\n## 一、简介\n\nRedis 使用的是客户端-服务器（CS）模型和请求/响应协议的 TCP 服务器。这意味着通常情况下一个请求会遵循以下步骤：\n\n- 客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。\n- 服务端处理命令，并将结果返回给客户端。\n\nRedis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。\n\nredis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，即算redis server端有很强的处理能力，也由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须部分请求放到队列中（使用内存）执行完毕后一次性发送结果；如果发送的命名很多的话，建议对返回的结果加标签，当然这也会增加使用的内存；\n\nPipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，而且对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能,性能提升的原因主要是TCP链接中较少了“交互往返”的时间。不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。\n\n不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。\n\n由于通信会有网络延迟，假如 client 和 server 之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使 redis 每秒能处理100个命令，而我们的 client 也只能一秒钟发出四个命令。这显然没有充分利用 redis 的处理能力。\n\n而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。\n\n需要注意到是用 pipeline 方式打包命令发送，redis 必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。\n\n## 二、适用场景\n\n有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 redis 了，那这种场景就不适合。\n\n还有的系统，可能是批量的将数据写入 redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入 redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用 pipeline 最好了。\n\n## 三、管道（Pipelining） VS 脚本（Scripting）\n\n大量 pipeline 应用场景可通过 Redis 脚本（Redis 版本 >= 2.6）得到更高效的处理，后者在服务器端执行大量工作。脚本的一大优势是可通过最小的延迟读写数据，让读、计算、写等操作变得非常快（pipeline 在这种情况下不能使用，因为客户端在写命令前需要读命令返回的结果）。\n\n应用程序有时可能在 pipeline 中发送 EVAL 或 EVALSHA 命令。Redis 通过 SCRIPT LOAD 命令（保证 EVALSHA 成功被调用）明确支持这种情况。","slug":"re0-redis-pipeline","published":1,"updated":"2022-04-28T11:36:46.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58y000omauybgmm147o","content":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>Redis 使用的是客户端-服务器（CS）模型和请求/响应协议的 TCP 服务器。这意味着通常情况下一个请求会遵循以下步骤：</p>\n<ul>\n<li>客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。</li>\n<li>服务端处理命令，并将结果返回给客户端。</li>\n</ul>\n<p>Redis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。</p>\n<p>redis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，即算redis server端有很强的处理能力，也由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须部分请求放到队列中（使用内存）执行完毕后一次性发送结果；如果发送的命名很多的话，建议对返回的结果加标签，当然这也会增加使用的内存；</p>\n<p>Pipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，而且对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能,性能提升的原因主要是TCP链接中较少了“交互往返”的时间。不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。</p>\n<p>不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。</p>\n<p>由于通信会有网络延迟，假如 client 和 server 之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使 redis 每秒能处理100个命令，而我们的 client 也只能一秒钟发出四个命令。这显然没有充分利用 redis 的处理能力。</p>\n<p>而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。</p>\n<p>需要注意到是用 pipeline 方式打包命令发送，redis 必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。</p>\n<h2 id=\"二、适用场景\"><a href=\"#二、适用场景\" class=\"headerlink\" title=\"二、适用场景\"></a>二、适用场景</h2><p>有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 redis 了，那这种场景就不适合。</p>\n<p>还有的系统，可能是批量的将数据写入 redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入 redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用 pipeline 最好了。</p>\n<h2 id=\"三、管道（Pipelining）-VS-脚本（Scripting）\"><a href=\"#三、管道（Pipelining）-VS-脚本（Scripting）\" class=\"headerlink\" title=\"三、管道（Pipelining） VS 脚本（Scripting）\"></a>三、管道（Pipelining） VS 脚本（Scripting）</h2><p>大量 pipeline 应用场景可通过 Redis 脚本（Redis 版本 &gt;= 2.6）得到更高效的处理，后者在服务器端执行大量工作。脚本的一大优势是可通过最小的延迟读写数据，让读、计算、写等操作变得非常快（pipeline 在这种情况下不能使用，因为客户端在写命令前需要读命令返回的结果）。</p>\n<p>应用程序有时可能在 pipeline 中发送 EVAL 或 EVALSHA 命令。Redis 通过 SCRIPT LOAD 命令（保证 EVALSHA 成功被调用）明确支持这种情况。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>Redis 使用的是客户端-服务器（CS）模型和请求/响应协议的 TCP 服务器。这意味着通常情况下一个请求会遵循以下步骤：</p>\n<ul>\n<li>客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。</li>\n<li>服务端处理命令，并将结果返回给客户端。</li>\n</ul>\n<p>Redis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。</p>\n<p>redis的pipeline(管道)功能在命令行中没有，但redis是支持pipeline的，而且在各个语言版的client中都有相应的实现。 由于网络开销延迟，即算redis server端有很强的处理能力，也由于收到的client消息少，而造成吞吐量小。当client 使用pipelining 发送命令时，redis server必须部分请求放到队列中（使用内存）执行完毕后一次性发送结果；如果发送的命名很多的话，建议对返回的结果加标签，当然这也会增加使用的内存；</p>\n<p>Pipeline在某些场景下非常有用，比如有多个command需要被“及时的”提交，而且他们对相应结果没有互相依赖，而且对结果响应也无需立即获得，那么pipeline就可以充当这种“批处理”的工具；而且在一定程度上，可以较大的提升性能,性能提升的原因主要是TCP链接中较少了“交互往返”的时间。不过在编码时请注意，pipeline期间将“独占”链接，此期间将不能进行非“管道”类型的其他操作，直到pipeline关闭；如果你的pipeline的指令集很庞大，为了不干扰链接中的其他操作，你可以为pipeline操作新建Client链接，让pipeline和其他正常操作分离在2个client中。</p>\n<p>不过pipeline事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的pipeline链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。</p>\n<p>由于通信会有网络延迟，假如 client 和 server 之间的包传输时间需要0.125秒。那么上面的三个命令6个报文至少需要0.75秒才能完成。这样即使 redis 每秒能处理100个命令，而我们的 client 也只能一秒钟发出四个命令。这显然没有充分利用 redis 的处理能力。</p>\n<p>而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。</p>\n<p>需要注意到是用 pipeline 方式打包命令发送，redis 必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。</p>\n<h2 id=\"二、适用场景\"><a href=\"#二、适用场景\" class=\"headerlink\" title=\"二、适用场景\"></a>二、适用场景</h2><p>有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 redis 了，那这种场景就不适合。</p>\n<p>还有的系统，可能是批量的将数据写入 redis，允许一定比例的写入失败，那么这种场景就可以使用了，比如10000条一下进入 redis，可能失败了2条无所谓，后期有补偿机制就行了，比如短信群发这种场景，如果一下群发10000条，按照第一种模式去实现，那这个请求过来，要很久才能给客户端响应，这个延迟就太长了，如果客户端请求设置了超时时间5秒，那肯定就抛出异常了，而且本身群发短信要求实时性也没那么高，这时候用 pipeline 最好了。</p>\n<h2 id=\"三、管道（Pipelining）-VS-脚本（Scripting）\"><a href=\"#三、管道（Pipelining）-VS-脚本（Scripting）\" class=\"headerlink\" title=\"三、管道（Pipelining） VS 脚本（Scripting）\"></a>三、管道（Pipelining） VS 脚本（Scripting）</h2><p>大量 pipeline 应用场景可通过 Redis 脚本（Redis 版本 &gt;= 2.6）得到更高效的处理，后者在服务器端执行大量工作。脚本的一大优势是可通过最小的延迟读写数据，让读、计算、写等操作变得非常快（pipeline 在这种情况下不能使用，因为客户端在写命令前需要读命令返回的结果）。</p>\n<p>应用程序有时可能在 pipeline 中发送 EVAL 或 EVALSHA 命令。Redis 通过 SCRIPT LOAD 命令（保证 EVALSHA 成功被调用）明确支持这种情况。</p>\n"},{"title":"Redis中的内存管理","date":"2021-09-14T16:54:20.000Z","_content":"\n## 零、从问题出发\n\n- 使用的是哪个内存管理器\n- 内存是如何淘汰的\n- 不同的结构体的内存结构\n- 内存如何优化\n- 内存的分类\n\n## 一、 内存消耗\n\n理解Redis内存， 首先需要掌握Redis内存消耗在哪些方面。 有些内存消耗是必不可少的， 而有些可以通过参数调整和合理使用来规避内存浪费。 内存消耗可以分为进程自身消耗和子进程消耗。\n\n### 内存使用统计\n\n首先需要了解Redis自身使用内存的统计数据， 可通过执行info memory命令获取内存相关指标。 读懂每个指标有助于分析Redis内存使用情况：\n\n| 属性名                  | 属性说明                                                |\n| :---------------------- | :------------------------------------------------------ |\n| used_memory             | Redis分配器分配的内存总量，内存存储的所有数据内存占用量 |\n| used_memory_human       | 以可读的格式返回used_memory                             |\n| used_memory_rss         | 以操作系统的角度显示Redis进程占用的物理内存总量         |\n| used_memory_peak        | 内存使用的最大值                                        |\n| used_memory_peak_human  | 以可读的格式返回used_memory_peak                        |\n| used_memory_lua         | Lua引擎消耗的内存大小                                   |\n| mem_fragmentation_ratio | used_memory_rss/used_memory比值，表示内存碎片率         |\n| mem_allocator           | Redis所使用的内存分配器，默认为jemalloc                 |\n\n需要重点关注的指标有： used_memory_rss和used_memory以及它们的比值mem_fragmentation_ratio。\n\n当mem_fragmentation_ratio>1时， 说明used_memory_rss - used_memory多出的部分内存并没有用于数据存储， 而是被内存碎片所消耗， 如果两者相差很大， 说明碎片率严重。\n\n当mem_fragmentation_ratio<1时， 这种情况一般出现在操作系统把Redis内存交换（Swap）到硬盘导致， 出现这种情况时要格外关注， 由于硬盘速度远远慢于内存， Redis性能会变得很差， 甚至僵死。\n\n### 内存消耗划分\n\nRedis进程内消耗主要包括： 自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少， 通常used_memory_rss在3MB左右，used_memory在800KB左右， 一个空的Redis进程消耗内存可以忽略不计。Redis主要内存消耗如图所示。\n\n1. 对象内存 对象内存是Redis内存占用最大的一块， 存储着用户所有的数据。Redis所有的数据都采用key-value数据类型， 每次创建键值对时， 至少创建两个类型对象： key对象和value对象。 对象内存消耗可以简单理解为sizeof（keys）+sizeof（values） 。 键对象都是字符串， 在使用Redis时很容易忽略键对内存消耗的影响， 应当避免使用过长的键。 value对象更复杂些， 主要包含5种基本数据类型： 字符串、 列表、 哈希、 集合、 有序集合。 其他数据类型都是建立在这5种数据结构之上实现的， 如： Bitmaps和HyperLogLog使用字符串实现， GEO使用有序集合实现等。每种value对象类型根据使用规模不同， 占用内存不同。 在使用时一定要合理预估并监控value对象占用情况， 避免内存溢出。\n2. 缓冲内存 缓冲内存主要包括： 客户端缓冲、 复制积压缓冲区、 AOF缓冲区。\n\n客户端缓冲指的是所有接入到Redis服务器TCP连接的输入输出缓冲。输入缓冲无法控制， 最大空间为1G， 如果超过将断开连接。 输出缓冲通过参数client-output-buffer-limit控制， 如下所示：\n\n- 普通客户端 除了复制和订阅的客户端之外的所有连接， Redis的默认配置是： client-output-buffer-limit normal000， Redis并没有对普通客户端的输出缓冲区做限制， 一般普通客户端的内存消耗可以忽略不计， 但是当有大量慢连接客户端接入时这部分内存消耗就不能忽略了， 可以设置maxclients做限制。 特别是当使用大量数据输出的命令且数据无法及时推送给客户端时，如monitor命令， 容易造成Redis服务器内存突然飙升。\n- 从客户端 主节点会为每个从节点单独建立一条连接用于命令复制，默认配置是： client-output-buffer-limit slave256mb64mb60。 当主从节点之间网络延迟较高或主节点挂载大量从节点时这部分内存消耗将占用很大一部分， 建议主节点挂载的从节点不要多于2个， 主从节点不要部署在较差的网络环境下， 如异地跨机房环境， 防止复制客户端连接缓慢造成溢出。\n- 订阅客户端 当使用发布订阅功能时， 连接客户端使用单独的输出缓冲区， 默认配置为： client-output-buffer-limit pubsub32mb8mb60， 当订阅服务的消息生产快于消费速度时， 输出缓冲区会产生积压造成输出缓冲区空间溢出。\n\n输入输出缓冲区在大流量的场景中容易失控， 造成Redis内存的不稳定， 需要重点监控。\n\n复制积压缓冲区：Redis在2.8版本之后提供了一个可重用的固定大小缓冲区用于实现部分复制功能， 根据repl-backlog-size参数控制， 默认1MB。对于复制积压缓冲区整个主节点只有一个， 所有的从节点共享此缓冲区， 因此可以设置较大的缓冲区空间， 如100MB， 这部分内存投入是有价值的， 可以有效避免全量复制。\n\nAOF缓冲区： 这部分空间用于在Redis重写期间保存最近的写入命令，AOF缓冲区空间消耗用户无法控制， 消耗的内存取决于AOF重写时间和写入命令量， 这部分空间占用通常很小。\n\n1. 内存碎片 Redis默认的内存分配器采用jemalloc， 可选的分配器还有： glibc、tcmalloc。 内存分配器为了更好地管理和重复利用内存， 分配内存策略一般采用固定范围的内存块进行分配。 例如jemalloc在64位系统中将内存空间划分为： 小、 大、 巨大三个范围。 每个范围内又划分为多个小的内存块单位，如下所示：\n\n- 小： [8byte]， [16byte， 32byte， 48byte， ...， 128byte]， [192byte，256byte， ...， 512byte]， [768byte， 1024byte， ...， 3840byte]\n- 大： [4KB， 8KB， 12KB， ...， 4072KB]\n- 巨大： [4MB， 8MB， 12MB， ...]\n\n比如当保存5KB对象时jemalloc可能会采用8KB的块存储， 而剩下的3KB空间变为了内存碎片不能再分配给其他[对象存储](https://cloud.tencent.com/product/cos?from=10680)。 内存碎片问题虽然是所有内存服务的通病， 但是jemalloc针对碎片化问题专门做了优化， 一般不会存在过度碎片化的问题， 正常的碎片率（mem_fragmentation_ratio） 在1.03左右。 但是当存储的数据长短差异较大时， 以下场景容易出现高内存碎片问题：\n\n- 频繁做更新操作， 例如频繁对已存在的键执行append、 setrange等更新操作。\n- 大量过期键删除， 键对象过期删除后， 释放的空间无法得到充分利用， 导致碎片率上升。\n\n出现高内存碎片问题时常见的解决方式如下：\n\n- 数据对齐： 在条件允许的情况下尽量做数据对齐， 比如数据尽量采用数字类型或者固定长度字符串等， 但是这要视具体的业务而定， 有些场景无法做到。\n- 安全重启： 重启节点可以做到内存碎片重新整理， 因此可以利用高可用架构， 如Sentinel或Cluster， 将碎片率过高的主节点转换为从节点， 进行安全重启。\n\n### 子进程内存消耗\n\n子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。 Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。 但Linux具有写时复制技术（copy-on-write） ， 父子进程会共享相同的物理内存页， 当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作， 而子进程依然读取fork时整个父进程的内存快照。\n\nLinux Kernel在2.6.38内核增加了Transparent Huge Pages（THP） 机制， 而有些Linux发行版即使内核达不到2.6.38也会默认加入并开启这个功能， 如Redhat Enterprise Linux在6.0以上版本默认会引入THP。 虽然开启THP可以降低fork子进程的速度， 但之后copy-on-write期间复制内存页的单位从4KB变为2MB， 如果父进程有大量写命令， 会加重内存拷贝量， 从而造成过度内存 消耗。 例如， 以下两个执行AOF重写时的内存消耗日志：\n\n```javascript\n// 开启THP:\nC * AOF rewrite: 1039 MB of memory used by copy-on-write\n// 关闭THP:\nC * AOF rewrite: 9 MB of memory used by copy-on-write\n```\n\n这两个日志出自同一Redis进程， used_memory总量为1.5GB， 子进程执行期间每秒写命令量都在200左右。 当分别开启和关闭THP时， 子进程内存消耗有天壤之别。 如果在高并发写的场景下开启THP， 子进程内存消耗可能是父进程的数倍， 极易造成机器物理内存溢出， 从而触发SWAP或OOM killer。\n\n子进程内存消耗总结如下：\n\n- Redis产生的子进程并不需要消耗1倍的父进程内存， 实际消耗根据期间写入命令量决定， 但是依然要预留出一些内存防止溢出。\n- 需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存， 防止Redis进程执行fork时因系统剩余内存不足而失败。\n- 排查当前系统是否支持并开启THP， 如果开启建议关闭， 防止copy-onwrite期间内存过度消耗。\n\n\n## 二、\n\n\n## 相关链接\n- https://www.cnblogs.com/wangiqngpei557/p/8323680.html\n- https://blog.csdn.net/yahuuqq1314/article/details/100566688\n- https://cloud.tencent.com/developer/article/1692195","source":"_posts/re0-redis-memory.md","raw":"---\ntitle: Redis中的内存管理\ndate: 2021-09-15 00:54:20\ntags: 从0开始的Redis\n---\n\n## 零、从问题出发\n\n- 使用的是哪个内存管理器\n- 内存是如何淘汰的\n- 不同的结构体的内存结构\n- 内存如何优化\n- 内存的分类\n\n## 一、 内存消耗\n\n理解Redis内存， 首先需要掌握Redis内存消耗在哪些方面。 有些内存消耗是必不可少的， 而有些可以通过参数调整和合理使用来规避内存浪费。 内存消耗可以分为进程自身消耗和子进程消耗。\n\n### 内存使用统计\n\n首先需要了解Redis自身使用内存的统计数据， 可通过执行info memory命令获取内存相关指标。 读懂每个指标有助于分析Redis内存使用情况：\n\n| 属性名                  | 属性说明                                                |\n| :---------------------- | :------------------------------------------------------ |\n| used_memory             | Redis分配器分配的内存总量，内存存储的所有数据内存占用量 |\n| used_memory_human       | 以可读的格式返回used_memory                             |\n| used_memory_rss         | 以操作系统的角度显示Redis进程占用的物理内存总量         |\n| used_memory_peak        | 内存使用的最大值                                        |\n| used_memory_peak_human  | 以可读的格式返回used_memory_peak                        |\n| used_memory_lua         | Lua引擎消耗的内存大小                                   |\n| mem_fragmentation_ratio | used_memory_rss/used_memory比值，表示内存碎片率         |\n| mem_allocator           | Redis所使用的内存分配器，默认为jemalloc                 |\n\n需要重点关注的指标有： used_memory_rss和used_memory以及它们的比值mem_fragmentation_ratio。\n\n当mem_fragmentation_ratio>1时， 说明used_memory_rss - used_memory多出的部分内存并没有用于数据存储， 而是被内存碎片所消耗， 如果两者相差很大， 说明碎片率严重。\n\n当mem_fragmentation_ratio<1时， 这种情况一般出现在操作系统把Redis内存交换（Swap）到硬盘导致， 出现这种情况时要格外关注， 由于硬盘速度远远慢于内存， Redis性能会变得很差， 甚至僵死。\n\n### 内存消耗划分\n\nRedis进程内消耗主要包括： 自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少， 通常used_memory_rss在3MB左右，used_memory在800KB左右， 一个空的Redis进程消耗内存可以忽略不计。Redis主要内存消耗如图所示。\n\n1. 对象内存 对象内存是Redis内存占用最大的一块， 存储着用户所有的数据。Redis所有的数据都采用key-value数据类型， 每次创建键值对时， 至少创建两个类型对象： key对象和value对象。 对象内存消耗可以简单理解为sizeof（keys）+sizeof（values） 。 键对象都是字符串， 在使用Redis时很容易忽略键对内存消耗的影响， 应当避免使用过长的键。 value对象更复杂些， 主要包含5种基本数据类型： 字符串、 列表、 哈希、 集合、 有序集合。 其他数据类型都是建立在这5种数据结构之上实现的， 如： Bitmaps和HyperLogLog使用字符串实现， GEO使用有序集合实现等。每种value对象类型根据使用规模不同， 占用内存不同。 在使用时一定要合理预估并监控value对象占用情况， 避免内存溢出。\n2. 缓冲内存 缓冲内存主要包括： 客户端缓冲、 复制积压缓冲区、 AOF缓冲区。\n\n客户端缓冲指的是所有接入到Redis服务器TCP连接的输入输出缓冲。输入缓冲无法控制， 最大空间为1G， 如果超过将断开连接。 输出缓冲通过参数client-output-buffer-limit控制， 如下所示：\n\n- 普通客户端 除了复制和订阅的客户端之外的所有连接， Redis的默认配置是： client-output-buffer-limit normal000， Redis并没有对普通客户端的输出缓冲区做限制， 一般普通客户端的内存消耗可以忽略不计， 但是当有大量慢连接客户端接入时这部分内存消耗就不能忽略了， 可以设置maxclients做限制。 特别是当使用大量数据输出的命令且数据无法及时推送给客户端时，如monitor命令， 容易造成Redis服务器内存突然飙升。\n- 从客户端 主节点会为每个从节点单独建立一条连接用于命令复制，默认配置是： client-output-buffer-limit slave256mb64mb60。 当主从节点之间网络延迟较高或主节点挂载大量从节点时这部分内存消耗将占用很大一部分， 建议主节点挂载的从节点不要多于2个， 主从节点不要部署在较差的网络环境下， 如异地跨机房环境， 防止复制客户端连接缓慢造成溢出。\n- 订阅客户端 当使用发布订阅功能时， 连接客户端使用单独的输出缓冲区， 默认配置为： client-output-buffer-limit pubsub32mb8mb60， 当订阅服务的消息生产快于消费速度时， 输出缓冲区会产生积压造成输出缓冲区空间溢出。\n\n输入输出缓冲区在大流量的场景中容易失控， 造成Redis内存的不稳定， 需要重点监控。\n\n复制积压缓冲区：Redis在2.8版本之后提供了一个可重用的固定大小缓冲区用于实现部分复制功能， 根据repl-backlog-size参数控制， 默认1MB。对于复制积压缓冲区整个主节点只有一个， 所有的从节点共享此缓冲区， 因此可以设置较大的缓冲区空间， 如100MB， 这部分内存投入是有价值的， 可以有效避免全量复制。\n\nAOF缓冲区： 这部分空间用于在Redis重写期间保存最近的写入命令，AOF缓冲区空间消耗用户无法控制， 消耗的内存取决于AOF重写时间和写入命令量， 这部分空间占用通常很小。\n\n1. 内存碎片 Redis默认的内存分配器采用jemalloc， 可选的分配器还有： glibc、tcmalloc。 内存分配器为了更好地管理和重复利用内存， 分配内存策略一般采用固定范围的内存块进行分配。 例如jemalloc在64位系统中将内存空间划分为： 小、 大、 巨大三个范围。 每个范围内又划分为多个小的内存块单位，如下所示：\n\n- 小： [8byte]， [16byte， 32byte， 48byte， ...， 128byte]， [192byte，256byte， ...， 512byte]， [768byte， 1024byte， ...， 3840byte]\n- 大： [4KB， 8KB， 12KB， ...， 4072KB]\n- 巨大： [4MB， 8MB， 12MB， ...]\n\n比如当保存5KB对象时jemalloc可能会采用8KB的块存储， 而剩下的3KB空间变为了内存碎片不能再分配给其他[对象存储](https://cloud.tencent.com/product/cos?from=10680)。 内存碎片问题虽然是所有内存服务的通病， 但是jemalloc针对碎片化问题专门做了优化， 一般不会存在过度碎片化的问题， 正常的碎片率（mem_fragmentation_ratio） 在1.03左右。 但是当存储的数据长短差异较大时， 以下场景容易出现高内存碎片问题：\n\n- 频繁做更新操作， 例如频繁对已存在的键执行append、 setrange等更新操作。\n- 大量过期键删除， 键对象过期删除后， 释放的空间无法得到充分利用， 导致碎片率上升。\n\n出现高内存碎片问题时常见的解决方式如下：\n\n- 数据对齐： 在条件允许的情况下尽量做数据对齐， 比如数据尽量采用数字类型或者固定长度字符串等， 但是这要视具体的业务而定， 有些场景无法做到。\n- 安全重启： 重启节点可以做到内存碎片重新整理， 因此可以利用高可用架构， 如Sentinel或Cluster， 将碎片率过高的主节点转换为从节点， 进行安全重启。\n\n### 子进程内存消耗\n\n子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。 Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。 但Linux具有写时复制技术（copy-on-write） ， 父子进程会共享相同的物理内存页， 当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作， 而子进程依然读取fork时整个父进程的内存快照。\n\nLinux Kernel在2.6.38内核增加了Transparent Huge Pages（THP） 机制， 而有些Linux发行版即使内核达不到2.6.38也会默认加入并开启这个功能， 如Redhat Enterprise Linux在6.0以上版本默认会引入THP。 虽然开启THP可以降低fork子进程的速度， 但之后copy-on-write期间复制内存页的单位从4KB变为2MB， 如果父进程有大量写命令， 会加重内存拷贝量， 从而造成过度内存 消耗。 例如， 以下两个执行AOF重写时的内存消耗日志：\n\n```javascript\n// 开启THP:\nC * AOF rewrite: 1039 MB of memory used by copy-on-write\n// 关闭THP:\nC * AOF rewrite: 9 MB of memory used by copy-on-write\n```\n\n这两个日志出自同一Redis进程， used_memory总量为1.5GB， 子进程执行期间每秒写命令量都在200左右。 当分别开启和关闭THP时， 子进程内存消耗有天壤之别。 如果在高并发写的场景下开启THP， 子进程内存消耗可能是父进程的数倍， 极易造成机器物理内存溢出， 从而触发SWAP或OOM killer。\n\n子进程内存消耗总结如下：\n\n- Redis产生的子进程并不需要消耗1倍的父进程内存， 实际消耗根据期间写入命令量决定， 但是依然要预留出一些内存防止溢出。\n- 需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存， 防止Redis进程执行fork时因系统剩余内存不足而失败。\n- 排查当前系统是否支持并开启THP， 如果开启建议关闭， 防止copy-onwrite期间内存过度消耗。\n\n\n## 二、\n\n\n## 相关链接\n- https://www.cnblogs.com/wangiqngpei557/p/8323680.html\n- https://blog.csdn.net/yahuuqq1314/article/details/100566688\n- https://cloud.tencent.com/developer/article/1692195","slug":"re0-redis-memory","published":1,"updated":"2022-04-28T11:36:46.639Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg58z000qmauyey7pe8sg","content":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><ul>\n<li>使用的是哪个内存管理器</li>\n<li>内存是如何淘汰的</li>\n<li>不同的结构体的内存结构</li>\n<li>内存如何优化</li>\n<li>内存的分类</li>\n</ul>\n<h2 id=\"一、-内存消耗\"><a href=\"#一、-内存消耗\" class=\"headerlink\" title=\"一、 内存消耗\"></a>一、 内存消耗</h2><p>理解Redis内存， 首先需要掌握Redis内存消耗在哪些方面。 有些内存消耗是必不可少的， 而有些可以通过参数调整和合理使用来规避内存浪费。 内存消耗可以分为进程自身消耗和子进程消耗。</p>\n<h3 id=\"内存使用统计\"><a href=\"#内存使用统计\" class=\"headerlink\" title=\"内存使用统计\"></a>内存使用统计</h3><p>首先需要了解Redis自身使用内存的统计数据， 可通过执行info memory命令获取内存相关指标。 读懂每个指标有助于分析Redis内存使用情况：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">属性名</th>\n<th align=\"left\">属性说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">used_memory</td>\n<td align=\"left\">Redis分配器分配的内存总量，内存存储的所有数据内存占用量</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_human</td>\n<td align=\"left\">以可读的格式返回used_memory</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_rss</td>\n<td align=\"left\">以操作系统的角度显示Redis进程占用的物理内存总量</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_peak</td>\n<td align=\"left\">内存使用的最大值</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_peak_human</td>\n<td align=\"left\">以可读的格式返回used_memory_peak</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_lua</td>\n<td align=\"left\">Lua引擎消耗的内存大小</td>\n</tr>\n<tr>\n<td align=\"left\">mem_fragmentation_ratio</td>\n<td align=\"left\">used_memory_rss/used_memory比值，表示内存碎片率</td>\n</tr>\n<tr>\n<td align=\"left\">mem_allocator</td>\n<td align=\"left\">Redis所使用的内存分配器，默认为jemalloc</td>\n</tr>\n</tbody></table>\n<p>需要重点关注的指标有： used_memory_rss和used_memory以及它们的比值mem_fragmentation_ratio。</p>\n<p>当mem_fragmentation_ratio&gt;1时， 说明used_memory_rss - used_memory多出的部分内存并没有用于数据存储， 而是被内存碎片所消耗， 如果两者相差很大， 说明碎片率严重。</p>\n<p>当mem_fragmentation_ratio&lt;1时， 这种情况一般出现在操作系统把Redis内存交换（Swap）到硬盘导致， 出现这种情况时要格外关注， 由于硬盘速度远远慢于内存， Redis性能会变得很差， 甚至僵死。</p>\n<h3 id=\"内存消耗划分\"><a href=\"#内存消耗划分\" class=\"headerlink\" title=\"内存消耗划分\"></a>内存消耗划分</h3><p>Redis进程内消耗主要包括： 自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少， 通常used_memory_rss在3MB左右，used_memory在800KB左右， 一个空的Redis进程消耗内存可以忽略不计。Redis主要内存消耗如图所示。</p>\n<ol>\n<li>对象内存 对象内存是Redis内存占用最大的一块， 存储着用户所有的数据。Redis所有的数据都采用key-value数据类型， 每次创建键值对时， 至少创建两个类型对象： key对象和value对象。 对象内存消耗可以简单理解为sizeof（keys）+sizeof（values） 。 键对象都是字符串， 在使用Redis时很容易忽略键对内存消耗的影响， 应当避免使用过长的键。 value对象更复杂些， 主要包含5种基本数据类型： 字符串、 列表、 哈希、 集合、 有序集合。 其他数据类型都是建立在这5种数据结构之上实现的， 如： Bitmaps和HyperLogLog使用字符串实现， GEO使用有序集合实现等。每种value对象类型根据使用规模不同， 占用内存不同。 在使用时一定要合理预估并监控value对象占用情况， 避免内存溢出。</li>\n<li>缓冲内存 缓冲内存主要包括： 客户端缓冲、 复制积压缓冲区、 AOF缓冲区。</li>\n</ol>\n<p>客户端缓冲指的是所有接入到Redis服务器TCP连接的输入输出缓冲。输入缓冲无法控制， 最大空间为1G， 如果超过将断开连接。 输出缓冲通过参数client-output-buffer-limit控制， 如下所示：</p>\n<ul>\n<li>普通客户端 除了复制和订阅的客户端之外的所有连接， Redis的默认配置是： client-output-buffer-limit normal000， Redis并没有对普通客户端的输出缓冲区做限制， 一般普通客户端的内存消耗可以忽略不计， 但是当有大量慢连接客户端接入时这部分内存消耗就不能忽略了， 可以设置maxclients做限制。 特别是当使用大量数据输出的命令且数据无法及时推送给客户端时，如monitor命令， 容易造成Redis服务器内存突然飙升。</li>\n<li>从客户端 主节点会为每个从节点单独建立一条连接用于命令复制，默认配置是： client-output-buffer-limit slave256mb64mb60。 当主从节点之间网络延迟较高或主节点挂载大量从节点时这部分内存消耗将占用很大一部分， 建议主节点挂载的从节点不要多于2个， 主从节点不要部署在较差的网络环境下， 如异地跨机房环境， 防止复制客户端连接缓慢造成溢出。</li>\n<li>订阅客户端 当使用发布订阅功能时， 连接客户端使用单独的输出缓冲区， 默认配置为： client-output-buffer-limit pubsub32mb8mb60， 当订阅服务的消息生产快于消费速度时， 输出缓冲区会产生积压造成输出缓冲区空间溢出。</li>\n</ul>\n<p>输入输出缓冲区在大流量的场景中容易失控， 造成Redis内存的不稳定， 需要重点监控。</p>\n<p>复制积压缓冲区：Redis在2.8版本之后提供了一个可重用的固定大小缓冲区用于实现部分复制功能， 根据repl-backlog-size参数控制， 默认1MB。对于复制积压缓冲区整个主节点只有一个， 所有的从节点共享此缓冲区， 因此可以设置较大的缓冲区空间， 如100MB， 这部分内存投入是有价值的， 可以有效避免全量复制。</p>\n<p>AOF缓冲区： 这部分空间用于在Redis重写期间保存最近的写入命令，AOF缓冲区空间消耗用户无法控制， 消耗的内存取决于AOF重写时间和写入命令量， 这部分空间占用通常很小。</p>\n<ol>\n<li>内存碎片 Redis默认的内存分配器采用jemalloc， 可选的分配器还有： glibc、tcmalloc。 内存分配器为了更好地管理和重复利用内存， 分配内存策略一般采用固定范围的内存块进行分配。 例如jemalloc在64位系统中将内存空间划分为： 小、 大、 巨大三个范围。 每个范围内又划分为多个小的内存块单位，如下所示：</li>\n</ol>\n<ul>\n<li>小： [8byte]， [16byte， 32byte， 48byte， …， 128byte]， [192byte，256byte， …， 512byte]， [768byte， 1024byte， …， 3840byte]</li>\n<li>大： [4KB， 8KB， 12KB， …， 4072KB]</li>\n<li>巨大： [4MB， 8MB， 12MB， …]</li>\n</ul>\n<p>比如当保存5KB对象时jemalloc可能会采用8KB的块存储， 而剩下的3KB空间变为了内存碎片不能再分配给其他<a href=\"https://cloud.tencent.com/product/cos?from=10680\" target=\"_blank\" rel=\"noopener\">对象存储</a>。 内存碎片问题虽然是所有内存服务的通病， 但是jemalloc针对碎片化问题专门做了优化， 一般不会存在过度碎片化的问题， 正常的碎片率（mem_fragmentation_ratio） 在1.03左右。 但是当存储的数据长短差异较大时， 以下场景容易出现高内存碎片问题：</p>\n<ul>\n<li>频繁做更新操作， 例如频繁对已存在的键执行append、 setrange等更新操作。</li>\n<li>大量过期键删除， 键对象过期删除后， 释放的空间无法得到充分利用， 导致碎片率上升。</li>\n</ul>\n<p>出现高内存碎片问题时常见的解决方式如下：</p>\n<ul>\n<li>数据对齐： 在条件允许的情况下尽量做数据对齐， 比如数据尽量采用数字类型或者固定长度字符串等， 但是这要视具体的业务而定， 有些场景无法做到。</li>\n<li>安全重启： 重启节点可以做到内存碎片重新整理， 因此可以利用高可用架构， 如Sentinel或Cluster， 将碎片率过高的主节点转换为从节点， 进行安全重启。</li>\n</ul>\n<h3 id=\"子进程内存消耗\"><a href=\"#子进程内存消耗\" class=\"headerlink\" title=\"子进程内存消耗\"></a>子进程内存消耗</h3><p>子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。 Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。 但Linux具有写时复制技术（copy-on-write） ， 父子进程会共享相同的物理内存页， 当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作， 而子进程依然读取fork时整个父进程的内存快照。</p>\n<p>Linux Kernel在2.6.38内核增加了Transparent Huge Pages（THP） 机制， 而有些Linux发行版即使内核达不到2.6.38也会默认加入并开启这个功能， 如Redhat Enterprise Linux在6.0以上版本默认会引入THP。 虽然开启THP可以降低fork子进程的速度， 但之后copy-on-write期间复制内存页的单位从4KB变为2MB， 如果父进程有大量写命令， 会加重内存拷贝量， 从而造成过度内存 消耗。 例如， 以下两个执行AOF重写时的内存消耗日志：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 开启THP:</span></span><br><span class=\"line\">C * AOF rewrite: <span class=\"number\">1039</span> MB <span class=\"keyword\">of</span> memory used by copy-on-write</span><br><span class=\"line\"><span class=\"comment\">// 关闭THP:</span></span><br><span class=\"line\">C * AOF rewrite: <span class=\"number\">9</span> MB <span class=\"keyword\">of</span> memory used by copy-on-write</span><br></pre></td></tr></table></figure>\n\n<p>这两个日志出自同一Redis进程， used_memory总量为1.5GB， 子进程执行期间每秒写命令量都在200左右。 当分别开启和关闭THP时， 子进程内存消耗有天壤之别。 如果在高并发写的场景下开启THP， 子进程内存消耗可能是父进程的数倍， 极易造成机器物理内存溢出， 从而触发SWAP或OOM killer。</p>\n<p>子进程内存消耗总结如下：</p>\n<ul>\n<li>Redis产生的子进程并不需要消耗1倍的父进程内存， 实际消耗根据期间写入命令量决定， 但是依然要预留出一些内存防止溢出。</li>\n<li>需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存， 防止Redis进程执行fork时因系统剩余内存不足而失败。</li>\n<li>排查当前系统是否支持并开启THP， 如果开启建议关闭， 防止copy-onwrite期间内存过度消耗。</li>\n</ul>\n<h2 id=\"二、\"><a href=\"#二、\" class=\"headerlink\" title=\"二、\"></a>二、</h2><h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://www.cnblogs.com/wangiqngpei557/p/8323680.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/wangiqngpei557/p/8323680.html</a></li>\n<li><a href=\"https://blog.csdn.net/yahuuqq1314/article/details/100566688\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yahuuqq1314/article/details/100566688</a></li>\n<li><a href=\"https://cloud.tencent.com/developer/article/1692195\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/article/1692195</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><ul>\n<li>使用的是哪个内存管理器</li>\n<li>内存是如何淘汰的</li>\n<li>不同的结构体的内存结构</li>\n<li>内存如何优化</li>\n<li>内存的分类</li>\n</ul>\n<h2 id=\"一、-内存消耗\"><a href=\"#一、-内存消耗\" class=\"headerlink\" title=\"一、 内存消耗\"></a>一、 内存消耗</h2><p>理解Redis内存， 首先需要掌握Redis内存消耗在哪些方面。 有些内存消耗是必不可少的， 而有些可以通过参数调整和合理使用来规避内存浪费。 内存消耗可以分为进程自身消耗和子进程消耗。</p>\n<h3 id=\"内存使用统计\"><a href=\"#内存使用统计\" class=\"headerlink\" title=\"内存使用统计\"></a>内存使用统计</h3><p>首先需要了解Redis自身使用内存的统计数据， 可通过执行info memory命令获取内存相关指标。 读懂每个指标有助于分析Redis内存使用情况：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">属性名</th>\n<th align=\"left\">属性说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">used_memory</td>\n<td align=\"left\">Redis分配器分配的内存总量，内存存储的所有数据内存占用量</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_human</td>\n<td align=\"left\">以可读的格式返回used_memory</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_rss</td>\n<td align=\"left\">以操作系统的角度显示Redis进程占用的物理内存总量</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_peak</td>\n<td align=\"left\">内存使用的最大值</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_peak_human</td>\n<td align=\"left\">以可读的格式返回used_memory_peak</td>\n</tr>\n<tr>\n<td align=\"left\">used_memory_lua</td>\n<td align=\"left\">Lua引擎消耗的内存大小</td>\n</tr>\n<tr>\n<td align=\"left\">mem_fragmentation_ratio</td>\n<td align=\"left\">used_memory_rss/used_memory比值，表示内存碎片率</td>\n</tr>\n<tr>\n<td align=\"left\">mem_allocator</td>\n<td align=\"left\">Redis所使用的内存分配器，默认为jemalloc</td>\n</tr>\n</tbody></table>\n<p>需要重点关注的指标有： used_memory_rss和used_memory以及它们的比值mem_fragmentation_ratio。</p>\n<p>当mem_fragmentation_ratio&gt;1时， 说明used_memory_rss - used_memory多出的部分内存并没有用于数据存储， 而是被内存碎片所消耗， 如果两者相差很大， 说明碎片率严重。</p>\n<p>当mem_fragmentation_ratio&lt;1时， 这种情况一般出现在操作系统把Redis内存交换（Swap）到硬盘导致， 出现这种情况时要格外关注， 由于硬盘速度远远慢于内存， Redis性能会变得很差， 甚至僵死。</p>\n<h3 id=\"内存消耗划分\"><a href=\"#内存消耗划分\" class=\"headerlink\" title=\"内存消耗划分\"></a>内存消耗划分</h3><p>Redis进程内消耗主要包括： 自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少， 通常used_memory_rss在3MB左右，used_memory在800KB左右， 一个空的Redis进程消耗内存可以忽略不计。Redis主要内存消耗如图所示。</p>\n<ol>\n<li>对象内存 对象内存是Redis内存占用最大的一块， 存储着用户所有的数据。Redis所有的数据都采用key-value数据类型， 每次创建键值对时， 至少创建两个类型对象： key对象和value对象。 对象内存消耗可以简单理解为sizeof（keys）+sizeof（values） 。 键对象都是字符串， 在使用Redis时很容易忽略键对内存消耗的影响， 应当避免使用过长的键。 value对象更复杂些， 主要包含5种基本数据类型： 字符串、 列表、 哈希、 集合、 有序集合。 其他数据类型都是建立在这5种数据结构之上实现的， 如： Bitmaps和HyperLogLog使用字符串实现， GEO使用有序集合实现等。每种value对象类型根据使用规模不同， 占用内存不同。 在使用时一定要合理预估并监控value对象占用情况， 避免内存溢出。</li>\n<li>缓冲内存 缓冲内存主要包括： 客户端缓冲、 复制积压缓冲区、 AOF缓冲区。</li>\n</ol>\n<p>客户端缓冲指的是所有接入到Redis服务器TCP连接的输入输出缓冲。输入缓冲无法控制， 最大空间为1G， 如果超过将断开连接。 输出缓冲通过参数client-output-buffer-limit控制， 如下所示：</p>\n<ul>\n<li>普通客户端 除了复制和订阅的客户端之外的所有连接， Redis的默认配置是： client-output-buffer-limit normal000， Redis并没有对普通客户端的输出缓冲区做限制， 一般普通客户端的内存消耗可以忽略不计， 但是当有大量慢连接客户端接入时这部分内存消耗就不能忽略了， 可以设置maxclients做限制。 特别是当使用大量数据输出的命令且数据无法及时推送给客户端时，如monitor命令， 容易造成Redis服务器内存突然飙升。</li>\n<li>从客户端 主节点会为每个从节点单独建立一条连接用于命令复制，默认配置是： client-output-buffer-limit slave256mb64mb60。 当主从节点之间网络延迟较高或主节点挂载大量从节点时这部分内存消耗将占用很大一部分， 建议主节点挂载的从节点不要多于2个， 主从节点不要部署在较差的网络环境下， 如异地跨机房环境， 防止复制客户端连接缓慢造成溢出。</li>\n<li>订阅客户端 当使用发布订阅功能时， 连接客户端使用单独的输出缓冲区， 默认配置为： client-output-buffer-limit pubsub32mb8mb60， 当订阅服务的消息生产快于消费速度时， 输出缓冲区会产生积压造成输出缓冲区空间溢出。</li>\n</ul>\n<p>输入输出缓冲区在大流量的场景中容易失控， 造成Redis内存的不稳定， 需要重点监控。</p>\n<p>复制积压缓冲区：Redis在2.8版本之后提供了一个可重用的固定大小缓冲区用于实现部分复制功能， 根据repl-backlog-size参数控制， 默认1MB。对于复制积压缓冲区整个主节点只有一个， 所有的从节点共享此缓冲区， 因此可以设置较大的缓冲区空间， 如100MB， 这部分内存投入是有价值的， 可以有效避免全量复制。</p>\n<p>AOF缓冲区： 这部分空间用于在Redis重写期间保存最近的写入命令，AOF缓冲区空间消耗用户无法控制， 消耗的内存取决于AOF重写时间和写入命令量， 这部分空间占用通常很小。</p>\n<ol>\n<li>内存碎片 Redis默认的内存分配器采用jemalloc， 可选的分配器还有： glibc、tcmalloc。 内存分配器为了更好地管理和重复利用内存， 分配内存策略一般采用固定范围的内存块进行分配。 例如jemalloc在64位系统中将内存空间划分为： 小、 大、 巨大三个范围。 每个范围内又划分为多个小的内存块单位，如下所示：</li>\n</ol>\n<ul>\n<li>小： [8byte]， [16byte， 32byte， 48byte， …， 128byte]， [192byte，256byte， …， 512byte]， [768byte， 1024byte， …， 3840byte]</li>\n<li>大： [4KB， 8KB， 12KB， …， 4072KB]</li>\n<li>巨大： [4MB， 8MB， 12MB， …]</li>\n</ul>\n<p>比如当保存5KB对象时jemalloc可能会采用8KB的块存储， 而剩下的3KB空间变为了内存碎片不能再分配给其他<a href=\"https://cloud.tencent.com/product/cos?from=10680\" target=\"_blank\" rel=\"noopener\">对象存储</a>。 内存碎片问题虽然是所有内存服务的通病， 但是jemalloc针对碎片化问题专门做了优化， 一般不会存在过度碎片化的问题， 正常的碎片率（mem_fragmentation_ratio） 在1.03左右。 但是当存储的数据长短差异较大时， 以下场景容易出现高内存碎片问题：</p>\n<ul>\n<li>频繁做更新操作， 例如频繁对已存在的键执行append、 setrange等更新操作。</li>\n<li>大量过期键删除， 键对象过期删除后， 释放的空间无法得到充分利用， 导致碎片率上升。</li>\n</ul>\n<p>出现高内存碎片问题时常见的解决方式如下：</p>\n<ul>\n<li>数据对齐： 在条件允许的情况下尽量做数据对齐， 比如数据尽量采用数字类型或者固定长度字符串等， 但是这要视具体的业务而定， 有些场景无法做到。</li>\n<li>安全重启： 重启节点可以做到内存碎片重新整理， 因此可以利用高可用架构， 如Sentinel或Cluster， 将碎片率过高的主节点转换为从节点， 进行安全重启。</li>\n</ul>\n<h3 id=\"子进程内存消耗\"><a href=\"#子进程内存消耗\" class=\"headerlink\" title=\"子进程内存消耗\"></a>子进程内存消耗</h3><p>子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。 Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。 但Linux具有写时复制技术（copy-on-write） ， 父子进程会共享相同的物理内存页， 当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作， 而子进程依然读取fork时整个父进程的内存快照。</p>\n<p>Linux Kernel在2.6.38内核增加了Transparent Huge Pages（THP） 机制， 而有些Linux发行版即使内核达不到2.6.38也会默认加入并开启这个功能， 如Redhat Enterprise Linux在6.0以上版本默认会引入THP。 虽然开启THP可以降低fork子进程的速度， 但之后copy-on-write期间复制内存页的单位从4KB变为2MB， 如果父进程有大量写命令， 会加重内存拷贝量， 从而造成过度内存 消耗。 例如， 以下两个执行AOF重写时的内存消耗日志：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 开启THP:</span></span><br><span class=\"line\">C * AOF rewrite: <span class=\"number\">1039</span> MB <span class=\"keyword\">of</span> memory used by copy-on-write</span><br><span class=\"line\"><span class=\"comment\">// 关闭THP:</span></span><br><span class=\"line\">C * AOF rewrite: <span class=\"number\">9</span> MB <span class=\"keyword\">of</span> memory used by copy-on-write</span><br></pre></td></tr></table></figure>\n\n<p>这两个日志出自同一Redis进程， used_memory总量为1.5GB， 子进程执行期间每秒写命令量都在200左右。 当分别开启和关闭THP时， 子进程内存消耗有天壤之别。 如果在高并发写的场景下开启THP， 子进程内存消耗可能是父进程的数倍， 极易造成机器物理内存溢出， 从而触发SWAP或OOM killer。</p>\n<p>子进程内存消耗总结如下：</p>\n<ul>\n<li>Redis产生的子进程并不需要消耗1倍的父进程内存， 实际消耗根据期间写入命令量决定， 但是依然要预留出一些内存防止溢出。</li>\n<li>需要设置sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存， 防止Redis进程执行fork时因系统剩余内存不足而失败。</li>\n<li>排查当前系统是否支持并开启THP， 如果开启建议关闭， 防止copy-onwrite期间内存过度消耗。</li>\n</ul>\n<h2 id=\"二、\"><a href=\"#二、\" class=\"headerlink\" title=\"二、\"></a>二、</h2><h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"https://www.cnblogs.com/wangiqngpei557/p/8323680.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/wangiqngpei557/p/8323680.html</a></li>\n<li><a href=\"https://blog.csdn.net/yahuuqq1314/article/details/100566688\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yahuuqq1314/article/details/100566688</a></li>\n<li><a href=\"https://cloud.tencent.com/developer/article/1692195\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/article/1692195</a></li>\n</ul>\n"},{"title":"redlock设计","date":"2021-09-13T17:52:43.000Z","_content":"## 零、从问题出发\n\n## 一、介绍\n\n> Redlock：全名叫做 Redis Distributed Lock;即使用redis实现的分布式锁；\n\n使用场景：多个服务间保证同一时刻同一时间段内同一用户只能有一个请求（防止关键业务出现并发攻击）；\n\n官网文档地址如下：https://redis.io/topics/distlock\n\n这个锁的算法实现了多redis实例的情况，相对于单redis节点来说，**优点**在于 防止了 单节点故障造成整个服务停止运行的情况；并且在多节点中锁的设计，及多节点同时崩溃等各种意外情况有自己独特的设计方法；\n\n此博客或者官方文档的相关概念：\n1. TTL：Time To Live;只 redis key 的过期时间或有效生存时间\n2. clock drift:时钟漂移；指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程间）时间的差值；如果电脑距离过远会造成时钟漂移值 过大\n\nredis常用的方式有单节点、主从模式、哨兵模式、集群模式。\n单节点在生产环境基本上不会使用，因为不能达到高可用，且连RDB或AOF备份都只能放在master上，所以基本上不会使用。\n另外几种模式都无法避免两个问题：\n1. 异步数据丢失。\n2. 脑裂问题。\n\n最低保证分布式锁的有效性及安全性的要求如下：\n1. 互斥；任何时刻只能有一个client获取锁\n2. 释放死锁；即使锁定资源的服务崩溃或者分区，仍然能释放锁\n3. 容错性；只要多数redis节点（一半以上）在使用，client就可以获取和释放锁\n\n## 二、具体实现\n\nantirez提出的redlock算法大概是这样的：\n\n在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。\n\n为了取到锁，客户端应该执行以下操作:\n\n- 获取当前Unix时间，以毫秒为单位。\n- 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。\n- 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。\n- 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。\n- 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。\n\n## Redlock源码\n\nredisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。\n\n- POM依赖\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.redisson/redisson -->\n<dependency>\n    <groupId>org.redisson</groupId>\n    <artifactId>redisson</artifactId>\n    <version>3.3.2</version>\n</dependency>\n```\n\n#### 用法\n\n首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似：\n\n```java\nConfig config1 = new Config();\nconfig1.useSingleServer().setAddress(\"redis://192.168.0.1:5378\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient1 = Redisson.create(config1);\n\nConfig config2 = new Config();\nconfig2.useSingleServer().setAddress(\"redis://192.168.0.1:5379\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient2 = Redisson.create(config2);\n\nConfig config3 = new Config();\nconfig3.useSingleServer().setAddress(\"redis://192.168.0.1:5380\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient3 = Redisson.create(config3);\n\nString resourceName = \"REDLOCK_KEY\";\n\nRLock lock1 = redissonClient1.getLock(resourceName);\nRLock lock2 = redissonClient2.getLock(resourceName);\nRLock lock3 = redissonClient3.getLock(resourceName);\n// 向3个redis实例尝试加锁\nRedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);\nboolean isLock;\ntry {\n    // isLock = redLock.tryLock();\n    // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。\n    isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS);\n    System.out.println(\"isLock = \"+isLock);\n    if (isLock) {\n        //TODO if get lock success, do something;\n    }\n} catch (Exception e) {\n} finally {\n    // 无论如何, 最后都要解锁\n    redLock.unlock();\n}\n```\n\n#### 唯一ID\n\n实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是**UUID+threadId**。入口在redissonClient.getLock(\"REDLOCK_KEY\")，源码在Redisson.java和RedissonLock.java中：\n\n\n```java\nprotected final UUID id = UUID.randomUUID();\nString getLockName(long threadId) {\n    return id + \":\" + threadId;\n}\n```\n\n#### 获取锁\n\n获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s：\n\n```java\n<T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {\n    internalLockLeaseTime = unit.toMillis(leaseTime);\n    // 获取锁时需要在redis实例上执行的lua命令\n    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,\n              // 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间）\n              \"if (redis.call('exists', KEYS[1]) == 0) then \" +\n                  \"redis.call('hset', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              // 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间\n              \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" +\n                  \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              // 获取分布式锁的KEY的失效时间毫秒数\n              \"return redis.call('pttl', KEYS[1]);\",\n              // 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2]\n                Collections.<Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId));\n}\n```\n\n获取锁的命令中，\n\n- **KEYS[1]**就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY；\n- **ARGV[1]**就是internalLockLeaseTime，即锁的租约时间，默认30s；\n- **ARGV[2]**就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId：\n\n------\n\n#### 释放锁\n\n释放锁的代码为redLock.unlock()，核心源码如下：\n\n```java\nprotected RFuture<Boolean> unlockInnerAsync(long threadId) {\n    // 释放锁时需要在redis实例上执行的lua命令\n    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,\n            // 如果分布式锁KEY不存在，那么向channel发布一条消息\n            \"if (redis.call('exists', KEYS[1]) == 0) then \" +\n                \"redis.call('publish', KEYS[2], ARGV[1]); \" +\n                \"return 1; \" +\n            \"end;\" +\n            // 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回\n            \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" +\n                \"return nil;\" +\n            \"end; \" +\n            // 如果就是当前线程占有分布式锁，那么将重入次数减1\n            \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" +\n            // 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除\n            \"if (counter > 0) then \" +\n                \"redis.call('pexpire', KEYS[1], ARGV[2]); \" +\n                \"return 0; \" +\n            \"else \" +\n                // 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息\n                \"redis.call('del', KEYS[1]); \" +\n                \"redis.call('publish', KEYS[2], ARGV[1]); \" +\n                \"return 1; \"+\n            \"end; \" +\n            \"return nil;\",\n            // 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3]\n            Arrays.<Object>asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));\n\n}\n```\n\n## 四、相关问题\n\n**RedLock算法是否是异步算法？？**\n\n可以看成是同步算法；因为 即使进程间（多个电脑间）没有同步时钟，但是每个进程时间流速大致相同；并且时钟漂移相对于TTL叫小，可以忽略，所以可以看成同步算法；（不够严谨，算法上要算上时钟漂移，因为如果两个电脑在地球两端，则时钟漂移非常大）\n\n\n**RedLock失败重试**\n\n当client不能获取锁时，应该在随机时间后重试获取锁；并且最好在同一时刻并发的把set命令发送给所有redis实例；而且对于已经获取锁的client在完成任务后要及时释放锁，这是为了节省时间；\n \n\n**RedLock释放锁**\n\n由于释放锁时会判断这个锁的value是不是自己设置的，如果是才删除；所以在释放锁时非常简单，只要向所有实例都发出释放锁的命令，不用考虑能否成功释放锁；\n\n \n\n**RedLock注意点（Safety arguments）:**\n\n1. 先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移;\n\n2. 对于以N/2+ 1(也就是一半以 上)的方式判断获取锁成功，是因为如果小于一半判断为成功的话，有可能出现多个client都成功获取锁的情况， 从而使锁失效\n\n3. 一个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效，并且解锁这个redis实例(不执行业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁;否则无效\n\n \n\n**系统有活性的三个特征**\n\n1. 能够自动释放锁\n\n2. 在获取锁失败（不到一半以上），或任务完成后 能够自动释放锁，不用等到其自动过期\n\n3. 在client重试获取哦锁前（第一次失败到第二次重试时间间隔）大于第一次获取锁消耗的时间；\n\n4. 重试获取锁要有一定次数限制\n\n \n\n**RedLock性能及崩溃恢复的相关解决方法**\n\n1. 如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁的排他互斥性;\n\n2. 如果启动AOF永久化存储，事情会好些， 举例:当我们重启redis后，由于redis过期机制是按照unix时间戳走的，所以在重启后，然后会按照规定的时间过期，不影响业务;但是由于AOF同步到磁盘的方式默认是每秒-次，如果在一秒内断电，会导致数据丢失，立即重启会造成锁互斥性失效;但如果同步磁盘方式使用Always(每一个写命令都同步到硬盘)造成性能急剧下降;所以在锁完全有效性和性能方面要有所取舍; \n\n3. 有效解决既保证锁完全有效性及性能高效及即使断电情况的方法是redis同步到磁盘方式保持默认的每秒，在redis无论因为什么原因停掉后要等待TTL时间后再重启(学名:**延迟重启**) ;缺点是 在TTL时间内服务相当于暂停状态;\n\n \n\n## 五、总结\n\n1. TTL时长 要大于正常业务执行的时间+获取所有redis服务消耗时间+时钟漂移\n2. 获取redis所有服务消耗时间要 远小于TTL时间，并且获取成功的锁个数要 在总数的一般以上:N/2+1\n3. 尝试获取每个redis实例锁时的时间要 远小于TTL时间\n4. 尝试获取所有锁失败后 重新尝试一定要有一定次数限制\n5. 在redis崩溃后（无论一个还是所有），要延迟TTL时间重启redis\n6. 在实现多redis节点时要结合单节点分布式锁算法 共同实现","source":"_posts/re0-redis-redlock.md","raw":"---\ntitle: redlock设计\ndate: 2021-09-14 01:52:43\ntags: 从0开始的Redis\n---\n## 零、从问题出发\n\n## 一、介绍\n\n> Redlock：全名叫做 Redis Distributed Lock;即使用redis实现的分布式锁；\n\n使用场景：多个服务间保证同一时刻同一时间段内同一用户只能有一个请求（防止关键业务出现并发攻击）；\n\n官网文档地址如下：https://redis.io/topics/distlock\n\n这个锁的算法实现了多redis实例的情况，相对于单redis节点来说，**优点**在于 防止了 单节点故障造成整个服务停止运行的情况；并且在多节点中锁的设计，及多节点同时崩溃等各种意外情况有自己独特的设计方法；\n\n此博客或者官方文档的相关概念：\n1. TTL：Time To Live;只 redis key 的过期时间或有效生存时间\n2. clock drift:时钟漂移；指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程间）时间的差值；如果电脑距离过远会造成时钟漂移值 过大\n\nredis常用的方式有单节点、主从模式、哨兵模式、集群模式。\n单节点在生产环境基本上不会使用，因为不能达到高可用，且连RDB或AOF备份都只能放在master上，所以基本上不会使用。\n另外几种模式都无法避免两个问题：\n1. 异步数据丢失。\n2. 脑裂问题。\n\n最低保证分布式锁的有效性及安全性的要求如下：\n1. 互斥；任何时刻只能有一个client获取锁\n2. 释放死锁；即使锁定资源的服务崩溃或者分区，仍然能释放锁\n3. 容错性；只要多数redis节点（一半以上）在使用，client就可以获取和释放锁\n\n## 二、具体实现\n\nantirez提出的redlock算法大概是这样的：\n\n在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。\n\n为了取到锁，客户端应该执行以下操作:\n\n- 获取当前Unix时间，以毫秒为单位。\n- 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。\n- 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。\n- 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。\n- 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。\n\n## Redlock源码\n\nredisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。\n\n- POM依赖\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.redisson/redisson -->\n<dependency>\n    <groupId>org.redisson</groupId>\n    <artifactId>redisson</artifactId>\n    <version>3.3.2</version>\n</dependency>\n```\n\n#### 用法\n\n首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似：\n\n```java\nConfig config1 = new Config();\nconfig1.useSingleServer().setAddress(\"redis://192.168.0.1:5378\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient1 = Redisson.create(config1);\n\nConfig config2 = new Config();\nconfig2.useSingleServer().setAddress(\"redis://192.168.0.1:5379\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient2 = Redisson.create(config2);\n\nConfig config3 = new Config();\nconfig3.useSingleServer().setAddress(\"redis://192.168.0.1:5380\")\n        .setPassword(\"a123456\").setDatabase(0);\nRedissonClient redissonClient3 = Redisson.create(config3);\n\nString resourceName = \"REDLOCK_KEY\";\n\nRLock lock1 = redissonClient1.getLock(resourceName);\nRLock lock2 = redissonClient2.getLock(resourceName);\nRLock lock3 = redissonClient3.getLock(resourceName);\n// 向3个redis实例尝试加锁\nRedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);\nboolean isLock;\ntry {\n    // isLock = redLock.tryLock();\n    // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。\n    isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS);\n    System.out.println(\"isLock = \"+isLock);\n    if (isLock) {\n        //TODO if get lock success, do something;\n    }\n} catch (Exception e) {\n} finally {\n    // 无论如何, 最后都要解锁\n    redLock.unlock();\n}\n```\n\n#### 唯一ID\n\n实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是**UUID+threadId**。入口在redissonClient.getLock(\"REDLOCK_KEY\")，源码在Redisson.java和RedissonLock.java中：\n\n\n```java\nprotected final UUID id = UUID.randomUUID();\nString getLockName(long threadId) {\n    return id + \":\" + threadId;\n}\n```\n\n#### 获取锁\n\n获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s：\n\n```java\n<T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {\n    internalLockLeaseTime = unit.toMillis(leaseTime);\n    // 获取锁时需要在redis实例上执行的lua命令\n    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,\n              // 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间）\n              \"if (redis.call('exists', KEYS[1]) == 0) then \" +\n                  \"redis.call('hset', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              // 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间\n              \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" +\n                  \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              // 获取分布式锁的KEY的失效时间毫秒数\n              \"return redis.call('pttl', KEYS[1]);\",\n              // 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2]\n                Collections.<Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId));\n}\n```\n\n获取锁的命令中，\n\n- **KEYS[1]**就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY；\n- **ARGV[1]**就是internalLockLeaseTime，即锁的租约时间，默认30s；\n- **ARGV[2]**就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId：\n\n------\n\n#### 释放锁\n\n释放锁的代码为redLock.unlock()，核心源码如下：\n\n```java\nprotected RFuture<Boolean> unlockInnerAsync(long threadId) {\n    // 释放锁时需要在redis实例上执行的lua命令\n    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,\n            // 如果分布式锁KEY不存在，那么向channel发布一条消息\n            \"if (redis.call('exists', KEYS[1]) == 0) then \" +\n                \"redis.call('publish', KEYS[2], ARGV[1]); \" +\n                \"return 1; \" +\n            \"end;\" +\n            // 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回\n            \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" +\n                \"return nil;\" +\n            \"end; \" +\n            // 如果就是当前线程占有分布式锁，那么将重入次数减1\n            \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" +\n            // 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除\n            \"if (counter > 0) then \" +\n                \"redis.call('pexpire', KEYS[1], ARGV[2]); \" +\n                \"return 0; \" +\n            \"else \" +\n                // 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息\n                \"redis.call('del', KEYS[1]); \" +\n                \"redis.call('publish', KEYS[2], ARGV[1]); \" +\n                \"return 1; \"+\n            \"end; \" +\n            \"return nil;\",\n            // 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3]\n            Arrays.<Object>asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));\n\n}\n```\n\n## 四、相关问题\n\n**RedLock算法是否是异步算法？？**\n\n可以看成是同步算法；因为 即使进程间（多个电脑间）没有同步时钟，但是每个进程时间流速大致相同；并且时钟漂移相对于TTL叫小，可以忽略，所以可以看成同步算法；（不够严谨，算法上要算上时钟漂移，因为如果两个电脑在地球两端，则时钟漂移非常大）\n\n\n**RedLock失败重试**\n\n当client不能获取锁时，应该在随机时间后重试获取锁；并且最好在同一时刻并发的把set命令发送给所有redis实例；而且对于已经获取锁的client在完成任务后要及时释放锁，这是为了节省时间；\n \n\n**RedLock释放锁**\n\n由于释放锁时会判断这个锁的value是不是自己设置的，如果是才删除；所以在释放锁时非常简单，只要向所有实例都发出释放锁的命令，不用考虑能否成功释放锁；\n\n \n\n**RedLock注意点（Safety arguments）:**\n\n1. 先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移;\n\n2. 对于以N/2+ 1(也就是一半以 上)的方式判断获取锁成功，是因为如果小于一半判断为成功的话，有可能出现多个client都成功获取锁的情况， 从而使锁失效\n\n3. 一个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效，并且解锁这个redis实例(不执行业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁;否则无效\n\n \n\n**系统有活性的三个特征**\n\n1. 能够自动释放锁\n\n2. 在获取锁失败（不到一半以上），或任务完成后 能够自动释放锁，不用等到其自动过期\n\n3. 在client重试获取哦锁前（第一次失败到第二次重试时间间隔）大于第一次获取锁消耗的时间；\n\n4. 重试获取锁要有一定次数限制\n\n \n\n**RedLock性能及崩溃恢复的相关解决方法**\n\n1. 如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁的排他互斥性;\n\n2. 如果启动AOF永久化存储，事情会好些， 举例:当我们重启redis后，由于redis过期机制是按照unix时间戳走的，所以在重启后，然后会按照规定的时间过期，不影响业务;但是由于AOF同步到磁盘的方式默认是每秒-次，如果在一秒内断电，会导致数据丢失，立即重启会造成锁互斥性失效;但如果同步磁盘方式使用Always(每一个写命令都同步到硬盘)造成性能急剧下降;所以在锁完全有效性和性能方面要有所取舍; \n\n3. 有效解决既保证锁完全有效性及性能高效及即使断电情况的方法是redis同步到磁盘方式保持默认的每秒，在redis无论因为什么原因停掉后要等待TTL时间后再重启(学名:**延迟重启**) ;缺点是 在TTL时间内服务相当于暂停状态;\n\n \n\n## 五、总结\n\n1. TTL时长 要大于正常业务执行的时间+获取所有redis服务消耗时间+时钟漂移\n2. 获取redis所有服务消耗时间要 远小于TTL时间，并且获取成功的锁个数要 在总数的一般以上:N/2+1\n3. 尝试获取每个redis实例锁时的时间要 远小于TTL时间\n4. 尝试获取所有锁失败后 重新尝试一定要有一定次数限制\n5. 在redis崩溃后（无论一个还是所有），要延迟TTL时间重启redis\n6. 在实现多redis节点时要结合单节点分布式锁算法 共同实现","slug":"re0-redis-redlock","published":1,"updated":"2022-04-28T11:36:46.686Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg590000smauy21hpghej","content":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h2><blockquote>\n<p>Redlock：全名叫做 Redis Distributed Lock;即使用redis实现的分布式锁；</p>\n</blockquote>\n<p>使用场景：多个服务间保证同一时刻同一时间段内同一用户只能有一个请求（防止关键业务出现并发攻击）；</p>\n<p>官网文档地址如下：<a href=\"https://redis.io/topics/distlock\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/distlock</a></p>\n<p>这个锁的算法实现了多redis实例的情况，相对于单redis节点来说，<strong>优点</strong>在于 防止了 单节点故障造成整个服务停止运行的情况；并且在多节点中锁的设计，及多节点同时崩溃等各种意外情况有自己独特的设计方法；</p>\n<p>此博客或者官方文档的相关概念：</p>\n<ol>\n<li>TTL：Time To Live;只 redis key 的过期时间或有效生存时间</li>\n<li>clock drift:时钟漂移；指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程间）时间的差值；如果电脑距离过远会造成时钟漂移值 过大</li>\n</ol>\n<p>redis常用的方式有单节点、主从模式、哨兵模式、集群模式。<br>单节点在生产环境基本上不会使用，因为不能达到高可用，且连RDB或AOF备份都只能放在master上，所以基本上不会使用。<br>另外几种模式都无法避免两个问题：</p>\n<ol>\n<li>异步数据丢失。</li>\n<li>脑裂问题。</li>\n</ol>\n<p>最低保证分布式锁的有效性及安全性的要求如下：</p>\n<ol>\n<li>互斥；任何时刻只能有一个client获取锁</li>\n<li>释放死锁；即使锁定资源的服务崩溃或者分区，仍然能释放锁</li>\n<li>容错性；只要多数redis节点（一半以上）在使用，client就可以获取和释放锁</li>\n</ol>\n<h2 id=\"二、具体实现\"><a href=\"#二、具体实现\" class=\"headerlink\" title=\"二、具体实现\"></a>二、具体实现</h2><p>antirez提出的redlock算法大概是这样的：</p>\n<p>在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。</p>\n<p>为了取到锁，客户端应该执行以下操作:</p>\n<ul>\n<li>获取当前Unix时间，以毫秒为单位。</li>\n<li>依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li>\n<li>客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。</li>\n<li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>\n<li>如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li>\n</ul>\n<h2 id=\"Redlock源码\"><a href=\"#Redlock源码\" class=\"headerlink\" title=\"Redlock源码\"></a>Redlock源码</h2><p>redisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。</p>\n<ul>\n<li>POM依赖</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.redisson<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>redisson<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.3.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h4><p>首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Config config1 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config1.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5378\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient1 = Redisson.create(config1);</span><br><span class=\"line\"></span><br><span class=\"line\">Config config2 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config2.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5379\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient2 = Redisson.create(config2);</span><br><span class=\"line\"></span><br><span class=\"line\">Config config3 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config3.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5380\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient3 = Redisson.create(config3);</span><br><span class=\"line\"></span><br><span class=\"line\">String resourceName = <span class=\"string\">\"REDLOCK_KEY\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">RLock lock1 = redissonClient1.getLock(resourceName);</span><br><span class=\"line\">RLock lock2 = redissonClient2.getLock(resourceName);</span><br><span class=\"line\">RLock lock3 = redissonClient3.getLock(resourceName);</span><br><span class=\"line\"><span class=\"comment\">// 向3个redis实例尝试加锁</span></span><br><span class=\"line\">RedissonRedLock redLock = <span class=\"keyword\">new</span> RedissonRedLock(lock1, lock2, lock3);</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isLock;</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// isLock = redLock.tryLock();</span></span><br><span class=\"line\">    <span class=\"comment\">// 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。</span></span><br><span class=\"line\">    isLock = redLock.tryLock(<span class=\"number\">500</span>, <span class=\"number\">10000</span>, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"isLock = \"</span>+isLock);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (isLock) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO if get lock success, do something;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 无论如何, 最后都要解锁</span></span><br><span class=\"line\">    redLock.unlock();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"唯一ID\"><a href=\"#唯一ID\" class=\"headerlink\" title=\"唯一ID\"></a>唯一ID</h4><p>实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是<strong>UUID+threadId</strong>。入口在redissonClient.getLock(“REDLOCK_KEY”)，源码在Redisson.java和RedissonLock.java中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> <span class=\"keyword\">final</span> UUID id = UUID.randomUUID();</span><br><span class=\"line\"><span class=\"function\">String <span class=\"title\">getLockName</span><span class=\"params\">(<span class=\"keyword\">long</span> threadId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> id + <span class=\"string\">\":\"</span> + threadId;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"获取锁\"><a href=\"#获取锁\" class=\"headerlink\" title=\"获取锁\"></a>获取锁</h4><p>获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;T&gt; <span class=\"function\">RFuture&lt;T&gt; <span class=\"title\">tryLockInnerAsync</span><span class=\"params\">(<span class=\"keyword\">long</span> leaseTime, TimeUnit unit, <span class=\"keyword\">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class=\"line\">    internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class=\"line\">    <span class=\"comment\">// 获取锁时需要在redis实例上执行的lua命令</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,</span><br><span class=\"line\">              <span class=\"comment\">// 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间）</span></span><br><span class=\"line\">              <span class=\"string\">\"if (redis.call('exists', KEYS[1]) == 0) then \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('hset', KEYS[1], ARGV[2], 1); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[1]); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"return nil; \"</span> +</span><br><span class=\"line\">              <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">              <span class=\"comment\">// 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间</span></span><br><span class=\"line\">              <span class=\"string\">\"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('hincrby', KEYS[1], ARGV[2], 1); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[1]); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"return nil; \"</span> +</span><br><span class=\"line\">              <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">              <span class=\"comment\">// 获取分布式锁的KEY的失效时间毫秒数</span></span><br><span class=\"line\">              <span class=\"string\">\"return redis.call('pttl', KEYS[1]);\"</span>,</span><br><span class=\"line\">              <span class=\"comment\">// 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2]</span></span><br><span class=\"line\">                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>获取锁的命令中，</p>\n<ul>\n<li><strong>KEYS[1]</strong>就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY；</li>\n<li><strong>ARGV[1]</strong>就是internalLockLeaseTime，即锁的租约时间，默认30s；</li>\n<li><strong>ARGV[2]</strong>就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId：</li>\n</ul>\n<hr>\n<h4 id=\"释放锁\"><a href=\"#释放锁\" class=\"headerlink\" title=\"释放锁\"></a>释放锁</h4><p>释放锁的代码为redLock.unlock()，核心源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> RFuture&lt;Boolean&gt; <span class=\"title\">unlockInnerAsync</span><span class=\"params\">(<span class=\"keyword\">long</span> threadId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 释放锁时需要在redis实例上执行的lua命令</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class=\"line\">            <span class=\"comment\">// 如果分布式锁KEY不存在，那么向channel发布一条消息</span></span><br><span class=\"line\">            <span class=\"string\">\"if (redis.call('exists', KEYS[1]) == 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('publish', KEYS[2], ARGV[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 1; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"end;\"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回</span></span><br><span class=\"line\">            <span class=\"string\">\"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return nil;\"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 如果就是当前线程占有分布式锁，那么将重入次数减1</span></span><br><span class=\"line\">            <span class=\"string\">\"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除</span></span><br><span class=\"line\">            <span class=\"string\">\"if (counter &gt; 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[2]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 0; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"else \"</span> +</span><br><span class=\"line\">                <span class=\"comment\">// 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息</span></span><br><span class=\"line\">                <span class=\"string\">\"redis.call('del', KEYS[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('publish', KEYS[2], ARGV[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 1; \"</span>+</span><br><span class=\"line\">            <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"return nil;\"</span>,</span><br><span class=\"line\">            <span class=\"comment\">// 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3]</span></span><br><span class=\"line\">            Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"四、相关问题\"><a href=\"#四、相关问题\" class=\"headerlink\" title=\"四、相关问题\"></a>四、相关问题</h2><p><strong>RedLock算法是否是异步算法？？</strong></p>\n<p>可以看成是同步算法；因为 即使进程间（多个电脑间）没有同步时钟，但是每个进程时间流速大致相同；并且时钟漂移相对于TTL叫小，可以忽略，所以可以看成同步算法；（不够严谨，算法上要算上时钟漂移，因为如果两个电脑在地球两端，则时钟漂移非常大）</p>\n<p><strong>RedLock失败重试</strong></p>\n<p>当client不能获取锁时，应该在随机时间后重试获取锁；并且最好在同一时刻并发的把set命令发送给所有redis实例；而且对于已经获取锁的client在完成任务后要及时释放锁，这是为了节省时间；</p>\n<p><strong>RedLock释放锁</strong></p>\n<p>由于释放锁时会判断这个锁的value是不是自己设置的，如果是才删除；所以在释放锁时非常简单，只要向所有实例都发出释放锁的命令，不用考虑能否成功释放锁；</p>\n<p><strong>RedLock注意点（Safety arguments）:</strong></p>\n<ol>\n<li><p>先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移;</p>\n</li>\n<li><p>对于以N/2+ 1(也就是一半以 上)的方式判断获取锁成功，是因为如果小于一半判断为成功的话，有可能出现多个client都成功获取锁的情况， 从而使锁失效</p>\n</li>\n<li><p>一个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效，并且解锁这个redis实例(不执行业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁;否则无效</p>\n</li>\n</ol>\n<p><strong>系统有活性的三个特征</strong></p>\n<ol>\n<li><p>能够自动释放锁</p>\n</li>\n<li><p>在获取锁失败（不到一半以上），或任务完成后 能够自动释放锁，不用等到其自动过期</p>\n</li>\n<li><p>在client重试获取哦锁前（第一次失败到第二次重试时间间隔）大于第一次获取锁消耗的时间；</p>\n</li>\n<li><p>重试获取锁要有一定次数限制</p>\n</li>\n</ol>\n<p><strong>RedLock性能及崩溃恢复的相关解决方法</strong></p>\n<ol>\n<li><p>如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁的排他互斥性;</p>\n</li>\n<li><p>如果启动AOF永久化存储，事情会好些， 举例:当我们重启redis后，由于redis过期机制是按照unix时间戳走的，所以在重启后，然后会按照规定的时间过期，不影响业务;但是由于AOF同步到磁盘的方式默认是每秒-次，如果在一秒内断电，会导致数据丢失，立即重启会造成锁互斥性失效;但如果同步磁盘方式使用Always(每一个写命令都同步到硬盘)造成性能急剧下降;所以在锁完全有效性和性能方面要有所取舍; </p>\n</li>\n<li><p>有效解决既保证锁完全有效性及性能高效及即使断电情况的方法是redis同步到磁盘方式保持默认的每秒，在redis无论因为什么原因停掉后要等待TTL时间后再重启(学名:<strong>延迟重启</strong>) ;缺点是 在TTL时间内服务相当于暂停状态;</p>\n</li>\n</ol>\n<h2 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h2><ol>\n<li>TTL时长 要大于正常业务执行的时间+获取所有redis服务消耗时间+时钟漂移</li>\n<li>获取redis所有服务消耗时间要 远小于TTL时间，并且获取成功的锁个数要 在总数的一般以上:N/2+1</li>\n<li>尝试获取每个redis实例锁时的时间要 远小于TTL时间</li>\n<li>尝试获取所有锁失败后 重新尝试一定要有一定次数限制</li>\n<li>在redis崩溃后（无论一个还是所有），要延迟TTL时间重启redis</li>\n<li>在实现多redis节点时要结合单节点分布式锁算法 共同实现</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h2><blockquote>\n<p>Redlock：全名叫做 Redis Distributed Lock;即使用redis实现的分布式锁；</p>\n</blockquote>\n<p>使用场景：多个服务间保证同一时刻同一时间段内同一用户只能有一个请求（防止关键业务出现并发攻击）；</p>\n<p>官网文档地址如下：<a href=\"https://redis.io/topics/distlock\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/distlock</a></p>\n<p>这个锁的算法实现了多redis实例的情况，相对于单redis节点来说，<strong>优点</strong>在于 防止了 单节点故障造成整个服务停止运行的情况；并且在多节点中锁的设计，及多节点同时崩溃等各种意外情况有自己独特的设计方法；</p>\n<p>此博客或者官方文档的相关概念：</p>\n<ol>\n<li>TTL：Time To Live;只 redis key 的过期时间或有效生存时间</li>\n<li>clock drift:时钟漂移；指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程间）时间的差值；如果电脑距离过远会造成时钟漂移值 过大</li>\n</ol>\n<p>redis常用的方式有单节点、主从模式、哨兵模式、集群模式。<br>单节点在生产环境基本上不会使用，因为不能达到高可用，且连RDB或AOF备份都只能放在master上，所以基本上不会使用。<br>另外几种模式都无法避免两个问题：</p>\n<ol>\n<li>异步数据丢失。</li>\n<li>脑裂问题。</li>\n</ol>\n<p>最低保证分布式锁的有效性及安全性的要求如下：</p>\n<ol>\n<li>互斥；任何时刻只能有一个client获取锁</li>\n<li>释放死锁；即使锁定资源的服务崩溃或者分区，仍然能释放锁</li>\n<li>容错性；只要多数redis节点（一半以上）在使用，client就可以获取和释放锁</li>\n</ol>\n<h2 id=\"二、具体实现\"><a href=\"#二、具体实现\" class=\"headerlink\" title=\"二、具体实现\"></a>二、具体实现</h2><p>antirez提出的redlock算法大概是这样的：</p>\n<p>在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。</p>\n<p>为了取到锁，客户端应该执行以下操作:</p>\n<ul>\n<li>获取当前Unix时间，以毫秒为单位。</li>\n<li>依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li>\n<li>客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。</li>\n<li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>\n<li>如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li>\n</ul>\n<h2 id=\"Redlock源码\"><a href=\"#Redlock源码\" class=\"headerlink\" title=\"Redlock源码\"></a>Redlock源码</h2><p>redisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。</p>\n<ul>\n<li>POM依赖</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.redisson<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>redisson<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.3.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h4><p>首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Config config1 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config1.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5378\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient1 = Redisson.create(config1);</span><br><span class=\"line\"></span><br><span class=\"line\">Config config2 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config2.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5379\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient2 = Redisson.create(config2);</span><br><span class=\"line\"></span><br><span class=\"line\">Config config3 = <span class=\"keyword\">new</span> Config();</span><br><span class=\"line\">config3.useSingleServer().setAddress(<span class=\"string\">\"redis://192.168.0.1:5380\"</span>)</span><br><span class=\"line\">        .setPassword(<span class=\"string\">\"a123456\"</span>).setDatabase(<span class=\"number\">0</span>);</span><br><span class=\"line\">RedissonClient redissonClient3 = Redisson.create(config3);</span><br><span class=\"line\"></span><br><span class=\"line\">String resourceName = <span class=\"string\">\"REDLOCK_KEY\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">RLock lock1 = redissonClient1.getLock(resourceName);</span><br><span class=\"line\">RLock lock2 = redissonClient2.getLock(resourceName);</span><br><span class=\"line\">RLock lock3 = redissonClient3.getLock(resourceName);</span><br><span class=\"line\"><span class=\"comment\">// 向3个redis实例尝试加锁</span></span><br><span class=\"line\">RedissonRedLock redLock = <span class=\"keyword\">new</span> RedissonRedLock(lock1, lock2, lock3);</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isLock;</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// isLock = redLock.tryLock();</span></span><br><span class=\"line\">    <span class=\"comment\">// 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。</span></span><br><span class=\"line\">    isLock = redLock.tryLock(<span class=\"number\">500</span>, <span class=\"number\">10000</span>, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"isLock = \"</span>+isLock);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (isLock) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO if get lock success, do something;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 无论如何, 最后都要解锁</span></span><br><span class=\"line\">    redLock.unlock();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"唯一ID\"><a href=\"#唯一ID\" class=\"headerlink\" title=\"唯一ID\"></a>唯一ID</h4><p>实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是<strong>UUID+threadId</strong>。入口在redissonClient.getLock(“REDLOCK_KEY”)，源码在Redisson.java和RedissonLock.java中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> <span class=\"keyword\">final</span> UUID id = UUID.randomUUID();</span><br><span class=\"line\"><span class=\"function\">String <span class=\"title\">getLockName</span><span class=\"params\">(<span class=\"keyword\">long</span> threadId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> id + <span class=\"string\">\":\"</span> + threadId;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"获取锁\"><a href=\"#获取锁\" class=\"headerlink\" title=\"获取锁\"></a>获取锁</h4><p>获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;T&gt; <span class=\"function\">RFuture&lt;T&gt; <span class=\"title\">tryLockInnerAsync</span><span class=\"params\">(<span class=\"keyword\">long</span> leaseTime, TimeUnit unit, <span class=\"keyword\">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class=\"line\">    internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class=\"line\">    <span class=\"comment\">// 获取锁时需要在redis实例上执行的lua命令</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,</span><br><span class=\"line\">              <span class=\"comment\">// 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间）</span></span><br><span class=\"line\">              <span class=\"string\">\"if (redis.call('exists', KEYS[1]) == 0) then \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('hset', KEYS[1], ARGV[2], 1); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[1]); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"return nil; \"</span> +</span><br><span class=\"line\">              <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">              <span class=\"comment\">// 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间</span></span><br><span class=\"line\">              <span class=\"string\">\"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('hincrby', KEYS[1], ARGV[2], 1); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[1]); \"</span> +</span><br><span class=\"line\">                  <span class=\"string\">\"return nil; \"</span> +</span><br><span class=\"line\">              <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">              <span class=\"comment\">// 获取分布式锁的KEY的失效时间毫秒数</span></span><br><span class=\"line\">              <span class=\"string\">\"return redis.call('pttl', KEYS[1]);\"</span>,</span><br><span class=\"line\">              <span class=\"comment\">// 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2]</span></span><br><span class=\"line\">                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>获取锁的命令中，</p>\n<ul>\n<li><strong>KEYS[1]</strong>就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY；</li>\n<li><strong>ARGV[1]</strong>就是internalLockLeaseTime，即锁的租约时间，默认30s；</li>\n<li><strong>ARGV[2]</strong>就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId：</li>\n</ul>\n<hr>\n<h4 id=\"释放锁\"><a href=\"#释放锁\" class=\"headerlink\" title=\"释放锁\"></a>释放锁</h4><p>释放锁的代码为redLock.unlock()，核心源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> RFuture&lt;Boolean&gt; <span class=\"title\">unlockInnerAsync</span><span class=\"params\">(<span class=\"keyword\">long</span> threadId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 释放锁时需要在redis实例上执行的lua命令</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class=\"line\">            <span class=\"comment\">// 如果分布式锁KEY不存在，那么向channel发布一条消息</span></span><br><span class=\"line\">            <span class=\"string\">\"if (redis.call('exists', KEYS[1]) == 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('publish', KEYS[2], ARGV[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 1; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"end;\"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回</span></span><br><span class=\"line\">            <span class=\"string\">\"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return nil;\"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 如果就是当前线程占有分布式锁，那么将重入次数减1</span></span><br><span class=\"line\">            <span class=\"string\">\"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \"</span> +</span><br><span class=\"line\">            <span class=\"comment\">// 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除</span></span><br><span class=\"line\">            <span class=\"string\">\"if (counter &gt; 0) then \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('pexpire', KEYS[1], ARGV[2]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 0; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"else \"</span> +</span><br><span class=\"line\">                <span class=\"comment\">// 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息</span></span><br><span class=\"line\">                <span class=\"string\">\"redis.call('del', KEYS[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"redis.call('publish', KEYS[2], ARGV[1]); \"</span> +</span><br><span class=\"line\">                <span class=\"string\">\"return 1; \"</span>+</span><br><span class=\"line\">            <span class=\"string\">\"end; \"</span> +</span><br><span class=\"line\">            <span class=\"string\">\"return nil;\"</span>,</span><br><span class=\"line\">            <span class=\"comment\">// 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3]</span></span><br><span class=\"line\">            Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"四、相关问题\"><a href=\"#四、相关问题\" class=\"headerlink\" title=\"四、相关问题\"></a>四、相关问题</h2><p><strong>RedLock算法是否是异步算法？？</strong></p>\n<p>可以看成是同步算法；因为 即使进程间（多个电脑间）没有同步时钟，但是每个进程时间流速大致相同；并且时钟漂移相对于TTL叫小，可以忽略，所以可以看成同步算法；（不够严谨，算法上要算上时钟漂移，因为如果两个电脑在地球两端，则时钟漂移非常大）</p>\n<p><strong>RedLock失败重试</strong></p>\n<p>当client不能获取锁时，应该在随机时间后重试获取锁；并且最好在同一时刻并发的把set命令发送给所有redis实例；而且对于已经获取锁的client在完成任务后要及时释放锁，这是为了节省时间；</p>\n<p><strong>RedLock释放锁</strong></p>\n<p>由于释放锁时会判断这个锁的value是不是自己设置的，如果是才删除；所以在释放锁时非常简单，只要向所有实例都发出释放锁的命令，不用考虑能否成功释放锁；</p>\n<p><strong>RedLock注意点（Safety arguments）:</strong></p>\n<ol>\n<li><p>先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移;</p>\n</li>\n<li><p>对于以N/2+ 1(也就是一半以 上)的方式判断获取锁成功，是因为如果小于一半判断为成功的话，有可能出现多个client都成功获取锁的情况， 从而使锁失效</p>\n</li>\n<li><p>一个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效，并且解锁这个redis实例(不执行业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁;否则无效</p>\n</li>\n</ol>\n<p><strong>系统有活性的三个特征</strong></p>\n<ol>\n<li><p>能够自动释放锁</p>\n</li>\n<li><p>在获取锁失败（不到一半以上），或任务完成后 能够自动释放锁，不用等到其自动过期</p>\n</li>\n<li><p>在client重试获取哦锁前（第一次失败到第二次重试时间间隔）大于第一次获取锁消耗的时间；</p>\n</li>\n<li><p>重试获取锁要有一定次数限制</p>\n</li>\n</ol>\n<p><strong>RedLock性能及崩溃恢复的相关解决方法</strong></p>\n<ol>\n<li><p>如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁的排他互斥性;</p>\n</li>\n<li><p>如果启动AOF永久化存储，事情会好些， 举例:当我们重启redis后，由于redis过期机制是按照unix时间戳走的，所以在重启后，然后会按照规定的时间过期，不影响业务;但是由于AOF同步到磁盘的方式默认是每秒-次，如果在一秒内断电，会导致数据丢失，立即重启会造成锁互斥性失效;但如果同步磁盘方式使用Always(每一个写命令都同步到硬盘)造成性能急剧下降;所以在锁完全有效性和性能方面要有所取舍; </p>\n</li>\n<li><p>有效解决既保证锁完全有效性及性能高效及即使断电情况的方法是redis同步到磁盘方式保持默认的每秒，在redis无论因为什么原因停掉后要等待TTL时间后再重启(学名:<strong>延迟重启</strong>) ;缺点是 在TTL时间内服务相当于暂停状态;</p>\n</li>\n</ol>\n<h2 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h2><ol>\n<li>TTL时长 要大于正常业务执行的时间+获取所有redis服务消耗时间+时钟漂移</li>\n<li>获取redis所有服务消耗时间要 远小于TTL时间，并且获取成功的锁个数要 在总数的一般以上:N/2+1</li>\n<li>尝试获取每个redis实例锁时的时间要 远小于TTL时间</li>\n<li>尝试获取所有锁失败后 重新尝试一定要有一定次数限制</li>\n<li>在redis崩溃后（无论一个还是所有），要延迟TTL时间重启redis</li>\n<li>在实现多redis节点时要结合单节点分布式锁算法 共同实现</li>\n</ol>\n"},{"title":"从0开始的Mysql学习","date":"2021-09-13T18:04:44.000Z","_content":"\n- 基本类型\n- 索引原理\n- 关于锁\n- 关于mvcc\n- 关于binlog的一些事\n- 关于优化器\n- ","source":"_posts/re0-mysql.md","raw":"---\ntitle: 从0开始的Mysql学习\ndate: 2021-09-14 02:04:44\ntags: 从0开始的Mysql\n---\n\n- 基本类型\n- 索引原理\n- 关于锁\n- 关于mvcc\n- 关于binlog的一些事\n- 关于优化器\n- ","slug":"re0-mysql","published":1,"updated":"2022-04-28T11:36:46.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg592000vmauy91s3671d","content":"<ul>\n<li>基本类型</li>\n<li>索引原理</li>\n<li>关于锁</li>\n<li>关于mvcc</li>\n<li>关于binlog的一些事</li>\n<li>关于优化器</li>\n<li></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>基本类型</li>\n<li>索引原理</li>\n<li>关于锁</li>\n<li>关于mvcc</li>\n<li>关于binlog的一些事</li>\n<li>关于优化器</li>\n<li></li>\n</ul>\n"},{"title":"Redis数据类型","date":"2021-09-13T17:41:41.000Z","_content":"\n## 零、从问题出发\n\n\n\n## 一、 Redis介绍\n概念：Redis是用C语言开发的一个开源的高性能键值对数据库。\n\n特征：\n\n- 数据间没有必然的联系\n- 内部采用单线程机制进行工作\n- 高性能\n- 多数据类型支持\n    - 字符串类型 String\n    - 列表类型 List\n    - 散列类型 Map\n    - 集合类型 Set\n    - 有序集合类型 SortedSet\n- 持久化支持\n\n应用场景：\n- 为热点数据加速查询；如：热点商品、热点新闻、热点资讯等高访问量信息。\n- 任务队列；如：秒杀、抢购、购票等。\n- 即时信息查询；如：排行榜等。\n- 时效性信息控制；如：验证码、投票控制等。\n- 分布式数据共享；如：分布式架构中的session等。\n- 消息队列\n- 分布式锁\n\n## 二、类型介绍\n\n### 字符串类型\n\n- 能存储任何形式的字符串，包括二进制数据\n- 一个字符类型键允许存储的最大容量是512M\n- 内部数据结构\n    - 通过 int、SDS(simple dynamic string)作为结构存储\n    - int用来存放整型数据，sds存放字节/字符串和浮点型数据\n    - redis3.2分支引入了五种sdshdr类型，\n    - 目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存\n\n### 列表类型\n- 列表类型内部使用双向链表实现\n- value对象内部以linkedlist或者ziplist来实现\n    - 当list的元素个数和单个元素的长度比较小的时候，\n        - Redis会采用ziplist（压缩列表）来实现来减少内存占用。\n    - 否则就会采用linkedlist（双向链表）结构。\n- redis3.2之后，采用的一种叫quicklist的数据结构\n    - 二者结合\n    - quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist\n\n### hash类型\n\nhash提供两种结构来存储，一种是hashtable、另一种是前面讲的ziplist，数据量小的时候用ziplist.\n\n在redis中，哈希表分为三层\n\n- dictEntry\n    - 管理一个key-value，\n    - 同时保留同一个桶(bucket)中相邻元素的指针，\n    - 用来维护哈希桶(bucket)的**内部链**；\n\n```cpp\n        typedef struct dictEntry {\n        void *key;\n        union { //因为value有多种类型，所以value用了union来存储\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n        } v;\n        struct dictEntry *next;\n        //下一个节点的地址，用来处理碰撞，所有分配到同一索引的元素通过next指针\n        //链接起来形成链表key和v都可以保存多种类型的数据\n        } dictEntry;\n        ```\n\n- dictht\n    - 实现一个hash表会使用一个**buckets**存放dictEntry的地址\n    - 通过hash(key)%len得到的值就是buckets的索引\n\n```cpp\n        typedef struct dictht {\n        dictEntry **table;//buckets的地址\n        unsigned long size;//buckets的大小,总保持为 2^n\n        unsigned long sizemask;//掩码，用来计算hash值对应的buckets索引\n        unsigned long used;//当前dictht有多少个dictEntry节点\n        } dictht;\n```\n\n- dict\n    - dictht实际上就是hash表的核心\n    - 只有一个dictht还不够，比如rehash、遍历hash等操作，\n    - 所以redis定义了一个叫dict的结构以支持字典的各种操作，\n    - 当dictht需要扩容/缩容时，用来管理dictht的迁移\n\n\n### 集合类型\n\n- 不能有重复数据，\n- 同时集合类型中的数据是无序的\n- 集合类型和列表类型的最大的区别是\n  - 有序性\n    - 列表有序\n  - 唯一性\n    - 集合唯一\n- 使用的值为空的散列表(hash table)，\n  - 所以这些操作的时间复杂度都是O(1).\n- 数据结构\n  - 底层数据结构以**intset**或者**hashtable**来存储\n\n### 有序集合\n\n- 有序集合类型为集合中的每个元素都关联了一个分数\n- 数据结构\n  - 内部是以ziplist或者skiplist+hashtable来实现\n  - skiplist，也就是跳跃表\n  - 跳跃表\n    - 跳跃表是一种随机化的数据结构，\n      - 在查找、插入和删除这些字典操作上，\n        - 其效率可比拟于平衡二叉树（如红黑树）","source":"_posts/re0-redis-struct.md","raw":"---\ntitle: Redis数据类型\ndate: 2021-09-14 01:41:41\ntags: 从0开始的Redis\n---\n\n## 零、从问题出发\n\n\n\n## 一、 Redis介绍\n概念：Redis是用C语言开发的一个开源的高性能键值对数据库。\n\n特征：\n\n- 数据间没有必然的联系\n- 内部采用单线程机制进行工作\n- 高性能\n- 多数据类型支持\n    - 字符串类型 String\n    - 列表类型 List\n    - 散列类型 Map\n    - 集合类型 Set\n    - 有序集合类型 SortedSet\n- 持久化支持\n\n应用场景：\n- 为热点数据加速查询；如：热点商品、热点新闻、热点资讯等高访问量信息。\n- 任务队列；如：秒杀、抢购、购票等。\n- 即时信息查询；如：排行榜等。\n- 时效性信息控制；如：验证码、投票控制等。\n- 分布式数据共享；如：分布式架构中的session等。\n- 消息队列\n- 分布式锁\n\n## 二、类型介绍\n\n### 字符串类型\n\n- 能存储任何形式的字符串，包括二进制数据\n- 一个字符类型键允许存储的最大容量是512M\n- 内部数据结构\n    - 通过 int、SDS(simple dynamic string)作为结构存储\n    - int用来存放整型数据，sds存放字节/字符串和浮点型数据\n    - redis3.2分支引入了五种sdshdr类型，\n    - 目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存\n\n### 列表类型\n- 列表类型内部使用双向链表实现\n- value对象内部以linkedlist或者ziplist来实现\n    - 当list的元素个数和单个元素的长度比较小的时候，\n        - Redis会采用ziplist（压缩列表）来实现来减少内存占用。\n    - 否则就会采用linkedlist（双向链表）结构。\n- redis3.2之后，采用的一种叫quicklist的数据结构\n    - 二者结合\n    - quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist\n\n### hash类型\n\nhash提供两种结构来存储，一种是hashtable、另一种是前面讲的ziplist，数据量小的时候用ziplist.\n\n在redis中，哈希表分为三层\n\n- dictEntry\n    - 管理一个key-value，\n    - 同时保留同一个桶(bucket)中相邻元素的指针，\n    - 用来维护哈希桶(bucket)的**内部链**；\n\n```cpp\n        typedef struct dictEntry {\n        void *key;\n        union { //因为value有多种类型，所以value用了union来存储\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n        } v;\n        struct dictEntry *next;\n        //下一个节点的地址，用来处理碰撞，所有分配到同一索引的元素通过next指针\n        //链接起来形成链表key和v都可以保存多种类型的数据\n        } dictEntry;\n        ```\n\n- dictht\n    - 实现一个hash表会使用一个**buckets**存放dictEntry的地址\n    - 通过hash(key)%len得到的值就是buckets的索引\n\n```cpp\n        typedef struct dictht {\n        dictEntry **table;//buckets的地址\n        unsigned long size;//buckets的大小,总保持为 2^n\n        unsigned long sizemask;//掩码，用来计算hash值对应的buckets索引\n        unsigned long used;//当前dictht有多少个dictEntry节点\n        } dictht;\n```\n\n- dict\n    - dictht实际上就是hash表的核心\n    - 只有一个dictht还不够，比如rehash、遍历hash等操作，\n    - 所以redis定义了一个叫dict的结构以支持字典的各种操作，\n    - 当dictht需要扩容/缩容时，用来管理dictht的迁移\n\n\n### 集合类型\n\n- 不能有重复数据，\n- 同时集合类型中的数据是无序的\n- 集合类型和列表类型的最大的区别是\n  - 有序性\n    - 列表有序\n  - 唯一性\n    - 集合唯一\n- 使用的值为空的散列表(hash table)，\n  - 所以这些操作的时间复杂度都是O(1).\n- 数据结构\n  - 底层数据结构以**intset**或者**hashtable**来存储\n\n### 有序集合\n\n- 有序集合类型为集合中的每个元素都关联了一个分数\n- 数据结构\n  - 内部是以ziplist或者skiplist+hashtable来实现\n  - skiplist，也就是跳跃表\n  - 跳跃表\n    - 跳跃表是一种随机化的数据结构，\n      - 在查找、插入和删除这些字典操作上，\n        - 其效率可比拟于平衡二叉树（如红黑树）","slug":"re0-redis-struct","published":1,"updated":"2022-04-28T11:36:46.709Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg593000xmauy4j4x3p9l","content":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、-Redis介绍\"><a href=\"#一、-Redis介绍\" class=\"headerlink\" title=\"一、 Redis介绍\"></a>一、 Redis介绍</h2><p>概念：Redis是用C语言开发的一个开源的高性能键值对数据库。</p>\n<p>特征：</p>\n<ul>\n<li>数据间没有必然的联系</li>\n<li>内部采用单线程机制进行工作</li>\n<li>高性能</li>\n<li>多数据类型支持<ul>\n<li>字符串类型 String</li>\n<li>列表类型 List</li>\n<li>散列类型 Map</li>\n<li>集合类型 Set</li>\n<li>有序集合类型 SortedSet</li>\n</ul>\n</li>\n<li>持久化支持</li>\n</ul>\n<p>应用场景：</p>\n<ul>\n<li>为热点数据加速查询；如：热点商品、热点新闻、热点资讯等高访问量信息。</li>\n<li>任务队列；如：秒杀、抢购、购票等。</li>\n<li>即时信息查询；如：排行榜等。</li>\n<li>时效性信息控制；如：验证码、投票控制等。</li>\n<li>分布式数据共享；如：分布式架构中的session等。</li>\n<li>消息队列</li>\n<li>分布式锁</li>\n</ul>\n<h2 id=\"二、类型介绍\"><a href=\"#二、类型介绍\" class=\"headerlink\" title=\"二、类型介绍\"></a>二、类型介绍</h2><h3 id=\"字符串类型\"><a href=\"#字符串类型\" class=\"headerlink\" title=\"字符串类型\"></a>字符串类型</h3><ul>\n<li>能存储任何形式的字符串，包括二进制数据</li>\n<li>一个字符类型键允许存储的最大容量是512M</li>\n<li>内部数据结构<ul>\n<li>通过 int、SDS(simple dynamic string)作为结构存储</li>\n<li>int用来存放整型数据，sds存放字节/字符串和浮点型数据</li>\n<li>redis3.2分支引入了五种sdshdr类型，</li>\n<li>目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"列表类型\"><a href=\"#列表类型\" class=\"headerlink\" title=\"列表类型\"></a>列表类型</h3><ul>\n<li>列表类型内部使用双向链表实现</li>\n<li>value对象内部以linkedlist或者ziplist来实现<ul>\n<li>当list的元素个数和单个元素的长度比较小的时候，<ul>\n<li>Redis会采用ziplist（压缩列表）来实现来减少内存占用。</li>\n</ul>\n</li>\n<li>否则就会采用linkedlist（双向链表）结构。</li>\n</ul>\n</li>\n<li>redis3.2之后，采用的一种叫quicklist的数据结构<ul>\n<li>二者结合</li>\n<li>quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"hash类型\"><a href=\"#hash类型\" class=\"headerlink\" title=\"hash类型\"></a>hash类型</h3><p>hash提供两种结构来存储，一种是hashtable、另一种是前面讲的ziplist，数据量小的时候用ziplist.</p>\n<p>在redis中，哈希表分为三层</p>\n<ul>\n<li>dictEntry<ul>\n<li>管理一个key-value，</li>\n<li>同时保留同一个桶(bucket)中相邻元素的指针，</li>\n<li>用来维护哈希桶(bucket)的<strong>内部链</strong>；</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictEntry</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> *key;</span><br><span class=\"line\"><span class=\"keyword\">union</span> &#123; <span class=\"comment\">//因为value有多种类型，所以value用了union来存储</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> *val;</span><br><span class=\"line\"><span class=\"keyword\">uint64_t</span> u64;</span><br><span class=\"line\"><span class=\"keyword\">int64_t</span> s64;</span><br><span class=\"line\"><span class=\"keyword\">double</span> d;</span><br><span class=\"line\">&#125; v;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictEntry</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\"><span class=\"comment\">//下一个节点的地址，用来处理碰撞，所有分配到同一索引的元素通过next指针</span></span><br><span class=\"line\"><span class=\"comment\">//链接起来形成链表key和v都可以保存多种类型的数据</span></span><br><span class=\"line\">&#125; dictEntry;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dictht<ul>\n<li>实现一个hash表会使用一个<strong>buckets</strong>存放dictEntry的地址</li>\n<li>通过hash(key)%len得到的值就是buckets的索引</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictht</span> &#123;</span></span><br><span class=\"line\">dictEntry **table;<span class=\"comment\">//buckets的地址</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> size;<span class=\"comment\">//buckets的大小,总保持为 2^n</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> sizemask;<span class=\"comment\">//掩码，用来计算hash值对应的buckets索引</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> used;<span class=\"comment\">//当前dictht有多少个dictEntry节点</span></span><br><span class=\"line\">&#125; dictht;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dict<ul>\n<li>dictht实际上就是hash表的核心</li>\n<li>只有一个dictht还不够，比如rehash、遍历hash等操作，</li>\n<li>所以redis定义了一个叫dict的结构以支持字典的各种操作，</li>\n<li>当dictht需要扩容/缩容时，用来管理dictht的迁移</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"集合类型\"><a href=\"#集合类型\" class=\"headerlink\" title=\"集合类型\"></a>集合类型</h3><ul>\n<li>不能有重复数据，</li>\n<li>同时集合类型中的数据是无序的</li>\n<li>集合类型和列表类型的最大的区别是<ul>\n<li>有序性<ul>\n<li>列表有序</li>\n</ul>\n</li>\n<li>唯一性<ul>\n<li>集合唯一</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>使用的值为空的散列表(hash table)，<ul>\n<li>所以这些操作的时间复杂度都是O(1).</li>\n</ul>\n</li>\n<li>数据结构<ul>\n<li>底层数据结构以<strong>intset</strong>或者<strong>hashtable</strong>来存储</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"有序集合\"><a href=\"#有序集合\" class=\"headerlink\" title=\"有序集合\"></a>有序集合</h3><ul>\n<li>有序集合类型为集合中的每个元素都关联了一个分数</li>\n<li>数据结构<ul>\n<li>内部是以ziplist或者skiplist+hashtable来实现</li>\n<li>skiplist，也就是跳跃表</li>\n<li>跳跃表<ul>\n<li>跳跃表是一种随机化的数据结构，<ul>\n<li>在查找、插入和删除这些字典操作上，<ul>\n<li>其效率可比拟于平衡二叉树（如红黑树）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、从问题出发\"><a href=\"#零、从问题出发\" class=\"headerlink\" title=\"零、从问题出发\"></a>零、从问题出发</h2><h2 id=\"一、-Redis介绍\"><a href=\"#一、-Redis介绍\" class=\"headerlink\" title=\"一、 Redis介绍\"></a>一、 Redis介绍</h2><p>概念：Redis是用C语言开发的一个开源的高性能键值对数据库。</p>\n<p>特征：</p>\n<ul>\n<li>数据间没有必然的联系</li>\n<li>内部采用单线程机制进行工作</li>\n<li>高性能</li>\n<li>多数据类型支持<ul>\n<li>字符串类型 String</li>\n<li>列表类型 List</li>\n<li>散列类型 Map</li>\n<li>集合类型 Set</li>\n<li>有序集合类型 SortedSet</li>\n</ul>\n</li>\n<li>持久化支持</li>\n</ul>\n<p>应用场景：</p>\n<ul>\n<li>为热点数据加速查询；如：热点商品、热点新闻、热点资讯等高访问量信息。</li>\n<li>任务队列；如：秒杀、抢购、购票等。</li>\n<li>即时信息查询；如：排行榜等。</li>\n<li>时效性信息控制；如：验证码、投票控制等。</li>\n<li>分布式数据共享；如：分布式架构中的session等。</li>\n<li>消息队列</li>\n<li>分布式锁</li>\n</ul>\n<h2 id=\"二、类型介绍\"><a href=\"#二、类型介绍\" class=\"headerlink\" title=\"二、类型介绍\"></a>二、类型介绍</h2><h3 id=\"字符串类型\"><a href=\"#字符串类型\" class=\"headerlink\" title=\"字符串类型\"></a>字符串类型</h3><ul>\n<li>能存储任何形式的字符串，包括二进制数据</li>\n<li>一个字符类型键允许存储的最大容量是512M</li>\n<li>内部数据结构<ul>\n<li>通过 int、SDS(simple dynamic string)作为结构存储</li>\n<li>int用来存放整型数据，sds存放字节/字符串和浮点型数据</li>\n<li>redis3.2分支引入了五种sdshdr类型，</li>\n<li>目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"列表类型\"><a href=\"#列表类型\" class=\"headerlink\" title=\"列表类型\"></a>列表类型</h3><ul>\n<li>列表类型内部使用双向链表实现</li>\n<li>value对象内部以linkedlist或者ziplist来实现<ul>\n<li>当list的元素个数和单个元素的长度比较小的时候，<ul>\n<li>Redis会采用ziplist（压缩列表）来实现来减少内存占用。</li>\n</ul>\n</li>\n<li>否则就会采用linkedlist（双向链表）结构。</li>\n</ul>\n</li>\n<li>redis3.2之后，采用的一种叫quicklist的数据结构<ul>\n<li>二者结合</li>\n<li>quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"hash类型\"><a href=\"#hash类型\" class=\"headerlink\" title=\"hash类型\"></a>hash类型</h3><p>hash提供两种结构来存储，一种是hashtable、另一种是前面讲的ziplist，数据量小的时候用ziplist.</p>\n<p>在redis中，哈希表分为三层</p>\n<ul>\n<li>dictEntry<ul>\n<li>管理一个key-value，</li>\n<li>同时保留同一个桶(bucket)中相邻元素的指针，</li>\n<li>用来维护哈希桶(bucket)的<strong>内部链</strong>；</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictEntry</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> *key;</span><br><span class=\"line\"><span class=\"keyword\">union</span> &#123; <span class=\"comment\">//因为value有多种类型，所以value用了union来存储</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> *val;</span><br><span class=\"line\"><span class=\"keyword\">uint64_t</span> u64;</span><br><span class=\"line\"><span class=\"keyword\">int64_t</span> s64;</span><br><span class=\"line\"><span class=\"keyword\">double</span> d;</span><br><span class=\"line\">&#125; v;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictEntry</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\"><span class=\"comment\">//下一个节点的地址，用来处理碰撞，所有分配到同一索引的元素通过next指针</span></span><br><span class=\"line\"><span class=\"comment\">//链接起来形成链表key和v都可以保存多种类型的数据</span></span><br><span class=\"line\">&#125; dictEntry;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dictht<ul>\n<li>实现一个hash表会使用一个<strong>buckets</strong>存放dictEntry的地址</li>\n<li>通过hash(key)%len得到的值就是buckets的索引</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dictht</span> &#123;</span></span><br><span class=\"line\">dictEntry **table;<span class=\"comment\">//buckets的地址</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> size;<span class=\"comment\">//buckets的大小,总保持为 2^n</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> sizemask;<span class=\"comment\">//掩码，用来计算hash值对应的buckets索引</span></span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> used;<span class=\"comment\">//当前dictht有多少个dictEntry节点</span></span><br><span class=\"line\">&#125; dictht;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dict<ul>\n<li>dictht实际上就是hash表的核心</li>\n<li>只有一个dictht还不够，比如rehash、遍历hash等操作，</li>\n<li>所以redis定义了一个叫dict的结构以支持字典的各种操作，</li>\n<li>当dictht需要扩容/缩容时，用来管理dictht的迁移</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"集合类型\"><a href=\"#集合类型\" class=\"headerlink\" title=\"集合类型\"></a>集合类型</h3><ul>\n<li>不能有重复数据，</li>\n<li>同时集合类型中的数据是无序的</li>\n<li>集合类型和列表类型的最大的区别是<ul>\n<li>有序性<ul>\n<li>列表有序</li>\n</ul>\n</li>\n<li>唯一性<ul>\n<li>集合唯一</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>使用的值为空的散列表(hash table)，<ul>\n<li>所以这些操作的时间复杂度都是O(1).</li>\n</ul>\n</li>\n<li>数据结构<ul>\n<li>底层数据结构以<strong>intset</strong>或者<strong>hashtable</strong>来存储</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"有序集合\"><a href=\"#有序集合\" class=\"headerlink\" title=\"有序集合\"></a>有序集合</h3><ul>\n<li>有序集合类型为集合中的每个元素都关联了一个分数</li>\n<li>数据结构<ul>\n<li>内部是以ziplist或者skiplist+hashtable来实现</li>\n<li>skiplist，也就是跳跃表</li>\n<li>跳跃表<ul>\n<li>跳跃表是一种随机化的数据结构，<ul>\n<li>在查找、插入和删除这些字典操作上，<ul>\n<li>其效率可比拟于平衡二叉树（如红黑树）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Redis通信协议","date":"2021-09-13T14:28:51.000Z","_content":"\n## 零、带着问题出发\n\n- 如何表示基本的类型：数字还是字符串\n- 数组和对象有该如何表示\n- 如何判断请求是否正常\n- 数据不存在如何表示\n- pipeline中的命令如何发布\n- 内联命令是如何支持的\n- 发布和订阅在命令中是如何实现的\n\n## 一、简介\n\nredis 客户端和服务端之间通信的协议是RESP（REdis Serialization Protocol）。传输层使用TCP。RESP的特点是：\n\n- 实现容易\n- 解析快\n- 人类可读\n\n##  二、数据类型 和协议格式\n\nRESP实际上是一个支持以下数据类型的序列化协议：简单字符串（Simple Strings），错误(Errors)，整数(Integers)，批量字符串（Bulk String）和数组（Arrays）。\n\nRESP在Redis中用作请求 - 响应协议的方式如下：\n\n- 客户端将命令作为Bulk Strings的RESP数组发送到Redis服务器。\n- 服务器根据命令实现回复一种RESP类型。\n\n在RESP中，某些数据的类型取决于第一个字节：\n\n- 对于简单字符串，回复的第一个字节是“+”\n- 对于错误，回复的第一个字节是“ - ”\n- 对于整数，回复的第一个字节是“：”\n- 对于批量字符串，回复的第一个字节是“$”\n- 对于数组，回复的第一个字节是“\\*”\n\n在RESP中，协议的不同部分始终以“\\ r \\ n”（CRLF）结束。\n\n## 三、请求、回复格式\n\n#### 1、简单字符串（Simple Strings）\n```\n+OK\\r\\n\n```\n+ 固定开始，\\r\\n固定结束， 中间即为回复的内容。\n\n#### 2、错误(Errors)\n```\n-Error message\\r\\n\n```\n类似简单字符串，但是开头用‘-’表示是错误信息。\n\nError 称为错误类型，“ - ”之后的第一个单词，直到第一个空格或换行符 ,常见的有ERR、WRONGTYPE、NOSCRIPT等。\n\nmessage 表示错误信息。\n\n以下是一些redis返回的错误：\n```\n-ERR unknown command 'foobar'\n-WRONGTYPE Operation against a key holding the wrong kind of value\n-NOSCRIPT No matching script. Please use EVAL.\n-READONLY You can't write against a read only slave.\n-OOM command not allowed when used memory > 'maxmemory'.\n-EXECABORT Transaction discarded because of previous errors.\n-BUSYKEY Target key name already exists.\n```\n#### 3、整数（Integers）\n```\n:1000\\r\\n\n```\n像INCR、LLEN、LASTSAVE等命令返回的都是整数表示增量编号、长度、时间。\n\n像EXISTS或SISMEMBER之类类的命令将返回1表示true，0表示false\n\n返回的整数保证在有符号的64位整数范围内。\n\n#### 4、批量字符串（Bulk strings）\n```\n$6\\r\\nfoobar\\r\\n\n```\nBulk Strings用于表示长度最大为512 MB的单个二进制安全字符串。\n\n批量字符串按以下方式编码：\n\n一个“$”字节后跟组成字符串的字节数（一个前缀长度），由CRLF终止。\n实际的字符串数据。\n最终的CRLF。 \n```\n$0\\r\\n\\r\\n\n```\n表示空字符串\n```\n$-1\\r\\n\n```\n表示NULL\n\n#### 5、数组（Arrays）\n\nRESP数组使用以下格式发送：\n\n一个*字符作为第一个字节，后跟数组中的元素数作为十进制数，后跟CRLF。\nArray的每个元素的附加RESP类型。\n```\n*0\\r\\n\n```\n表示空数组\n```\n*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\n```\n表示\"foo\"和\"bar\" 两个批量字符串数组\n```\n*-1\\r\\n\n```\n表示NULL数组\n```\n*2\\r\\n\n*3\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n*2\\r\\n\n+Foo\\r\\n\n-Bar\\r\\n\n```\n\n表示一个由两个元素组成的数组，该数组包含三个整数1,2,3以及一个简单字符串和一个错误的数组。\n\n\n## 四、内联命令\n\n当你需要和 Redis 服务器进行沟通， 但又找不到 redis-cli ， 而手上只有 telnet 的时候， 你可以通过 Redis 特别为这种情形而设的内联命令格式来发送命令。\n\n以下是一个客户端和服务器使用内联命令来进行交互的例子：\n\n```\n客户端： PING\n服务器： +PONG\n```\n以下另一个返回整数值的内联命令的例子：\n```\n客户端： EXISTS somekey\n服务器： :0\n```\n因为没有了统一请求协议中的 \"*\" 项来声明参数的数量， 所以在 telnet 会话输入命令的时候， 必须使用空格来分割各个参数， 服务器在接收到数据之后， 会按空格对用户的输入进行分析（parse）， 并获取其中的命令参数。\n\n## 五、多命令和流水线\n\n客户端可以通过流水线， 在一次写入操作中发送多个命令：\n\n- 在发送新命令之前， 无须阅读前一个命令的回复。\n- 多个命令的回复会在最后一并返回。\n\n## 六、订阅和发布\n\nSUBSCRIBE、UNSUBSCRIBE  和 PUBLISH三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm）， 在这个实现中， 发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端）， 而是将信息发送给频道（channel）， 然后由频道将信息转发给所有对这个频道感兴趣的订阅者。\n\n发送者无须知道任何关于订阅者的信息， 而订阅者也无须知道是那个客户端给它发送信息， 它只要关注自己感兴趣的频道即可。\n\n对发布者和订阅者进行解构（decoupling）， 可以极大地提高系统的扩展性（scalability）， 并得到一个更动态的网络拓扑（network topology）。\n\n比如说， 要订阅频道 foo 和 bar ， 客户端可以使用频道名字作为参数来调用 SUBSCRIBE 命令：\n```\nredis> SUBSCRIBE foo bar\n```\n当有客户端发送信息到这些频道时， Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。\n\n正在订阅频道的客户端不应该发送除 SUBSCRIBE 和 UNSUBSCRIBE 之外的其他命令。 其中， SUBSCRIBE 可以用于订阅更多频道， 而 UNSUBSCRIBE 则可以用于退订已订阅的一个或多个频道。\n\nSUBSCRIBE 和 UNSUBSCRIBE 的执行结果会以信息的形式返回， 客户端可以通过分析所接收信息的第一个元素， 从而判断所收到的内容是一条真正的信息， 还是 SUBSCRIBE 或 UNSUBSCRIBE 命令的操作结果。\n\n频道转发的每条信息都是一条带有三个元素的多条批量回复（multi-bulk reply）。\n\n信息的第一个元素标识了信息的类型：\n\n- subscribe ： 表示当前客户端成功地订阅了信息第二个元素所指示的频道。 而信息的第三个元素则记录了目前客户端已订阅频道的总数。\n- unsubscribe ： 表示当前客户端成功地退订了信息第二个元素所指示的频道。 信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为 0 时， 客户端不再订阅任何频道， 它可以像往常一样， 执行任何 Redis 命令。\n- message ： 表示这条信息是由某个客户端执行 PUBLISH 命令所发送的， 真正的信息。 信息的第二个元素是信息来源的频道， 而第三个元素则是信息的内容。\n\n举个例子， 如果客户端执行以下命令：\n```\nredis> SUBSCRIBE first second\n```\n那么它将收到以下回复：\n```\n1) \"subscribe\"\n2) \"first\"\n3) (integer) 1\n \n1) \"subscribe\"\n2) \"second\"\n3) (integer) 2\n```\n如果在这时， 另一个客户端执行以下 PUBLISH 命令：\n```\nredis> PUBLISH second Hello\n```\n那么之前订阅了 second 频道的客户端将收到以下信息：\n```\n1) \"message\"\n2) \"second\"\n3) \"hello\"\n```\n当订阅者决定退订所有频道时， 它可以执行一个无参数的 UNSUBSCRIBE 命令：\n```\nredis> UNSUBSCRIBE\n```\n这个命令将接到以下回复：\n```\n1) \"unsubscribe\"\n2) \"second\"\n3) (integer) 1\n \n1) \"unsubscribe\"\n2) \"first\"\n3) (integer) 0\n```\n\n## 参考链接\n- https://blog.csdn.net/u014608280/article/details/84586042","source":"_posts/re0-redis-protocol.md","raw":"---\ntitle: Redis通信协议\ndate: 2021-09-13 22:28:51\ntags: 从0开始的Redis\n---\n\n## 零、带着问题出发\n\n- 如何表示基本的类型：数字还是字符串\n- 数组和对象有该如何表示\n- 如何判断请求是否正常\n- 数据不存在如何表示\n- pipeline中的命令如何发布\n- 内联命令是如何支持的\n- 发布和订阅在命令中是如何实现的\n\n## 一、简介\n\nredis 客户端和服务端之间通信的协议是RESP（REdis Serialization Protocol）。传输层使用TCP。RESP的特点是：\n\n- 实现容易\n- 解析快\n- 人类可读\n\n##  二、数据类型 和协议格式\n\nRESP实际上是一个支持以下数据类型的序列化协议：简单字符串（Simple Strings），错误(Errors)，整数(Integers)，批量字符串（Bulk String）和数组（Arrays）。\n\nRESP在Redis中用作请求 - 响应协议的方式如下：\n\n- 客户端将命令作为Bulk Strings的RESP数组发送到Redis服务器。\n- 服务器根据命令实现回复一种RESP类型。\n\n在RESP中，某些数据的类型取决于第一个字节：\n\n- 对于简单字符串，回复的第一个字节是“+”\n- 对于错误，回复的第一个字节是“ - ”\n- 对于整数，回复的第一个字节是“：”\n- 对于批量字符串，回复的第一个字节是“$”\n- 对于数组，回复的第一个字节是“\\*”\n\n在RESP中，协议的不同部分始终以“\\ r \\ n”（CRLF）结束。\n\n## 三、请求、回复格式\n\n#### 1、简单字符串（Simple Strings）\n```\n+OK\\r\\n\n```\n+ 固定开始，\\r\\n固定结束， 中间即为回复的内容。\n\n#### 2、错误(Errors)\n```\n-Error message\\r\\n\n```\n类似简单字符串，但是开头用‘-’表示是错误信息。\n\nError 称为错误类型，“ - ”之后的第一个单词，直到第一个空格或换行符 ,常见的有ERR、WRONGTYPE、NOSCRIPT等。\n\nmessage 表示错误信息。\n\n以下是一些redis返回的错误：\n```\n-ERR unknown command 'foobar'\n-WRONGTYPE Operation against a key holding the wrong kind of value\n-NOSCRIPT No matching script. Please use EVAL.\n-READONLY You can't write against a read only slave.\n-OOM command not allowed when used memory > 'maxmemory'.\n-EXECABORT Transaction discarded because of previous errors.\n-BUSYKEY Target key name already exists.\n```\n#### 3、整数（Integers）\n```\n:1000\\r\\n\n```\n像INCR、LLEN、LASTSAVE等命令返回的都是整数表示增量编号、长度、时间。\n\n像EXISTS或SISMEMBER之类类的命令将返回1表示true，0表示false\n\n返回的整数保证在有符号的64位整数范围内。\n\n#### 4、批量字符串（Bulk strings）\n```\n$6\\r\\nfoobar\\r\\n\n```\nBulk Strings用于表示长度最大为512 MB的单个二进制安全字符串。\n\n批量字符串按以下方式编码：\n\n一个“$”字节后跟组成字符串的字节数（一个前缀长度），由CRLF终止。\n实际的字符串数据。\n最终的CRLF。 \n```\n$0\\r\\n\\r\\n\n```\n表示空字符串\n```\n$-1\\r\\n\n```\n表示NULL\n\n#### 5、数组（Arrays）\n\nRESP数组使用以下格式发送：\n\n一个*字符作为第一个字节，后跟数组中的元素数作为十进制数，后跟CRLF。\nArray的每个元素的附加RESP类型。\n```\n*0\\r\\n\n```\n表示空数组\n```\n*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\n```\n表示\"foo\"和\"bar\" 两个批量字符串数组\n```\n*-1\\r\\n\n```\n表示NULL数组\n```\n*2\\r\\n\n*3\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n*2\\r\\n\n+Foo\\r\\n\n-Bar\\r\\n\n```\n\n表示一个由两个元素组成的数组，该数组包含三个整数1,2,3以及一个简单字符串和一个错误的数组。\n\n\n## 四、内联命令\n\n当你需要和 Redis 服务器进行沟通， 但又找不到 redis-cli ， 而手上只有 telnet 的时候， 你可以通过 Redis 特别为这种情形而设的内联命令格式来发送命令。\n\n以下是一个客户端和服务器使用内联命令来进行交互的例子：\n\n```\n客户端： PING\n服务器： +PONG\n```\n以下另一个返回整数值的内联命令的例子：\n```\n客户端： EXISTS somekey\n服务器： :0\n```\n因为没有了统一请求协议中的 \"*\" 项来声明参数的数量， 所以在 telnet 会话输入命令的时候， 必须使用空格来分割各个参数， 服务器在接收到数据之后， 会按空格对用户的输入进行分析（parse）， 并获取其中的命令参数。\n\n## 五、多命令和流水线\n\n客户端可以通过流水线， 在一次写入操作中发送多个命令：\n\n- 在发送新命令之前， 无须阅读前一个命令的回复。\n- 多个命令的回复会在最后一并返回。\n\n## 六、订阅和发布\n\nSUBSCRIBE、UNSUBSCRIBE  和 PUBLISH三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm）， 在这个实现中， 发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端）， 而是将信息发送给频道（channel）， 然后由频道将信息转发给所有对这个频道感兴趣的订阅者。\n\n发送者无须知道任何关于订阅者的信息， 而订阅者也无须知道是那个客户端给它发送信息， 它只要关注自己感兴趣的频道即可。\n\n对发布者和订阅者进行解构（decoupling）， 可以极大地提高系统的扩展性（scalability）， 并得到一个更动态的网络拓扑（network topology）。\n\n比如说， 要订阅频道 foo 和 bar ， 客户端可以使用频道名字作为参数来调用 SUBSCRIBE 命令：\n```\nredis> SUBSCRIBE foo bar\n```\n当有客户端发送信息到这些频道时， Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。\n\n正在订阅频道的客户端不应该发送除 SUBSCRIBE 和 UNSUBSCRIBE 之外的其他命令。 其中， SUBSCRIBE 可以用于订阅更多频道， 而 UNSUBSCRIBE 则可以用于退订已订阅的一个或多个频道。\n\nSUBSCRIBE 和 UNSUBSCRIBE 的执行结果会以信息的形式返回， 客户端可以通过分析所接收信息的第一个元素， 从而判断所收到的内容是一条真正的信息， 还是 SUBSCRIBE 或 UNSUBSCRIBE 命令的操作结果。\n\n频道转发的每条信息都是一条带有三个元素的多条批量回复（multi-bulk reply）。\n\n信息的第一个元素标识了信息的类型：\n\n- subscribe ： 表示当前客户端成功地订阅了信息第二个元素所指示的频道。 而信息的第三个元素则记录了目前客户端已订阅频道的总数。\n- unsubscribe ： 表示当前客户端成功地退订了信息第二个元素所指示的频道。 信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为 0 时， 客户端不再订阅任何频道， 它可以像往常一样， 执行任何 Redis 命令。\n- message ： 表示这条信息是由某个客户端执行 PUBLISH 命令所发送的， 真正的信息。 信息的第二个元素是信息来源的频道， 而第三个元素则是信息的内容。\n\n举个例子， 如果客户端执行以下命令：\n```\nredis> SUBSCRIBE first second\n```\n那么它将收到以下回复：\n```\n1) \"subscribe\"\n2) \"first\"\n3) (integer) 1\n \n1) \"subscribe\"\n2) \"second\"\n3) (integer) 2\n```\n如果在这时， 另一个客户端执行以下 PUBLISH 命令：\n```\nredis> PUBLISH second Hello\n```\n那么之前订阅了 second 频道的客户端将收到以下信息：\n```\n1) \"message\"\n2) \"second\"\n3) \"hello\"\n```\n当订阅者决定退订所有频道时， 它可以执行一个无参数的 UNSUBSCRIBE 命令：\n```\nredis> UNSUBSCRIBE\n```\n这个命令将接到以下回复：\n```\n1) \"unsubscribe\"\n2) \"second\"\n3) (integer) 1\n \n1) \"unsubscribe\"\n2) \"first\"\n3) (integer) 0\n```\n\n## 参考链接\n- https://blog.csdn.net/u014608280/article/details/84586042","slug":"re0-redis-protocol","published":1,"updated":"2022-04-28T11:36:46.662Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5940010mauy4q6zdyuz","content":"<h2 id=\"零、带着问题出发\"><a href=\"#零、带着问题出发\" class=\"headerlink\" title=\"零、带着问题出发\"></a>零、带着问题出发</h2><ul>\n<li>如何表示基本的类型：数字还是字符串</li>\n<li>数组和对象有该如何表示</li>\n<li>如何判断请求是否正常</li>\n<li>数据不存在如何表示</li>\n<li>pipeline中的命令如何发布</li>\n<li>内联命令是如何支持的</li>\n<li>发布和订阅在命令中是如何实现的</li>\n</ul>\n<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>redis 客户端和服务端之间通信的协议是RESP（REdis Serialization Protocol）。传输层使用TCP。RESP的特点是：</p>\n<ul>\n<li>实现容易</li>\n<li>解析快</li>\n<li>人类可读</li>\n</ul>\n<h2 id=\"二、数据类型-和协议格式\"><a href=\"#二、数据类型-和协议格式\" class=\"headerlink\" title=\"二、数据类型 和协议格式\"></a>二、数据类型 和协议格式</h2><p>RESP实际上是一个支持以下数据类型的序列化协议：简单字符串（Simple Strings），错误(Errors)，整数(Integers)，批量字符串（Bulk String）和数组（Arrays）。</p>\n<p>RESP在Redis中用作请求 - 响应协议的方式如下：</p>\n<ul>\n<li>客户端将命令作为Bulk Strings的RESP数组发送到Redis服务器。</li>\n<li>服务器根据命令实现回复一种RESP类型。</li>\n</ul>\n<p>在RESP中，某些数据的类型取决于第一个字节：</p>\n<ul>\n<li>对于简单字符串，回复的第一个字节是“+”</li>\n<li>对于错误，回复的第一个字节是“ - ”</li>\n<li>对于整数，回复的第一个字节是“：”</li>\n<li>对于批量字符串，回复的第一个字节是“$”</li>\n<li>对于数组，回复的第一个字节是“*”</li>\n</ul>\n<p>在RESP中，协议的不同部分始终以“\\ r \\ n”（CRLF）结束。</p>\n<h2 id=\"三、请求、回复格式\"><a href=\"#三、请求、回复格式\" class=\"headerlink\" title=\"三、请求、回复格式\"></a>三、请求、回复格式</h2><h4 id=\"1、简单字符串（Simple-Strings）\"><a href=\"#1、简单字符串（Simple-Strings）\" class=\"headerlink\" title=\"1、简单字符串（Simple Strings）\"></a>1、简单字符串（Simple Strings）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+OK\\r\\n</span><br></pre></td></tr></table></figure>\n<ul>\n<li>固定开始，\\r\\n固定结束， 中间即为回复的内容。</li>\n</ul>\n<h4 id=\"2、错误-Errors\"><a href=\"#2、错误-Errors\" class=\"headerlink\" title=\"2、错误(Errors)\"></a>2、错误(Errors)</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Error message\\r\\n</span><br></pre></td></tr></table></figure>\n<p>类似简单字符串，但是开头用‘-’表示是错误信息。</p>\n<p>Error 称为错误类型，“ - ”之后的第一个单词，直到第一个空格或换行符 ,常见的有ERR、WRONGTYPE、NOSCRIPT等。</p>\n<p>message 表示错误信息。</p>\n<p>以下是一些redis返回的错误：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-ERR unknown command &#39;foobar&#39;</span><br><span class=\"line\">-WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class=\"line\">-NOSCRIPT No matching script. Please use EVAL.</span><br><span class=\"line\">-READONLY You can&#39;t write against a read only slave.</span><br><span class=\"line\">-OOM command not allowed when used memory &gt; &#39;maxmemory&#39;.</span><br><span class=\"line\">-EXECABORT Transaction discarded because of previous errors.</span><br><span class=\"line\">-BUSYKEY Target key name already exists.</span><br></pre></td></tr></table></figure>\n<h4 id=\"3、整数（Integers）\"><a href=\"#3、整数（Integers）\" class=\"headerlink\" title=\"3、整数（Integers）\"></a>3、整数（Integers）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:1000\\r\\n</span><br></pre></td></tr></table></figure>\n<p>像INCR、LLEN、LASTSAVE等命令返回的都是整数表示增量编号、长度、时间。</p>\n<p>像EXISTS或SISMEMBER之类类的命令将返回1表示true，0表示false</p>\n<p>返回的整数保证在有符号的64位整数范围内。</p>\n<h4 id=\"4、批量字符串（Bulk-strings）\"><a href=\"#4、批量字符串（Bulk-strings）\" class=\"headerlink\" title=\"4、批量字符串（Bulk strings）\"></a>4、批量字符串（Bulk strings）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$6\\r\\nfoobar\\r\\n</span><br></pre></td></tr></table></figure>\n<p>Bulk Strings用于表示长度最大为512 MB的单个二进制安全字符串。</p>\n<p>批量字符串按以下方式编码：</p>\n<p>一个“$”字节后跟组成字符串的字节数（一个前缀长度），由CRLF终止。<br>实际的字符串数据。<br>最终的CRLF。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$0\\r\\n\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示空字符串</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$-1\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示NULL</p>\n<h4 id=\"5、数组（Arrays）\"><a href=\"#5、数组（Arrays）\" class=\"headerlink\" title=\"5、数组（Arrays）\"></a>5、数组（Arrays）</h4><p>RESP数组使用以下格式发送：</p>\n<p>一个*字符作为第一个字节，后跟数组中的元素数作为十进制数，后跟CRLF。<br>Array的每个元素的附加RESP类型。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*0\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示空数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示”foo”和”bar” 两个批量字符串数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*-1\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示NULL数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*2\\r\\n</span><br><span class=\"line\">*3\\r\\n</span><br><span class=\"line\">:1\\r\\n</span><br><span class=\"line\">:2\\r\\n</span><br><span class=\"line\">:3\\r\\n</span><br><span class=\"line\">*2\\r\\n</span><br><span class=\"line\">+Foo\\r\\n</span><br><span class=\"line\">-Bar\\r\\n</span><br></pre></td></tr></table></figure>\n\n<p>表示一个由两个元素组成的数组，该数组包含三个整数1,2,3以及一个简单字符串和一个错误的数组。</p>\n<h2 id=\"四、内联命令\"><a href=\"#四、内联命令\" class=\"headerlink\" title=\"四、内联命令\"></a>四、内联命令</h2><p>当你需要和 Redis 服务器进行沟通， 但又找不到 redis-cli ， 而手上只有 telnet 的时候， 你可以通过 Redis 特别为这种情形而设的内联命令格式来发送命令。</p>\n<p>以下是一个客户端和服务器使用内联命令来进行交互的例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端： PING</span><br><span class=\"line\">服务器： +PONG</span><br></pre></td></tr></table></figure>\n<p>以下另一个返回整数值的内联命令的例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端： EXISTS somekey</span><br><span class=\"line\">服务器： :0</span><br></pre></td></tr></table></figure>\n<p>因为没有了统一请求协议中的 “*” 项来声明参数的数量， 所以在 telnet 会话输入命令的时候， 必须使用空格来分割各个参数， 服务器在接收到数据之后， 会按空格对用户的输入进行分析（parse）， 并获取其中的命令参数。</p>\n<h2 id=\"五、多命令和流水线\"><a href=\"#五、多命令和流水线\" class=\"headerlink\" title=\"五、多命令和流水线\"></a>五、多命令和流水线</h2><p>客户端可以通过流水线， 在一次写入操作中发送多个命令：</p>\n<ul>\n<li>在发送新命令之前， 无须阅读前一个命令的回复。</li>\n<li>多个命令的回复会在最后一并返回。</li>\n</ul>\n<h2 id=\"六、订阅和发布\"><a href=\"#六、订阅和发布\" class=\"headerlink\" title=\"六、订阅和发布\"></a>六、订阅和发布</h2><p>SUBSCRIBE、UNSUBSCRIBE  和 PUBLISH三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm）， 在这个实现中， 发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端）， 而是将信息发送给频道（channel）， 然后由频道将信息转发给所有对这个频道感兴趣的订阅者。</p>\n<p>发送者无须知道任何关于订阅者的信息， 而订阅者也无须知道是那个客户端给它发送信息， 它只要关注自己感兴趣的频道即可。</p>\n<p>对发布者和订阅者进行解构（decoupling）， 可以极大地提高系统的扩展性（scalability）， 并得到一个更动态的网络拓扑（network topology）。</p>\n<p>比如说， 要订阅频道 foo 和 bar ， 客户端可以使用频道名字作为参数来调用 SUBSCRIBE 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; SUBSCRIBE foo bar</span><br></pre></td></tr></table></figure>\n<p>当有客户端发送信息到这些频道时， Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。</p>\n<p>正在订阅频道的客户端不应该发送除 SUBSCRIBE 和 UNSUBSCRIBE 之外的其他命令。 其中， SUBSCRIBE 可以用于订阅更多频道， 而 UNSUBSCRIBE 则可以用于退订已订阅的一个或多个频道。</p>\n<p>SUBSCRIBE 和 UNSUBSCRIBE 的执行结果会以信息的形式返回， 客户端可以通过分析所接收信息的第一个元素， 从而判断所收到的内容是一条真正的信息， 还是 SUBSCRIBE 或 UNSUBSCRIBE 命令的操作结果。</p>\n<p>频道转发的每条信息都是一条带有三个元素的多条批量回复（multi-bulk reply）。</p>\n<p>信息的第一个元素标识了信息的类型：</p>\n<ul>\n<li>subscribe ： 表示当前客户端成功地订阅了信息第二个元素所指示的频道。 而信息的第三个元素则记录了目前客户端已订阅频道的总数。</li>\n<li>unsubscribe ： 表示当前客户端成功地退订了信息第二个元素所指示的频道。 信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为 0 时， 客户端不再订阅任何频道， 它可以像往常一样， 执行任何 Redis 命令。</li>\n<li>message ： 表示这条信息是由某个客户端执行 PUBLISH 命令所发送的， 真正的信息。 信息的第二个元素是信息来源的频道， 而第三个元素则是信息的内容。</li>\n</ul>\n<p>举个例子， 如果客户端执行以下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; SUBSCRIBE first second</span><br></pre></td></tr></table></figure>\n<p>那么它将收到以下回复：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;first&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\"> </span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) (integer) 2</span><br></pre></td></tr></table></figure>\n<p>如果在这时， 另一个客户端执行以下 PUBLISH 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; PUBLISH second Hello</span><br></pre></td></tr></table></figure>\n<p>那么之前订阅了 second 频道的客户端将收到以下信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) &quot;hello&quot;</span><br></pre></td></tr></table></figure>\n<p>当订阅者决定退订所有频道时， 它可以执行一个无参数的 UNSUBSCRIBE 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; UNSUBSCRIBE</span><br></pre></td></tr></table></figure>\n<p>这个命令将接到以下回复：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;unsubscribe&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\"> </span><br><span class=\"line\">1) &quot;unsubscribe&quot;</span><br><span class=\"line\">2) &quot;first&quot;</span><br><span class=\"line\">3) (integer) 0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/u014608280/article/details/84586042\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u014608280/article/details/84586042</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"零、带着问题出发\"><a href=\"#零、带着问题出发\" class=\"headerlink\" title=\"零、带着问题出发\"></a>零、带着问题出发</h2><ul>\n<li>如何表示基本的类型：数字还是字符串</li>\n<li>数组和对象有该如何表示</li>\n<li>如何判断请求是否正常</li>\n<li>数据不存在如何表示</li>\n<li>pipeline中的命令如何发布</li>\n<li>内联命令是如何支持的</li>\n<li>发布和订阅在命令中是如何实现的</li>\n</ul>\n<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>redis 客户端和服务端之间通信的协议是RESP（REdis Serialization Protocol）。传输层使用TCP。RESP的特点是：</p>\n<ul>\n<li>实现容易</li>\n<li>解析快</li>\n<li>人类可读</li>\n</ul>\n<h2 id=\"二、数据类型-和协议格式\"><a href=\"#二、数据类型-和协议格式\" class=\"headerlink\" title=\"二、数据类型 和协议格式\"></a>二、数据类型 和协议格式</h2><p>RESP实际上是一个支持以下数据类型的序列化协议：简单字符串（Simple Strings），错误(Errors)，整数(Integers)，批量字符串（Bulk String）和数组（Arrays）。</p>\n<p>RESP在Redis中用作请求 - 响应协议的方式如下：</p>\n<ul>\n<li>客户端将命令作为Bulk Strings的RESP数组发送到Redis服务器。</li>\n<li>服务器根据命令实现回复一种RESP类型。</li>\n</ul>\n<p>在RESP中，某些数据的类型取决于第一个字节：</p>\n<ul>\n<li>对于简单字符串，回复的第一个字节是“+”</li>\n<li>对于错误，回复的第一个字节是“ - ”</li>\n<li>对于整数，回复的第一个字节是“：”</li>\n<li>对于批量字符串，回复的第一个字节是“$”</li>\n<li>对于数组，回复的第一个字节是“*”</li>\n</ul>\n<p>在RESP中，协议的不同部分始终以“\\ r \\ n”（CRLF）结束。</p>\n<h2 id=\"三、请求、回复格式\"><a href=\"#三、请求、回复格式\" class=\"headerlink\" title=\"三、请求、回复格式\"></a>三、请求、回复格式</h2><h4 id=\"1、简单字符串（Simple-Strings）\"><a href=\"#1、简单字符串（Simple-Strings）\" class=\"headerlink\" title=\"1、简单字符串（Simple Strings）\"></a>1、简单字符串（Simple Strings）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+OK\\r\\n</span><br></pre></td></tr></table></figure>\n<ul>\n<li>固定开始，\\r\\n固定结束， 中间即为回复的内容。</li>\n</ul>\n<h4 id=\"2、错误-Errors\"><a href=\"#2、错误-Errors\" class=\"headerlink\" title=\"2、错误(Errors)\"></a>2、错误(Errors)</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Error message\\r\\n</span><br></pre></td></tr></table></figure>\n<p>类似简单字符串，但是开头用‘-’表示是错误信息。</p>\n<p>Error 称为错误类型，“ - ”之后的第一个单词，直到第一个空格或换行符 ,常见的有ERR、WRONGTYPE、NOSCRIPT等。</p>\n<p>message 表示错误信息。</p>\n<p>以下是一些redis返回的错误：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-ERR unknown command &#39;foobar&#39;</span><br><span class=\"line\">-WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class=\"line\">-NOSCRIPT No matching script. Please use EVAL.</span><br><span class=\"line\">-READONLY You can&#39;t write against a read only slave.</span><br><span class=\"line\">-OOM command not allowed when used memory &gt; &#39;maxmemory&#39;.</span><br><span class=\"line\">-EXECABORT Transaction discarded because of previous errors.</span><br><span class=\"line\">-BUSYKEY Target key name already exists.</span><br></pre></td></tr></table></figure>\n<h4 id=\"3、整数（Integers）\"><a href=\"#3、整数（Integers）\" class=\"headerlink\" title=\"3、整数（Integers）\"></a>3、整数（Integers）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:1000\\r\\n</span><br></pre></td></tr></table></figure>\n<p>像INCR、LLEN、LASTSAVE等命令返回的都是整数表示增量编号、长度、时间。</p>\n<p>像EXISTS或SISMEMBER之类类的命令将返回1表示true，0表示false</p>\n<p>返回的整数保证在有符号的64位整数范围内。</p>\n<h4 id=\"4、批量字符串（Bulk-strings）\"><a href=\"#4、批量字符串（Bulk-strings）\" class=\"headerlink\" title=\"4、批量字符串（Bulk strings）\"></a>4、批量字符串（Bulk strings）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$6\\r\\nfoobar\\r\\n</span><br></pre></td></tr></table></figure>\n<p>Bulk Strings用于表示长度最大为512 MB的单个二进制安全字符串。</p>\n<p>批量字符串按以下方式编码：</p>\n<p>一个“$”字节后跟组成字符串的字节数（一个前缀长度），由CRLF终止。<br>实际的字符串数据。<br>最终的CRLF。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$0\\r\\n\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示空字符串</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$-1\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示NULL</p>\n<h4 id=\"5、数组（Arrays）\"><a href=\"#5、数组（Arrays）\" class=\"headerlink\" title=\"5、数组（Arrays）\"></a>5、数组（Arrays）</h4><p>RESP数组使用以下格式发送：</p>\n<p>一个*字符作为第一个字节，后跟数组中的元素数作为十进制数，后跟CRLF。<br>Array的每个元素的附加RESP类型。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*0\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示空数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示”foo”和”bar” 两个批量字符串数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*-1\\r\\n</span><br></pre></td></tr></table></figure>\n<p>表示NULL数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*2\\r\\n</span><br><span class=\"line\">*3\\r\\n</span><br><span class=\"line\">:1\\r\\n</span><br><span class=\"line\">:2\\r\\n</span><br><span class=\"line\">:3\\r\\n</span><br><span class=\"line\">*2\\r\\n</span><br><span class=\"line\">+Foo\\r\\n</span><br><span class=\"line\">-Bar\\r\\n</span><br></pre></td></tr></table></figure>\n\n<p>表示一个由两个元素组成的数组，该数组包含三个整数1,2,3以及一个简单字符串和一个错误的数组。</p>\n<h2 id=\"四、内联命令\"><a href=\"#四、内联命令\" class=\"headerlink\" title=\"四、内联命令\"></a>四、内联命令</h2><p>当你需要和 Redis 服务器进行沟通， 但又找不到 redis-cli ， 而手上只有 telnet 的时候， 你可以通过 Redis 特别为这种情形而设的内联命令格式来发送命令。</p>\n<p>以下是一个客户端和服务器使用内联命令来进行交互的例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端： PING</span><br><span class=\"line\">服务器： +PONG</span><br></pre></td></tr></table></figure>\n<p>以下另一个返回整数值的内联命令的例子：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端： EXISTS somekey</span><br><span class=\"line\">服务器： :0</span><br></pre></td></tr></table></figure>\n<p>因为没有了统一请求协议中的 “*” 项来声明参数的数量， 所以在 telnet 会话输入命令的时候， 必须使用空格来分割各个参数， 服务器在接收到数据之后， 会按空格对用户的输入进行分析（parse）， 并获取其中的命令参数。</p>\n<h2 id=\"五、多命令和流水线\"><a href=\"#五、多命令和流水线\" class=\"headerlink\" title=\"五、多命令和流水线\"></a>五、多命令和流水线</h2><p>客户端可以通过流水线， 在一次写入操作中发送多个命令：</p>\n<ul>\n<li>在发送新命令之前， 无须阅读前一个命令的回复。</li>\n<li>多个命令的回复会在最后一并返回。</li>\n</ul>\n<h2 id=\"六、订阅和发布\"><a href=\"#六、订阅和发布\" class=\"headerlink\" title=\"六、订阅和发布\"></a>六、订阅和发布</h2><p>SUBSCRIBE、UNSUBSCRIBE  和 PUBLISH三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm）， 在这个实现中， 发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端）， 而是将信息发送给频道（channel）， 然后由频道将信息转发给所有对这个频道感兴趣的订阅者。</p>\n<p>发送者无须知道任何关于订阅者的信息， 而订阅者也无须知道是那个客户端给它发送信息， 它只要关注自己感兴趣的频道即可。</p>\n<p>对发布者和订阅者进行解构（decoupling）， 可以极大地提高系统的扩展性（scalability）， 并得到一个更动态的网络拓扑（network topology）。</p>\n<p>比如说， 要订阅频道 foo 和 bar ， 客户端可以使用频道名字作为参数来调用 SUBSCRIBE 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; SUBSCRIBE foo bar</span><br></pre></td></tr></table></figure>\n<p>当有客户端发送信息到这些频道时， Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。</p>\n<p>正在订阅频道的客户端不应该发送除 SUBSCRIBE 和 UNSUBSCRIBE 之外的其他命令。 其中， SUBSCRIBE 可以用于订阅更多频道， 而 UNSUBSCRIBE 则可以用于退订已订阅的一个或多个频道。</p>\n<p>SUBSCRIBE 和 UNSUBSCRIBE 的执行结果会以信息的形式返回， 客户端可以通过分析所接收信息的第一个元素， 从而判断所收到的内容是一条真正的信息， 还是 SUBSCRIBE 或 UNSUBSCRIBE 命令的操作结果。</p>\n<p>频道转发的每条信息都是一条带有三个元素的多条批量回复（multi-bulk reply）。</p>\n<p>信息的第一个元素标识了信息的类型：</p>\n<ul>\n<li>subscribe ： 表示当前客户端成功地订阅了信息第二个元素所指示的频道。 而信息的第三个元素则记录了目前客户端已订阅频道的总数。</li>\n<li>unsubscribe ： 表示当前客户端成功地退订了信息第二个元素所指示的频道。 信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为 0 时， 客户端不再订阅任何频道， 它可以像往常一样， 执行任何 Redis 命令。</li>\n<li>message ： 表示这条信息是由某个客户端执行 PUBLISH 命令所发送的， 真正的信息。 信息的第二个元素是信息来源的频道， 而第三个元素则是信息的内容。</li>\n</ul>\n<p>举个例子， 如果客户端执行以下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; SUBSCRIBE first second</span><br></pre></td></tr></table></figure>\n<p>那么它将收到以下回复：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;first&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\"> </span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) (integer) 2</span><br></pre></td></tr></table></figure>\n<p>如果在这时， 另一个客户端执行以下 PUBLISH 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; PUBLISH second Hello</span><br></pre></td></tr></table></figure>\n<p>那么之前订阅了 second 频道的客户端将收到以下信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) &quot;hello&quot;</span><br></pre></td></tr></table></figure>\n<p>当订阅者决定退订所有频道时， 它可以执行一个无参数的 UNSUBSCRIBE 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis&gt; UNSUBSCRIBE</span><br></pre></td></tr></table></figure>\n<p>这个命令将接到以下回复：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;unsubscribe&quot;</span><br><span class=\"line\">2) &quot;second&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\"> </span><br><span class=\"line\">1) &quot;unsubscribe&quot;</span><br><span class=\"line\">2) &quot;first&quot;</span><br><span class=\"line\">3) (integer) 0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://blog.csdn.net/u014608280/article/details/84586042\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u014608280/article/details/84586042</a></li>\n</ul>\n"},{"title":"从0开始的Redis学习","date":"2021-09-13T14:22:30.000Z","_content":"\n- [通信协议](https://www.naive1s.cn/2021/09/13/re0-redis-protocol/)\n- [Redis事件模型](https://www.naive1s.cn/2021/09/13/re0-redis-event/)\n- [Redis基础类型](https://www.naive1s.cn/2021/09/14/re0-redis-struct/)\n- Redis特殊类型\n- [Redis中的主从同步](https://www.naive1s.cn/2021/09/16/re0-redis-master/)\n- Redis的配置分类\n- Redis中的哨兵模式\n- [Redis中的pipeline](https://www.naive1s.cn/2021/09/16/re0-redis-pipeline/)\n- [Redis中的内存管理](https://www.naive1s.cn/2021/09/15/re0-redis-memory/)\n- [Redis中的淘汰机制](https://www.naive1s.cn/2021/09/17/re0-redis-expire/)\n- Redis中的持久化\n- Redis中的分布式设计\n- [redlock设计](https://www.naive1s.cn/2021/09/14/re0-redis-redlock/)\n- Redis线程模型\n- lua脚本的使用","source":"_posts/re0-redis.md","raw":"---\ntitle: 从0开始的Redis学习\ndate: 2021-09-13 22:22:30\ntags: 从0开始的Redis\n---\n\n- [通信协议](https://www.naive1s.cn/2021/09/13/re0-redis-protocol/)\n- [Redis事件模型](https://www.naive1s.cn/2021/09/13/re0-redis-event/)\n- [Redis基础类型](https://www.naive1s.cn/2021/09/14/re0-redis-struct/)\n- Redis特殊类型\n- [Redis中的主从同步](https://www.naive1s.cn/2021/09/16/re0-redis-master/)\n- Redis的配置分类\n- Redis中的哨兵模式\n- [Redis中的pipeline](https://www.naive1s.cn/2021/09/16/re0-redis-pipeline/)\n- [Redis中的内存管理](https://www.naive1s.cn/2021/09/15/re0-redis-memory/)\n- [Redis中的淘汰机制](https://www.naive1s.cn/2021/09/17/re0-redis-expire/)\n- Redis中的持久化\n- Redis中的分布式设计\n- [redlock设计](https://www.naive1s.cn/2021/09/14/re0-redis-redlock/)\n- Redis线程模型\n- lua脚本的使用","slug":"re0-redis","published":1,"updated":"2022-04-28T11:36:46.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5950012mauyb55l9cdb","content":"<ul>\n<li><a href=\"https://www.naive1s.cn/2021/09/13/re0-redis-protocol/\" target=\"_blank\" rel=\"noopener\">通信协议</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/13/re0-redis-event/\" target=\"_blank\" rel=\"noopener\">Redis事件模型</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/14/re0-redis-struct/\" target=\"_blank\" rel=\"noopener\">Redis基础类型</a></li>\n<li>Redis特殊类型</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/16/re0-redis-master/\" target=\"_blank\" rel=\"noopener\">Redis中的主从同步</a></li>\n<li>Redis的配置分类</li>\n<li>Redis中的哨兵模式</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/16/re0-redis-pipeline/\" target=\"_blank\" rel=\"noopener\">Redis中的pipeline</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/15/re0-redis-memory/\" target=\"_blank\" rel=\"noopener\">Redis中的内存管理</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/17/re0-redis-expire/\" target=\"_blank\" rel=\"noopener\">Redis中的淘汰机制</a></li>\n<li>Redis中的持久化</li>\n<li>Redis中的分布式设计</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/14/re0-redis-redlock/\" target=\"_blank\" rel=\"noopener\">redlock设计</a></li>\n<li>Redis线程模型</li>\n<li>lua脚本的使用</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><a href=\"https://www.naive1s.cn/2021/09/13/re0-redis-protocol/\" target=\"_blank\" rel=\"noopener\">通信协议</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/13/re0-redis-event/\" target=\"_blank\" rel=\"noopener\">Redis事件模型</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/14/re0-redis-struct/\" target=\"_blank\" rel=\"noopener\">Redis基础类型</a></li>\n<li>Redis特殊类型</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/16/re0-redis-master/\" target=\"_blank\" rel=\"noopener\">Redis中的主从同步</a></li>\n<li>Redis的配置分类</li>\n<li>Redis中的哨兵模式</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/16/re0-redis-pipeline/\" target=\"_blank\" rel=\"noopener\">Redis中的pipeline</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/15/re0-redis-memory/\" target=\"_blank\" rel=\"noopener\">Redis中的内存管理</a></li>\n<li><a href=\"https://www.naive1s.cn/2021/09/17/re0-redis-expire/\" target=\"_blank\" rel=\"noopener\">Redis中的淘汰机制</a></li>\n<li>Redis中的持久化</li>\n<li>Redis中的分布式设计</li>\n<li><a href=\"https://www.naive1s.cn/2021/09/14/re0-redis-redlock/\" target=\"_blank\" rel=\"noopener\">redlock设计</a></li>\n<li>Redis线程模型</li>\n<li>lua脚本的使用</li>\n</ul>\n"},{"title":"总结RPC高可用实践之路","_content":"\nRPC的高可用存在几个方向：Load Balancing负载均衡、Rate Limiting限流、Load Shedding熔断、Graceful Degradation优雅退化、Latency and Deadlines延迟和死线\n\n### Load Balancing负载均衡 \n\n负载均衡核心目标其实主要是俩类：首先是减少负载、其次是提高可用性。\n\n减少负载首先是分摊流量、并做到均匀分发，而可用性则是减少错误数、更低的延迟、并支持弹性。\n\n而在这目标背后有很多障碍，对于每个请求的处理成本不同，第二是物理环境有差异，包括CPU性能差异以及邻居间互相影响。包括性能因素，中间例如JIT的预热、批量任务、大型GC导致性能出现问题。\n\n在解决这些背景的核心问题是活跃的请求数量不代表后端容量，CPU更好的处理的更多，而大集群最终退化成随机选择。而每个客户端的活跃请求不包括其他客户端发完一个后端的请求，导致容易缺少全局视角，且最闲的轮询容易引发惊群效应。\n\n### 方案\n\n用于解决负载均衡有各种各样的方案设计\n\nP2C方案，作为一个实现简单、负载均衡器的CPU成本低、请求分布好、O(1)的复杂度。**Power of Two Choices**方式是我们常见的做法。比如说现在有多个机房，因为线上的集群是多个，比如100个机器一个集群，我们正常把20个放到一个机房，一般要5个机房，就可以做到同城的多机房容灾。\n\n对于这种情况以前的做法是需要在配置里面加zone，弄清楚这个机器的节点属于哪个zone，做一些复杂的配置去管理这个请求该去哪儿访问，通过这种方式就能比较好的进行规避。\n\n比如说图里的A节点访问其它节点模拟了2ms的延迟，它可以比较好的把更多的请求放到本机房里，同时也确保本机房请求过多或延迟过高时会动态调度到其他的机房，这是一个动态的平衡。这里放了三个节点演示，通过数学的方式比较好的把多机房balance解决掉，而不需要用复杂的配置来完成这件事。\n\n基于client统计指标调度\n\n在client侧可以通过采集三类信息来进行均衡判断：Health、连接或特定的错误比率，Latency：请求的耗时，Inflight：当前正在运行的请求数量。通过三者来判断当前的server端是否正常已经进行相关的权重调节。\n\n同时还存在基于server统计指标进行调度，其中利用类似于Actively：利用healthcheck同步；Passively：每次rpc response同步，CPU：百ms内的Moving Average 这类指标供均衡判断。\n\n同时，为了保证数据的可用性，需要对相关计算分数进行衰减处理。\n\n### 影响\n\n负载均衡的策略执行后，很容易出现的影响是服务器之间的流量差异逐步放大，较慢的服务器接收的流量更少，从而容易导致abtest实验准确性，同时问题机器更难被监控发现\n\n## 相关链接\n\n[流量洪峰中如何设计弹性微服务架构 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/354401594)","source":"_posts/rpc-monitor.md","raw":"---\ntitle: 总结RPC高可用实践之路\n---\n\nRPC的高可用存在几个方向：Load Balancing负载均衡、Rate Limiting限流、Load Shedding熔断、Graceful Degradation优雅退化、Latency and Deadlines延迟和死线\n\n### Load Balancing负载均衡 \n\n负载均衡核心目标其实主要是俩类：首先是减少负载、其次是提高可用性。\n\n减少负载首先是分摊流量、并做到均匀分发，而可用性则是减少错误数、更低的延迟、并支持弹性。\n\n而在这目标背后有很多障碍，对于每个请求的处理成本不同，第二是物理环境有差异，包括CPU性能差异以及邻居间互相影响。包括性能因素，中间例如JIT的预热、批量任务、大型GC导致性能出现问题。\n\n在解决这些背景的核心问题是活跃的请求数量不代表后端容量，CPU更好的处理的更多，而大集群最终退化成随机选择。而每个客户端的活跃请求不包括其他客户端发完一个后端的请求，导致容易缺少全局视角，且最闲的轮询容易引发惊群效应。\n\n### 方案\n\n用于解决负载均衡有各种各样的方案设计\n\nP2C方案，作为一个实现简单、负载均衡器的CPU成本低、请求分布好、O(1)的复杂度。**Power of Two Choices**方式是我们常见的做法。比如说现在有多个机房，因为线上的集群是多个，比如100个机器一个集群，我们正常把20个放到一个机房，一般要5个机房，就可以做到同城的多机房容灾。\n\n对于这种情况以前的做法是需要在配置里面加zone，弄清楚这个机器的节点属于哪个zone，做一些复杂的配置去管理这个请求该去哪儿访问，通过这种方式就能比较好的进行规避。\n\n比如说图里的A节点访问其它节点模拟了2ms的延迟，它可以比较好的把更多的请求放到本机房里，同时也确保本机房请求过多或延迟过高时会动态调度到其他的机房，这是一个动态的平衡。这里放了三个节点演示，通过数学的方式比较好的把多机房balance解决掉，而不需要用复杂的配置来完成这件事。\n\n基于client统计指标调度\n\n在client侧可以通过采集三类信息来进行均衡判断：Health、连接或特定的错误比率，Latency：请求的耗时，Inflight：当前正在运行的请求数量。通过三者来判断当前的server端是否正常已经进行相关的权重调节。\n\n同时还存在基于server统计指标进行调度，其中利用类似于Actively：利用healthcheck同步；Passively：每次rpc response同步，CPU：百ms内的Moving Average 这类指标供均衡判断。\n\n同时，为了保证数据的可用性，需要对相关计算分数进行衰减处理。\n\n### 影响\n\n负载均衡的策略执行后，很容易出现的影响是服务器之间的流量差异逐步放大，较慢的服务器接收的流量更少，从而容易导致abtest实验准确性，同时问题机器更难被监控发现\n\n## 相关链接\n\n[流量洪峰中如何设计弹性微服务架构 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/354401594)","slug":"rpc-monitor","published":1,"date":"1970-01-01T00:00:00.000Z","updated":"2022-04-28T11:36:46.747Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5960015mauy3s2vfu6g","content":"<p>RPC的高可用存在几个方向：Load Balancing负载均衡、Rate Limiting限流、Load Shedding熔断、Graceful Degradation优雅退化、Latency and Deadlines延迟和死线</p>\n<h3 id=\"Load-Balancing负载均衡\"><a href=\"#Load-Balancing负载均衡\" class=\"headerlink\" title=\"Load Balancing负载均衡\"></a>Load Balancing负载均衡</h3><p>负载均衡核心目标其实主要是俩类：首先是减少负载、其次是提高可用性。</p>\n<p>减少负载首先是分摊流量、并做到均匀分发，而可用性则是减少错误数、更低的延迟、并支持弹性。</p>\n<p>而在这目标背后有很多障碍，对于每个请求的处理成本不同，第二是物理环境有差异，包括CPU性能差异以及邻居间互相影响。包括性能因素，中间例如JIT的预热、批量任务、大型GC导致性能出现问题。</p>\n<p>在解决这些背景的核心问题是活跃的请求数量不代表后端容量，CPU更好的处理的更多，而大集群最终退化成随机选择。而每个客户端的活跃请求不包括其他客户端发完一个后端的请求，导致容易缺少全局视角，且最闲的轮询容易引发惊群效应。</p>\n<h3 id=\"方案\"><a href=\"#方案\" class=\"headerlink\" title=\"方案\"></a>方案</h3><p>用于解决负载均衡有各种各样的方案设计</p>\n<p>P2C方案，作为一个实现简单、负载均衡器的CPU成本低、请求分布好、O(1)的复杂度。<strong>Power of Two Choices</strong>方式是我们常见的做法。比如说现在有多个机房，因为线上的集群是多个，比如100个机器一个集群，我们正常把20个放到一个机房，一般要5个机房，就可以做到同城的多机房容灾。</p>\n<p>对于这种情况以前的做法是需要在配置里面加zone，弄清楚这个机器的节点属于哪个zone，做一些复杂的配置去管理这个请求该去哪儿访问，通过这种方式就能比较好的进行规避。</p>\n<p>比如说图里的A节点访问其它节点模拟了2ms的延迟，它可以比较好的把更多的请求放到本机房里，同时也确保本机房请求过多或延迟过高时会动态调度到其他的机房，这是一个动态的平衡。这里放了三个节点演示，通过数学的方式比较好的把多机房balance解决掉，而不需要用复杂的配置来完成这件事。</p>\n<p>基于client统计指标调度</p>\n<p>在client侧可以通过采集三类信息来进行均衡判断：Health、连接或特定的错误比率，Latency：请求的耗时，Inflight：当前正在运行的请求数量。通过三者来判断当前的server端是否正常已经进行相关的权重调节。</p>\n<p>同时还存在基于server统计指标进行调度，其中利用类似于Actively：利用healthcheck同步；Passively：每次rpc response同步，CPU：百ms内的Moving Average 这类指标供均衡判断。</p>\n<p>同时，为了保证数据的可用性，需要对相关计算分数进行衰减处理。</p>\n<h3 id=\"影响\"><a href=\"#影响\" class=\"headerlink\" title=\"影响\"></a>影响</h3><p>负载均衡的策略执行后，很容易出现的影响是服务器之间的流量差异逐步放大，较慢的服务器接收的流量更少，从而容易导致abtest实验准确性，同时问题机器更难被监控发现</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://zhuanlan.zhihu.com/p/354401594\" target=\"_blank\" rel=\"noopener\">流量洪峰中如何设计弹性微服务架构 - 知乎 (zhihu.com)</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>RPC的高可用存在几个方向：Load Balancing负载均衡、Rate Limiting限流、Load Shedding熔断、Graceful Degradation优雅退化、Latency and Deadlines延迟和死线</p>\n<h3 id=\"Load-Balancing负载均衡\"><a href=\"#Load-Balancing负载均衡\" class=\"headerlink\" title=\"Load Balancing负载均衡\"></a>Load Balancing负载均衡</h3><p>负载均衡核心目标其实主要是俩类：首先是减少负载、其次是提高可用性。</p>\n<p>减少负载首先是分摊流量、并做到均匀分发，而可用性则是减少错误数、更低的延迟、并支持弹性。</p>\n<p>而在这目标背后有很多障碍，对于每个请求的处理成本不同，第二是物理环境有差异，包括CPU性能差异以及邻居间互相影响。包括性能因素，中间例如JIT的预热、批量任务、大型GC导致性能出现问题。</p>\n<p>在解决这些背景的核心问题是活跃的请求数量不代表后端容量，CPU更好的处理的更多，而大集群最终退化成随机选择。而每个客户端的活跃请求不包括其他客户端发完一个后端的请求，导致容易缺少全局视角，且最闲的轮询容易引发惊群效应。</p>\n<h3 id=\"方案\"><a href=\"#方案\" class=\"headerlink\" title=\"方案\"></a>方案</h3><p>用于解决负载均衡有各种各样的方案设计</p>\n<p>P2C方案，作为一个实现简单、负载均衡器的CPU成本低、请求分布好、O(1)的复杂度。<strong>Power of Two Choices</strong>方式是我们常见的做法。比如说现在有多个机房，因为线上的集群是多个，比如100个机器一个集群，我们正常把20个放到一个机房，一般要5个机房，就可以做到同城的多机房容灾。</p>\n<p>对于这种情况以前的做法是需要在配置里面加zone，弄清楚这个机器的节点属于哪个zone，做一些复杂的配置去管理这个请求该去哪儿访问，通过这种方式就能比较好的进行规避。</p>\n<p>比如说图里的A节点访问其它节点模拟了2ms的延迟，它可以比较好的把更多的请求放到本机房里，同时也确保本机房请求过多或延迟过高时会动态调度到其他的机房，这是一个动态的平衡。这里放了三个节点演示，通过数学的方式比较好的把多机房balance解决掉，而不需要用复杂的配置来完成这件事。</p>\n<p>基于client统计指标调度</p>\n<p>在client侧可以通过采集三类信息来进行均衡判断：Health、连接或特定的错误比率，Latency：请求的耗时，Inflight：当前正在运行的请求数量。通过三者来判断当前的server端是否正常已经进行相关的权重调节。</p>\n<p>同时还存在基于server统计指标进行调度，其中利用类似于Actively：利用healthcheck同步；Passively：每次rpc response同步，CPU：百ms内的Moving Average 这类指标供均衡判断。</p>\n<p>同时，为了保证数据的可用性，需要对相关计算分数进行衰减处理。</p>\n<h3 id=\"影响\"><a href=\"#影响\" class=\"headerlink\" title=\"影响\"></a>影响</h3><p>负载均衡的策略执行后，很容易出现的影响是服务器之间的流量差异逐步放大，较慢的服务器接收的流量更少，从而容易导致abtest实验准确性，同时问题机器更难被监控发现</p>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p><a href=\"https://zhuanlan.zhihu.com/p/354401594\" target=\"_blank\" rel=\"noopener\">流量洪峰中如何设计弹性微服务架构 - 知乎 (zhihu.com)</a></p>\n"},{"title":"从0开始的操作系统学习","date":"2021-09-13T14:25:46.000Z","_content":"\n- 汇编基础\n- 如何打印字符串\n- 从磁盘中读取信息\n- 关于程序的分布","source":"_posts/re0-system.md","raw":"---\ntitle: 从0开始的操作系统学习\ndate: 2021-09-13 22:25:46\ntags: 从0开始的操作系统\n---\n\n- 汇编基础\n- 如何打印字符串\n- 从磁盘中读取信息\n- 关于程序的分布","slug":"re0-system","published":1,"updated":"2022-04-28T11:36:46.734Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl2iyg5970017mauygtpre5un","content":"<ul>\n<li>汇编基础</li>\n<li>如何打印字符串</li>\n<li>从磁盘中读取信息</li>\n<li>关于程序的分布</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>汇编基础</li>\n<li>如何打印字符串</li>\n<li>从磁盘中读取信息</li>\n<li>关于程序的分布</li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/golang-gmp/1767848-9c4b06362907280d.webp","post":"cl2iyg57r0002mauyf5217bft","slug":"1767848-9c4b06362907280d.webp","modified":1,"renderable":1},{"_id":"source/_posts/golang-gmp/3184f3.jpg","post":"cl2iyg57r0002mauyf5217bft","slug":"3184f3.jpg","modified":1,"renderable":1},{"_id":"source/_posts/golang-gmp/567399-d400f4b192f3dc48.webp","post":"cl2iyg57r0002mauyf5217bft","slug":"567399-d400f4b192f3dc48.webp","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"cl2iyg58l000fmauy2w7d8emp","tag_id":"cl2iyg58n000hmauy50zz6t0s","_id":"cl2iyg58x000mmauyhxts5sk8"},{"post_id":"cl2iyg58m000gmauy3pvd60lh","tag_id":"cl2iyg58w000lmauye5hbbgll","_id":"cl2iyg58z000rmauyhx4o5hvd"},{"post_id":"cl2iyg58z000qmauyey7pe8sg","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg591000umauy7dlm1fjd"},{"post_id":"cl2iyg58t000jmauy0pria8w4","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg593000wmauy32ab6inn"},{"post_id":"cl2iyg590000smauy21hpghej","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg594000zmauydi6phg0p"},{"post_id":"cl2iyg58v000kmauygn2a4klt","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg5950011mauy2d2o4k1f"},{"post_id":"cl2iyg593000xmauy4j4x3p9l","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg5960014mauyfqfc5mxa"},{"post_id":"cl2iyg5940010mauy4q6zdyuz","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg5970016mauyb25h5wub"},{"post_id":"cl2iyg58x000nmauy896z705j","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg59a0019mauy8ty76anr"},{"post_id":"cl2iyg5950012mauyb55l9cdb","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg59a001amauy8b800hp0"},{"post_id":"cl2iyg58y000omauybgmm147o","tag_id":"cl2iyg58y000pmauy697qbb5p","_id":"cl2iyg59b001bmauyeywa6ito"},{"post_id":"cl2iyg592000vmauy91s3671d","tag_id":"cl2iyg5980018mauy2mtsdx4s","_id":"cl2iyg59b001dmauygqtt75fc"},{"post_id":"cl2iyg5970017mauygtpre5un","tag_id":"cl2iyg59b001cmauy8ae94tua","_id":"cl2iyg59b001emauy17xnhybt"}],"Tag":[{"name":"读书笔记","_id":"cl2iyg58n000hmauy50zz6t0s"},{"name":"从0开始的golang","_id":"cl2iyg58w000lmauye5hbbgll"},{"name":"从0开始的Redis","_id":"cl2iyg58y000pmauy697qbb5p"},{"name":"从0开始的Mysql","_id":"cl2iyg5980018mauy2mtsdx4s"},{"name":"从0开始的操作系统","_id":"cl2iyg59b001cmauy8ae94tua"}]}}