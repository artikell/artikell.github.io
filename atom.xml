<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[artikell]]></title>
  <link href="https://artikell.github.io/atom.xml" rel="self"/>
  <link href="https://artikell.github.io/"/>
  <updated>2018-06-12T00:28:59+08:00</updated>
  <id>https://artikell.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Redis 有序列表zset源码解析]]></title>
    <link href="https://artikell.github.io/15287304018827.html"/>
    <updated>2018-06-11T23:20:01+08:00</updated>
    <id>https://artikell.github.io/15287304018827.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>有序列表底层使用了<em>ziplist</em>和<em>skiplist</em>2种数据结构，2者都是redis中相对比较复杂的数据结构，此次，我们来通过主要的命令来解析相关的核心操作。</p>

<h2 id="toc_1">相关命令</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>解释</th>
</tr>
</thead>

<tbody>
<tr>
<td>Zadd</td>
<td>创建</td>
<td>将带有给定分值的成员添加到有序列表里面</td>
</tr>
<tr>
<td>Zrem</td>
<td>删除</td>
<td>从有序集合里面移除给定的成员，并返回被移除成员的数量</td>
</tr>
<tr>
<td>Zcard</td>
<td>查询</td>
<td>返回有序集合包含的成员数量</td>
</tr>
<tr>
<td>Zincrby</td>
<td>修改</td>
<td>将member成员的分值加上increment</td>
</tr>
<tr>
<td>Zcount</td>
<td>查询</td>
<td>返回分值介于min和max之间的成员数量，包括min和max在内</td>
</tr>
<tr>
<td>Zrank</td>
<td>查询</td>
<td>返回成员member在有序集合中的排名，成员按照分值从小到大排列</td>
</tr>
<tr>
<td>Zrevrank</td>
<td>查询</td>
<td>返回成员member在有序集合中的排名 ，成员按照分值从大到小排列</td>
</tr>
<tr>
<td>Zscore</td>
<td>查询</td>
<td>返回成员member的分值</td>
</tr>
<tr>
<td>Zrange</td>
<td>查询</td>
<td>返回有序集合中排名介于start和stop之间的成员，包括start和stop在内，如果给定了可选的WITHSCORES选项，那么命令会将成员的分值一并返回，成员按照分值从小到大排列</td>
</tr>
<tr>
<td>Zrevrange</td>
<td>查询</td>
<td>返回有序集合中排名介于start和stop之间的成员，包括start和stop在内，如果给定了可选的WITHSCORES选项，那么命令会将成员的分值一并返回，成员按照分值从大到小排列</td>
</tr>
<tr>
<td>Zrangebyscore</td>
<td>查询</td>
<td>返回有序集合中分值介于min和max之间的所有成员，包括min和max在内，并按照分值从小到大的排序来返回他们</td>
</tr>
<tr>
<td>Zrevrangebyscore</td>
<td>查询</td>
<td>返回有序集合中分值介于min和max之间的所有成员，包括min和max在内，并按照分值从大到小的排序来返回他们</td>
</tr>
<tr>
<td>Zremrangebyrank</td>
<td>删除</td>
<td>移除有序集合中排名介于start和stop之间的所有成员，包括start和stop在内</td>
</tr>
<tr>
<td>Zremrangebyscore</td>
<td>删除</td>
<td>移除有序集合中分值介于min和max之间的所有成员，包括min和max在内</td>
</tr>
<tr>
<td>Zinterstore</td>
<td>合并</td>
<td>对给定的有序集合执行类似于集合的交集运算</td>
</tr>
<tr>
<td>Zunionstore</td>
<td>合并</td>
<td>对给定的有序集合执行类似于集合的并集运算</td>
</tr>
</tbody>
</table>

<p>其中 <em>查询操作</em> 包含 9个命令，<em>增加或更新</em>只有2个，而<em>删除类命令</em>包括了3个。</p>

<p>这么一看，核心操作主要在于如何高效查询，以及如何进行底层数据结构的升级。</p>

<h2 id="toc_2">高效查询</h2>

<p>查询本身也分为2类：单元素查询、范围查询。</p>

<h3 id="toc_3">单元素查询</h3>

<p>单元素查询相对比较简单，一般都是某个成员的分值、排名等信息。2者之间的核心就是在于：如何快速查询到所需的成员。</p>

<h4 id="toc_4">对于ziplist</h4>

<p>ziplist最多也就512个元素，所以，不需要什么算法，暴力就行！！！</p>

<pre><code>while(eptr != NULL) {
    if (ziplistCompare(eptr,(unsigned char*)ele,sdslen(ele)))
        break;
    rank++;
    zzlNext(zl,&amp;eptr,&amp;sptr);
}
</code></pre>

<h4 id="toc_5">对于skiplist</h4>

<p><em>skiplist</em>本身可能会有很多元素，所以，本身的设计也是为了高效设计，所以，本身按照跳跃表的特性，我们只需要从最大的元素开始不断往下寻找元素即可。</p>

<pre><code>for (i = zsl-&gt;level-1; i &gt;= 0; i--) {
    while (x-&gt;level[i].forward &amp;&amp;
        (x-&gt;level[i].forward-&gt;score &lt; score ||
            (x-&gt;level[i].forward-&gt;score == score &amp;&amp;
            sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt;= 0))) {
        rank += x-&gt;level[i].span;
        x = x-&gt;level[i].forward;
    }

    /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */
    if (x-&gt;ele &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) {
        return rank;
    }
}
</code></pre>

<h3 id="toc_6">范围查询</h3>

<p>范围查询也可以分为3类：<em>分值范围、排名范围、字符串匹配</em>。不过三者之间的差异并没有特别巨大，也可以根据不同的结构体进行分类讨论。</p>

<h4 id="toc_7">对于ziplist</h4>

<p>ziplist 本身由于节省内存，所以，方法上没有不同，照常还是遍历。</p>

<p>首先，ziplist会获取的范围的对象，通过first类函数找到最初的元素：</p>

<pre><code>    while (eptr != NULL) {
        sptr = ziplistNext(zl,eptr);
        serverAssert(sptr != NULL);

        score = zzlGetScore(sptr);
        if (zslValueGteMin(score,range)) {
            /* Check if score &lt;= max. */
            if (zslValueLteMax(score,range))
                return eptr;
            return NULL;
        }

        /* Move to next element. */
        eptr = ziplistNext(zl,sptr);
    }
</code></pre>

<p>找到起始元素后，会通过迭代的方式来获取范围类的数据，并进行删除。</p>

<pre><code>while ((sptr = ziplistNext(zl,eptr)) != NULL) {
    if (zzlLexValueLteMax(eptr,range)) {
        /* Delete both the element and the score. */
        zl = ziplistDelete(zl,&amp;eptr);
        zl = ziplistDelete(zl,&amp;eptr);
        num++;
    } else {
        /* No longer in range. */
        break;
    }
}
</code></pre>

<h4 id="toc_8">对于skiplist</h4>

<p>skiplist 本身的高效，所以，不需要特别的处理，不过，也只是在最开始的时候快速找到起始元素，然后开始不断遍历。</p>

<pre><code>x = zsl-&gt;header;
for (i = zsl-&gt;level-1; i &gt;= 0; i--) {
    while (x-&gt;level[i].forward &amp;&amp;
        !zslLexValueGteMin(x-&gt;level[i].forward-&gt;ele,range))
            x = x-&gt;level[i].forward;
    update[i] = x;
}

/* Current node is the last with score &lt; or &lt;= min. */
x = x-&gt;level[0].forward;

/* Delete nodes while in range. */
while (x &amp;&amp; zslLexValueLteMax(x-&gt;ele,range)) {
    zskiplistNode *next = x-&gt;level[0].forward;
    zslDeleteNode(zsl,x,update);
    dictDelete(dict,x-&gt;ele);
    zslFreeNode(x); /* Here is where x-&gt;ele is actually released. */
    removed++;
    x = next;
}
</code></pre>

<h2 id="toc_9">合并操作</h2>

<p>对于差集，多个集合进行轮询，判断第一个集合的元素是否在其他集合中，若存在，则添加进一个新建的有序集合中即可。</p>

<p>对于并集，那就是先把所有集合全部插入一个字典中，在遍历字典，插入集合中即可。</p>

<p>2者默认都是skiplist模式的有序列表。</p>

<h2 id="toc_10">总结</h2>

<p>此次只看到一点皮毛，感觉redis源码很多地方写法与自身写法不同，侧面反映作者注重于效率。</p>

<h2 id="toc_11">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/xiaouncle/article/details/62236593">Redis常用命令-Zset</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis常用数据类型介绍、使用场景]]></title>
    <link href="https://artikell.github.io/15286369556294.html"/>
    <updated>2018-06-10T21:22:35+08:00</updated>
    <id>https://artikell.github.io/15286369556294.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">String（字符串）</h2>

<p>String是简单的 key-value 键值对，value 不仅可以是 String，也可以是数字。String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</p>

<p>String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</p>

<h3 id="toc_1">应用场景</h3>

<p>String是最常用的一种数据类型，普通的key/value存储都可以归为此类，这里就不所做解释了。</p>

<h2 id="toc_2">List（列表）</h2>

<p>Redis列表是简单的字符串列表，可以类比到C++中的std::list，简单的说就是一个链表或者说是一个队列。可以从头部或尾部向Redis列表添加元素。列表的最大长度为2<sup>32</sup> - 1，也即每个列表支持超过40亿个元素。</p>

<p>Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。</p>

<h3 id="toc_3">应用场景</h3>

<p>Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表、粉丝列表等都可以用Redis的list结构来实现，再比如有的应用使用Redis的list类型实现一个简单的轻量级消息队列，生产者push，消费者pop/bpop。</p>

<h2 id="toc_4">Hash（字典，哈希表）</h2>

<p>类似C#中的dict类型或者C++中的hash_map类型。</p>

<p>Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。</p>

<h3 id="toc_5">应用场景</h3>

<p>假设有多个用户及对应的用户信息，可以用来存储以用户ID为key，将用户信息序列化为比如json格式做为value进行保存。</p>

<h2 id="toc_6">Set（集合）</h2>

<p>可以理解为一堆值不重复的列表，类似数学领域中的集合概念，且Redis也提供了针对集合的求交集、并集、差集等操作。</p>

<p>set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。</p>

<h3 id="toc_7">应用场景</h3>

<p>Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。</p>

<p>又或者在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。</p>

<h2 id="toc_8">Sorted Set（有序集合）</h2>

<p>Redis有序集合类似Redis集合，不同的是增加了一个功能，即集合是有序的。一个有序集合的每个成员带有分数，用于进行排序。</p>

<p>Redis有序集合添加、删除和测试的时间复杂度均为O(1)(固定时间，无论里面包含的元素集合的数量)。列表的最大长度为2<sup>32-</sup> 1元素(4294967295，超过40亿每个元素的集合)。</p>

<p>Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。</p>

<h3 id="toc_9">使用场景</h3>

<p>Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。</p>

<p>又比如用户的积分排行榜需求就可以通过有序集合实现。还有上面介绍的使用List实现轻量级的消息队列，其实也可以通过Sorted Set实现有优先级或按权重的队列。</p>

<h2 id="toc_10">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/lizhenghn/p/5322887.html">Redis常用数据类型介绍、使用场景及其操作命令</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis Bio模块的学习]]></title>
    <link href="https://artikell.github.io/15286278830553.html"/>
    <updated>2018-06-10T18:51:23+08:00</updated>
    <id>https://artikell.github.io/15286278830553.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p><em>Redis</em>宣称的单进程的程序，但是，源码中到处都有为了防止顺序混乱的代码，之后，在淘汰机制中发现了<em>dbAsyncDelete</em>函数，才了解到<em>Redis</em>本身的存在异步操作的，现在，我们来看看异步IO都做了什么处理吧。</p>

<h2 id="toc_1">Bio的功能</h2>

<p>Bio模块本身代码不多，可以一一来介绍各个函数的功能，首先，我们看看线程相关的一下对象。</p>

<h3 id="toc_2">线程相关对象</h3>

<pre><code>static pthread_t bio_threads[BIO_NUM_OPS];  //BIO线程
static pthread_mutex_t bio_mutex[BIO_NUM_OPS]; //BIO每个线程的mutex锁变量
static pthread_cond_t bio_newjob_cond[BIO_NUM_OPS]; //BIO线程锁的条件变量， 监听这个条件变量唤起当前线程
static pthread_cond_t bio_step_cond[BIO_NUM_OPS]; //BIO线程阻塞锁，bioWaitStepOfType监听这个条件变量被通知该操作的执行。
static list *bio_jobs[BIO_NUM_OPS];
static unsigned long long bio_pending[BIO_NUM_OPS]; // BIO未执行的
</code></pre>

<p>从中我们可以看出，线程本身是作为一个变量存储，同时，对于每个线程，都有相关的锁以及锁条件。</p>

<p>同时，<em>Redis</em>中的线程，为每种类型的操作都分配了一个线程进行处理，其中拥有3中类型：</p>

<pre><code>#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */
#define BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */
#define BIO_LAZY_FREE     2 /* Deferred objects freeing. */
</code></pre>

<p>这样可以很好的控制线程的数量，这也是为什么<em>Redis</em>会设置一个<em>jobs</em>列表来存储任务的原因。</p>

<h3 id="toc_3">bioInit 函数</h3>

<p>bioInit函数是在整个Redis服务启动时调用，源码如下：</p>

<pre><code>void bioInit(void) {
    pthread_attr_t attr;
    pthread_t thread;
    size_t stacksize;
    int j;

    /* Initialization of state vars and objects */
    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        pthread_mutex_init(&amp;bio_mutex[j],NULL);
        pthread_cond_init(&amp;bio_newjob_cond[j],NULL);
        pthread_cond_init(&amp;bio_step_cond[j],NULL);
        bio_jobs[j] = listCreate();
        bio_pending[j] = 0;
    }

    /* Set the stack size as by default it may be small in some system */
    pthread_attr_init(&amp;attr);
    pthread_attr_getstacksize(&amp;attr,&amp;stacksize);
    if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */
    while (stacksize &lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2;
    pthread_attr_setstacksize(&amp;attr, stacksize);

    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        void *arg = (void*)(unsigned long) j;
        if (pthread_create(&amp;thread,&amp;attr,bioProcessBackgroundJobs,arg) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can&#39;t initialize Background Jobs.&quot;);
            exit(1);
        }
        bio_threads[j] = thread;
    }
}
</code></pre>

<p>在BIO初始化时，首先是对线程相关的对象进行初始化，包括<em>线程锁、锁条件、线程队列</em>等。<br/>
在之后，通过<em>pthread_attr_init</em>函数对线程环境进行初始化，并对栈大小进行重设。<br/>
最后，根据<em>线程环境</em>创建了一系列的线程，用于后续使用。</p>

<h3 id="toc_4">bioCreateBackgroundJob 函数</h3>

<p>该函数主要是用于添加一个异步任务，传入的参数比较简单，包括Type和3个变量。这些都存储在bio_job结构体中：</p>

<pre><code>struct bio_job {
    time_t time; /* Time at which the job was created. */
    void *arg1, *arg2, *arg3;
};
</code></pre>

<p>关于为啥是3个变量，主要是针对不同类型的异步事件使用，3个变量的排列组合共有8种，差不多够用了。<br/>
代码中主要是对于惰性淘汰进行分类：若第一个指针，则代表释放object；第二个指针代表释放一个数据库；第三个指针代表释放一个哈希表。</p>

<p><em>bioCreateBackgroundJob</em> 函数在赋值完，会将相关的线程进行唤醒让其来主动处理队列中的任务。这其中的逻辑与协程相似，但却有所不同。</p>

<h3 id="toc_5">bioProcessBackgroundJobs 函数</h3>

<p>该函数在创建线程后，会直接执行，那么本身对线程做了一些设定：<br/>
<code><br/>
    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);<br/>
    pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);<br/>
</code><br/>
首先，使线程保持可控制性，这样能线程能被杀死，这样做的目的暂时是为了debug调试。</p>

<p>之后，函数对线程进行了信号量的设置：</p>

<pre><code>sigemptyset(&amp;sigset);
sigaddset(&amp;sigset, SIGALRM);
if (pthread_sigmask(SIG_BLOCK, &amp;sigset, NULL))
    serverLog(LL_WARNING,
        &quot;Warning: can&#39;t mask SIGALRM in bio.c thread: %s&quot;, strerror(errno));
</code></pre>

<p>这个之后可以多了解一番。</p>

<p>之后，函数就进入了一个死循环用来不断的处理来自队列的任务，包括AOF同步等。</p>

<h2 id="toc_6">总结</h2>

<p><em>Redis</em>的线程使用比较谨慎，其中仅仅只包含3种类型的线程事件。这样保证了Redis本身代码的简洁。</p>

<h2 id="toc_7">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/lijunamneg/archive/2013/01/25/2877211.html">线程取消</a></li>
<li><a href="https://yq.aliyun.com/articles/58703?utm_source=tool.lu">bio学习</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 跳跃表]]></title>
    <link href="https://artikell.github.io/15286261757400.html"/>
    <updated>2018-06-10T18:22:55+08:00</updated>
    <id>https://artikell.github.io/15286261757400.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<h2 id="toc_1">算法分析</h2>

<h2 id="toc_2">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/men_wen/article/details/70040026">CSDN - 跳跃表(skiplist)</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 对象Object]]></title>
    <link href="https://artikell.github.io/15286147511534.html"/>
    <updated>2018-06-10T15:12:31+08:00</updated>
    <id>https://artikell.github.io/15286147511534.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>在<em>Redis</em>中，对对象拥有一套管理的机制，包括引用、内存、以及淘汰机制，这套机制的的建立，便是Object结构体本身的设计，所以此次，我们通过相关的方面来了解<em>Object</em>对象。</p>

<h2 id="toc_1">主要的类型</h2>

<p>在对象系统中，共有6个类型：<code>string、list、set、zset、hash、stream</code>。</p>

<p>相对应的基础的数据结构也有7类：<code>string、adlist、ziplist、quicklist、dict、skiplist、inset</code></p>

<p>下面的表格将会列出各个类型对应的使用的数据结构：</p>

<table>
<thead>
<tr>
<th>Type_Encoding</th>
<th>DataStruct</th>
<th>Limit</th>
</tr>
</thead>

<tbody>
<tr>
<td>String_int</td>
<td>long long</td>
<td>Element is int</td>
</tr>
<tr>
<td>String_raw</td>
<td>sbs</td>
<td>Length &gt; 44</td>
</tr>
<tr>
<td>String_embstr</td>
<td>embstr</td>
<td>Length &lt;= 44</td>
</tr>
<tr>
<td>List_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
<tr>
<td>List_quicklist</td>
<td>quicklist</td>
<td>Size &gt; 64 or Count &gt; 512</td>
</tr>
<tr>
<td>Set_ht</td>
<td>dict</td>
<td>Element isn’t int or Cout &gt; 512</td>
</tr>
<tr>
<td>Set_intset</td>
<td>intset</td>
<td>Default</td>
</tr>
<tr>
<td>Hash_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
<tr>
<td>Hash_ht</td>
<td>dict</td>
<td>Size &gt; 64 or Count &gt; 512</td>
</tr>
<tr>
<td>Zset_skiplist</td>
<td>dict、skiplist</td>
<td>Size &gt; 64 or Count &gt; 128</td>
</tr>
<tr>
<td>Zset_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
</tbody>
</table>

<p>大部分情况的转换都是根据元素个数与元素大小超过限制进行判断。当然这些限制也是可配置项：</p>

<pre><code>hash-max-ziplist-entries 512 
hash-max-ziplist-value 64 
list-max-ziplist-entries 512 
list-max-ziplist-value 64 
set-max-intset-entries 512 
zset-max-ziplist-entries 128 
zset-max-ziplist-value 64
</code></pre>

<h2 id="toc_2">Object的设计</h2>

<p><em>Object</em>的设计拥有所有对象系统共有的特征：<em>relcount、ptr、type</em>。细节的结构体如下：</p>

<pre><code>typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or
                            * LFU data (least significant 8 bits frequency
                            * and most significant 16 bits access time). */
    int refcount;
    void *ptr;
} robj;
</code></pre>

<p>结构体不难理解，拥有类型、编码、超时权重、引用次数以及所指内存。<br/>
其中<em>类型\编码</em>在上一节已经列举出来，相关的类型原理之后再进行描述。</p>

<h2 id="toc_3">对象的销毁以及共享</h2>

<p>在拥有对象引用属性时，系统就会考虑对象销毁的时机。对象系统提供了<em>decrRefCount</em>和<em>incrRefCount</em>2个方法，前者用于减少引用数，后者相反。</p>

<p>所以，当<em>Redis</em>使用完对象时，会调用<em>decrRefCount</em>方法来减少引用数，当发现引用数为1时，说明当前对象需要被销毁，对象系统会主动调用相关类型的销毁函数进行内存清理。</p>

<p>当然，<em>Redis</em>为了高效，提供了共享对象，其中包含<em>1~10000</em>中间的所有数字，创建时将其的引用数设置为无穷大，同时在减少引用数的时候，判断引用数是否为无穷大，是则不进行引用数减少，提高了内存利用率</p>

<h2 id="toc_4">总结</h2>

<p>关于Redis的对象系统，其实没有什么需要过多的介绍，对于对象来说，<em>Redis</em>本身对不同的类型进行了多态化的分解，导致主要的操作都分散在各个部分中，包括淘汰策略、以及内存分配等。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 字典扫描算法]]></title>
    <link href="https://artikell.github.io/15285709665764.html"/>
    <updated>2018-06-10T03:02:46+08:00</updated>
    <id>https://artikell.github.io/15285709665764.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>字典扫描算法包含了2个特别精巧的位运算算法，2者保证了整个扫描过程即使穿插了重哈希操作也不会顺序混合。</p>

<h2 id="toc_1">问题一：反转一个数</h2>

<p>如何快速反转一个数，正常往往都是<em>O(n)</em>的算法，虽然数字正常不会超过64位，但是，<em>Redis</em>使用了更加位运算将其复杂度减低至了<em>O(logn)</em>。</p>

<p>首先，考虑对于一个二进制数：11010100(212)，如何进行反转？</p>

<p>第一次反转，反转4位：</p>

<pre><code>mask = 0000 1111
1101 0100 &gt;&gt; 4 &amp; 0000 1111 = 0000 1101
1101 0100 &lt;&lt; 4 &amp; 1111 0000 = 0100 0000
0000 1101 | 0100 0000 = 0100 1101
</code></pre>

<p>第二次反转，反转2位：</p>

<pre><code>mask = 0000 1111 ^ 0011 1100  = 0011 0011
0100 1101 &gt;&gt; 2 &amp; 0011 0011 = 0001 0011
0100 1101 &lt;&lt; 2 &amp; 1100 1100 = 0000 0100
0001 0011 | 0000 0100 = 0001 0111
</code></pre>

<p>第三次反转，反转1位：</p>

<pre><code>mask = 0110 0110 ^ 0011 0011  = 0101 0101
0001 0111 &gt;&gt; 1 &amp; 0101 0101 = 0000 0001
0001 0111 &lt;&lt; 1 &amp; 1010 1010 = 0010 1010
0000 0001 | 0010 1010 = 0010 1011
</code></pre>

<p>其实可以发现关键的点就是<em>mask</em>的生成，规律如下：</p>

<pre><code>1. 0000 1111
2. 0011 0011
3. 0101 0101
</code></pre>

<p>通过位运算来反转二进制数。</p>

<h2 id="toc_2">问题二：遍历变长字典</h2>

<p>答案是：从高位遍历到低位。</p>

<p>遍历的情况分为3种：未进行重哈希、扩大字典、缩小字典。对于未进行重哈希的情况就不进行描述。</p>

<h3 id="toc_3">优点</h3>

<ol>
<li>提供键空间的遍历操作，支持游标，复杂度O(1), 整体遍历一遍只需要O(N)；</li>
<li>提供结果模式匹配；</li>
<li>支持一次返回的数据条数设置，但仅仅是个hints，有时候返回的会多；</li>
<li>弱状态，所有状态只需要客户端需要维护一个游标；</li>
</ol>

<h3 id="toc_4">缺点</h3>

<ol>
<li>无法提供完整的快照遍历，也就是中间如果有数据修改，可能有些涉及改动的数据遍历不到；</li>
<li>每次返回的数据条数不一定，极度依赖内部实现；</li>
<li>返回的数据可能有重复，应用层必须能够处理重入逻辑；</li>
</ol>

<h2 id="toc_5">相关链接</h2>

<ul>
<li><a href="http://chenzhenianqing.com/articles/1090.html">Redis Scan迭代器遍历操作原理</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 淘汰策略解读]]></title>
    <link href="https://artikell.github.io/15285605915126.html"/>
    <updated>2018-06-10T00:09:51+08:00</updated>
    <id>https://artikell.github.io/15285605915126.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p><em>Redis</em>本身是一款高效的内存数据库，内存数据库中很重要的一点在于能很好的利用并管理内存，这也衍生出了内存淘汰策略，这和操作系统的内存页管理机制相同，拥有各种淘汰算法，例如：FIFO、LRU、OPT等，这次我们主要是讨论一下关于<em>Redis</em>本身的内存淘汰策略。</p>

<!--more-->

<h2 id="toc_1">过期键淘汰逻辑</h2>

<p>淘汰逻辑<em>Redis</em>本身存在2种方式的淘汰并存，这样做的目的也是为了提高效率。</p>

<h3 id="toc_2">惰性淘汰逻辑</h3>

<p><em>Redis</em>当键值已经超出失效时间时，是无法做到及时的将内存进行空闲出来，同时考虑到及时的将内存空闲出来会需要有十分高的成本。<br/>
于是<em>Redis</em>将淘汰功能，下发至各个命令操作中，当有客户端对相关的键进行访问时，命令将会调用<em>expireIfNeeded</em>方法来判断键值是否已经失效，若是，则将其删除。</p>

<pre><code>int expireIfNeeded(redisDb *db, robj *key) {
    mstime_t when = getExpire(db,key);
    
    mstime_t now;

    if (when &lt; 0) return 0;

    if (server.loading) return 0;

    now = server.lua_caller ? server.lua_time_start : mstime();

    if (server.masterhost != NULL) return now &gt; when;

    if (now &lt;= when) return 0;

    server.stat_expiredkeys++;
    propagateExpire(db,key,server.lazyfree_lazy_expire);
    notifyKeyspaceEvent(NOTIFY_EXPIRED,
        &quot;expired&quot;,key,db-&gt;id);
    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                         dbSyncDelete(db,key);
}
</code></pre>

<p><em>expireIfNeeded</em>函数大致逻辑如下：<br/>
1. 获取当前键的失效时间<br/>
2. 判断失效时间是否小于0，是则表示不失效<br/>
3. 判断当前服务器是否正在加载数据信息<br/>
4. 获取当前时间<br/>
5. 判断是否已经失效<br/>
6. 统计失效键信息<br/>
7. 发送失效键信息至其余节点<br/>
8. 发送键失效通知给订阅通道<br/>
9. 键值删除</p>

<blockquote>
<p>其中键删除操作包括同步删除和异步删除，这次不进行细讲</p>
</blockquote>

<h3 id="toc_3">主动淘汰逻辑</h3>

<p>消极方法的缺点是，如果<em>key</em>迟迟不被访问，就会占用很多内存空间。 所以就产生的主动淘汰：此方法利用了<em>Redis</em>的时间事件，即每隔一段时间就中断一下完成一些指定操作，其中就包括检查并删除失效主键。<br/>
主动淘汰机制相关的配置项为<em>set-active-expire</em>，主要的调用位置为：<em>beforeSleep</em> 和 <em>databasesCron</em> ，一个是事件循环前触发，一个是数据库定时触发。</p>

<pre><code>void activeExpireCycle(int type) {
    static unsigned int current_db = 0; /* Last DB tested. */
    static int timelimit_exit = 0;      /* Time limit hit in previous call? */
    static long long last_fast_cycle = 0; /* When last fast cycle ran. */

    int j, iteration = 0;
    int dbs_per_call = CRON_DBS_PER_CALL;
    long long start = ustime(), timelimit, elapsed;

    if (clientsArePaused()) return;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {
        if (!timelimit_exit) return;
        if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;
        last_fast_cycle = start;
    }

    if (dbs_per_call &gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;
    timelimit_exit = 0;
    if (timelimit &lt;= 0) timelimit = 1;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */

    long total_sampled = 0;
    long total_expired = 0;

    for (j = 0; j &lt; dbs_per_call &amp;&amp; timelimit_exit == 0; j++) {
        int expired;
        redisDb *db = server.db+(current_db % server.dbnum);

        current_db++;
        do {
            unsigned long num, slots;
            long long now, ttl_sum;
            int ttl_samples;
            iteration++;

            if ((num = dictSize(db-&gt;expires)) == 0) {
                db-&gt;avg_ttl = 0;
                break;
            }
            slots = dictSlots(db-&gt;expires);
            now = mstime();
            
            if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;
                (num*100/slots &lt; 1)) break;

            expired = 0;
            ttl_sum = 0;
            ttl_samples = 0;

            if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)
                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;

            while (num--) {
                dictEntry *de;
                long long ttl;

                if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;
                ttl = dictGetSignedIntegerVal(de)-now;
                if (activeExpireCycleTryExpire(db,de,now)) expired++;
                if (ttl &gt; 0) {
                    /* We want the average TTL of keys yet not expired. */
                    ttl_sum += ttl;
                    ttl_samples++;
                }
                total_sampled++;
            }
            total_expired += expired;

            if (ttl_samples) {
                long long avg_ttl = ttl_sum/ttl_samples;

                if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;
                db-&gt;avg_ttl = (db-&gt;avg_ttl/50)*49 + (avg_ttl/50);
            }

            if ((iteration &amp; 0xf) == 0) { /* check once every 16 iterations. */
                elapsed = ustime()-start;
                if (elapsed &gt; timelimit) {
                    timelimit_exit = 1;
                    server.stat_expired_time_cap_reached_count++;
                    break;
                }
            }
        } while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);
    }

    elapsed = ustime()-start;
    latencyAddSampleIfNeeded(&quot;expire-cycle&quot;,elapsed/1000);

    double current_perc;
    if (total_sampled) {
        current_perc = (double)total_expired/total_sampled;
    } else
        current_perc = 0;
    server.stat_expired_stale_perc = (current_perc*0.05)+
                                     (server.stat_expired_stale_perc*0.95);
}

</code></pre>

<p><em>activeExpireCycle</em>函数关键点如下：<br/>
1. 函数提供了 <em>ACTIVE_EXPIRE_CYCLE_FAST</em> 和 <em>ACTIVE_EXPIRE_CYCLE_SLOW</em> 2种模式，区别在于：FAST模式本身对时间有苛刻的要求，不允许淘汰键导致过高的延时，所以会有一个超时时间(1000ms)的限制。<br/>
2. 函数会遍历每个数据库，然后从过期键中获取20个值，若20个中淘汰了5个，则继续淘汰，尽可能的保证过期比例小于0.25。<br/>
3. 其中，函数会统计相关的超时情况以及淘汰时间等。</p>

<h2 id="toc_4">内存淘汰策略</h2>

<p>内存淘汰策略的设置项为<em>maxmemory-policy</em>，其中拥有6种策略：<br/>
1. <em>noeviction</em>策略(不淘汰策略)<br/>
    该策略不进行内存淘汰，当内存达到阀值后，将会报错。但该策略为默认策略，所以每次启用<em>Redis</em>服务时，最好是设置一下淘汰策略<br/>
2. <em>allkeys-lru</em>策略(主键lru策略)<br/>
    在主键空间中，优先移除最近未使用的key。<br/>
3. <em>volatile-lru</em>策略(过期键lru策略)<br/>
    在设置了过期时间的键空间中，优先移除最近未使用的key。<br/>
4. <em>allkeys-random</em>策略(主键随机淘汰策略)<br/>
    在主键空间中，随机移除某个key。<br/>
5. <em>volatile-random</em>策略(过期键随机淘汰策略)<br/>
    在设置了过期时间的键空间中，随机移除某个key。<br/>
6. <em>volatile-ttl</em>策略(过期键fifo策略)<br/>
    在设置了过期时间的键空间中，具有更早过期时间的key优先移除。</p>

<p>对于不同淘汰机制，也存在相关的使用场景：<br/>
1. <em>allkeys-lru</em>：如果我们的应用对缓存的访问符合幂律分布（也就是存在相对热点数据），或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择<em>allkeys-lru</em>策略。<br/>
2. <em>allkeys-random</em>：如果我们的应用对于缓存<em>key</em>的访问概率相等，则可以使用这个策略。<br/>
3. <em>volatile-ttl</em>：这种策略使得我们可以向<em>Redis</em>提示哪些<em>key</em>更适合被<em>eviction</em>。</p>

<h2 id="toc_5">内存淘汰逻辑</h2>

<p>内存超限淘汰机制与上述的过期键淘汰机制不同，它本身存在触发的条件是在于每次定时请求，若发现内存不足时，将会进行键值淘汰，来保证正常运行。</p>

<p>与过期键淘汰函数<em>expireIfNeeded</em>对应的函数为：<em>freeMemoryIfNeeded</em>函数，它将会在定时事件和脚本运行时进行内存检查。它主要的判断条件为当前服务是否设置了<em>maxmemory</em>，若设置了则需要进行内存淘汰。</p>

<p><em>freeMemoryIfNeeded</em>函数本身针对不同的淘汰策略会有不同的逻辑。主要分为随机淘汰和策略淘汰。</p>

<h3 id="toc_6">内存随机淘汰</h3>

<p>随机淘汰的实现相对简单，只需要对不同的空间进行随机筛选键，并进内存释放即可。</p>

<pre><code>for (i = 0; i &lt; server.dbnum; i++) {
    j = (++next_db) % server.dbnum;
    db = server.db+j;
    dict = (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM) ?
            db-&gt;dict : db-&gt;expires;
    if (dictSize(dict) != 0) {
        de = dictGetRandomKey(dict);
        bestkey = dictGetKey(de);
        bestdbid = j;
        break;
    }
}
</code></pre>

<h3 id="toc_7">内存策略淘汰</h3>

<p>待续，关键点：LRU算法</p>

<h2 id="toc_8">总结</h2>

<p><em>Redis</em>淘汰逻辑核心点不多，主要只是将整个淘汰工作分布至各个操作中，提高了整体的效率，同时也使用了异步删除等机制。之后还能衍生出集群的键值淘汰逻辑等。</p>

<h2 id="toc_9">参考链接</h2>

<ul>
<li><a href="https://blog.csdn.net/kl1106/article/details/79566594">CSDN - Redis缓存淘汰</a></li>
<li><a href="https://blog.csdn.net/lizhi_java/article/details/68953179">CSDN - 缓存淘汰策略</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World]]></title>
    <link href="https://artikell.github.io/15284948308748.html"/>
    <updated>2018-06-09T05:53:50+08:00</updated>
    <id>https://artikell.github.io/15284948308748.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
</feed>
