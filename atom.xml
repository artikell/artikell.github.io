<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[artikell]]></title>
  <link href="https://artikell.github.io/atom.xml" rel="self"/>
  <link href="https://artikell.github.io/"/>
  <updated>2019-07-01T10:51:03+08:00</updated>
  <id>https://artikell.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im">MWeb</generator>

  
  <entry>
    <title type="html"><![CDATA[共享内存探真]]></title>
    <link href="https://artikell.github.io/15649767035810.html"/>
    <updated>2019-08-05T11:45:03+08:00</updated>
    <id>https://artikell.github.io/15649767035810.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>当有人问起共享内存的实现的时候，被人问倒了。</p>

<h2 id="toc_1">共享内存类型</h2>

<p>现有系统共有2类共享内存的方法：mmap、shm。下面来介绍2类的优缺点：</p>

<h3 id="toc_2">mmap</h3>

<p>机制： 在磁盘上建立一个文件，每个进程存储器中，单独开辟一个空间来映射，保存到实际硬盘，实际并没有反映到主存上<br/>
优点： 存储量大<br/>
缺点： 读取和写入速度比较慢<br/>
使用方法：<br/>
<code><br/>
int fd = open(argv[1],O_RDWR|O_CREAT|O_TRUNC,0644);<br/>
mmap(NULL,sizeof(struct STU),PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);<br/>
munmap(p,sizeof(student))<br/>
</code><br/>
<img src="media/15649767035810/15649864204288.jpg" alt="mmap模型图示"/></p>

<h3 id="toc_3">shm</h3>

<p>机制： 每个进程的共享内存都直接映射到实际物理存储器上，shm保存到物理存储器(主存)，实际的存储量直接反映到主存上<br/>
优点：进程间访问速度比磁盘快<br/>
缺点： 存储量不能非常大<br/>
使用方法：<br/>
<code><br/>
key_t ftok(const char *pathname, int proj_id) <br/>
int shmget( key_t shmkey , int shmsiz , int flag );<br/>
void *shmat( int shmid , char *shmaddr , int shmflag );<br/>
</code></p>

<p><img src="media/15649767035810/15649864440502.jpg" alt="shm模型图示"/></p>

<h3 id="toc_4">mmap和shm的差异</h3>

<p>1、mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间进行映射。<br/>
而对于shm而言，shm每个进程最终会映射到同一块物理内存。shm保存在物理内存，这样读写的速度要比磁盘要快，但是存储量不是特别大。<br/>
2、相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。<br/>
3、另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget就会丢失。</p>

<h2 id="toc_5">shm实现</h2>

<p>结构图示都如此明白，那共享内存功能如何实现？通过页表。</p>

<p><img src="media/15649767035810/15649869796950.jpg" alt=""/></p>

<p>ftok将一个已存在的路径名和一个整数标识符转换成一个key_t值。<br/>
<code><br/>
key_t ftok(const char *pathname, int proj_id)<br/>
</code><br/>
ftok会组合三个值来产生key：<br/>
1. pathname所在的文件系统的信息。<br/>
2. 该文件在本文件系统内的索引节点号。<br/>
3. id的低序8位。 </p>

<p>在使用shm方法时，可以通过ftok和IPC_PRIVATE的方法结合shm_get方法申请一块共享内存项。当使用shmat方法时，会将页表加载至进程的页表项中。</p>

<h2 id="toc_6">mmap实现</h2>

<p><img src="media/15649767035810/15649879653349.jpg" alt=""/></p>

<p>mmap的执行，仅仅是在内核中建立了文件与虚拟内存空间的对应关系。用户访问这些虚拟内存空间时，页面表里面是没有这些空间的表项的。当用户程序试图访问这些映射的空间时，于是产生缺页异常。内核捕捉这些异常，逐渐将文件载入。<br/>
所谓的载入过程，具体的操作就是read和write在管理pagecache。Vma的结构体中有很文件操作集。vma操作集中会有自己关于page cache的操作集合。这样，虽然是两种不同的系统调用，由于操作和调用触发的路径不同。但是最后还是落实到了page cache的管理。实现了文件内容的操作。</p>

<h2 id="toc_7">问题</h2>

<ol>
<li>进程是如何管理内存的</li>
</ol>

<h2 id="toc_8">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/52php/p/5861372.html">Linux进程间通信（六）：共享内存 shmget()、shmat()、shmdt()、shmctl()</a></li>
<li><a href="https://blog.csdn.net/hj605635529/article/details/73163513">mmap映射区和shm共享内存的区别总结</a></li>
<li><a href="https://blog.csdn.net/xhu_eternalcc/article/details/16801825">IPC之IPC_PRIVATE与ftok比较</a></li>
<li><a href="http://blog.chinaunix.net/uid-24517549-id-4114814.html">共享内存的常用函数原理剖析</a></li>
<li><a href="https://blog.csdn.net/edwardlulinux/article/details/8604400">Mmap的实现原理和应用</a></li>
<li><a href="http://ju.outofmemory.cn/entry/224106">mmap实例及原理分析</a></li>
<li><a href="https://www.cnblogs.com/zhaoyl/p/5515317.html">mmap为什么比read/write快(兼论buffercache和pagecache)</a></li>
<li><a href="https://www.cnblogs.com/alantu2018/p/8472097.html">内存管理概述、内存分配与释放、地址映射机制（mm_struct, vm_area_struct）、malloc/free 的实现</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP基本数据结构]]></title>
    <link href="https://artikell.github.io/15629235064982.html"/>
    <updated>2019-07-12T17:25:06+08:00</updated>
    <id>https://artikell.github.io/15629235064982.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[php-fpm学习]]></title>
    <link href="https://artikell.github.io/15629232560831.html"/>
    <updated>2019-07-12T17:20:56+08:00</updated>
    <id>https://artikell.github.io/15629232560831.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>PHP提供了多种SAPI接口，例如 apache2hander、fastcgi、cli等等。当然，php-fpm也是其中一种。相比其他接口，php-fpm运用更加广泛。</p>

<p>PHP-FPM官方的主要特征：</p>

<ul>
<li>支持平滑停止/启动的高级进程管理功能；</li>
<li>可以工作于不同的 uid/gid/chroot 环境下，并监听不同的端口和使用不同的 php.ini 配置文件（可取代 safe_mode 的设置）；</li>
<li>stdout 和 stderr 日志记录;</li>
<li>在发生意外情况的时候能够重新启动并缓存被破坏的 opcode;</li>
<li>文件上传优化支持;</li>
<li>&quot;慢日志&quot; - 记录脚本（不仅记录文件名，还记录 PHP backtrace 信息，可以使用 ptrace或者类似工具读取和分析远程进程的运行数据）运行所导致的异常缓慢;</li>
<li>fastcgi_finish_request() - 特殊功能：用于在请求完成和刷新数据后，继续在后台执行耗时的工作（录入视频转换、统计处理等）；</li>
<li>动态／静态子进程产生；</li>
<li>基本 SAPI 运行状态信息（类似Apache的 mod_status）；</li>
<li>基于 php.ini 的配置文件。</li>
</ul>

<h2 id="toc_1">fpm的启动</h2>

<p>php-fpm启动流程主要分为三步：<br/>
1. 配置和命令行参数解析<br/>
2. 环境初始化<br/>
3. 进程启动并处理请求</p>

<h2 id="toc_2">核心模块初始化</h2>

<pre><code>    if (0 &gt; fpm_php_init_main()           || // 启动
        0 &gt; fpm_stdio_init_main()         || // 设置输入和输出
        0 &gt; fpm_conf_init_main(test_conf, force_daemon) || // 配置初始化
        0 &gt; fpm_unix_init_main()          ||
        0 &gt; fpm_scoreboard_init_main()    || // 计分板初始化
        0 &gt; fpm_pctl_init_main()          || // 控制初始化
        0 &gt; fpm_env_init_main()           || // 环境初始化
        0 &gt; fpm_signals_init_main()       || // 信号初始化
        0 &gt; fpm_children_init_main()      || // 子进程初始化
        0 &gt; fpm_sockets_init_main()       || // socket初始化
        0 &gt; fpm_worker_pool_init_main()   || // 工作进程初始化
        0 &gt; fpm_event_init_main()) { // 事件初始化

        if (fpm_globals.test_successful) {
            exit(FPM_EXIT_OK);
        } else {
            zlog(ZLOG_ERROR, &quot;FPM initialization failed&quot;);
            return -1;
        }
    
</code></pre>

<ol>
<li>fpm_php_init_main：初始化cleanup链表</li>
<li>fpm_stdio_init_main：初始化命令行的输入输出，输出至/dev/null文件</li>
<li>fpm_conf_init_main：解析配置信息</li>
<li>fpm_unix_init_main：初始化环境信息，包括内存限制以及僵尸化进程</li>
<li>fpm_scoreboard_init_main：计分板初始化，用于统计子进程状态</li>
<li>fpm_pctl_init_main：进程控制初始化，主要是保存可执行文件的路径，用于后续重启进程</li>
<li>fpm_env_init_main：环境初始化，主要是设置进程标题</li>
<li>fpm_signals_init_main：信号初始化，初始化信息屏蔽和处理函数</li>
<li>fpm_children_init_main：子进程初始化，主要是设置<code>emergency_restart_threshold</code>参数</li>
<li>fpm_sockets_init_main：初始化socket描述符</li>
<li>fpm_worker_pool_init_main：初始化工作池对象，只是挂着一个清空的函数</li>
<li>fpm_event_init_main：初始化事件对象，主要是设置最大的事件数</li>
</ol>

<h2 id="toc_3">进程模型</h2>

<p>进程模型主要是fpm的父子进程的关系控制，这就涉及到了进程间通信的问题。<br/>
在fpm中，进程间通信主要有2类：信号下发的信号和数据上报的共享内存</p>

<h3 id="toc_4">进程间通信</h3>

<h4 id="toc_5">信号</h4>

<p>信号主要有：<br/>
1. SIGINT/SIGTERM/SIGQUIT: 退出fpm，在master收到退出信号后将向所有的worker进程发送退出信号，然后master退出<br/>
2. SIGUSR1: 重新加载日志文件，生产环境中通常会对日志进行切割，切割后会生成一个新的日志文件，如果fpm不重新加载将无法继续写入日志，这个时候就需要向master发送一个USR1的信号<br/>
3. SIGUSR2: 重启fpm，首先master也是会向所有的worker进程发送退出信号，然后master会调用execvp()重新启动fpm，最后旧的master退出<br/>
4. SIGCHLD: 这个信号是子进程退出时操作系统发送给父进程的，子进程退出时，内核将子进程置为僵尸状态，这个进程称为僵尸进程，它只保留最小的一些内核数据结构，以便父进程查询子进程的退出状态，只有当父进程调用wait或者waitpid函数查询子进程退出状态后子进程才告终止，fpm中当worker进程因为异常原因(比如coredump了)退出而非master主动杀掉时master将受到此信号，这个时候父进程将调用waitpid()查下子进程的退出，然后检查下是不是需要重新fork新的worker</p>

<p>其中，信号的处理是通过挂载函数sig_handler写入管道，后续由事件模型处理管道在发送信号给子进程，这也成功实现了非阻塞流程。</p>

<h4 id="toc_6">共享内存</h4>

<p>共享内存的实践则是用在计分板功能上。fpm为了获取子进程状态，则为每个子进程开辟一块共享内存区域，子进程自动更新相关数据，而由主进程来获取并进行相关操作。同时计分板还担任了进程数控制的功能，如果在创建子进程时未获取到计分板对象，则无法fork新进程</p>

<p>计分板状态：<br/>
1. FPM_REQUEST_ACCEPTING 空闲状态(等待请求)<br/>
2. FPM_REQUEST_READING_HEADERS 读取头信息<br/>
3. FPM_REQUEST_INFO 获取请求信息<br/>
4. FPM_REQUEST_EXECUTING 执行状态<br/>
5. FPM_REQUEST_END 请求结束状态</p>

<p>计分板相关结构体：</p>

<pre><code>struct fpm_scoreboard_proc_s {
    union {
        atomic_t lock;
        char dummy[16];
    };//锁状态
    int used; //使用标识 0=未使用 1=正在使用
    time_t start_epoch; //使用开始时间
    pid_t pid; //进程id
    unsigned long requests; //处理请求次数
    enum fpm_request_stage_e request_stage; //处理请求阶段
    struct timeval accepted; //accept请求时间
    struct timeval duration; //脚本总执行时间
    time_t accepted_epoch;//accept请求时间戳(秒)
    struct timeval tv; //活跃时间
    char request_uri[128]; //请求路径
    char query_string[512]; //请求参数
    char request_method[16]; //请求方式
    size_t content_length; //请求内容长度 
    char script_filename[256];//脚本名称
    char auth_user[32];
#ifdef HAVE_TIMES
    struct tms cpu_accepted;
    struct timeval cpu_duration;
    struct tms last_request_cpu;
    struct timeval last_request_cpu_duration;
#endif
    size_t memory;//脚本占用的内存大小
};
</code></pre>

<h3 id="toc_7">进程模式</h3>

<p>fpm存在三种不同的进程管理方式：<br/>
- <strong>static</strong>: 这种方式比较简单，在启动时 master 按照pm.max_children配置 fork 出相应数量的 worker 进程，即 worker 进程数是固定不变的；<br/>
- <strong>dynamic</strong>: 动态进程管理，首先在 fpm 启动时按照pm.start_servers初始化一定数量的 worker，运行期间如果 master 发现空闲 worker 数低于pm.min_spare_servers配置数（表示请求比较多，worker 处理不过来了）则会 fork worker 进程，但总的 worker 数不能超过pm.max_children，如果 master 发现空闲 worker 数超过了pm.max_spare_servers(表示闲着的 worker 太多了)则会杀掉一些 worker，避免占用过多资源，master 通过这 4 个值来控制 worker 数；<br/>
- <strong>ondemand</strong>: 这种方式一般很少用，在启动时不分配 worker 进程，等到有请求了后再通知 master 进程 fork worker 进程，总的 worker 数不超过pm.max_children，处理完成后 worker 进程不会立即退出，当空闲时间超过pm.process_idle_timeout后再退出；</p>

<h3 id="toc_8">事件模型</h3>

<p>事件模型主要针对master进程而言，同时需要了解的是，master进程是通过链表和epoll等事件模型来实现自身的事件循环。</p>

<pre><code>void fpm_event_loop(int err)
{
    //创建一个io read的监听事件，这里监听的就是在fpm_init()阶段中通过socketpair()创建管道sp[0]
    //当sp[0]可读时将回调fpm_got_signal()
    fpm_event_set(&amp;signal_fd_event, fpm_signals_get_fd(), FPM_EV_READ, &amp;fpm_got_signal, NULL);
    fpm_event_add(&amp;signal_fd_event, 0);

    //如果在php-fpm.conf配置了request_terminate_timeout则启动心跳检查
    if (fpm_globals.heartbeat &gt; 0) {
        fpm_pctl_heartbeat(NULL, 0, NULL);
    }
    //定时触发进程管理
    fpm_pctl_perform_idle_server_maintenance_heartbeat(NULL, 0, NULL);
    
    //进入事件循环，master进程将阻塞在此
    while (1) {
        ...
        //等待IO事件
        ret = module-&gt;wait(fpm_event_queue_fd, timeout);
        ...
        //检查定时器事件
        ...
    }
}
</code></pre>

<p>其中主要的3大事件分别是：<br/>
1. sp[1]管道可读事件<br/>
2. fpm_pctl_perform_idle_server_maintenance_heartbeat 进程管理事件<br/>
3. fpm_pctl_heartbeat 超时管理事件</p>

<h2 id="toc_9">相关链接</h2>

<ol>
<li><a href="https://www.fanhaobai.com/2017/10/internal-php-fpm.html">深入源码剖析PHP-FPM</a></li>
<li><a href="https://blog.csdn.net/mijar2016/article/details/53414402">PHP源码分析 - PHP-FPM scoreboard模块介绍</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis特征整理学习]]></title>
    <link href="https://artikell.github.io/15621254404161.html"/>
    <updated>2019-07-03T11:44:00+08:00</updated>
    <id>https://artikell.github.io/15621254404161.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Redis特征</h2>

<p>学习是一个从头开始的过程，于是看看Redis都是怎么发展的。</p>

<h3 id="toc_1">Redis历史升级</h3>

<h4 id="toc_2">Redis2.6</h4>

<p>1）键的过期时间支持毫秒<br/>
2）从节点提供只读功能<br/>
3）服务端支持Lua脚本<br/>
4）放开客户端连接数的硬编码限制<br/>
5）去掉虚拟内存相关功能等</p>

<h4 id="toc_3">Redis2.8</h4>

<p>1）完善主从复制功能，实现增量复制<br/>
2）Redis设置明显的进程名，在系统中ps命令即可查看<br/>
3）发布/订阅添加pub/sub命令<br/>
4）Redis Sentinel第二版发布，较Redis 2.6更加完善，可以线上使用<br/>
5）可以通过config set命令设置maxclients等</p>

<h4 id="toc_4">Redis3.0</h4>

<p>1）推出Redis的分布式集群 Redis Cluster<br/>
2）全新的embedded string对象编码结果，优化小对象的内存访问，在特定的工作负载下能大幅度提升性能<br/>
3）LRU算法提升<br/>
4）config set 设置maxmemory的时候可以设置不用的单位<br/>
5）新的Client pause命令，在指定时间内停止处理客户端请求等</p>

<h4 id="toc_5">Redis3.2</h4>

<p>1）添加GEO功能<br/>
2）新的List编码类型quicklist<br/>
3）SDS在速度和节省空间上都做了优化<br/>
4）Lua脚本功能增强<br/>
5）新的RDB格式，仍兼容旧版RDB，同时加载速度上也有提升<br/>
6）Cluster nodes命令加速等</p>

<h4 id="toc_6">Redis4.0</h4>

<p>1）psync2.0，优化了之前版本主从节点切换必然引起全量复制的问题<br/>
2）提供全新的缓存剔除算法LFU，并对已有算法进行了优化<br/>
3）提供了非阻塞del和flushall和flushdb功能，有效解决了删除bigkey可能造成的Redis阻塞<br/>
4）提供了RDB-AOF混合持久化格式<br/>
5）提供memory命令，实现对内存的更为全面的监控统计<br/>
6）Redis Cluster 兼容NAT和Docker<br/>
7）引入Jemalloc库，优化内存访问等等</p>

<h3 id="toc_7">Redis升级亮点</h3>

<ul>
<li>推出Redis的分布式集群 Redis Cluster</li>
<li>全新的embedded string对象编码结果，优化小对象的内存访问，在特定的工作负载下能大幅度提升性能</li>
<li>LRU算法提升</li>
<li>新的List编码类型quicklist</li>
<li>psync2.0，优化了之前版本主从节点切换必然引起全量复制的问题</li>
<li>提供全新的缓存剔除算法LFU，并对已有算法进行了优化</li>
<li>新的RDB格式，仍兼容旧版RDB，同时加载速度上也有提升</li>
<li>Redis Cluster 兼容NAT和Docker</li>
<li>提供了RDB-AOF混合持久化格式</li>
</ul>

<h2 id="toc_8">基础结构</h2>

<p>从底层往上层整理相关疑问点，这样可以具体理清楚细节。</p>

<h3 id="toc_9">基础类型</h3>

<p>Redis 五大数据类型是：</p>

<ul>
<li><strong>string（字符串）</strong>是 redis 最基本的类型，一个 key 对应一 个 value 。string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象 。它也是 redis 最基本的数据类型，一个 redis 中字符串 value 最多可以是512M。</li>
<li><strong>hash（哈希）</strong>是一个键值对集合，是一个 string 类型的 field 和 value 的映射表，hash特别适合用于存储对象。类似Java里面的Map<String,Object>。</li>
<li><strong>list（列表）</strong>是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。</li>
<li><strong>set（集合）</strong>是string类型的无序集合。它是通过HashTable实现实现的。</li>
<li>**zset(sorted set：有序集合) **set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。</li>
</ul>

<h3 id="toc_10">对象类型</h3>

<p>针对每个对象，有一个类型和一个编码字段，并还有引用和数据指针：</p>

<pre><code>typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */
    int refcount;
    void *ptr;
} robj;
</code></pre>

<p><img src="media/15621254404161/15621274941958.jpg" alt="存储结构对应图"/></p>

<h2 id="toc_11">命令处理流程</h2>

<h3 id="toc_12">Redis协议</h3>

<p>客户端发送命令的格式(类型)：<br/>
间隔符号，在Linux下是\r\n，在Windows下是\n</p>

<ol>
<li><p>简单字符串 Simple Strings, 以 &quot;+&quot;加号 开头<br/>
格式：+ 字符串 \r\n<br/>
字符串不能包含 CR或者 LF(不允许换行)<br/>
<code><br/>
eg: &quot;+OK\r\n&quot;<br/>
</code></p>

<blockquote>
<p>注意：为了发送二进制安全的字符串，一般推荐使用后面的 Bulk Strings类型</p>
</blockquote></li>
<li><p>错误 Errors, 以&quot;-&quot;减号 开头<br/>
格式：- 错误前缀 错误信息 \r\n<br/>
错误信息不能包含 CR或者 LF(不允许换行)，Errors与Simple Strings很相似，不同的是Erros会被当作异常来看待<br/>
<code><br/>
eg: &quot;-Error unknow command &#39;foobar&#39;\r\n&quot;<br/>
</code></p></li>
<li><p>整数型 Integer， 以 &quot;:&quot; 冒号开头<br/>
格式：: 数字 \r\n<br/>
<code><br/>
eg: &quot;:1000\r\n&quot;<br/>
</code></p></li>
<li><p>大字符串类型 Bulk Strings, 以 &quot;\(&quot;美元符号开头，长度限制512M<br/>
格式：\) 字符串的长度 \r\n 字符串 \r\n<br/>
字符串不能包含 CR或者 LF(不允许换行);<br/>
eg: <br/>
<code><br/>
&quot;$6\r\nfoobar\r\n&quot;    其中字符串为 foobar，而6就是foobar的字符长度<br/>
&quot;$0\r\n\r\n&quot;       空字符串<br/>
&quot;$-1\r\n&quot;           null<br/>
</code></p></li>
<li><p>数组类型 Arrays，以 &quot;*&quot;星号开头<br/>
格式：* 数组元素个数 \r\n 其他所有类型 (结尾不需要\r\n)<br/>
eg: <br/>
<code><br/>
&quot;*0\r\n&quot;      空数组<br/>
&quot;*2\r\n$2\r\nfoo\r\n$3\r\nbar\r\n&quot;      数组包含2个元素，分别是字符串foo和bar<br/>
&quot;*3\r\n:1\r\n:2\r\n:3\r\n&quot;       数组包含3个整数：1、2、3<br/>
&quot;*5\r\n:1\r\n:2\r\n:3\r\n:4\r\n$6\r\nfoobar\r\n&quot;  包含混合类型的数组<br/>
&quot;*-1\r\n&quot;         Null数组<br/>
</code></p>

<blockquote>
<p>注意：只有元素个数后面的\r\n是属于该数组的，结尾的\r\n一般是元素的</p>
</blockquote></li>
</ol>

<h2 id="toc_13">事件处理</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[系统调用探真]]></title>
    <link href="https://artikell.github.io/15619022452968.html"/>
    <updated>2019-06-30T21:44:05+08:00</updated>
    <id>https://artikell.github.io/15619022452968.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>大家都说：系统调用比较耗时。所以，那什么是系统调用，什么是陷入内核。</p>

<p>好像没人好好解释过，于是，整理一段资料来集中说明系统调用的实现</p>

<h2 id="toc_1">定义</h2>

<p>操作系统实现提供的所有系统调用所构成的集合即程序接口或应用编程接口(Application Programming Interface，API)。是应用程序同系统之间的接口。</p>

<p>而系统调用的实现，又是如何通知到系统的呢？是简单的调用一个函数吗？显然不是。</p>

<p>很重要的一个问题是，系统调用是一个内核提供的接口，所以，接口就有同一个的一个入口，同时也要保持隔离性。这就是所谓的<strong>中断和内核态</strong>。</p>

<h3 id="toc_2">中断</h3>

<p>中断是计算机发展中一个重要的技术，它的出现很大程度上解放了CPU，提高了CPU的执行效率。</p>

<p>从物理学的角度看，中断是一种电信号，由硬件设备产生，并直接送入中断控制器的输入引脚上，然后再由中断控制器向处理器发送相应的信号。处理器一经检测到该信号，便中断自己当前正在处理的工作，转而去处理中断。此后， 处理器会通知 OS 已经产生中断。</p>

<p>其中中断有分为硬中断和软中断。</p>

<h4 id="toc_3">硬中断的特点</h4>

<ol>
<li><p>硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。</p></li>
<li><p>处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主CPU的支持下，可以同时处理多个中断。）。</p></li>
<li><p>硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。</p></li>
<li><p>对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。</p></li>
</ol>

<h4 id="toc_4">软中断的特点</h4>

<ol>
<li><p>软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。</p></li>
<li><p>通常，软中断是一些对I/O的请求。这些请求会调用内核中可以调度I/O发生的程序。对于某些设备，I/O请求需要被立即处理，而磁盘I/O请求通常可以排队并且可以稍后处理。根据I/O模型的不同，进程或许会被挂起直到I/O完成，此时内核调度器就会选择另一个进程去运行。I/O可以在进程之间产生并且调度过程通常和磁盘I/O的方式是相同。</p></li>
<li><p>软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。</p></li>
<li><p>软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。</p></li>
</ol>

<h4 id="toc_5">软硬中断的本质</h4>

<p>软中断的本质就是在内核某些位置检查是否有挂起的软中断（<em>local_software_pending</em>()不为0则表示有挂起的软中断），若有则调用<em>do_softirq</em>函数，在<em>do_softirq</em>函数中切换到软中断请求栈后，调用<em>__do_softirq</em>软中断回调函数。</p>

<p>硬中断的本质是接收到中断信号后，跳转到公共段代码执行<em>do_IRQ</em>，并切换到硬中断请求栈，执行中断回调函数。</p>

<p>而针对不同的中断类型调用不同的中断函数，linux则提供了一个中断向量表来实现这一功能。</p>

<h4 id="toc_6">系统调用和中断</h4>

<p>Linux系统中的系统调用在不断的增加，而中断向量表的大小则被固定为255（1字节）个，所以，一一对应是不可能的，内核固定一个软中断（<em>int 0x80</em>）来接收系统调用，并利用参数来区分不同的系统调用。</p>

<p>中断发生以后，CPU跳到内核设置好的中断处理代码中去，由这部分内核代码来处理中断。这个处理过程中的上下文就是中断上下文。这个跳到内核的过程，就是<strong>陷入内核</strong>。</p>

<h2 id="toc_7">内核态</h2>

<p>要说起内核态，那相对要说说用户态。为什么会有这一层隔离呢？那继续要讲讲内存的隔离。</p>

<h3 id="toc_8">内存隔离</h3>

<p>内存如同系统中的数据库一样，而内核则就是一个独立子系统，系统要保持稳定，最重要的就是进行彻底隔离。<br/>
既然要隔离，如果数据被轻易查询并修改，那是不行的，所以首先要做的就是将数据查询功能进行改造，也就是<strong>寻址</strong></p>

<h4 id="toc_9">分段和分页</h4>

<p>分段和分页功能，关键就是解决寻址上的隔离，这是cpu支持的功能，也就是MMU（<em>内存管理单元</em>）模块。</p>

<p>要理解段页式，则还要讲到物理地址(physical address)、线性地址(linear address)或也叫虚拟地址(virtual address)的区别</p>

<ol>
<li><strong>物理地址(physical address)：</strong>用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相对应。</li>
<li><strong>线性地址(linear address)</strong>：跟逻辑地址类似，它也是一个不真实的地址，如果逻辑地址是对应的硬件平台段式管理转换前地址的话，那么线性地址则对应了硬件页式内存的转换前地址。</li>
<li><strong>逻辑地址(logical address)：</strong>是指由程序产生的与段相关的偏移地址部分。例如，你在进行C语言指针编程中，可以读取指针变量本身值(&amp;操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址，不和绝对物理地址相干。</li>
</ol>

<p><img src="media/15619022452968/15619060395681.jpg" alt="三种地址转换流程"/></p>

<p>其实分页可以解决逻辑地址到物理地址的转换工作：只要逻辑地址前置支持索引并查询页表即可。但有个问题在于，一个程序中的地址在编译时已经固定，而页表中的索引在不断变化，在不同时间启动，对应的索引可能就会不一致。<br/>
于是，系统做了一次隔离，通过段描述符来将固定的虚拟地址映射到动态的段基地址中，后续再通过页表来找到对应的物理地址，页表的功能也避免的<em>碎片化</em>的产生，因为如果只存在段表的话，扩缩容是一个很头疼的问题。</p>

<h5 id="toc_10">GDT和LDT</h5>

<p>段描述符的数组就叫做GDT(Global Descriptor Table，全局描述表)，Intel的设计者门提供了一个寄存器GDTR用来存放GDT的入口地址。程序员将GDT设定在内存中某个位置之后，可以通过LGDT指令将GDT的入口地址装入此寄存器，从此以后，CPU就根据此寄存器中的内容作为GDT的入口来访问GDT了。</p>

<p>除了GDT之外，还有LDT(Local Descriptor Table，本地描述表)，但与GDT不同的是，LDT在系统中可以存在多个，每个进程可以拥有自己的LDT。LDT的内存地址在LDTR寄存器中。</p>

<blockquote>
<p>而，页表地址则是通过PCB的指针进行定义，因为每个进程是独享一份。</p>
</blockquote>

<h3 id="toc_11">调用隔离</h3>

<p>内存寻址通过段页式进行改造，那么，系统就可以在其中进行鉴权并隔离。这其中，就是口口相传的Ring0和Ring3权限。</p>

<p>首先，逻辑地址是由段选择符(16位) + 段内偏移量offset(32位)得来。<br/>
而段选择符则是GDT和LDT的索引ID，如下图：</p>

<p><img src="media/15619022452968/15619160286018.jpg" alt="段选择符"/></p>

<p>表指示器用于区分GDT还是LDT，高13位则是索引，也就是说最大有2<sup>14=16384个段信息。而其中最后2个字符RPL，大名叫做Rquest</sup> Privilege Level，请求权限等级。它还有2个兄弟，分别是CPL和DPL。</p>

<h4 id="toc_12">RPL\CPL\DPL是啥</h4>

<h5 id="toc_13">CPL(Current Privilege Level)</h5>

<p>CPL是当前执行的任务的特权等级，<em>存储在CS和SS的第0位和第1位上</em>。(两位表示0~3四个等级)<br/>
通常情况下，CPL等于代码所在段的特权等级，当程序转移到不同的代码段时，处理器将改变CPL。<br/>
注意:在遇到一致代码段时，情况特殊，一致代码段的特点是：可以被等级相同或者更低特权级的代码访问，当处理器访问一个与当前代码段CPL特权级不同的一致代码段时，CPL不会改变。</p>

<h5 id="toc_14">DPL(Descriptor Privilege Level)</h5>

<p>表示门或者段的特权级，<em>存储在门（中断描述符IDT）或者段的描述符（GDT）</em>的DPL字段中。正如上面说的那样，当当前代码段试图访问一个段或者门时，其DPL将会和当前特权级CPL以及段或门的选择子比较，根据段或者门的类型不同，DPL的含义不同：<br/>
1. 数据段的DPL：规定了访问此段的最低权限。比如一个数据段的DPL是1，那么只有运行在CPL为0或1的程序才可能访问它。为什么说可能呢？因为还有一个比较的因素是RPL。访问数据段要满足有效特权级别（上述）高于数据段的DPL.<br/>
2. 非一致代码段的DPL(不使用调用门的情况)：DPL规定访问此段的特权，只有CPL与之相等才有可能访问。<br/>
3. 调用门的DPL，规定了程序或任务访问该门的最低权限。与数据段同。<br/>
4. 一致代码段和通过调用门访问的非一致代码段，DPL规定访问此段的最高权限。<br/>
 比如一个段的DPL为2，那么CPL为0或者1的程序都无法访问。<br/>
5. TSS的DPL，同数据段。</p>

<h5 id="toc_15">RPL（Rquest Privilege Level）</h5>

<p>RPL是通过<em>段选择符的低两位</em>来表现出来的(这么说来，CS和SS也是存放选择子的，同时CPL存放在CS和SS的低两位上，那么对CS和SS来说，选择子的RPL=当前段的CPL)。<br/>
处理器通过检查RPL和CPL来确认一个访问是否合法。即提出访问的段除了有足够的特权级CPL，如果RPL不够也是不行的(有些情况会忽略RPL检查)。</p>

<p>三兄弟解决了什么问题？内存鉴权</p>

<h4 id="toc_16">鉴权</h4>

<p>上述的三兄弟，分别为使用方（CPL）、数据方（DPL）、中间寻址方（RPL），那系统就可以在寻址的时候做数据鉴权。那有个很严重的问题：<strong>权限谁能修改呢？</strong></p>

<p>这个问题很严重，关系到鉴权是否成功。那我们就考虑一下，什么时候需要修改权限？<br/>
获取数据的时候？我们做的隔离就是为了避免用户进程直接修改内核数据。<br/>
那剩下的就是方法调用的时候！这就是CPU在一些特点情况下支持的方法调用，例如<code>jmp</code>和<code>call</code>方法。也就是四个门：<em>任务门(task gate）、中断门(interrupt gate)、陷阱门(trap gate)以及调用门（call gate）</em>，而系统调用是通过中断门来实现。</p>

<h5 id="toc_17">中断流程</h5>

<p>产生中断后，CPU一定不会将运行控制从高特权级转向低特权级，特权级必须要么保持不变（当操作系统内核自己被中断的时候），或被提升（当用户态程序被中断的时候）。无论哪一种情况，作为结果的CPL必须等于目的代码段的DPL。</p>

<p>如果CPL发生了改变（比如从用户态到内核态），一个<em>栈切换操作</em>（通过TSS完成）就会发生。如果中断是被用户态程序中的指令所触发的（比如软件执行INT n生产的中断），还会增加一个额外的检查：<em>门的DPL必须具有与CPL相同或更低的特权</em>。这就防止了用户代码随意触发中断。如果这些检查失败，就会产生一个一般保护异常（general-protection exception）。</p>

<h2 id="toc_18">系统调用耗时</h2>

<p>所以，系统调用的耗时，主要和中断耗时一样：需要保存用户程序得上下文(context), 在进入内核得时候需要保存用户态得寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容。这是一个开销的地方。系统调用的返回过程有很多额外工作，比如检查是否需要调度等。 </p>

<p>当然还包括中断表的查询、参数校验等操作。</p>

<p>这样的设计核心原因还是由于需要系统的安全稳定。</p>

<blockquote>
<p>听说，系统调用大约在50us左右</p>
</blockquote>

<h2 id="toc_19">相关链接</h2>

<ol>
<li><a href="https://blog.csdn.net/xuchenhuics/article/details/79120644">硬中断与软中断区别</a></li>
<li><a href="https://blog.csdn.net/haolianglh/article/details/51946687">LINUX-内核-中断分析-中断向量表（1）-x86</a></li>
<li><a href="https://www.cnblogs.com/chenwb89/p/operating_system_003.html">操作系统篇-分段机制与GDT|LDT</a></li>
<li><a href="http://www.it610.com/article/3713465.htm">页表以及相关的描述符详解</a></li>
<li><a href="https://blog.csdn.net/rabbit_in_android/article/details/49976101">虚拟地址、逻辑地址、线性地址、物理地址</a></li>
<li><a href="https://blog.csdn.net/tianhuadihuo/article/details/6845287">linux操作系统CPL、DPL、RPL说明</a></li>
<li><a href="https://www.yuerer.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B-%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E3%80%81%E4%B8%AD%E6%96%AD%E3%80%81%E8%B0%83%E7%94%A8/">操作系统之 系统启动、中断、调用</a></li>
<li><a href="http://www.sohu.com/a/297560924_100008608">一篇就能帮助新手搞懂 Linux 内存</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_6b94d5680101va6e.html">Linux内核源代码情景分析---第三章 中断、异常和系统调用 </a></li>
<li><a href="https://blog.csdn.net/bfboys/article/details/52420211">总结：特权级之间的转换</a></li>
<li><a href="https://blog.csdn.net/chen1540524015/article/details/73818689">中断处理特权级转换</a></li>
<li><a href="https://blog.csdn.net/liuhangtiant/article/details/85227125">谈一谈copy_from_user和copy_to_user</a></li>
<li>[]</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux 锁]]></title>
    <link href="https://artikell.github.io/15616155804503.html"/>
    <updated>2019-06-27T14:06:20+08:00</updated>
    <id>https://artikell.github.io/15616155804503.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>锁，在系统中，有那么多，可是没看到有一个整体介绍的问题，没有的话，我咋和妹子愉快的交流。</p>

<h2 id="toc_1">锁的类型</h2>

<p>遵循互联网三大原则：是什么、为什么、怎么做，我们来锁看看是什么。</p>

<h3 id="toc_2">互斥量(mutex)</h3>

<p>锁操作主要包括加锁<em>pthread_mutex_lock()</em>、解锁<em>pthread_mutex_unlock()</em>和测试加锁 <em>pthread_mutex_trylock()</em>三个，不论哪种类型的锁，都不可能被两个不同的线程同时得到，而必须等待解锁。</p>

<p><em>pthread_mutex_trylock()</em>语义与<em>pthread_mutex_lock()</em>类似，不同的是在锁已经被占据时返回<em>EBUSY</em>而不是挂起等待。</p>

<ol>
<li>读写锁(rwlock)</li>
<li>条件变量(cond)</li>
<li>信号量(sem)</li>
<li>自旋锁(spin_lock)</li>
<li>文件互斥</li>
<li>原子操作(atomic)</li>
</ol>

<h2 id="toc_3">相关链接</h2>

<ul>
<li><a href="http://mingxinglai.com/cn/2013/06/mutil-threads/#1">http://mingxinglai.com/cn/2013/06/mutil-threads/#1</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[限流算法整理]]></title>
    <link href="https://artikell.github.io/15613654156668.html"/>
    <updated>2019-06-24T16:36:55+08:00</updated>
    <id>https://artikell.github.io/15613654156668.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>曾经有个人问：如何给一个系统做流量限制。</p>

<p>大笔一挥：redis记录访问日志，入口控制流量。然后，自我感觉很不好，于是学习相关知识，并整理相关内容。</p>

<h2 id="toc_1">问题来源</h2>

<p>每个API接口都是有访问上限的,当访问频率或者并发量超过其承受范围时候,我们就必须考虑限流来保证接口的可用性或者降级可用性。即接口也需要安装上保险丝,以防止非预期的请求对系统压力过大而引起的系统瘫痪.</p>

<p>限流是一个兜底性的能力，业务不强依赖，所以尽可能的减低成本，但用的时候要保证正常可用。若直接使用Redis来进行限流操作，成本过高，而且增加依赖。市面上主流算法有2类：令牌 OR 漏斗。</p>

<h2 id="toc_2">主流算法</h2>

<h3 id="toc_3">漏桶算法</h3>

<p>漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率.示意图如下:</p>

<p><img src="media/15613654156668/15613823262965.jpg" alt=""/></p>

<p>可见这里有两个变量,一个是桶的大小,支持流量突发增多时可以存多少的水(burst),另一个是水桶漏洞的大小(rate)，</p>

<p>因为漏桶的漏出速率是固定的参数,所以,即使网络中不存在资源冲突(没有发生拥塞),漏桶算法也不能使流突发(burst)到端口速率.因此,漏桶算法对于存在突发特性的流量来说缺乏效率.</p>

<h3 id="toc_4">令牌算法</h3>

<p>令牌桶算法(Token Bucket)和 Leaky Bucket 效果一样但方向相反的算法,更加容易理解.随着时间流逝,系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反,有个水龙头在不断的加水),如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务.</p>

<p><img src="media/15613654156668/15613823013929.jpg" alt=""/></p>

<p>令牌桶的另外一个好处是可以方便的改变速度. 一旦需要提高速率,则按需提高放入桶中的令牌的速率. 一般会定时(比如100毫秒)往桶中增加一定数量的令牌, 有些变种算法则实时的计算应该增加的令牌的数量.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP错误等级]]></title>
    <link href="https://artikell.github.io/15610970687582.html"/>
    <updated>2019-06-21T14:04:28+08:00</updated>
    <id>https://artikell.github.io/15610970687582.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>有人问，在PHP中，函数名重复和函数不存在，分别会报什么错误？而我，一头雾水，于是，来整理整理。</p>

<h2 id="toc_1">PHP的错误</h2>

<h3 id="toc_2">错误分类</h3>

<p>首先，至少能知道，php中有个可以控制报错信息的函数：<code>error_reporting</code>，而该函数的参数，则是各个错误与等级：</p>

<pre><code>1    E_ERROR        报告运行时的致命错误
2    E_WARNING      报告运行的非致命错误

4    E_PARSE        报告解析错误
8    E_NOTICE       报告通告，注意，表示所做的事情可能是错误的.
16   E_CORE_ERROR   报告PHP引擎启动失败
32   E_CORE_WARNING 报告PHP引擎启动时非致命错误

64   E_COMPILE_ERROR    报告编译错误
128  E_COMPILE_WARNING  报告编译时出现的非致命错误

256  E_USER_ERROR      报告用户触发的错误
512  E_USER_WARNING    报告用户触发的警告
1024 E_USER_NOTICE     报告用户触发的通告

2048 E_STRICT         报告不赞成的用法和不推荐的行为
8192 E_DEPRECATED     运行时通知。启用后将会对在未来版本中可能无法正常工作的代码给出警告。
30719 E_ALL           报告所有的错误和警告
</code></pre>

<p>当然，你可以通过修改php.ini文件来设置默认错误等级：<br/>
<code><br/>
error_reporting = E_ALL &amp; ~(E_NOTICE) &amp; ~(E_WARNING)<br/>
</code></p>

<p>在php.ini文件中，和错误有关的设置有如下几个:<br/>
1. error_reporting，设定错误级别<br/>
2. display_errors，是否显示错误报告，设置为ON则打开,设置为OFF则关闭所有错误提示<br/>
3. log_errors，默认设置为OFF,是否记录错误日志;<br/>
4. track_errors，默认设置为OFF,该选项可以帮助解决代码中的错误,而不是让PHP提供其默认的功能。</p>

<h3 id="toc_3">错误级别</h3>

<p>为了那快速定位类型，于是就有下面的前置脚本：</p>

<pre><code>&lt;?php
error_reporting(E_ALL);
function errorHandler($errno, $errstr, $errfile, $errline)
{
    switch($errno)
    {
        case E_ERROR: // 1 //
            echo &#39;E_ERROR&#39;.PHP_EOL;
        case E_WARNING: // 2 //
            echo &#39;E_WARNING&#39;.PHP_EOL;
        case E_PARSE: // 4 //
            echo &#39;E_PARSE&#39;.PHP_EOL;
        case E_NOTICE: // 8 //
            echo &#39;E_NOTICE&#39;.PHP_EOL;
        case E_CORE_ERROR: // 16 //
            echo &#39;E_CORE_ERROR&#39;.PHP_EOL;
        case E_CORE_WARNING: // 32 //
            echo &#39;E_CORE_WARNING&#39;.PHP_EOL;
        case E_COMPILE_ERROR: // 64 //
            echo &#39;E_COMPILE_ERROR&#39;.PHP_EOL;
        case E_COMPILE_WARNING: // 128 //
            echo &#39;E_COMPILE_WARNING&#39;.PHP_EOL;
        case E_USER_ERROR: // 256 //
            echo &#39;E_USER_ERROR&#39;.PHP_EOL;
        case E_USER_WARNING: // 512 //
            echo &#39;E_USER_WARNING&#39;.PHP_EOL;
        case E_USER_NOTICE: // 1024 //
            echo &#39;E_USER_NOTICE&#39;.PHP_EOL;
        case E_STRICT: // 2048 //
            echo &#39;E_STRICT&#39;.PHP_EOL;
        case E_RECOVERABLE_ERROR: // 4096 //
            echo &#39;E_RECOVERABLE_ERROR&#39;.PHP_EOL;
        case E_DEPRECATED: // 8192 //
            echo &#39;E_DEPRECATED&#39;.PHP_EOL;
        case E_USER_DEPRECATED: // 16384 //
            echo &#39;E_USER_DEPRECATED&#39;.PHP_EOL;
    }
}

$error_handler = set_error_handler(&quot;errorHandler&quot;);
</code></pre>

<p>这样，我们就开始定位相关错误会出现的情况。</p>

<h4 id="toc_4">E_DEPRECATED &amp;&amp; E_USER_DEPRECATED</h4>

<pre><code>&lt;?php
include &#39;err.php&#39;;
class A {
    public function b() {
    }
}
$a = new A();
$a::b();
</code></pre>

<p>这个问题主要是因为通过静态方法的方式访问了非静态方法，官方介绍为：<em>启用后将会对在未来版本中可能无法正常工作的代码给出警告</em></p>

<h4 id="toc_5">函数重复</h4>

<pre><code>&lt;?php
include &#39;err.php&#39;;
class A {
    public function a(){
    }
    public function a(){
    }
}
$a = new A();
$a-&gt;a();
</code></pre>

<p>该问题则直接报：<code>PHP Fatal error:  Cannot redeclare A::a()</code>，说明这个直接解析失败，并走不到报错的逻辑。</p>

<h4 id="toc_6">访问不存在的方法</h4>

<pre><code>&lt;?php
include &#39;err.php&#39;;
class A {
}
$a = new A();
$a-&gt;a();
</code></pre>

<p>这个问题，也是报<code>PHP Fatal error:  Uncaught Error: Call to undefined method</code>，但是，这个会走到解析，主要原因也是因为<code>__call</code>方法的存在可能导致错误可以避免。</p>

<h4 id="toc_7">除0操作</h4>

<pre><code>&lt;?php
include &#39;err.php&#39;;
echo 1/0;
</code></pre>

<p>这个就不列举了，报了一堆错误：<br/>
<code><br/>
E_WARNING<br/>
E_PARSE<br/>
E_NOTICE<br/>
E_CORE_ERROR<br/>
E_CORE_WARNING<br/>
E_COMPILE_ERROR<br/>
E_COMPILE_WARNING<br/>
E_USER_ERROR<br/>
E_USER_WARNING<br/>
E_USER_NOTICE<br/>
E_STRICT<br/>
E_RECOVERABLE_ERROR<br/>
E_DEPRECATED<br/>
E_USER_DEPRECATED<br/>
</code></p>

<h2 id="toc_8">后续</h2>

<p>暂时并没有后续，可能后续进行php源码级别的解析吧</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[服务发现架构]]></title>
    <link href="https://artikell.github.io/15606052161429.html"/>
    <updated>2019-06-15T21:26:56+08:00</updated>
    <id>https://artikell.github.io/15606052161429.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">由来</h2>

<h3 id="toc_1">什么是微服务</h3>

<p>微服务架构（Microservice Architecture）是一种架构概念，旨在通过将功能分解到各个离散的服务中以实现对解决方案的解耦。你可以将其看作是在架构层次而非获取服务的类上应用很多SOLID原则。</p>

<blockquote>
<p>SOLID原则是指：单一职责原则（SRP）、开放封闭原则（OCP）、里氏替换原则（LSP）、接口隔离原则（ISP）、依赖倒置原则（DIP）的缩写。</p>
</blockquote>

<p>本质：用一些功能比较明确、业务比较精练的服务去解决更大、更实际的问题。</p>

<h3 id="toc_2">为什么要服务化</h3>

<p>架构痛点一：代码到处拷贝<br/>
架构痛点二：复杂性扩散<br/>
架构痛点三：库的复用与耦合<br/>
架构痛点四：SQL 质量得不到保障，业务相互影响<br/>
架构痛点五：疯狂的 DB 耦合<br/>
... ...</p>

<p>了解决上面的诸多问题，互联网高可用分层架构演进的过程中，引入了“服务层”。这就是所谓的服务化。</p>

<h3 id="toc_3">什么是服务发现</h3>

<p>当服务化不断进行，会出现大量的微服务，服务之间需要互相调用，每个服务的配置信息则单独存储，导致出现故障或者需要进行扩缩容时，需要对所有模块进行变更。<br/>
为了解决服务配置快速变更的问题，于是增加了一个中间层，用于管理各个微服务的配置信息，由此，服务发现诞生。</p>

<h2 id="toc_4">服务发现</h2>

<h3 id="toc_5">服务发现模式</h3>

<p>现存根据配置的获取方式，有两种主要的服务发现机制：<em>客户端发现机制</em>和<em>服务端发现机制</em>。</p>

<h4 id="toc_6">客户端发现模式</h4>

<p>在客户端模式下，如果要进行微服务调用，首先要进行的是到服务注册中心获取服务列表，然后再根据调用端本地的负载均衡策略，进行服务调用。</p>

<p><strong>特点：</strong><br/>
1. 只需要周期性获取列表，在调用服务时可以直接调用少了一个RT。但需要在每个客户端维护获取列表的逻辑<br/>
2. 可用性高，即使注册中心出现故障也能正常工作<br/>
3. 服务上下线对调用方有影响（会出现短暂调用失败）</p>

<h4 id="toc_7">服务端发现模式</h4>

<p>在服务端模式下，调用方直接向服务注册中心进行请求，服务注册中心再通过自身负载均衡策略，对微服务进行调用。这个模式下，调用方不需要在自身节点维护服务发现逻辑以及服务注册信息，这个模式相对来说比较类似DNS模式。</p>

<p><strong>特点：</strong><br/>
1. 简单，不需要在客户端维护获取服务列表的逻辑<br/>
2. 可用性由路由器中间件决定，路由中间件故障则所有服务不可用，同时，由于所有调度以及存储都由中间件服务器完成，中间件服务器可能会面临过高的负载<br/>
3. 服务上下线调用方无感知</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式事务]]></title>
    <link href="https://artikell.github.io/15605931624272.html"/>
    <updated>2019-06-15T18:06:02+08:00</updated>
    <id>https://artikell.github.io/15605931624272.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">分布式一致性算法</h2>

<p>分布式一致性算法有多种，</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[缓存总结]]></title>
    <link href="https://artikell.github.io/15605709598391.html"/>
    <updated>2019-06-15T11:55:59+08:00</updated>
    <id>https://artikell.github.io/15605709598391.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>缓存系统是架构设计中一个高并发支持的关键。主要是要解决缓存和源数据的一致性，以及缓存自身的高可用，以此来避免并发量打击到源数据，使得源数据受损</p>

<h2 id="toc_1">缓存介绍</h2>

<h3 id="toc_2">什么是缓存？</h3>

<p>缓存就是数据交换的缓冲区（称作：Cache），当某一硬件要读取数据时，会首先从缓存汇总查询数据，有则直接执行，不存在时从内存中获取。由于缓存的数据比内存快的多，所以缓存的作用就是帮助硬件更快的运行。</p>

<h3 id="toc_3">缓存的分类</h3>

<p>缓存在系统的各个阶段都存在：<br/>
* 操作系统磁盘缓存 ——&gt; 减少磁盘机械操作。<br/>
* 数据库缓存——&gt;减少文件系统IO。<br/>
* 应用程序缓存——&gt;减少对数据库的查询。<br/>
* Web服务器缓存——&gt;减少应用服务器请求。<br/>
* 客户端浏览器缓存——&gt;减少对网站的访问。</p>

<h3 id="toc_4">缓存的问题</h3>

<p>在具体了解缓存问题之前先来明确几个术语：</p>

<p><strong>缓存命中率</strong>：从缓存中得到数据的请求数与所有请求数的比率。理想状态是越高越好。<br/>
<strong>过期内容</strong>：超过设置的有效时间，被标记为“陈旧”的内容。通常过期内容不能用于回复客户端的请求，必须重新向源服务器请求新的内容或者验证缓存的内容是否仍然准备。<br/>
<strong>验证</strong>：验证缓存中的过期内容是否仍然有效，验证通过的话刷新过期时间。<br/>
<strong>失效</strong>：失效就是把内容从缓存中移除。当内容发生改变时就必须移除失效的内容。</p>

<p>缓存的使用不可避免的会带来更新的问题，如何更新是一个难题。而缓存更新又会带来几个问题：、</p>

<ol>
<li>大量查询不存在的缓存，导致缓存穿透</li>
<li>大量缓存更新，导致大部分不命中缓存，导致更新雪崩</li>
<li>大量请求命中单一缓存，缓存更新时，导致命中失败，则发生缓存击穿</li>
<li>同时，是先更新缓存，还是先更新数据，也是一个问题，前者可能出现数据异常，后者可能出现数据延时</li>
</ol>

<p>之后我们就一一来讨论以上问题。</p>

<h3 id="toc_5">缓存更新方式</h3>

<p>更新时序的方法有3种：<br/>
1. Cache Aside 更新模式实现起来比较简单，但是需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。<br/>
2. Read/Write Through 更新模式只需要维护一个数据存储（缓存），但是实现起来要复杂一些。<br/>
3. Write Behind Caching 更新模式和Read/Write Through 更新模式类似，区别是Write Behind Caching 更新模式的数据持久化操作是异步的，但是Read/Write Through 更新模式的数据持久化操作是同步的。</p>

<p>以下我们主要介绍第一种Cache Aside。</p>

<h4 id="toc_6">更新缓存 VS 淘汰缓存</h4>

<p>什么是更新缓存：数据不但写入数据库，还会写入缓存<br/>
什么是淘汰缓存：数据只会写入数据库，不会写入缓存，只会把数据淘汰掉</p>

<p>更新缓存的优点：缓存不会增加一次miss，命中率高<br/>
淘汰缓存的优点：简单</p>

<p>那到底是选择更新缓存还是淘汰缓存呢，主要取决于“更新缓存的复杂度”。</p>

<blockquote>
<p>更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率</p>
</blockquote>

<h4 id="toc_7">先操作数据库 vs 先操作缓存</h4>

<p>当写操作发生时，假设淘汰缓存作为对缓存通用的处理方式，又面临两种抉择：</p>

<p>（1）先写数据库，再淘汰缓存<br/>
（2）先淘汰缓存，再写数据库</p>

<p>究竟采用哪种时序呢？<br/>
对于一个不能保证事务性的操作，一定涉及“哪个任务先做，哪个任务后做”的问题，解决这个问题的方向是：<br/>
如果出现不一致，谁先做对业务的影响较小，就谁先执行。<br/>
由于写数据库与淘汰缓存不能保证原子性，谁先谁后同样要遵循上述原则。</p>

<p>假设先写数据库，再淘汰缓存：第一步写数据库操作成功，第二步淘汰缓存失败，则会出现DB中是新数据，Cache中是旧数据，数据不一致。<br/>
假设先淘汰缓存，再写数据库：第一步淘汰缓存成功，第二步写数据库失败，则只会引发一次Cache miss。</p>

<blockquote>
<p>结论：数据和缓存的操作时序，结论是清楚的：先淘汰缓存，再写数据库。</p>
</blockquote>

<h4 id="toc_8">结论强调</h4>

<p>（1）淘汰缓存是一种通用的缓存处理方式<br/>
（2）先淘汰缓存，再写数据库的时序是毋庸置疑的<br/>
（3）服务化是向业务方屏蔽底层数据库与缓存复杂性的一种通用方式</p>

<h3 id="toc_9">缓存异常问题</h3>

<h4 id="toc_10">缓存穿透</h4>

<p>缓存穿透是指查询一个一定不存在的数据，因为缓存中也无该数据的信息，则会直接去数据库层进行查询，从系统层面来看像是穿透了缓存层直接达到db，从而称为缓存穿透</p>

<h5 id="toc_11">解决方案</h5>

<p><strong>bloom filter</strong>：类似于哈希表的一种算法，用所有可能的查询条件生成一个bitmap，在进行数据库查询之前会使用这个bitmap进行过滤，如果不在其中则直接过滤，从而减轻数据库层面的压力。</p>

<p><strong>空值缓存</strong>：一种比较简单的解决办法，在第一次查询完不存在的数据后，将该key与对应的空值也放入缓存中，只不过设定为较短的失效时间，例如几分钟，这样则可以应对短时间的大量的该key攻击，设置为较短的失效时间是因为该值可能业务无关，存在意义不大，且该次的查询也未必是攻击者发起，无过久存储的必要，故可以早点失效。</p>

<h4 id="toc_12">缓存雪崩</h4>

<p>在普通的缓存系统中一般例如redis、memcache等中，我们会给缓存设置一个失效时间，但是如果所有的缓存的失效时间相同，那么在同一时间失效时，所有系统的请求都会发送到数据库层，db可能无法承受如此大的压力导致系统崩溃。</p>

<h5 id="toc_13">解决方案</h5>

<p><strong>线程互斥</strong>：只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据才可以，每个时刻只有一个线程在执行请求，减轻了db的压力，但缺点也很明显，降低了系统的qps。</p>

<p><strong>交错失效时间</strong>：这种方法时间比较简单粗暴，既然在同一时间失效会造成请求过多雪崩，那我们错开不同的失效时间即可从一定长度上避免这种问题，在缓存进行失效时间设置的时候，从某个适当的值域中随机一个时间作为失效时间即可。</p>

<h4 id="toc_14">缓存击穿</h4>

<p>缓存击穿实际上是缓存雪崩的一个特例，大家使用过微博的应该都知道，微博有一个热门话题的功能，用户对于热门话题的搜索量往往在一些时刻会大大的高于其他话题，这种我们成为系统的“热点“，由于系统中对这些热点的数据缓存也存在失效时间，在热点的缓存到达失效时间时，此时可能依然会有大量的请求到达系统，没有了缓存层的保护，这些请求同样的会到达db从而可能引起故障。击穿与雪崩的区别即在于击穿是对于特定的热点数据来说，而雪崩是全部数据。</p>

<h5 id="toc_15">解决方案</h5>

<p><strong>二级缓存</strong>：对于热点数据进行二级缓存，并对于不同级别的缓存设定不同的失效时间，则请求不会直接击穿缓存层到达数据库。</p>

<p><strong>LRU算法</strong>： 算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。最常见的实现是使用一个链表保存缓存数据。</p>

<h2 id="toc_16">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/duanxz/p/3740595.html">https://www.cnblogs.com/duanxz/p/3740595.html</a></li>
<li><a href="https://blog.csdn.net/chengxuyuan_110/article/details/81060865">https://blog.csdn.net/chengxuyuan_110/article/details/81060865</a></li>
<li><a href="https://blog.csdn.net/arenn/article/details/81490649">https://blog.csdn.net/arenn/article/details/81490649</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651961341&amp;idx=1&amp;sn=e27916b8e96bd771c72c055f1f53e5be&amp;chksm=bd2d02218a5a8b37ecffd78d20b65501645ac07c7ba2eb65b7e501a3eb9de023febe63bfdb36&amp;scene=21#wechat_redirect">http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651961341&amp;idx=1&amp;sn=e27916b8e96bd771c72c055f1f53e5be&amp;chksm=bd2d02218a5a8b37ecffd78d20b65501645ac07c7ba2eb65b7e501a3eb9de023febe63bfdb36&amp;scene=21#wechat_redirect</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql架构]]></title>
    <link href="https://artikell.github.io/15605689231307.html"/>
    <updated>2019-06-15T11:22:03+08:00</updated>
    <id>https://artikell.github.io/15605689231307.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">MySQL核心结构</h2>

<h2 id="toc_1">SQL执行顺序</h2>

<p>MySQL的语句一共分为11步，如下图所标注的那样，最先执行的总是FROM操作，最后执行的是LIMIT操作。<br/>
<img src="media/15605689231307/15605691055531.jpg" alt=""/></p>

<p>其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。</p>

<p><em>如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。</em></p>

<pre><code>FROM—&gt;ON—&gt;JOIN—&gt;WHERE—&gt;GROUP BY—&gt;SUM(聚合函数)—&gt;HAVING—&gt;SELECT—&gt;DISTINCT—&gt;UNION—&gt;ORDER BY—&gt;LIMIT
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP vs UDP 总结]]></title>
    <link href="https://artikell.github.io/15605624219274.html"/>
    <updated>2019-06-15T09:33:41+08:00</updated>
    <id>https://artikell.github.io/15605624219274.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">TCP/IP协议历史</h2>

<h3 id="toc_1">历史回溯</h3>

<p>TCP/IP的起源可以追溯到由美国国防部(DoD)高级研究计划局(DARPA)在二十世纪六十年代后期和七十年代早期进行的研究。下面摘要列出了TCP/IP发展史上的一些重大事件：</p>

<p>　　1970年，ARPANET主机开始使用网络控制协议(NCP)，这就是后来的传输控制协议(TCP)的雏形。</p>

<p>　　1972年，Telnet协议推出。Telnet用于终端仿真以连接相异的系统。在二十世纪七十年代早期，这些系统使用不同类型的主机。</p>

<p>　　1973年，文件传输协议(FTP)推出。FTP用于在相异的系统之间交换文件。</p>

<p>　　1974年，传输控制协议(TCP)被详细规定下来。TCP取代NCP，它为人们提供了更可靠的通信服务。</p>

<p>　　1981年，Internet协议(IP)(又称IP版本4[IPv4])被详细规定下来。IP为端到端传递提供寻址和路由功能。</p>

<p>　　1982年，国防通信署(DCA)和ARPA建立了传输控制协议(TCP)和Internet协议 (IP)作为TCP/IP协议套件。</p>

<p>　　1983年，ARPANET将NCP替换为TCP/IP。</p>

<p>　　1984年，域名系统(DNS)推出。DNS可将域名(如www.example.com)解析为IP地址(如192.168.5.18)。</p>

<p>　　1995年，Internet服务提供商(ISP)开始向企业和个人提供Internet接入。</p>

<p>　　1996年，超文本传送协议(HTTP)推出。万维网使用HTTP。</p>

<p>　　1996年，第一套IP版本6(IPv6)标准发布。</p>

<h3 id="toc_2">相关文献</h3>

<p>TCP协议： <a href="https://tools.ietf.org/html/rfc793">https://tools.ietf.org/html/rfc793</a> - September 1981<br/>
UDP协议： <a href="https://tools.ietf.org/html/rfc768">https://tools.ietf.org/html/rfc768</a> - 28 August 1980</p>

<blockquote>
<p>其实UDP先于TCP进入标准库中</p>
</blockquote>

<h3 id="toc_3">七层协议</h3>

<table>
<thead>
<tr>
<th>OSI中的层</th>
<th>功能</th>
<th>TCP/IP协议族</th>
</tr>
</thead>

<tbody>
<tr>
<td>7 应用层</td>
<td>文件传输，电子邮件，文件服务，虚拟终端</td>
<td>TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等</td>
</tr>
<tr>
<td>6 表示层</td>
<td>数据格式化，代码转换，数据加密</td>
<td>没有协议</td>
</tr>
<tr>
<td>5 会话层</td>
<td>解除或建立与别的接点的联系</td>
<td>没有协议</td>
</tr>
<tr>
<td>4 传输层</td>
<td>提供端对端的接口</td>
<td>TCP，UDP</td>
</tr>
<tr>
<td>3 网络层</td>
<td>为数据包选择路由</td>
<td>IP，ICMP，OSPF，EIGRP，IGMP</td>
</tr>
<tr>
<td>2 数据链路层</td>
<td>传输有地址的帧以及错误检测功能</td>
<td>SLIP，CSLIP，PPP，MTU</td>
</tr>
<tr>
<td>1 物理层</td>
<td>以二进制数据形式在物理媒体上传输数据</td>
<td>ISO2110，IEEE802，IEEE802.2</td>
</tr>
</tbody>
</table>

<p>7层和5层的区别，其实就在于应用层，而应用层只是在应用本身来进行区分，分别为会话层、表示层、应用层。</p>

<h2 id="toc_4">UDP和TCP的描述</h2>

<h3 id="toc_5">TCP详解</h3>

<p>特点：可靠，稳定。</p>

<p>TCP的可靠性方案：<br/>
1. 三次握手来建立连接。<br/>
2. 在数据传递时，有确认、窗口、重传、拥塞控制机制<br/>
3. 四次挥手，主要是为了保证最后一次请求能正常处理完成<br/>
4. 在数据传完后，还会断开连接用来节约系统资源。</p>

<p><img src="media/15605624219274/15605675717187.jpg" alt=""/></p>

<p>TCP的缺点： 慢，效率低，占用系统资源高，易被攻击</p>

<p>TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，<br/>
事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。</p>

<h3 id="toc_6">UDP详解</h3>

<p>特点：快，比TCP稍安全 <br/>
UDP是一个无状态的传输协议，所以它在传递数据时非常快。</p>

<p>UDP的缺点： 不可靠，不稳定 <br/>
因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 </p>

<h3 id="toc_7">特点对比</h3>

<p>1.基于连接与无连接；<br/>
2.对系统资源的要求（TCP较多，UDP少）；<br/>
3.UDP程序结构较简单；<br/>
4.流模式与数据报模式；<br/>
5.TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。</p>

<h2 id="toc_8">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/yeweilei/article/details/79279963">https://blog.csdn.net/yeweilei/article/details/79279963</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[张雅宸的空间]]></title>
    <link href="https://artikell.github.io/15605621287027.html"/>
    <updated>2019-06-15T09:28:48+08:00</updated>
    <id>https://artikell.github.io/15605621287027.html</id>
    <content type="html"><![CDATA[
<p><a href="https://github.com/zhangyachen/zhangyachen.github.io/issues">张雅宸</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[工作发展]]></title>
    <link href="https://artikell.github.io/15605615631803.html"/>
    <updated>2019-06-15T09:19:23+08:00</updated>
    <id>https://artikell.github.io/15605615631803.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>整理行业信息，不断学习</p>
</blockquote>

<ul>
<li>熟悉TCP/IP、HTTP等协议， 对网络编程有较多认识并有相关性能优化经验</li>
<li>熟悉MySQL，了解MySQL表设计、分区、分表等相关设计方案，具备MySQL优化经验；</li>
<li>熟悉WEB开发中各类缓存设计、站点优化方案；</li>
<li>服务化，serverless 经验</li>
<li>对缓存、队列、存储、网络、代理、配置等各种服务端开源方案有充分了解和实践</li>
<li>精通多线程编程,熟悉分布式服务开发,熟悉异步编程或函数式编程</li>
<li>在线即时通讯相关架构</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MYSQL技术内幕学习]]></title>
    <link href="https://artikell.github.io/15602214770128.html"/>
    <updated>2019-06-11T10:51:17+08:00</updated>
    <id>https://artikell.github.io/15602214770128.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<h2 id="toc_1">表空间结构</h2>

<p>首先，整个表空间分别由段、区、页组成。其中包含了数据、索引、插入缓冲bitmap页。<br/>
而，其他例如undo、redo、插入缓冲索引也、事务信息等，都是在<em>共享表空间</em>中。</p>

<blockquote>
<p>共享表空间和表空间的结构差异？</p>
</blockquote>

<h3 id="toc_2">表结构</h3>

<p>表空大致结构如下：<br/>
<img src="media/15602214770128/15602215597762.jpg" alt=""/></p>

<p>在表空间结构下面，是通过分段进行管理，段结构包含常用的数据段、索引段、回滚段。<br/>
而不同段下面，则是通过分区来进行数据划分，每个区都是1MB，而页面大小都是16KB，所以每个区都拥有64个页。</p>

<h3 id="toc_3">页结构</h3>

<p>页的具体类型有：<br/>
1. 数据页<br/>
2. undo页<br/>
3. 系统页<br/>
4. 事务数据页<br/>
5. 插入缓冲位图页<br/>
6. 插入缓冲空闲列表页<br/>
7. 未压缩二进制大对象页<br/>
8. 压缩二进制大对象页</p>

<p>每页则是通过行来进行组成。<br/>
行的类型包含Compact和Redundant2种格式存放。<br/>
<img src="media/15602214770128/15602252233925.jpg" alt="Compact格式"/></p>

<p><img src="media/15602214770128/15602252363913.jpg" alt="Redundant格式"/></p>

<p>2者差异在于，头部的数据，一个只给出变长字段长度列表，一个给出所有字段长度列表，这样前者节约了大量空间。而对于text和blob数据类型，为了保证每个页中至少存在2行数据，所以，当text的数据超过一点长度（768b）后，会尝试创建创建未压缩数据页。</p>

<p>InnoDB Plugin引入了新的文件格式（file format，可以理解为新的页格式），对于以前支持的Compact和Redundant格式将其称为Antelope文件格式，新的文件格式称为Barracuda。Barracuda文件格式下拥有两种新的行记录格式Compressed和Dynamic两种。新的两种格式对于存放BLOB的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在BLOB Page中，而之前的Compact和Redundant两种格式会存放768个前缀字节。</p>

<p>数据页结构<br/>
1. File Header - 文件头，记录页的头部信息，特征以及页面类型<br/>
2. Page Header - 页头，该部分记录数据页的状态信息<br/>
3. Infimun 和 Supremun Records，虚拟行，标记最大和最小边界<br/>
4. User Records - 行记录，实际存储的地址<br/>
5. Free space - 空闲空间<br/>
6. Page Directory - 页目录<br/>
7. File Trailer - 文件尾</p>

<p>其中，文件头、页头、文件尾大小固定，分别为38、56、8字节。<br/>
<img src="media/15602214770128/15602342959727.jpg" alt=""/></p>

<p><img src="media/15602214770128/15602367126223.jpg" alt=""/></p>

<h2 id="toc_4">Innodb的功能</h2>

<p>innodb主要是将数据放在一个表空间中进行管理，通过mvcc来获得高并发，同时提供插入缓冲、二次写、自适应哈希索引、预读来支持高性能和高可用。</p>

<p>innodb存储引擎主要支持请求处理：<br/>
1. 维护所有线程的数据结构<br/>
2. 缓存磁盘上的数据<br/>
3. 重做日志的缓存<br/>
... ...</p>

<p><img src="media/15602214770128/15602371597989.jpg" alt=""/></p>

<p>后台线程主要负责刷新内存池中的数据，保证数据是最新的。</p>

<p>Master Thread，主要负责将缓冲池的数据异步刷新到磁盘，保证数据一致性，<br/>
IO Thread，负责处理大量的IO操作<br/>
Purge Thread，负责回收已经使用的undolog页面<br/>
Page cleaner Thread，负责将脏页刷新至磁盘</p>

<h3 id="toc_5">内存分布</h3>

<p>缓冲池是一个大的内存块，其中包括：索引页、数据页、undo页等。<br/>
而刷新页面算法则通过LRU List算法来更新，而为了保证更好的效率，则新的页面会先插入midpoint位置上。<br/>
Free List和Flush List的功能和名字相同，一个是管理无用内存页列表，一个是管理脏页的列表。</p>

<p><img src="media/15602214770128/15602435608389.jpg" alt=""/></p>

<h3 id="toc_6">重做日志缓冲</h3>

<ol>
<li>Master Thread每一秒会刷新一次重做日志</li>
<li>事务提交会刷新一次重做日志</li>
<li>缓冲池小于1/2时，刷新重做日志</li>
</ol>

<h2 id="toc_7">相关链接</h2>

<ul>
<li><a href="https://draveness.me/mysql-innodb.html">https://draveness.me/mysql-innodb.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[红黑树学习纪要]]></title>
    <link href="https://artikell.github.io/15601369361254.html"/>
    <updated>2019-06-10T11:22:16+08:00</updated>
    <id>https://artikell.github.io/15601369361254.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>快速了解并学习红黑树，整理相关资料信息。</p>

<h2 id="toc_1">具体实现</h2>

<h3 id="toc_2">红黑树的特性</h3>

<p>（1）每个节点或者是黑色，或者是红色。<br/>
（2）根节点是黑色。<br/>
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]<br/>
（4）如果一个节点是红色的，则它的子节点必须是黑色的。<br/>
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</p>

<h3 id="toc_3">增删操作</h3>

<h4 id="toc_4">增加一个节点</h4>

<p>插入节点三步走：</p>

<p>第一步: 将红黑树当作一颗二叉查找树，将节点插入。<br/>
第二步：将插入的节点着色为&quot;红色&quot;。<br/>
第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。</p>

<blockquote>
<p>处理问题的核心思路都是：将红色的节点移到根节点；然后，将根节点设为黑色</p>
</blockquote>

<p>情况则会有四种：<br/>
1. 自己是红的、父亲是红的<br/>
2. 自己是红的、父亲是黑的</p>

<p>待定，2019年06月11日</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[优化专栏]]></title>
    <link href="https://artikell.github.io/15526053026851.html"/>
    <updated>2019-03-15T07:15:02+08:00</updated>
    <id>https://artikell.github.io/15526053026851.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>在阅读源码时，总是会发现代码细节无法深追，导致不理解作者的目的。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Todolist</h2>

<ul>
<li>磁盘顺序和随机读写的差异和实现</li>
<li>kafka和rockmq的性能对比</li>
<li>zero copy的具体实现</li>
<li>mmap的特点以及具体应用</li>
<li>c++中的各个关键字以及相关优化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang启动流程]]></title>
    <link href="https://artikell.github.io/15444908356391.html"/>
    <updated>2018-12-11T09:13:55+08:00</updated>
    <id>https://artikell.github.io/15444908356391.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>本文主要记录golang启动流程，从elf文件入口到main函数执行，包括中间的协程切换。</p>

<h2 id="toc_1">入口</h2>

<p>在golang源码中，入口文件很多，主要集中为：<em>runtime/rt0_linux_arm64.s</em>，其中入口函数为<em>_rt0_arm64_linux</em>，其中的逻辑暂时不细讲，主要先介绍几个关键点。</p>

<h3 id="toc_2">g0和m0的功能</h3>

<p>g0和m0是在 <em>proc.go</em> 文件中的两个全局变量，m0就是进程启动后的初始线程，g0也是代表着初始线程的stack</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang版本对比以及选择]]></title>
    <link href="https://artikell.github.io/15416610621281.html"/>
    <updated>2018-11-08T15:11:02+08:00</updated>
    <id>https://artikell.github.io/15416610621281.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>需要为新版的环境选择golang版本，其中需要参考相关的资料以及各个版本更新的信息进行挑选。</p>

<h2 id="toc_1">各个大版本的发布博客</h2>

<p><a href="go1.8%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.8</a><br/>
重点：优化了编译流程，同时Gc时间也有所优化，增加了http2的push功能，增加了context的取消和超时机制，同时提供了优雅退出的功能，优化了sort.Slice方法。</p>

<p><a href="go1.9%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.9</a><br/>
重点：支持了别名type功能，自动化测试支持了failure函数，sync库中添加了map类型，math包提供了更快速的计数操作，优化了Since为线程安全。</p>

<p><a href="go1.10%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.10</a><br/>
重点：go build支持传递相关参数</p>

<p><a href="go1.11%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.11</a><br/>
重点：支持了对modules的实验版本，以及WebAssembly的实验版本</p>

<h2 id="toc_2">版本发布时间</h2>

<p><a href="golang%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E5%8E%86%E5%8F%B2">https://golang.org/doc/devel/release.html</a></p>

<p>其中：<br/>
go1.8 有 7个子版本 (2017-02)<br/>
go1.9 有 7个子版本 (2017-08)<br/>
go1.10 有 5个子版本 (2018-02)<br/>
go1.11 有 2个子版本 (2018-08)</p>

<h2 id="toc_3">参考文章</h2>

<p><a href="golang%201.9%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84">https://colobu.com/2017/06/26/learn-go-type-aliases/</a><br/>
<a href="%E5%B9%B4%E7%BB%88%E7%9B%98%E7%82%B9%EF%BC%812017%E5%B9%B4%E8%B6%85%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84Golang%E6%96%87%E7%AB%A0">http://way.xiaojukeji.com/article/6489</a><br/>
<a href="Go%201.9.2%20%E7%9A%84%20bug">http://way.xiaojukeji.com/article/10750</a><br/>
<a href="1.8%E7%9A%84%E6%94%B9%E5%8A%A8">https://studygolang.com/articles/9298</a><br/>
<a href="Go%201.10%E4%B8%AD%E5%80%BC%E5%BE%97%E5%85%B3%E6%B3%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%98%E5%8C%96">http://ju.outofmemory.cn/entry/344575</a></p>

]]></content>
  </entry>
  
</feed>
