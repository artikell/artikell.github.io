<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[artikell]]></title>
  <link href="https://artikell.github.io/atom.xml" rel="self"/>
  <link href="https://artikell.github.io/"/>
  <updated>2019-06-15T11:38:08+08:00</updated>
  <id>https://artikell.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im">MWeb</generator>

  
  <entry>
    <title type="html"><![CDATA[Mysql架构]]></title>
    <link href="https://artikell.github.io/15605689231307.html"/>
    <updated>2019-06-15T11:22:03+08:00</updated>
    <id>https://artikell.github.io/15605689231307.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">MySQL核心结构</h2>

<h2 id="toc_1">SQL执行顺序</h2>

<p>MySQL的语句一共分为11步，如下图所标注的那样，最先执行的总是FROM操作，最后执行的是LIMIT操作。<br/>
<img src="media/15605689231307/15605691055531.jpg" alt=""/></p>

<p>其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。</p>

<p><em>如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。</em></p>

<pre><code>FROM—&gt;ON—&gt;JOIN—&gt;WHERE—&gt;GROUP BY—&gt;SUM(聚合函数)—&gt;HAVING—&gt;SELECT—&gt;DISTINCT—&gt;UNION—&gt;ORDER BY—&gt;LIMIT
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP vs UDP 总结]]></title>
    <link href="https://artikell.github.io/15605624219274.html"/>
    <updated>2019-06-15T09:33:41+08:00</updated>
    <id>https://artikell.github.io/15605624219274.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">TCP/IP协议历史</h2>

<h3 id="toc_1">历史回溯</h3>

<p>TCP/IP的起源可以追溯到由美国国防部(DoD)高级研究计划局(DARPA)在二十世纪六十年代后期和七十年代早期进行的研究。下面摘要列出了TCP/IP发展史上的一些重大事件：</p>

<p>　　1970年，ARPANET主机开始使用网络控制协议(NCP)，这就是后来的传输控制协议(TCP)的雏形。</p>

<p>　　1972年，Telnet协议推出。Telnet用于终端仿真以连接相异的系统。在二十世纪七十年代早期，这些系统使用不同类型的主机。</p>

<p>　　1973年，文件传输协议(FTP)推出。FTP用于在相异的系统之间交换文件。</p>

<p>　　1974年，传输控制协议(TCP)被详细规定下来。TCP取代NCP，它为人们提供了更可靠的通信服务。</p>

<p>　　1981年，Internet协议(IP)(又称IP版本4[IPv4])被详细规定下来。IP为端到端传递提供寻址和路由功能。</p>

<p>　　1982年，国防通信署(DCA)和ARPA建立了传输控制协议(TCP)和Internet协议 (IP)作为TCP/IP协议套件。</p>

<p>　　1983年，ARPANET将NCP替换为TCP/IP。</p>

<p>　　1984年，域名系统(DNS)推出。DNS可将域名(如www.example.com)解析为IP地址(如192.168.5.18)。</p>

<p>　　1995年，Internet服务提供商(ISP)开始向企业和个人提供Internet接入。</p>

<p>　　1996年，超文本传送协议(HTTP)推出。万维网使用HTTP。</p>

<p>　　1996年，第一套IP版本6(IPv6)标准发布。</p>

<h3 id="toc_2">相关文献</h3>

<p>TCP协议： <a href="https://tools.ietf.org/html/rfc793">https://tools.ietf.org/html/rfc793</a> - September 1981<br/>
UDP协议： <a href="https://tools.ietf.org/html/rfc768">https://tools.ietf.org/html/rfc768</a> - 28 August 1980</p>

<blockquote>
<p>其实UDP先于TCP进入标准库中</p>
</blockquote>

<h3 id="toc_3">七层协议</h3>

<table>
<thead>
<tr>
<th>OSI中的层</th>
<th>功能</th>
<th>TCP/IP协议族</th>
</tr>
</thead>

<tbody>
<tr>
<td>7 应用层</td>
<td>文件传输，电子邮件，文件服务，虚拟终端</td>
<td>TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等</td>
</tr>
<tr>
<td>6 表示层</td>
<td>数据格式化，代码转换，数据加密</td>
<td>没有协议</td>
</tr>
<tr>
<td>5 会话层</td>
<td>解除或建立与别的接点的联系</td>
<td>没有协议</td>
</tr>
<tr>
<td>4 传输层</td>
<td>提供端对端的接口</td>
<td>TCP，UDP</td>
</tr>
<tr>
<td>3 网络层</td>
<td>为数据包选择路由</td>
<td>IP，ICMP，OSPF，EIGRP，IGMP</td>
</tr>
<tr>
<td>2 数据链路层</td>
<td>传输有地址的帧以及错误检测功能</td>
<td>SLIP，CSLIP，PPP，MTU</td>
</tr>
<tr>
<td>1 物理层</td>
<td>以二进制数据形式在物理媒体上传输数据</td>
<td>ISO2110，IEEE802，IEEE802.2</td>
</tr>
</tbody>
</table>

<p>7层和5层的区别，其实就在于应用层，而应用层只是在应用本身来进行区分，分别为会话层、表示层、应用层。</p>

<h2 id="toc_4">UDP和TCP的描述</h2>

<h3 id="toc_5">TCP详解</h3>

<p>特点：可靠，稳定。</p>

<p>TCP的可靠性方案：<br/>
1. 三次握手来建立连接。<br/>
2. 在数据传递时，有确认、窗口、重传、拥塞控制机制<br/>
3. 四次挥手，主要是为了保证最后一次请求能正常处理完成<br/>
4. 在数据传完后，还会断开连接用来节约系统资源。</p>

<p><img src="media/15605624219274/15605675717187.jpg" alt=""/></p>

<p>TCP的缺点： 慢，效率低，占用系统资源高，易被攻击</p>

<p>TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，<br/>
事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。</p>

<h3 id="toc_6">UDP详解</h3>

<p>特点：快，比TCP稍安全 <br/>
UDP是一个无状态的传输协议，所以它在传递数据时非常快。</p>

<p>UDP的缺点： 不可靠，不稳定 <br/>
因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 </p>

<h3 id="toc_7">特点对比</h3>

<p>1.基于连接与无连接；<br/>
2.对系统资源的要求（TCP较多，UDP少）；<br/>
3.UDP程序结构较简单；<br/>
4.流模式与数据报模式；<br/>
5.TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。</p>

<h2 id="toc_8">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/yeweilei/article/details/79279963">https://blog.csdn.net/yeweilei/article/details/79279963</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[张雅宸的空间]]></title>
    <link href="https://artikell.github.io/15605621287027.html"/>
    <updated>2019-06-15T09:28:48+08:00</updated>
    <id>https://artikell.github.io/15605621287027.html</id>
    <content type="html"><![CDATA[
<p><a href="https://github.com/zhangyachen/zhangyachen.github.io/issues">张雅宸</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[工作发展]]></title>
    <link href="https://artikell.github.io/15605615631803.html"/>
    <updated>2019-06-15T09:19:23+08:00</updated>
    <id>https://artikell.github.io/15605615631803.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>整理行业信息，不断学习</p>
</blockquote>

<ul>
<li>熟悉TCP/IP、HTTP等协议， 对网络编程有较多认识并有相关性能优化经验</li>
<li>熟悉MySQL，了解MySQL表设计、分区、分表等相关设计方案，具备MySQL优化经验；</li>
<li>熟悉WEB开发中各类缓存设计、站点优化方案；</li>
<li>服务化，serverless 经验</li>
<li>对缓存、队列、存储、网络、代理、配置等各种服务端开源方案有充分了解和实践</li>
<li>精通多线程编程,熟悉分布式服务开发,熟悉异步编程或函数式编程</li>
<li>在线即时通讯相关架构</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MYSQL技术内幕学习]]></title>
    <link href="https://artikell.github.io/15602214770128.html"/>
    <updated>2019-06-11T10:51:17+08:00</updated>
    <id>https://artikell.github.io/15602214770128.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<h2 id="toc_1">表空间结构</h2>

<p>首先，整个表空间分别由段、区、页组成。其中包含了数据、索引、插入缓冲bitmap页。<br/>
而，其他例如undo、redo、插入缓冲索引也、事务信息等，都是在<em>共享表空间</em>中。</p>

<blockquote>
<p>共享表空间和表空间的结构差异？</p>
</blockquote>

<h3 id="toc_2">表结构</h3>

<p>表空大致结构如下：<br/>
<img src="media/15602214770128/15602215597762.jpg" alt=""/></p>

<p>在表空间结构下面，是通过分段进行管理，段结构包含常用的数据段、索引段、回滚段。<br/>
而不同段下面，则是通过分区来进行数据划分，每个区都是1MB，而页面大小都是16KB，所以每个区都拥有64个页。</p>

<h3 id="toc_3">页结构</h3>

<p>页的具体类型有：<br/>
1. 数据页<br/>
2. undo页<br/>
3. 系统页<br/>
4. 事务数据页<br/>
5. 插入缓冲位图页<br/>
6. 插入缓冲空闲列表页<br/>
7. 未压缩二进制大对象页<br/>
8. 压缩二进制大对象页</p>

<p>每页则是通过行来进行组成。<br/>
行的类型包含Compact和Redundant2种格式存放。<br/>
<img src="media/15602214770128/15602252233925.jpg" alt="Compact格式"/></p>

<p><img src="media/15602214770128/15602252363913.jpg" alt="Redundant格式"/></p>

<p>2者差异在于，头部的数据，一个只给出变长字段长度列表，一个给出所有字段长度列表，这样前者节约了大量空间。而对于text和blob数据类型，为了保证每个页中至少存在2行数据，所以，当text的数据超过一点长度（768b）后，会尝试创建创建未压缩数据页。</p>

<p>InnoDB Plugin引入了新的文件格式（file format，可以理解为新的页格式），对于以前支持的Compact和Redundant格式将其称为Antelope文件格式，新的文件格式称为Barracuda。Barracuda文件格式下拥有两种新的行记录格式Compressed和Dynamic两种。新的两种格式对于存放BLOB的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在BLOB Page中，而之前的Compact和Redundant两种格式会存放768个前缀字节。</p>

<p>数据页结构<br/>
1. File Header - 文件头，记录页的头部信息，特征以及页面类型<br/>
2. Page Header - 页头，该部分记录数据页的状态信息<br/>
3. Infimun 和 Supremun Records，虚拟行，标记最大和最小边界<br/>
4. User Records - 行记录，实际存储的地址<br/>
5. Free space - 空闲空间<br/>
6. Page Directory - 页目录<br/>
7. File Trailer - 文件尾</p>

<p>其中，文件头、页头、文件尾大小固定，分别为38、56、8字节。<br/>
<img src="media/15602214770128/15602342959727.jpg" alt=""/></p>

<p><img src="media/15602214770128/15602367126223.jpg" alt=""/></p>

<h2 id="toc_4">Innodb的功能</h2>

<p>innodb主要是将数据放在一个表空间中进行管理，通过mvcc来获得高并发，同时提供插入缓冲、二次写、自适应哈希索引、预读来支持高性能和高可用。</p>

<p>innodb存储引擎主要支持请求处理：<br/>
1. 维护所有线程的数据结构<br/>
2. 缓存磁盘上的数据<br/>
3. 重做日志的缓存<br/>
... ...</p>

<p><img src="media/15602214770128/15602371597989.jpg" alt=""/></p>

<p>后台线程主要负责刷新内存池中的数据，保证数据是最新的。</p>

<p>Master Thread，主要负责将缓冲池的数据异步刷新到磁盘，保证数据一致性，<br/>
IO Thread，负责处理大量的IO操作<br/>
Purge Thread，负责回收已经使用的undolog页面<br/>
Page cleaner Thread，负责将脏页刷新至磁盘</p>

<h3 id="toc_5">内存分布</h3>

<p>缓冲池是一个大的内存块，其中包括：索引页、数据页、undo页等。<br/>
而刷新页面算法则通过LRU List算法来更新，而为了保证更好的效率，则新的页面会先插入midpoint位置上。<br/>
Free List和Flush List的功能和名字相同，一个是管理无用内存页列表，一个是管理脏页的列表。</p>

<p><img src="media/15602214770128/15602435608389.jpg" alt=""/></p>

<h3 id="toc_6">重做日志缓冲</h3>

<ol>
<li>Master Thread每一秒会刷新一次重做日志</li>
<li>事务提交会刷新一次重做日志</li>
<li>缓冲池小于1/2时，刷新重做日志</li>
</ol>

<h2 id="toc_7">相关链接</h2>

<ul>
<li><a href="https://draveness.me/mysql-innodb.html">https://draveness.me/mysql-innodb.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[红黑树学习纪要]]></title>
    <link href="https://artikell.github.io/15601369361254.html"/>
    <updated>2019-06-10T11:22:16+08:00</updated>
    <id>https://artikell.github.io/15601369361254.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>快速了解并学习红黑树，整理相关资料信息。</p>

<h2 id="toc_1">具体实现</h2>

<h3 id="toc_2">红黑树的特性</h3>

<p>（1）每个节点或者是黑色，或者是红色。<br/>
（2）根节点是黑色。<br/>
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]<br/>
（4）如果一个节点是红色的，则它的子节点必须是黑色的。<br/>
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</p>

<h3 id="toc_3">增删操作</h3>

<h4 id="toc_4">增加一个节点</h4>

<p>插入节点三步走：</p>

<p>第一步: 将红黑树当作一颗二叉查找树，将节点插入。<br/>
第二步：将插入的节点着色为&quot;红色&quot;。<br/>
第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。</p>

<blockquote>
<p>处理问题的核心思路都是：将红色的节点移到根节点；然后，将根节点设为黑色</p>
</blockquote>

<p>情况则会有四种：<br/>
1. 自己是红的、父亲是红的<br/>
2. 自己是红的、父亲是黑的</p>

<p>待定，2019年06月11日</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[优化专栏]]></title>
    <link href="https://artikell.github.io/15526053026851.html"/>
    <updated>2019-03-15T07:15:02+08:00</updated>
    <id>https://artikell.github.io/15526053026851.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>在阅读源码时，总是会发现代码细节无法深追，导致不理解作者的目的。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Todolist</h2>

<ul>
<li>磁盘顺序和随机读写的差异和实现</li>
<li>kafka和rockmq的性能对比</li>
<li>zero copy的具体实现</li>
<li>mmap的特点以及具体应用</li>
<li>c++中的各个关键字以及相关优化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang启动流程]]></title>
    <link href="https://artikell.github.io/15444908356391.html"/>
    <updated>2018-12-11T09:13:55+08:00</updated>
    <id>https://artikell.github.io/15444908356391.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>本文主要记录golang启动流程，从elf文件入口到main函数执行，包括中间的协程切换。</p>

<h2 id="toc_1">入口</h2>

<p>在golang源码中，入口文件很多，主要集中为：<em>runtime/rt0_linux_arm64.s</em>，其中入口函数为<em>_rt0_arm64_linux</em>，其中的逻辑暂时不细讲，主要先介绍几个关键点。</p>

<h3 id="toc_2">g0和m0的功能</h3>

<p>g0和m0是在 <em>proc.go</em> 文件中的两个全局变量，m0就是进程启动后的初始线程，g0也是代表着初始线程的stack</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang版本对比以及选择]]></title>
    <link href="https://artikell.github.io/15416610621281.html"/>
    <updated>2018-11-08T15:11:02+08:00</updated>
    <id>https://artikell.github.io/15416610621281.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>需要为新版的环境选择golang版本，其中需要参考相关的资料以及各个版本更新的信息进行挑选。</p>

<h2 id="toc_1">各个大版本的发布博客</h2>

<p><a href="go1.8%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.8</a><br/>
重点：优化了编译流程，同时Gc时间也有所优化，增加了http2的push功能，增加了context的取消和超时机制，同时提供了优雅退出的功能，优化了sort.Slice方法。</p>

<p><a href="go1.9%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.9</a><br/>
重点：支持了别名type功能，自动化测试支持了failure函数，sync库中添加了map类型，math包提供了更快速的计数操作，优化了Since为线程安全。</p>

<p><a href="go1.10%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.10</a><br/>
重点：go build支持传递相关参数</p>

<p><a href="go1.11%E5%8F%91%E5%B8%83">https://blog.golang.org/go1.11</a><br/>
重点：支持了对modules的实验版本，以及WebAssembly的实验版本</p>

<h2 id="toc_2">版本发布时间</h2>

<p><a href="golang%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E5%8E%86%E5%8F%B2">https://golang.org/doc/devel/release.html</a></p>

<p>其中：<br/>
go1.8 有 7个子版本 (2017-02)<br/>
go1.9 有 7个子版本 (2017-08)<br/>
go1.10 有 5个子版本 (2018-02)<br/>
go1.11 有 2个子版本 (2018-08)</p>

<h2 id="toc_3">参考文章</h2>

<p><a href="golang%201.9%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84">https://colobu.com/2017/06/26/learn-go-type-aliases/</a><br/>
<a href="%E5%B9%B4%E7%BB%88%E7%9B%98%E7%82%B9%EF%BC%812017%E5%B9%B4%E8%B6%85%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84Golang%E6%96%87%E7%AB%A0">http://way.xiaojukeji.com/article/6489</a><br/>
<a href="Go%201.9.2%20%E7%9A%84%20bug">http://way.xiaojukeji.com/article/10750</a><br/>
<a href="1.8%E7%9A%84%E6%94%B9%E5%8A%A8">https://studygolang.com/articles/9298</a><br/>
<a href="Go%201.10%E4%B8%AD%E5%80%BC%E5%BE%97%E5%85%B3%E6%B3%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%98%E5%8C%96">http://ju.outofmemory.cn/entry/344575</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[总结docker搭建服务过程]]></title>
    <link href="https://artikell.github.io/15390880867263.html"/>
    <updated>2018-10-09T20:28:06+08:00</updated>
    <id>https://artikell.github.io/15390880867263.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">搭建步骤</h2>

<ol>
<li><p>安装docker服务</p>

<p>下载地址：<a href="https://docs.docker.com/docker-for-mac/install/#download-docker-for-mac">https://docs.docker.com/docker-for-mac/install/#download-docker-for-mac</a></p>

<p>下载Stable channel版本，作为一个稳定版本，之后根据文档进行docker服务的安装。</p></li>
<li><p>启动后，运行命令<code>docker pull ubuntu</code>，拉取<code>ubuntu</code>镜像。</p></li>
<li><p>新建一个容器服务，并得到容器编号：</p>

<pre><code>$ docker run --privileged=true -t -i -d ubuntu /bin/bash
</code></pre></li>
<li><p>运行<code>docker ps</code>查看容器列表</p></li>
<li><p>运行<code>docker exec -it 83f7b8757c17 /bin/bash</code>命令，进入相关容器</p></li>
<li><p>安装ssh相关服务：</p>

<pre><code>$ sudo apt install openssh-server
$ sudo apt install openssh-client
</code></pre></li>
<li><p>修改ssh相关配置：</p>

<pre><code>$ vi /etc/ssh/sshd_config

RSAAuthentication yes #启用 RSA 认证
PubkeyAuthentication yes #启用公钥私钥配对认证方式
AuthorizedKeysFile .ssh/authorized_keys #公钥文件路径（和上面生成的文件同）
PermitRootLogin yes #root能使用ssh登录
</code></pre></li>
<li><p>运行命令<code>passwd</code>修改root账号密码</p></li>
<li><p>重启ssh服务并设置为开机自启：</p>

<pre><code>$ service sshd restart
$ chkconfig sshd on
</code></pre></li>
<li><p>退出容器，并提交成镜像文件</p>

<pre><code>$ sudo docker commit [container id] skyfire/ssh
</code></pre></li>
<li><p>生成一个新的docker容器，并映射端口</p>

<pre><code>docker run -t -i -d -p 10022:22 skyfire/ssh /bin/bash
</code></pre></li>
<li><p>利用ssh连接容器服务</p>

<pre><code>$ ssh root@localhost -p 10022
</code></pre></li>
</ol>

<h2 id="toc_1">相关问题</h2>

<ol>
<li><code>docker</code>容器如何保证后台运行？</li>
<li><code>docker</code>能否不生成镜像而直接映射端口？</li>
</ol>

<h2 id="toc_2">相关链接</h2>

<ol>
<li><a href="http://blog.csdn.net/qq626387/article/details/50506636">Docker入门实战-SSH连接docker容器</a></li>
<li><a href="https://segmentfault.com/a/1190000002567459">Docker学习之路（六）用commit命令创建镜像</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_3dd53f260102uyj0.html">ssh问题：ssh_exchange_identification</a></li>
<li><a href="http://blog.csdn.net/qq_29994609/article/details/51730640">Docker学习笔记-Docker端口映射</a></li>
<li><a href="http://blog.csdn.net/minicto/article/details/63684583">ubuntu中ssh-server的安装与开机启动</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 主流程学习]]></title>
    <link href="https://artikell.github.io/15345862239174.html"/>
    <updated>2018-08-18T17:57:03+08:00</updated>
    <id>https://artikell.github.io/15345862239174.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>本文主要介绍Redis主流程的过程，包括<em>启动初始化，事件，命令处理，异常处理</em>4大块，尽可能覆盖全面。</p>

<h2 id="toc_1">启动初始化</h2>

<p>启动初始化一般都有3个流程：<em>环境设置、配置解析、模块初始化</em>。三者主要是为了后续持续的运行做准备。</p>

<h3 id="toc_2">环境设置</h3>

<p>环境设置大部分都是一些与系统相关的设置，例如不同的系统会使用不同的事件模型</p>

<table>
<thead>
<tr>
<th>事件模型</th>
<th>系统</th>
</tr>
</thead>

<tbody>
<tr>
<td>Evport</td>
<td>sun系统</td>
</tr>
<tr>
<td>Epoll</td>
<td>linux系统</td>
</tr>
<tr>
<td>Kqueue</td>
<td>unix系统</td>
</tr>
<tr>
<td>Select</td>
<td>兜底</td>
</tr>
</tbody>
</table>

<p>对于四种模型，select是最简单的，也是性能较差的一个，所以是用于兜底方案，而关于epoll和kqueue都是主动触发的事件模型。2者其实是用于解决C10K问题而从select中衍生出来的模型，同时是分别针对linux系统和Unix系统设计。</p>

<pre><code>#ifdef HAVE_EVPORT
#include &quot;ae_evport.c&quot;
#else
    #ifdef HAVE_EPOLL
    #include &quot;ae_epoll.c&quot;
    #else
        #ifdef HAVE_KQUEUE
        #include &quot;ae_kqueue.c&quot;
        #else
        #include &quot;ae_select.c&quot;
        #endif
    #endif
#endif
</code></pre>

<p>同时还有类似内存池的选择，是zmalloc,还是jmalloc，都是在编译时候设置好。</p>

<p>在启动的时候，能做的事情不多，主要就是：语言环境、标题、随机种子、监督。</p>

<h3 id="toc_3">配置解析</h3>

<p>配置主要都是从命令行参数列表中获取，而针对一下特殊的参数例如<em>version、help、test-memory</em>就有特殊处理。</p>

<pre><code>if (strcmp(argv[1], &quot;-v&quot;) == 0 ||
    strcmp(argv[1], &quot;--version&quot;) == 0) version();
if (strcmp(argv[1], &quot;--help&quot;) == 0 ||
    strcmp(argv[1], &quot;-h&quot;) == 0) usage();
if (strcmp(argv[1], &quot;--test-memory&quot;) == 0) {
    if (argc == 3) {
        memtest(atoi(argv[2]),50);
        exit(0);
    } else {
        fprintf(stderr,&quot;Please specify the amount of memory to test in megabytes.\n&quot;);
        fprintf(stderr,&quot;Example: ./redis-server --test-memory 4096\n\n&quot;);
        exit(1);
    }
}
</code></pre>

<p>配置检查第一个参数，如果不是以双减号开头，则作为配置文件，同时会补全configfile为绝对路径，这样的话，后续debug模式下重启服务可以正常启动。</p>

<pre><code>if (argv[j][0] != &#39;-&#39; || argv[j][1] != &#39;-&#39;) {
    configfile = argv[j];
    server.configfile = getAbsolutePath(configfile);
    /* Replace the config file in server.exec_argv with
     * its absoulte path. */
    zfree(server.exec_argv[j]);
    server.exec_argv[j] = zstrdup(server.configfile);
    j++;
}
</code></pre>

<p>后续的配置设置，都是以<code>--</code>开头，例如：<code>--port 6379</code>，都作为配置信息。<br/>
例如： <code>redis-server --port 6379 --save 900 1 --save 300 1</code> ，会被解析为：</p>

<pre><code>port 6379
save 900 1
save 300 1
</code></pre>

<p>这样的好处就是可以和配置文件复用同一套的解析方法。</p>

<p>其中有个有趣的模式是支持从输入流中获取配置信息，开启方法则是在配置文件的时候输入一个减号，例如：<code>redis-server -</code>，后续通过<code>ctrl+c</code>退出模式。当然，格式将和配置文件是相同。</p>

<p>后续的配置解析是将整个配置信息通过<code>\n\t\r</code>，进行分隔成多行，并针对每一行的第一个元素小写，找到相应的变量设置。若设置错误，则直接会报错并退出进程。</p>

<h3 id="toc_4">模块初始化</h3>

<p>初始化流程中，大部分模块都进行了初始化处理，例如：bio，lua，模块module，cluster，信号，慢日志等。</p>

<p>初始化的时候，主要功能都是在做对象内存的申请，端口的监听。其中当然包括多个数据库的申请，以及持久化数据的导入。</p>

<h2 id="toc_5">事件</h2>

<p>Redis事件分为2类：<em>时间事件和文件事件</em>，事件可以和Nginx的事件模型对齐，文件事件和定时事件交替执行。而和Nginx不一样的是，Redis对时间要求比Nginx严格，所以Redis会搜索最近的一个时间事件，并计算文件事件获取的超时时间。</p>

<h3 id="toc_6">时间事件</h3>

<p>在Redis中，时间事件记录就是通过链条来记录：</p>

<pre><code>typedef struct aeTimeEvent {
    long long id; /* time event identifier. */
    long when_sec; /* seconds */
    long when_ms; /* milliseconds */
    aeTimeProc *timeProc;
    aeEventFinalizerProc *finalizerProc;
    void *clientData;
    struct aeTimeEvent *next;
} aeTimeEvent;
</code></pre>

<p>所以，每次找最近的时间事件，都是直接遍历来获取。<br/>
从整个的Redis源码中，只有一个地方使用到了时间事件，那就是ServerCron方法，</p>

<pre><code>aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL)
</code></pre>

<p>这个方法主要用于维护Redis服务器的日常，可以看见的是，该方法是1ms执行一次，所以，所有的文件事件间隔不会大于1ms，这也是为啥Redis高效的原因。</p>

<h4 id="toc_7">ServerCron 函数</h4>

<p>作为主要的定时函数，ServerCron函数功能主要用于维护整个Redis的稳定。常见的操作有：数据库的重哈希、数据持久化、内存清理、删除超时客户端等。</p>

<p>与此同时，ServerCron函数也会调用其他的定时函数，例如：ClientCron、DatabaseCron函数，这些原本都是在ServerCron函数中，后来为了便于维护，所以，移出去了。</p>

<p>与ServerCron函数有关系的配置就是hz配置，官方解释是：<code>Time interrupt calls/sec</code>，默认是10，也就是说，默认是每100ms执行一次。</p>

<p><em>那如果对于有些定时任务需要1s执行一次，怎么实现？</em>有2种办法，一是新建一个定时任务来做这个操作，二是在ServerCron中来做调用这个函数。</p>

<p>而在类似ClientCron函数，Redis就采用的是第二种方法，其中会设置cronloops方法来记录当前是第几次循环，并判断是否需要调用：</p>

<pre><code>#define run_with_period(_ms_) if ((_ms_ &lt;= 1000/server.hz) || !(server.cronloops%((_ms_)/(1000/server.hz))))
</code></pre>

<p>这个宏类似于条件判断，每ms时间执行一次后续的操作。如:</p>

<pre><code>run_with_period(100) trackOperationsPerSecond();
</code></pre>

<p>每百微秒，执行一次跟踪操作函数，记录这段时间的命令执行情况</p>

<h3 id="toc_8">文件事件</h3>

<p>对于文件事件，是整个Redis异步处理的关键，在各个模块，例如AOF，集群，脚本等模块都需要文件事件来支撑。不过和时间事件不同，文件事件是根据不同的模型实现的，其中包含：select\epoll\evport\kqueue四种模型，每个模型都抽象出了7个方法：<br/>
1. aeApiCreate - 创建事件对象，类似初始化<br/>
2. aeApiResize - 重置事件对象<br/>
3. aeApiFree - 删除事件对象<br/>
4. aeApiAddEvent - 添加事件<br/>
5. aeApiDelEvent - 删除事件<br/>
6. aeApiPoll - 获取事件列表<br/>
7. aeApiName - 获取事件名称</p>

<!-- 而四个文件模型各自的优缺点如下： -->

<p>在端口监听的时候，使用到了文件模型来处理socket信息：</p>

<pre><code>(aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL)
</code></pre>

<h3 id="toc_9">循环前置</h3>

<p>对于一些需要频繁的操作，需要有一个地方来执行，如果使用时间模型来做的话，那容易导致间隔过长，于是在Redis的事件模型中，存在beforeSleep函数，在每次执行事件的时候，会先调用该函数，主要功能一般都是用于清理无用数据以及持久化数据落盘等简单动作。</p>

<h2 id="toc_10">命令处理</h2>

<p>命令处理可以划分3个部分：<em>连接建立、请求处理、返回数据</em>。</p>

<h3 id="toc_11">接收请求</h3>

<p>连接的建立在文件事件里面已经有提过，就是通过将socke绑定在文件事件中执行。</p>

<p>在建立连接的时候，redis都会循环1000次，尽可能多的接收请求。</p>

<p>获得了socket后，redis会创建客户端对象，其中需要检查2个事情：是否超过最大连接数、是否是无密码远程登录。对应配置为：<code>maxclients</code>和<code>protected-mode</code>。</p>

<p>后续再建立client的时候，会将socket设置为noblock和TcpNoDelay模式，加快数据的传输，同时还会设置keepalive模式。</p>

<p>请求处理的时候，在接收请求，redis进行了协议的处理，redis每次会申请16k的大小来获取数据，同时根据是否知道长度来调整缓存区<br/>
同时，redis后续会根据，是否成功，或缓存数据是否过多来中的客户端请求<br/>
之后，会根据是否为master来做一些广播的处理</p>

<h3 id="toc_12">请求处理</h3>

<p>当获取到请求的时候，redis会解析请求的第一个参数，找到相应的命令对象</p>

<pre><code>struct redisCommand redisCommandTable[] = {
    {&quot;module&quot;,moduleCommand,-2,&quot;as&quot;,0,NULL,1,1,1,0,0},
    {&quot;get&quot;,getCommand,2,&quot;rF&quot;,0,NULL,1,1,1,0,0},
    {&quot;set&quot;,setCommand,-3,&quot;wm&quot;,0,NULL,1,1,1,0,0},
</code></pre>

<p>以get命令来看，命令列表其实是通过一个枚举的过程来做的，到最后会变成一个字典，所以查询的效率很高。</p>

<p>在执行的过程中，命令需要做一系列的检查，包括各种情况：</p>

<ol>
<li>命令不存在</li>
<li>命令不合法</li>
<li>需要登录，却不是auth命令</li>
<li>若命令对内存严格要求，且服务器无内存</li>
<li>如果磁盘上存在问题，请不要接受写命令</li>
<li>如果不满足最低正常从服务器要求，不接受写操作</li>
<li>如果只是一个只读的从服务器，不接受写操作</li>
<li>在订阅模式下，只允许一部分命令</li>
<li>当连接断开时，是否接受请求</li>
<li>若正在加载，接受一部分请求</li>
<li>如果lua命令太慢，则只允许一部分请求</li>
<li>如果是事务命令，则加入事务列表</li>
<li>否则就执行</li>
</ol>

<h4 id="toc_13">事务操作</h4>

<p>对于事务类操作，有 MULTI、DISCARD、EXEC和WATCH四个命令。而参考mysql中的事务，有begin、rollback、commit三个命令。多了一个命令，而其实原理上已经完全不一样。<br/>
对于事务的实现，数据结构如下：</p>

<pre><code>typedef struct multiCmd {
    robj **argv;
    int argc;
    struct redisCommand *cmd;
} multiCmd;

typedef struct multiState {
    multiCmd *commands;     /* 事务命令数组 */
    int count;              /* 命令个数 */
    int minreplicas;        /* MINREPLICAS for synchronous replication */
    time_t minreplicas_timeout; /* MINREPLICAS timeout as unixtime. */
} multiState;
</code></pre>

<p>其中，主要是commands属性用于存储事务的命令列表，以及一些参数。</p>

<p>首先，watch命令是一个有趣的命令，它会监听一些数据是否变化，首先，对于每个数据库和每个客户端对象，都会有一个<code>watched_keys</code>属性：对于客户端对象而言，<code>watched_keys</code>是一个list列表，主要用于记录当前监听的键，而对于数据库对象而言，<code>watched_keys</code>则是一个以<code>watch</code>的变量名键的字典，用于记录当前键被监听的客户端列表。</p>

<p>如果每次数据库中有变化，其中包括列表排序、过期清空等操作，都会将相关的客户端状态置为<code>CLIENT_DIRTY_CAS</code>状态</p>

<p>MULTI命令和DISCARD命令则相对比较简单，前者只需要将客户端属性设置为事务态，而后者则相反，移除客户端的事务态标记，同时清空命令数组等。</p>

<p>而对于EXEC命令，则是极其复杂的，因为它需要检查异常情况，同时运行命令：</p>

<ol>
<li>检查客户端是否在事务态</li>
<li>检查命令是否正常以及键是否被改变</li>
<li>取消所有监听的键</li>
<li>广播事务命令</li>
<li>循环执行所有命令，并返回</li>
</ol>

<p>回顾一下事务的4个条件（ACID）：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。</p>

<p>Redis对于原子性是没有特别严格的保证，正常运行时，操作失败的时候，可能是语法错误或者错误的数据库类型操作，这种操作一般都可以避免。<br/>
由于Redis单线程来保证，由于命令只能串行运行，所以，隔离性和一致性，Redis完全没问题。<br/>
而关于持久性，Redis通过AOF和快照2中模式来实现，不过，并不是完全能持久化。</p>

<p>所以，对于Redis事务而言，实现了隔离性和一致性，但无法保证原子性和持久性</p>

<blockquote>
<p>待补充，事务中的异常处理以及广播</p>
</blockquote>

<h4 id="toc_14">阻塞操作</h4>

<p>阻塞命令在Redis中，其中是比较关键的一系列命令，很多工具都是通过它来实现，例如消息队列等。而核心命令则是：blpop和brpop。</p>

<p>关于阻塞，本身和事务的watch命令类似，在数据库对象中都存在一个<code>blocking_keys</code>字典，它的键为相关的键名，值则是客户端对象列表。</p>

<p>而在客户端对象这边是存在一个bpop属性，结构体如下：</p>

<pre><code>typedef struct blockingState {
    /* Generic fields. */
    mstime_t timeout;       /* Blocking operation timeout. If UNIX current time
                             * is &gt; timeout then the operation timed out. */

    /* BLOCKED_LIST */
    dict *keys;             /* The keys we are waiting to terminate a blocking
                             * operation such as BLPOP. Otherwise NULL. */
    robj *target;           /* The key that should receive the element,
                             * for BRPOPLPUSH. */

    /* BLOCKED_WAIT */
    int numreplicas;        /* Number of replicas we are waiting for ACK. */
    long long reploffset;   /* Replication offset to reach. */

    /* BLOCKED_MODULE */
    void *module_blocked_handle; /* RedisModuleBlockedClient structure.
                                    which is opaque for the Redis core, only
                                    handled in module.c. */
} blockingState;
</code></pre>

<p>其中需要关注的主要是keys、timeout、target三个属性，其中keys主要用于记录阻塞的列表名称，timeout则用于表示阻塞超时时间，target则用于特殊命令<code>BRPOPLPUSH</code>来标记转移的列表对象。</p>

<p>对于已阻塞的客户端而言，其实只有在增加键的时候才会结束阻塞，所以，每个新增列表的时候，都会将列表名加入<code>ready_keys</code>列表中，但命令执行的时候，会检查该列表是否为空，若不为空，则代表有新的列表变动，所以需要修改阻塞状态。</p>

<h4 id="toc_15">订阅操作</h4>

<p>对于订阅功能，其实包含的命令只有 PUBLISH、SUBSCRIBE 2个命令。一个用于订阅管道，一个用于推送消息。其中的中间键叫channel。这与阻塞操作不同的在于，订阅发布是一个1对n的模型，而pop操作是一个1对1的模型。这其中的难度就在于发布给多个客户端以及模式订阅的功能。</p>

<h2 id="toc_16">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/guodongxiaren/article/details/44747719">https://blog.csdn.net/guodongxiaren/article/details/44747719</a></li>
<li><a href="http://www.spongeliu.com/415.html">http://www.spongeliu.com/415.html</a></li>
<li><a href="https://github.com/huangz1990/blog/blob/master/diary/2013/how-redis-fix-invalid-aof-file.rst">https://github.com/huangz1990/blog/blob/master/diary/2013/how-redis-fix-invalid-aof-file.rst</a></li>
<li><a href="https://www.cnblogs.com/frank-yxs/p/5925838.html">https://www.cnblogs.com/frank-yxs/p/5925838.html</a></li>
<li><a href="https://people.eecs.berkeley.edu/%7Esangjin/2012/12/21/epoll-vs-kqueue.html">https://people.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html</a></li>
<li><a href="https://www.cnblogs.com/moonz-wu/p/4740908.html">https://www.cnblogs.com/moonz-wu/p/4740908.html</a></li>
</ul>

<h2 id="toc_17">总结</h2>

<p>贼累，准备做PPT，思考怎么写</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 集群管理学习]]></title>
    <link href="https://artikell.github.io/15319770094977.html"/>
    <updated>2018-07-19T13:10:09+08:00</updated>
    <id>https://artikell.github.io/15319770094977.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>Redis集群管理包括哨兵模式、分片、以及主从同步3大块。外部扩展包括codis以及kedis2个项目，顺带zookeeper的集群解决方案。<br/>
本文主要从主从和分片模块收集并解析。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">集群来源</h2>

<p>在Redis分布式的设计中，总共出现了3个模式：主从模式、哨兵模式、集群模式。主从是最基础的实现了读写分离功能，哨兵则是通过分布式集群进行故障的检查与转移，提高了整个分布式系统的高可用性，集群模式则是集大成者，提供了数据分片，以及故障转移的一系列功能。</p>

<p>在集群模式下，redis选用了p2p模式进行系统的构建，这个的优点是保证系统的性能能达到最大，避免中间出现proxy系统来管理，同时保证最终一致性。为此专门设计了一套系统消息系统用来进行信息同步，避免干扰了原有的命令协议。</p>

<p>后续，我们将会一一描述系统的各个功能。</p>

<h2 id="toc_2">关于分布式系统</h2>

<p>对于分布式系统的数据一致性协议，包含很多种：<br/>
1. 两阶段提交协议<br/>
2. 三阶段提交协议<br/>
3. TCC协议<br/>
4. Paxos协议<br/>
5. ZAB协议<br/>
6. Raft协议<br/>
7. Quorum协议<br/>
8. Gossip协议</p>

<p>两阶段提交协议和三阶段提交协议是一种强一致性的协议，需要在集群中选取协调者来协调所有节点同时更新数据，这样会导致效率严重的下降。</p>

<p>而在redis的集群中，节点间的信息同步是通过gossip协议，而选举算法，则是通过raft算法实现。其实2者并没什么冲突，完全可以用在同一个系统中。</p>

<h3 id="toc_3">集群消息</h3>

<p>前文讲了集群模式下，专门设计了一套新的消息协议来进行信息同步，也就是<em>clusterMsg</em>结构体：<br/>
<code><br/>
typedef struct {<br/>
    char sig[4];        /* Signature &quot;RCmb&quot; (Redis Cluster message bus). */<br/>
    uint32_t totlen;    /* Total length of this message */<br/>
    uint16_t ver;       /* Protocol version, currently set to 1. */<br/>
    uint16_t port;      /* TCP base port number. */<br/>
    uint16_t type;      /* Message type */<br/>
    uint16_t count;     /* Only used for some kind of messages. */<br/>
    uint64_t currentEpoch;  /* The epoch accordingly to the sending node. */<br/>
    uint64_t configEpoch;   /* The config epoch if it&#39;s a master, or the last<br/>
                               epoch advertised by its master if it is a<br/>
                               slave. */<br/>
    uint64_t offset;    /* Master replication offset if node is a master or<br/>
                           processed replication offset if node is a slave. */<br/>
    char sender[CLUSTER_NAMELEN]; /* Name of the sender node */<br/>
    unsigned char myslots[CLUSTER_SLOTS/8];<br/>
    char slaveof[CLUSTER_NAMELEN];<br/>
    char myip[NET_IP_STR_LEN];    /* Sender IP, if not all zeroed. */<br/>
    char notused1[34];  /* 34 bytes reserved for future usage. */<br/>
    uint16_t cport;      /* Sender TCP cluster bus port */<br/>
    uint16_t flags;      /* Sender node flags */<br/>
    unsigned char state; /* Cluster state from the POV of the sender */<br/>
    unsigned char mflags[3]; /* Message flags: CLUSTERMSG_FLAG[012]_... */<br/>
    union clusterMsgData data;<br/>
} clusterMsg;<br/>
</code></p>

<p>结构体头部主要是传输了一部分当前节点的信息：totlen信息长度，也就是最多32位，ver版本默认是1，port就是当前的节点端口，type表示当前信息的类型，大概有：PING\PONG\MEET\FAIL\UPDATE\PUBLISH几类。<br/>
Epoch则是代表当前的轮次，currentEpoch表示当前投票的轮次，而configEpoch表示当前信息的版本<br/>
offset表示当前节点的偏移量是多少。<br/>
sender表示当前节点的名称，myslots表示当前节点管理的slots。myip表示当前节点的ip信息。<br/>
<strong>后续几个信息待补充。</strong></p>

<p>对于集群信息，redis每秒会从所有节点中抽取5个节点中的一个节点来发送ping信息，同时针对很长时间没发送过的PING的节点会单独发送ping信息。</p>

<p>meet信息则是在客户端发送过了meet命令，或者在接收到新的节点信息的时候，会尝试去连接。这后续会讲解。</p>

<h3 id="toc_4">关于currentEpoch和configEpoch的区别</h3>

<p>这2个Epoch的区别，其实就是2种分布式协议所需要的信息。<br/>
currentEpoch表示raft协议中的选举轮次，每次加一，都代表新的投票。而configEpoch则表示当前节点的配置版本，gossip协议同步信息时，会将其带上，若有信息更新，则会选择一个新的epoch作为标识。</p>

<p>问：如果选错节点怎么办？？</p>

<h2 id="toc_5">节点管理</h2>

<h3 id="toc_6">关于MEET加入节点</h3>

<p>构建一个集群，主要是通过meet命令发送ip:port给集群内节点，后续都交由集群节点内部来处理。当然，这个配置也支持从配置文件中获取：</p>

<p>问：配置文件格式是啥？</p>

<p>当接收到了meet请求后，节点会将ip:port新建一个待握手的节点信息。其中会有2个状态，一个是CLUSTER_NODE_HANDSHAKE，一个是CLUSTER_NODE_MEET。<br/>
握手阶段的结束表示已经获得了对应节点的PING信息，拿到了相关的信息，而MEET阶段的结束只是表示已经建立好了连接并已发送了PING信息，但并没做完验证信息。</p>

<p>当一个节点已经和集群中的某个节点进行握手后，他们2将会通过ping消息将对方发送给其他节点，当其他节点获得到了新的节点信息，则会将其加入列表，并发送meet请求给新节点，这样就达到了分布式系统加入新节点的功能。</p>

<h3 id="toc_7">删除节点</h3>

<p>节点的删除则是通过<code>cluster forget</code>命令来进行的，</p>

<p>听说会广播出去，待查看</p>

<h3 id="toc_8">故障转移</h3>

<p>当某些master出现了异常，等于是未进行回复，则会进入故障标记阶段。</p>

<p>首先，如果集群中某个节点PONG回复过长，会被相关节点标记位fpail，同时会通过gossip协议将状态同步给其他节点。</p>

<p>当slave节点发现当前节点已经被大多数标记为下线时，则会向其他节点发送failover_auth请求选择自己为新的主节点。</p>

<p>每次事件前置后，都会检查是否已经满足条件，若已满足，则会开始进行故障转移的功能。这一步选举就是通过Raft协议进行。</p>

<p>从节点获取到超过半数的选票后，做的事件就比较简单，只是将当前节点设置为master并更新了slot信息，这样，后续的gossip消息同步，就会将数据给传播到各个节点上。</p>

<h3 id="toc_9">手动故障转移</h3>

<p>而，上述都是对于自动的故障转移设计的流程，redis集群本身还支持通过命令<code>CLUSTER  FAILOVER</code>手动的故障转移功能。其中有2中转移模式：<code>FORCE</code>和<code>TAKEOVER</code>。</p>

<p>如果有FORCE选项，则从节点不会与主节点进行交互，主节点也不会阻塞其客户端，而是从节点立即开始故障转移流程：发起选举、统计选票、赢得选举、升级为主节点并更新配置。</p>

<p>如果有TAKEOVER选项，则更加简单粗暴：从节点不再发起选举，而是直接将自己升级为主节点，接手原主节点的槽位，增加自己的configEpoch后更新配置。</p>

<p>因此，使用FORCE和TAKEOVER选项，主节点可以已经下线；而不使用任何选项，只发送”CLUSTER  FAILOVER”命令的话，主节点必须在线。</p>

<h2 id="toc_10">槽管理</h2>

<h3 id="toc_11">设置槽</h3>

<p>槽的设计是根据分布式系统的数据分片设计，整个的cluster支持将16384槽数据分片。</p>

<p>初始化的时候，可以使用<code>cluster addsolots</code>命令来设置节点所标记的slot。当然这个命令也有一定的注意事项：<br/>
1. 该命令只有当所有指定的slots在接收命令的节点上还没有分配得的情况下生效。节点将 拒绝接纳已经分配到其他节点的slots（包括它自己的）。<br/>
2. 同一个slot被指定多次的情况下命令会失败。<br/>
3. 执行这个命令有一个副作用，如果slot作为其中一个参数设置为importing，一旦节点向自己分配该slot（以前未绑定）这个状态将会被清除。</p>

<p>而当所有slots都已经被分配完成后，集群将进入正常服务模式。此时就不能在使用<code>addslots</code>命令来设置<code>slot</code>信息。</p>

<p>新的命令则是通过<code>cluster setslots</code>来设置slots的状态进行槽迁移：<br/>
1. cluster setslot <slot> importing <source_id><br/>
2. cluster setslot <slot> migrating <target_id><br/>
3. cluster getkeysinslot <slot> <count><br/>
4. migrate <target_id> <target_port> <key_name> 0 <timeout><br/>
5. cluster setslot <slot> none <source_id><br/>
6. cluster setslot <slot> none <target_id></p>

<p>关键步骤就是步骤4，此时需要通过脚本来不断的迁移相关的键信息，migrate命令是一个特殊的命令，他是一个迁移键的原子命令，内部是由dump和restore命令组成，每次都利用dump将数据序列号后，在调用目标节点的restore命令传输数据，后续再将数据从本地删除，达到原子的迁移数据功能。但风险就是如果键信息过大，则需要迁移过长时间。这也是无法避免的问题。</p>

<p>在分片的前提下，会产生2个新的错误码：ACK和MOVE。首先介绍MOVE错误码，该错误码主要是针对不在该节点的分片被查询，则会得到一个MOVE信息，并得到正常的节点信息。而对于ACK错误，则是在槽迁移过程中，访问的数据已经被迁移后，节点会返回ACK信息给客户端，使其重定向到新节点。</p>

<p>在数据分片时，常常有不可避免的分片不均的问题，如果某个槽的数据过多，这对于开发人员是无法避免的，而集群模式下，提供了tag的功能，当然也是在对键名进行改造。</p>

<h2 id="toc_12">节点均衡</h2>

<p>在故障转移后，常常会出现从节点不均衡的问题，那么就会触发从节点的均衡，这个功能其实相对简单。<br/>
在每次循环时，节点会检查自己是否为最大的主节点的从节点，如果是的话，从节点将会检查自己是否为名字最小的那个从节点，若是的，则就将自己的主节点切换。</p>

<h2 id="toc_13">信息处理</h2>

<p>信息处理是一个很重要的部分，cluster里面专门有好几百行来处理信息，其中就包括各种异常情况，后续我们来一一列举。</p>

<h3 id="toc_14">前置处理</h3>

<p>信息的前置处理大概分为2个部分：获取信息长度、更新节点信息。</p>

<p>首先由于这是一个新的信息格式，所以cluster中会先解析出信息的总长度，这和所有二进制协议是一样的。</p>

<p>之后，节点会查看新的连接是否已经是正常节点（存在且非握手状态），是的话，则修改选举轮次，偏移量等。</p>

<p>特殊逻辑是在手动故障转移的同时，收到了master请求的时候，同时还会记录下master当前的偏移量。</p>

<h3 id="toc_15">PING/PONG/MEET</h3>

<h2 id="toc_16">结语</h2>

<p>集群分析还没解析完成。</p>

<h2 id="toc_17">相关链接</h2>

<ul>
<li><a href="%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%EF%BC%8C%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%89%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%8D%8F%E8%AE%AE">https://www.cnblogs.com/balfish/p/8658691.html</a></li>
<li><a href="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E4%B9%8BQuorum%E6%9C%BA%E5%88%B6">https://www.cnblogs.com/hapjin/p/5626889.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 耗时记录模块]]></title>
    <link href="https://artikell.github.io/15304380579995.html"/>
    <updated>2018-07-01T17:40:57+08:00</updated>
    <id>https://artikell.github.io/15304380579995.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>学习一下耗时记录的模块</p>

<h2 id="toc_1">主要结构体</h2>

<p><em>latencySample</em>和<em>latencyTimeSeries</em>构成了整个耗时记录表</p>

<pre><code>struct latencySample {
    int32_t time; /* 当前时间 */
    uint32_t latency; /* 耗时信息 */
};

/* The latency time series for a given event. */
struct latencyTimeSeries {
    int idx; /* 当前记录的下标信息 */
    uint32_t max; /* 当前最大的耗时信息 */
    struct latencySample samples[LATENCY_TS_LEN]; /* 160条的日志记录 */
};
</code></pre>

<p><em>latencyStats</em>结构体则是针对事件的耗时分析</p>

<pre><code>struct latencyStats {
    uint32_t all_time_high; /* 复位后观察到的最大值 */
    uint32_t avg;           /* 平均值 */
    uint32_t min;           /* 最小值 */
    uint32_t max;           /* 最大值 */
    uint32_t mad;           /* 平均绝对离差 */
    uint32_t samples;       /* 实例数 */
    time_t period;          /* 经过的时间，（秒） */
};
</code></pre>

<h2 id="toc_2">主要函数</h2>

<p><em>latencyAddSample</em>函数是添加一个记录进耗时队列中</p>

<pre><code>void latencyAddSample(char *event, mstime_t latency) {
     /* 获取对应事件的耗时对象 */
    struct latencyTimeSeries *ts = dictFetchValue(server.latency_events,event);
    time_t now = time(NULL);
    int prev;

    /* 如果不存在，则分配一个对象 */
    if (ts == NULL) {
        ts = zmalloc(sizeof(*ts));
        ts-&gt;idx = 0;
        ts-&gt;max = 0;
        memset(ts-&gt;samples,0,sizeof(ts-&gt;samples));
        dictAdd(server.latency_events,zstrdup(event),ts);
    }

    /* 如果耗时过长，则记录下来 */
    if (latency &gt; ts-&gt;max) ts-&gt;max = latency;

    prev = (ts-&gt;idx + LATENCY_TS_LEN - 1) % LATENCY_TS_LEN; /* 获得前一个记录 */
    if (ts-&gt;samples[prev].time == now) {    /* 若时间相同且延时更改，则进行替换 */
        if (latency &gt; ts-&gt;samples[prev].latency)
            ts-&gt;samples[prev].latency = latency;
        return;
    }

    ts-&gt;samples[ts-&gt;idx].time = time(NULL);
    ts-&gt;samples[ts-&gt;idx].latency = latency;

    ts-&gt;idx++;
    if (ts-&gt;idx == LATENCY_TS_LEN) ts-&gt;idx = 0;     /* 重复轮回 */
}
</code></pre>

<p><em>latencyResetEvent</em> 函数用于重置某个事件的耗时记录</p>

<pre><code>int latencyResetEvent(char *event_to_reset) {
    dictIterator *di;
    dictEntry *de;
    int resets = 0;

    di = dictGetSafeIterator(server.latency_events);     /* 获得一个迭代器 */
    while((de = dictNext(di)) != NULL) {    /* 迭代整个字典，对符合条件的事件进行删除 */
        char *event = dictGetKey(de);

        if (event_to_reset == NULL || strcasecmp(event,event_to_reset) == 0) {
            dictDelete(server.latency_events, event);
            resets++;
        }
    }
    dictReleaseIterator(di);     /* 删除迭代器 */
    return resets;
}
</code></pre>

<h2 id="toc_3">主要命令</h2>

<p>主要命令有如下四个：</p>

<pre><code> * LATENCY SAMPLES: 指定事件的返回时间延迟采样.
 * LATENCY LATEST: 返回所有事件类的最新延迟.
 * LATENCY DOCTOR: 返回实例可读性的实例分析.
 * LATENCY GRAPH: 提供指定事件的等待时间的ASCII图.
</code></pre>

<h2 id="toc_4">总结</h2>

<p>看了看延迟记录而已</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 慢日志]]></title>
    <link href="https://artikell.github.io/15304363559324.html"/>
    <updated>2018-07-01T17:12:35+08:00</updated>
    <id>https://artikell.github.io/15304363559324.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>慢日志是一个比较简短的模块，先来看看</p>

<h2 id="toc_1">慢日志条件</h2>

<p>说的慢日志，我们可以先看看call调用函数的flags分类：</p>

<pre><code>#define CMD_CALL_NONE 0
#define CMD_CALL_SLOWLOG (1&lt;&lt;0)
#define CMD_CALL_STATS (1&lt;&lt;1)
#define CMD_CALL_PROPAGATE_AOF (1&lt;&lt;2)
#define CMD_CALL_PROPAGATE_REPL (1&lt;&lt;3)
#define CMD_CALL_PROPAGATE (CMD_CALL_PROPAGATE_AOF|CMD_CALL_PROPAGATE_REPL)
#define CMD_CALL_FULL (CMD_CALL_SLOWLOG | CMD_CALL_STATS | CMD_CALL_PROPAGATE)
</code></pre>

<p>包括四类：添加慢日志、进入命令统计、AOF传播和REPL传播<br/>
正常命令都会包含所有<em>flags</em>，所以默认会进行慢日志统计。</p>

<pre><code>    if (flags &amp; CMD_CALL_SLOWLOG &amp;&amp; c-&gt;cmd-&gt;proc != execCommand) {  // 慢日志写入
        char *latency_event = (c-&gt;cmd-&gt;flags &amp; CMD_FAST) ?
                              &quot;fast-command&quot; : &quot;command&quot;;
        latencyAddSampleIfNeeded(latency_event,duration/1000);
        slowlogPushEntryIfNeeded(c,c-&gt;argv,c-&gt;argc,duration);
    }
</code></pre>

<p>慢日志入口的判断就比较简单，判断是否有标记以及命令是否为<em>execCommand</em>，事务处理不计入统计。</p>

<h2 id="toc_2">慢日志源码剖析</h2>

<h3 id="toc_3">主要结构体</h3>

<p><em>slowlogEntry</em>是慢日志的唯一结构体</p>

<pre><code>typedef struct slowlogEntry {
    robj **argv;        /* 参数列表 */   
    int argc;           /* 参数个数 */   
    long long id;       /* 唯一编号 */
    long long duration; /* 处理时长，毫秒 */
    time_t time;        /* 执行时间 */
    sds cname;          /* 客户端名称 */
    sds peerid;         /* 客户端地址 */
} slowlogEntry;
</code></pre>

<h3 id="toc_4">主要函数</h3>

<p><em>slowlogPushEntryIfNeeded</em> 函数是整个慢日志的触发入口：</p>

<pre><code>void slowlogPushEntryIfNeeded(client *c, robj **argv, int argc, long long duration) {
    if (server.slowlog_log_slower_than &lt; 0) return; /* 未开启慢日志记录 */
    if (duration &gt;= server.slowlog_log_slower_than) /* 耗时足够 */
        /* 将慢日志插入列表中 */
        listAddNodeHead(server.slowlog,
                        slowlogCreateEntry(c,argv,argc,duration));

        
    while (listLength(server.slowlog) &gt; server.slowlog_max_len)
        listDelNode(server.slowlog,listLast(server.slowlog));
}
</code></pre>

<p><em>slowlogCreateEntry</em>函数，则是创建一个慢日志元素的方法：</p>

<pre><code>slowlogEntry *slowlogCreateEntry(client *c, robj **argv, int argc, long long duration) {
    slowlogEntry *se = zmalloc(sizeof(*se));
    int j, slargc = argc;

    /* 参数不允许超过32个，否则就截取前32个 */
    if (slargc &gt; SLOWLOG_ENTRY_MAX_ARGC) slargc = SLOWLOG_ENTRY_MAX_ARGC;
    se-&gt;argc = slargc;
    se-&gt;argv = zmalloc(sizeof(robj*)*slargc);
    for (j = 0; j &lt; slargc; j++) {
        /* 如果是最后一个元素时，则添加一个省略号来标记 */
        if (slargc != argc &amp;&amp; j == slargc-1) {
            se-&gt;argv[j] = createObject(OBJ_STRING,
                sdscatprintf(sdsempty(),&quot;... (%d more arguments)&quot;,
                argc-slargc+1));
        } else {
            /* 处理长度大于128的参数信息 */
            if (argv[j]-&gt;type == OBJ_STRING &amp;&amp;
                sdsEncodedObject(argv[j]) &amp;&amp;
                sdslen(argv[j]-&gt;ptr) &gt; SLOWLOG_ENTRY_MAX_STRING)
            {
                sds s = sdsnewlen(argv[j]-&gt;ptr, SLOWLOG_ENTRY_MAX_STRING);

                s = sdscatprintf(s,&quot;... (%lu more bytes)&quot;,
                    (unsigned long)
                    sdslen(argv[j]-&gt;ptr) - SLOWLOG_ENTRY_MAX_STRING);
                se-&gt;argv[j] = createObject(OBJ_STRING,s);
            } else if (argv[j]-&gt;refcount == OBJ_SHARED_REFCOUNT) {
                /* 如果是共享的变量，则直接复制 */
                se-&gt;argv[j] = argv[j];
            } else {
                /* 重新开辟内存 */
                se-&gt;argv[j] = dupStringObject(argv[j]);
            }
        }
    }
    se-&gt;time = time(NULL);
    se-&gt;duration = duration;
    se-&gt;id = server.slowlog_entry_id++;     /* 自增编号 */
    se-&gt;peerid = sdsnew(getClientPeerId(c));
    se-&gt;cname = c-&gt;name ? sdsnew(c-&gt;name-&gt;ptr) : sdsempty();
    return se;
}
</code></pre>

<p><em>slowlogReset</em>函数是用于重置慢日志的函数，方法就行遍历并删除节点</p>

<pre><code>void slowlogReset(void) {
    while (listLength(server.slowlog) &gt; 0)
        listDelNode(server.slowlog,listLast(server.slowlog));
}
</code></pre>

<h3 id="toc_5">结语</h3>

<p>看看比较简单的慢日志模块而已。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis启动过程分析]]></title>
    <link href="https://artikell.github.io/15298493212536.html"/>
    <updated>2018-06-24T22:08:41+08:00</updated>
    <id>https://artikell.github.io/15298493212536.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>一个优秀的软件都有一个优秀的启动过程来保证整个流程的高可用性。</p>

<h2 id="toc_1">Redis的各个模式</h2>

<p>要说起redis本身的启动的话，就要先区分redis本身的3个模式：</p>

<ol>
<li>主从模式</li>
<li>哨兵模式</li>
<li>集群模式</li>
</ol>

<h3 id="toc_2">主从模式</h3>

<ol>
<li><p>redis的复制功能是支持多个数据库之间的数据同步。一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。</p></li>
<li><p>通过redis的复制功能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。</p></li>
</ol>

<h3 id="toc_3">哨兵模式</h3>

<p>redis的sentinel系统用于管理多个redis服务器，该系统主要执行三个任务：监控、提醒、自动故障转移。</p>

<ol>
<li>监控（Monitoring）： Redis Sentinel实时监控主服务器和从服务器运行状态，并且实现自动切换。</li>
<li>提醒（Notification）：当被监控的某个 Redis 服务器出现问题时， Redis Sentinel 可以向系统管理员发送通知， 也可以通过 API 向其他程序发送通知。</li>
<li>自动故障转移（Automatic failover）： 当一个主服务器不能正常工作时，Redis Sentinel 可以将一个从服务器升级为主服务器， 并对其他从服务器进行配置，让它们使用新的主服务器。当应用程序连接Redis 服务器时， Redis Sentinel会告之新的主服务器地址和端口。</li>
</ol>

<h3 id="toc_4">集群模式</h3>

<p>redis集群是一个无中心的分布式Redis存储架构，可以在多个节点之间进行数据共享，解决了Redis高可用、可扩展等问题。redis集群提供了以下两个好处</p>

<ol>
<li>将数据自动切分(split)到多个节点</li>
<li>当集群中的某一个节点故障时，redis还可以继续处理客户端的请求。</li>
</ol>

<p>一个 Redis 集群包含 16384 个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽。集群中的每一个节点负责处理一部分哈希槽。</p>

<h2 id="toc_5">启动解析</h2>

<h3 id="toc_6">环境初始化</h3>

<h3 id="toc_7">命令获取并处理</h3>

<h2 id="toc_8">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/davidwang456/p/3539721.html">深入redis内部之redis启动过程之一</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis高频函数解读]]></title>
    <link href="https://artikell.github.io/15289024592933.html"/>
    <updated>2018-06-13T23:07:39+08:00</updated>
    <id>https://artikell.github.io/15289024592933.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>在阅读redis源码时，发现在整个源码中，作者有很多十分高频的函数在重复使用，于是决定收集一下相关函数来进行解析，以方便后续阅读源码。</p>

<h2 id="toc_1">高频函数整理</h2>

<h3 id="toc_2">serverAssert</h3>

<p><em>serverAssert</em> 有一系列函数都是用于整体的代码做正确校验的函数：</p>

<pre><code>#define serverAssertWithInfo(_c,_o,_e) ((_e)?(void)0 : (_serverAssertWithInfo(_c,_o,#_e,__FILE__,__LINE__),_exit(1)))
#define serverAssert(_e) ((_e)?(void)0 : (_serverAssert(#_e,__FILE__,__LINE__),_exit(1)))
#define serverPanic(...) _serverPanic(__FILE__,__LINE__,__VA_ARGS__),_exit(1)
</code></pre>

<p>可以看出，<em>serverAssert</em>函数在判断错误时，将会调用日志函数并退出程序，这就不像nginx源码那样通过不断的返回进行容错判断，这也许是数据库和服务器之间的区别。</p>

<h3 id="toc_3">checkType</h3>

<p>该函数主要用于检查对象类型，这个函数一般都是与获取对象函数<em>lookupKeyReadOrReply</em>一起进行处理，不过其实可以将其收敛起来，不需要全部暴露在外。源码如下：</p>

<pre><code>int checkType(client *c, robj *o, int type) {
    if (o-&gt;type != type) {
        addReply(c,shared.wrongtypeerr);
        return 1;
    }
    return 0;
}
</code></pre>

<h3 id="toc_4">lookupKey*系列</h3>

<p>这个系列的函数主要用于获得相关<em>key</em>值的对象信息，主要是6个函数：<br/>
1. lookupKey(redisDb *db, robj *key, int flags)<br/>
2. lookupKeyReadWithFlags(redisDb *db, robj *key, int flags)<br/>
3. lookupKeyRead(redisDb *db, robj *key)<br/>
4. lookupKeyWrite(redisDb *db, robj *key)<br/>
5. lookupKeyReadOrReply(client *c, robj *key, robj *reply)<br/>
6. lookupKeyWriteOrReply(client *c, robj *key, robj *reply)</p>

<p>6个函数也可以分为读写2类，其中的区别在于：读操作，需要判断是否过期，同时修改系统相关参数，而写操作，只需要判断一下超时时间即可</p>

<p>2个<em>OrReply</em>结尾的函数，主要是在未获取到对象时，将返回给客户端信息。</p>

<p>而<em>lookupKey</em>函数，本身只是从dict中获取到相关对象而已。</p>

<h3 id="toc_5">addReply</h3>

<p>这个函数，是返回给客户端信息的重要函数，源码如下：</p>

<pre><code>void addReply(client *c, robj *obj) {
    if (prepareClientToWrite(c) != C_OK) return;

    if (sdsEncodedObject(obj)) {
        if (_addReplyToBuffer(c,obj-&gt;ptr,sdslen(obj-&gt;ptr)) != C_OK)
            _addReplyStringToList(c,obj-&gt;ptr,sdslen(obj-&gt;ptr));
    } else if (obj-&gt;encoding == OBJ_ENCODING_INT) {
        char buf[32];
        size_t len = ll2string(buf,sizeof(buf),(long)obj-&gt;ptr);
        if (_addReplyToBuffer(c,buf,len) != C_OK)
            _addReplyStringToList(c,buf,len);
    }
}
</code></pre>

<p>首先，函数会判断客户端是否可写。<br/>
之后，利用<em>_addReplyToBuffer</em>函数写入缓存区中。<br/>
再调用<em>_addReplyStringToList</em>函数接入列表中？</p>

<h2 id="toc_6">总结</h2>

<p>怎么说呢，最近看数据结构，总感觉redis源码本身并不够优雅，没有nginx那种漂亮的结构以及更底层细致的操作。之后还会再继续学习。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 哈希表hash源码解析]]></title>
    <link href="https://artikell.github.io/15287362006822.html"/>
    <updated>2018-06-12T00:56:40+08:00</updated>
    <id>https://artikell.github.io/15287362006822.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<h2 id="toc_1">相关命令</h2>

<table>
<thead>
<tr>
<th>命令</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>HDEL</td>
<td>删除</td>
<td>删除一个或多个哈希表字段</td>
</tr>
<tr>
<td>HEXISTS</td>
<td>查询</td>
<td>查看哈希表 key 中，指定的字段是否存在。</td>
</tr>
<tr>
<td>HGET</td>
<td>查询</td>
<td>获取存储在哈希表中指定字段的值。</td>
</tr>
<tr>
<td>HGETALL</td>
<td>查询</td>
<td>获取在哈希表中指定 key 的所有字段和值</td>
</tr>
<tr>
<td>HINCRBY</td>
<td>更新</td>
<td>为哈希表 key 中的指定字段的整数值加上增量 increment 。</td>
</tr>
<tr>
<td>HINCRBYFLOAT</td>
<td>更新</td>
<td>为哈希表 key 中的指定字段的浮点数值加上增量 increment 。</td>
</tr>
<tr>
<td>HKEYS</td>
<td>查询</td>
<td>获取所有哈希表中的字段</td>
</tr>
<tr>
<td>HLEN</td>
<td>查询</td>
<td>获取哈希表中字段的数量</td>
</tr>
<tr>
<td>HMGET</td>
<td>查询</td>
<td>获取所有给定字段的值</td>
</tr>
<tr>
<td>HMSET</td>
<td>更新</td>
<td>同时将多个 field-value (域-值)对设置到哈希表 key 中。</td>
</tr>
<tr>
<td>HSET</td>
<td>更新</td>
<td>将哈希表 key 中的字段 field 的值设为 value 。</td>
</tr>
<tr>
<td>HSETNX</td>
<td>更新</td>
<td>只有在字段 field 不存在时，设置哈希表字段的值。</td>
</tr>
<tr>
<td>HVALS</td>
<td>查询</td>
<td>获取哈希表中所有值</td>
</tr>
<tr>
<td>HSCAN</td>
<td>查询</td>
<td>迭代哈希表中的键值对。</td>
</tr>
</tbody>
</table>

<h2 id="toc_2">核心操作</h2>

<h2 id="toc_3">总结</h2>

<h2 id="toc_4">相关链接</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 有序列表zset源码解析]]></title>
    <link href="https://artikell.github.io/15287304018827.html"/>
    <updated>2018-06-11T23:20:01+08:00</updated>
    <id>https://artikell.github.io/15287304018827.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>有序列表底层使用了<em>ziplist</em>和<em>skiplist</em>2种数据结构，2者都是redis中相对比较复杂的数据结构，此次，我们来通过主要的命令来解析相关的核心操作。</p>

<h2 id="toc_1">相关命令</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>解释</th>
</tr>
</thead>

<tbody>
<tr>
<td>Zadd</td>
<td>创建</td>
<td>将带有给定分值的成员添加到有序列表里面</td>
</tr>
<tr>
<td>Zrem</td>
<td>删除</td>
<td>从有序集合里面移除给定的成员，并返回被移除成员的数量</td>
</tr>
<tr>
<td>Zcard</td>
<td>查询</td>
<td>返回有序集合包含的成员数量</td>
</tr>
<tr>
<td>Zincrby</td>
<td>修改</td>
<td>将member成员的分值加上increment</td>
</tr>
<tr>
<td>Zcount</td>
<td>查询</td>
<td>返回分值介于min和max之间的成员数量，包括min和max在内</td>
</tr>
<tr>
<td>Zrank</td>
<td>查询</td>
<td>返回成员member在有序集合中的排名，成员按照分值从小到大排列</td>
</tr>
<tr>
<td>Zrevrank</td>
<td>查询</td>
<td>返回成员member在有序集合中的排名 ，成员按照分值从大到小排列</td>
</tr>
<tr>
<td>Zscore</td>
<td>查询</td>
<td>返回成员member的分值</td>
</tr>
<tr>
<td>Zrange</td>
<td>查询</td>
<td>返回有序集合中排名介于start和stop之间的成员，包括start和stop在内，如果给定了可选的WITHSCORES选项，那么命令会将成员的分值一并返回，成员按照分值从小到大排列</td>
</tr>
<tr>
<td>Zrevrange</td>
<td>查询</td>
<td>返回有序集合中排名介于start和stop之间的成员，包括start和stop在内，如果给定了可选的WITHSCORES选项，那么命令会将成员的分值一并返回，成员按照分值从大到小排列</td>
</tr>
<tr>
<td>Zrangebyscore</td>
<td>查询</td>
<td>返回有序集合中分值介于min和max之间的所有成员，包括min和max在内，并按照分值从小到大的排序来返回他们</td>
</tr>
<tr>
<td>Zrevrangebyscore</td>
<td>查询</td>
<td>返回有序集合中分值介于min和max之间的所有成员，包括min和max在内，并按照分值从大到小的排序来返回他们</td>
</tr>
<tr>
<td>Zremrangebyrank</td>
<td>删除</td>
<td>移除有序集合中排名介于start和stop之间的所有成员，包括start和stop在内</td>
</tr>
<tr>
<td>Zremrangebyscore</td>
<td>删除</td>
<td>移除有序集合中分值介于min和max之间的所有成员，包括min和max在内</td>
</tr>
<tr>
<td>Zinterstore</td>
<td>合并</td>
<td>对给定的有序集合执行类似于集合的交集运算</td>
</tr>
<tr>
<td>Zunionstore</td>
<td>合并</td>
<td>对给定的有序集合执行类似于集合的并集运算</td>
</tr>
</tbody>
</table>

<p>其中 <em>查询操作</em> 包含 9个命令，<em>增加或更新</em>只有2个，而<em>删除类命令</em>包括了3个。</p>

<p>这么一看，核心操作主要在于如何高效查询，以及如何进行底层数据结构的升级。</p>

<h2 id="toc_2">高效查询</h2>

<p>查询本身也分为2类：单元素查询、范围查询。</p>

<h3 id="toc_3">单元素查询</h3>

<p>单元素查询相对比较简单，一般都是某个成员的分值、排名等信息。2者之间的核心就是在于：如何快速查询到所需的成员。</p>

<h4 id="toc_4">对于ziplist</h4>

<p>ziplist最多也就512个元素，所以，不需要什么算法，暴力就行！！！</p>

<pre><code>while(eptr != NULL) {
    if (ziplistCompare(eptr,(unsigned char*)ele,sdslen(ele)))
        break;
    rank++;
    zzlNext(zl,&amp;eptr,&amp;sptr);
}
</code></pre>

<h4 id="toc_5">对于skiplist</h4>

<p><em>skiplist</em>本身可能会有很多元素，所以，本身的设计也是为了高效设计，所以，本身按照跳跃表的特性，我们只需要从最大的元素开始不断往下寻找元素即可。</p>

<pre><code>for (i = zsl-&gt;level-1; i &gt;= 0; i--) {
    while (x-&gt;level[i].forward &amp;&amp;
        (x-&gt;level[i].forward-&gt;score &lt; score ||
            (x-&gt;level[i].forward-&gt;score == score &amp;&amp;
            sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt;= 0))) {
        rank += x-&gt;level[i].span;
        x = x-&gt;level[i].forward;
    }

    /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */
    if (x-&gt;ele &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) {
        return rank;
    }
}
</code></pre>

<h3 id="toc_6">范围查询</h3>

<p>范围查询也可以分为3类：<em>分值范围、排名范围、字符串匹配</em>。不过三者之间的差异并没有特别巨大，也可以根据不同的结构体进行分类讨论。</p>

<h4 id="toc_7">对于ziplist</h4>

<p>ziplist 本身由于节省内存，所以，方法上没有不同，照常还是遍历。</p>

<p>首先，ziplist会获取的范围的对象，通过first类函数找到最初的元素：</p>

<pre><code>    while (eptr != NULL) {
        sptr = ziplistNext(zl,eptr);
        serverAssert(sptr != NULL);

        score = zzlGetScore(sptr);
        if (zslValueGteMin(score,range)) {
            /* Check if score &lt;= max. */
            if (zslValueLteMax(score,range))
                return eptr;
            return NULL;
        }

        /* Move to next element. */
        eptr = ziplistNext(zl,sptr);
    }
</code></pre>

<p>找到起始元素后，会通过迭代的方式来获取范围类的数据，并进行删除。</p>

<pre><code>while ((sptr = ziplistNext(zl,eptr)) != NULL) {
    if (zzlLexValueLteMax(eptr,range)) {
        /* Delete both the element and the score. */
        zl = ziplistDelete(zl,&amp;eptr);
        zl = ziplistDelete(zl,&amp;eptr);
        num++;
    } else {
        /* No longer in range. */
        break;
    }
}
</code></pre>

<h4 id="toc_8">对于skiplist</h4>

<p>skiplist 本身的高效，所以，不需要特别的处理，不过，也只是在最开始的时候快速找到起始元素，然后开始不断遍历。</p>

<pre><code>x = zsl-&gt;header;
for (i = zsl-&gt;level-1; i &gt;= 0; i--) {
    while (x-&gt;level[i].forward &amp;&amp;
        !zslLexValueGteMin(x-&gt;level[i].forward-&gt;ele,range))
            x = x-&gt;level[i].forward;
    update[i] = x;
}

/* Current node is the last with score &lt; or &lt;= min. */
x = x-&gt;level[0].forward;

/* Delete nodes while in range. */
while (x &amp;&amp; zslLexValueLteMax(x-&gt;ele,range)) {
    zskiplistNode *next = x-&gt;level[0].forward;
    zslDeleteNode(zsl,x,update);
    dictDelete(dict,x-&gt;ele);
    zslFreeNode(x); /* Here is where x-&gt;ele is actually released. */
    removed++;
    x = next;
}
</code></pre>

<h2 id="toc_9">合并操作</h2>

<p>对于差集，多个集合进行轮询，判断第一个集合的元素是否在其他集合中，若存在，则添加进一个新建的有序集合中即可。</p>

<p>对于并集，那就是先把所有集合全部插入一个字典中，在遍历字典，插入集合中即可。</p>

<p>2者默认都是skiplist模式的有序列表。</p>

<h2 id="toc_10">总结</h2>

<p>此次只看到一点皮毛，感觉redis源码很多地方写法与自身写法不同，侧面反映作者注重于效率。</p>

<h2 id="toc_11">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/xiaouncle/article/details/62236593">Redis常用命令-Zset</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis常用数据类型介绍、使用场景]]></title>
    <link href="https://artikell.github.io/15286369556294.html"/>
    <updated>2018-06-10T21:22:35+08:00</updated>
    <id>https://artikell.github.io/15286369556294.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">String（字符串）</h2>

<p>String是简单的 key-value 键值对，value 不仅可以是 String，也可以是数字。String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</p>

<p>String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</p>

<h3 id="toc_1">应用场景</h3>

<p>String是最常用的一种数据类型，普通的key/value存储都可以归为此类，这里就不所做解释了。</p>

<h2 id="toc_2">List（列表）</h2>

<p>Redis列表是简单的字符串列表，可以类比到C++中的std::list，简单的说就是一个链表或者说是一个队列。可以从头部或尾部向Redis列表添加元素。列表的最大长度为2<sup>32</sup> - 1，也即每个列表支持超过40亿个元素。</p>

<p>Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。</p>

<h3 id="toc_3">应用场景</h3>

<p>Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表、粉丝列表等都可以用Redis的list结构来实现，再比如有的应用使用Redis的list类型实现一个简单的轻量级消息队列，生产者push，消费者pop/bpop。</p>

<h2 id="toc_4">Hash（字典，哈希表）</h2>

<p>类似C#中的dict类型或者C++中的hash_map类型。</p>

<p>Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。</p>

<h3 id="toc_5">应用场景</h3>

<p>假设有多个用户及对应的用户信息，可以用来存储以用户ID为key，将用户信息序列化为比如json格式做为value进行保存。</p>

<h2 id="toc_6">Set（集合）</h2>

<p>可以理解为一堆值不重复的列表，类似数学领域中的集合概念，且Redis也提供了针对集合的求交集、并集、差集等操作。</p>

<p>set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。</p>

<h3 id="toc_7">应用场景</h3>

<p>Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。</p>

<p>又或者在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。</p>

<h2 id="toc_8">Sorted Set（有序集合）</h2>

<p>Redis有序集合类似Redis集合，不同的是增加了一个功能，即集合是有序的。一个有序集合的每个成员带有分数，用于进行排序。</p>

<p>Redis有序集合添加、删除和测试的时间复杂度均为O(1)(固定时间，无论里面包含的元素集合的数量)。列表的最大长度为2<sup>32-</sup> 1元素(4294967295，超过40亿每个元素的集合)。</p>

<p>Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。</p>

<h3 id="toc_9">使用场景</h3>

<p>Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。</p>

<p>又比如用户的积分排行榜需求就可以通过有序集合实现。还有上面介绍的使用List实现轻量级的消息队列，其实也可以通过Sorted Set实现有优先级或按权重的队列。</p>

<h2 id="toc_10">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/lizhenghn/p/5322887.html">Redis常用数据类型介绍、使用场景及其操作命令</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis Bio模块的学习]]></title>
    <link href="https://artikell.github.io/15286278830553.html"/>
    <updated>2018-06-10T18:51:23+08:00</updated>
    <id>https://artikell.github.io/15286278830553.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p><em>Redis</em>宣称的单进程的程序，但是，源码中到处都有为了防止顺序混乱的代码，之后，在淘汰机制中发现了<em>dbAsyncDelete</em>函数，才了解到<em>Redis</em>本身的存在异步操作的，现在，我们来看看异步IO都做了什么处理吧。</p>

<h2 id="toc_1">Bio的功能</h2>

<p>Bio模块本身代码不多，可以一一来介绍各个函数的功能，首先，我们看看线程相关的一下对象。</p>

<h3 id="toc_2">线程相关对象</h3>

<pre><code>static pthread_t bio_threads[BIO_NUM_OPS];  //BIO线程
static pthread_mutex_t bio_mutex[BIO_NUM_OPS]; //BIO每个线程的mutex锁变量
static pthread_cond_t bio_newjob_cond[BIO_NUM_OPS]; //BIO线程锁的条件变量， 监听这个条件变量唤起当前线程
static pthread_cond_t bio_step_cond[BIO_NUM_OPS]; //BIO线程阻塞锁，bioWaitStepOfType监听这个条件变量被通知该操作的执行。
static list *bio_jobs[BIO_NUM_OPS];
static unsigned long long bio_pending[BIO_NUM_OPS]; // BIO未执行的
</code></pre>

<p>从中我们可以看出，线程本身是作为一个变量存储，同时，对于每个线程，都有相关的锁以及锁条件。</p>

<p>同时，<em>Redis</em>中的线程，为每种类型的操作都分配了一个线程进行处理，其中拥有3中类型：</p>

<pre><code>#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */
#define BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */
#define BIO_LAZY_FREE     2 /* Deferred objects freeing. */
</code></pre>

<p>这样可以很好的控制线程的数量，这也是为什么<em>Redis</em>会设置一个<em>jobs</em>列表来存储任务的原因。</p>

<h3 id="toc_3">bioInit 函数</h3>

<p>bioInit函数是在整个Redis服务启动时调用，源码如下：</p>

<pre><code>void bioInit(void) {
    pthread_attr_t attr;
    pthread_t thread;
    size_t stacksize;
    int j;

    /* Initialization of state vars and objects */
    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        pthread_mutex_init(&amp;bio_mutex[j],NULL);
        pthread_cond_init(&amp;bio_newjob_cond[j],NULL);
        pthread_cond_init(&amp;bio_step_cond[j],NULL);
        bio_jobs[j] = listCreate();
        bio_pending[j] = 0;
    }

    /* Set the stack size as by default it may be small in some system */
    pthread_attr_init(&amp;attr);
    pthread_attr_getstacksize(&amp;attr,&amp;stacksize);
    if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */
    while (stacksize &lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2;
    pthread_attr_setstacksize(&amp;attr, stacksize);

    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        void *arg = (void*)(unsigned long) j;
        if (pthread_create(&amp;thread,&amp;attr,bioProcessBackgroundJobs,arg) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can&#39;t initialize Background Jobs.&quot;);
            exit(1);
        }
        bio_threads[j] = thread;
    }
}
</code></pre>

<p>在BIO初始化时，首先是对线程相关的对象进行初始化，包括<em>线程锁、锁条件、线程队列</em>等。<br/>
在之后，通过<em>pthread_attr_init</em>函数对线程环境进行初始化，并对栈大小进行重设。<br/>
最后，根据<em>线程环境</em>创建了一系列的线程，用于后续使用。</p>

<h3 id="toc_4">bioCreateBackgroundJob 函数</h3>

<p>该函数主要是用于添加一个异步任务，传入的参数比较简单，包括Type和3个变量。这些都存储在bio_job结构体中：</p>

<pre><code>struct bio_job {
    time_t time; /* Time at which the job was created. */
    void *arg1, *arg2, *arg3;
};
</code></pre>

<p>关于为啥是3个变量，主要是针对不同类型的异步事件使用，3个变量的排列组合共有8种，差不多够用了。<br/>
代码中主要是对于惰性淘汰进行分类：若第一个指针，则代表释放object；第二个指针代表释放一个数据库；第三个指针代表释放一个哈希表。</p>

<p><em>bioCreateBackgroundJob</em> 函数在赋值完，会将相关的线程进行唤醒让其来主动处理队列中的任务。这其中的逻辑与协程相似，但却有所不同。</p>

<h3 id="toc_5">bioProcessBackgroundJobs 函数</h3>

<p>该函数在创建线程后，会直接执行，那么本身对线程做了一些设定：<br/>
<code><br/>
    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);<br/>
    pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);<br/>
</code><br/>
首先，使线程保持可控制性，这样能线程能被杀死，这样做的目的暂时是为了debug调试。</p>

<p>之后，函数对线程进行了信号量的设置：</p>

<pre><code>sigemptyset(&amp;sigset);
sigaddset(&amp;sigset, SIGALRM);
if (pthread_sigmask(SIG_BLOCK, &amp;sigset, NULL))
    serverLog(LL_WARNING,
        &quot;Warning: can&#39;t mask SIGALRM in bio.c thread: %s&quot;, strerror(errno));
</code></pre>

<p>这个之后可以多了解一番。</p>

<p>之后，函数就进入了一个死循环用来不断的处理来自队列的任务，包括AOF同步等。</p>

<h2 id="toc_6">总结</h2>

<p><em>Redis</em>的线程使用比较谨慎，其中仅仅只包含3种类型的线程事件。这样保证了Redis本身代码的简洁。</p>

<h2 id="toc_7">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/lijunamneg/archive/2013/01/25/2877211.html">线程取消</a></li>
<li><a href="https://yq.aliyun.com/articles/58703?utm_source=tool.lu">bio学习</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
