<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[artikell]]></title>
  <link href="https://artikell.github.io/atom.xml" rel="self"/>
  <link href="https://artikell.github.io/"/>
  <updated>2018-06-10T19:36:00+08:00</updated>
  <id>https://artikell.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Redis Bio模块的学习]]></title>
    <link href="https://artikell.github.io/15286278830553.html"/>
    <updated>2018-06-10T18:51:23+08:00</updated>
    <id>https://artikell.github.io/15286278830553.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p><em>Redis</em>宣称的单进程的程序，但是，源码中到处都有为了防止顺序混乱的代码，之后，在淘汰机制中发现了<em>dbAsyncDelete</em>函数，才了解到<em>Redis</em>本身的存在异步操作的，现在，我们来看看异步IO都做了什么处理吧。</p>

<h2 id="toc_1">Bio的功能</h2>

<p>Bio模块本身代码不多，可以一一来介绍各个函数的功能，首先，我们看看线程相关的一下对象。</p>

<h3 id="toc_2">线程相关对象</h3>

<pre><code>static pthread_t bio_threads[BIO_NUM_OPS];  //BIO线程
static pthread_mutex_t bio_mutex[BIO_NUM_OPS]; //BIO每个线程的mutex锁变量
static pthread_cond_t bio_newjob_cond[BIO_NUM_OPS]; //BIO线程锁的条件变量， 监听这个条件变量唤起当前线程
static pthread_cond_t bio_step_cond[BIO_NUM_OPS]; //BIO线程阻塞锁，bioWaitStepOfType监听这个条件变量被通知该操作的执行。
static list *bio_jobs[BIO_NUM_OPS];
static unsigned long long bio_pending[BIO_NUM_OPS]; // BIO未执行的
</code></pre>

<p>从中我们可以看出，线程本身是作为一个变量存储，同时，对于每个线程，都有相关的锁以及锁条件。</p>

<p>同时，<em>Redis</em>中的线程，为每种类型的操作都分配了一个线程进行处理，其中拥有3中类型：</p>

<pre><code>#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */
#define BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */
#define BIO_LAZY_FREE     2 /* Deferred objects freeing. */
</code></pre>

<p>这样可以很好的控制线程的数量，这也是为什么<em>Redis</em>会设置一个<em>jobs</em>列表来存储任务的原因。</p>

<h3 id="toc_3">bioInit 函数</h3>

<p>bioInit函数是在整个Redis服务启动时调用，源码如下：</p>

<pre><code>void bioInit(void) {
    pthread_attr_t attr;
    pthread_t thread;
    size_t stacksize;
    int j;

    /* Initialization of state vars and objects */
    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        pthread_mutex_init(&amp;bio_mutex[j],NULL);
        pthread_cond_init(&amp;bio_newjob_cond[j],NULL);
        pthread_cond_init(&amp;bio_step_cond[j],NULL);
        bio_jobs[j] = listCreate();
        bio_pending[j] = 0;
    }

    /* Set the stack size as by default it may be small in some system */
    pthread_attr_init(&amp;attr);
    pthread_attr_getstacksize(&amp;attr,&amp;stacksize);
    if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */
    while (stacksize &lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2;
    pthread_attr_setstacksize(&amp;attr, stacksize);

    for (j = 0; j &lt; BIO_NUM_OPS; j++) {
        void *arg = (void*)(unsigned long) j;
        if (pthread_create(&amp;thread,&amp;attr,bioProcessBackgroundJobs,arg) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can&#39;t initialize Background Jobs.&quot;);
            exit(1);
        }
        bio_threads[j] = thread;
    }
}
</code></pre>

<p>在BIO初始化时，首先是对线程相关的对象进行初始化，包括<em>线程锁、锁条件、线程队列</em>等。<br/>
在之后，通过<em>pthread_attr_init</em>函数对线程环境进行初始化，并对栈大小进行重设。<br/>
最后，根据<em>线程环境</em>创建了一系列的线程，用于后续使用。</p>

<h3 id="toc_4">bioCreateBackgroundJob 函数</h3>

<p>该函数主要是用于添加一个异步任务，传入的参数比较简单，包括Type和3个变量。这些都存储在bio_job结构体中：</p>

<pre><code>struct bio_job {
    time_t time; /* Time at which the job was created. */
    void *arg1, *arg2, *arg3;
};
</code></pre>

<p>关于为啥是3个变量，主要是针对不同类型的异步事件使用，3个变量的排列组合共有8种，差不多够用了。<br/>
代码中主要是对于惰性淘汰进行分类：若第一个指针，则代表释放object；第二个指针代表释放一个数据库；第三个指针代表释放一个哈希表。</p>

<p><em>bioCreateBackgroundJob</em> 函数在赋值完，会将相关的线程进行唤醒让其来主动处理队列中的任务。这其中的逻辑与协程相似，但却有所不同。</p>

<h3 id="toc_5">bioProcessBackgroundJobs 函数</h3>

<p>该函数在创建线程后，会直接执行，那么本身对线程做了一些设定：<br/>
<code><br/>
    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);<br/>
    pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);<br/>
</code><br/>
首先，使线程保持可控制性，这样能线程能被杀死，这样做的目的暂时是为了debug调试。</p>

<p>之后，函数对线程进行了信号量的设置：</p>

<pre><code>sigemptyset(&amp;sigset);
sigaddset(&amp;sigset, SIGALRM);
if (pthread_sigmask(SIG_BLOCK, &amp;sigset, NULL))
    serverLog(LL_WARNING,
        &quot;Warning: can&#39;t mask SIGALRM in bio.c thread: %s&quot;, strerror(errno));
</code></pre>

<p>这个之后可以多了解一番。</p>

<p>之后，函数就进入了一个死循环用来不断的处理来自队列的任务，包括AOF同步等。</p>

<h2 id="toc_6">总结</h2>

<p><em>Redis</em>的线程使用比较谨慎，其中仅仅只包含3种类型的线程事件。这样保证了Redis本身代码的简洁。</p>

<h2 id="toc_7">相关链接</h2>

<ul>
<li><a href="https://www.cnblogs.com/lijunamneg/archive/2013/01/25/2877211.html">线程取消</a></li>
<li><a href="https://yq.aliyun.com/articles/58703?utm_source=tool.lu">bio学习</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 跳跃表]]></title>
    <link href="https://artikell.github.io/15286261757400.html"/>
    <updated>2018-06-10T18:22:55+08:00</updated>
    <id>https://artikell.github.io/15286261757400.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<h2 id="toc_1">算法分析</h2>

<h2 id="toc_2">相关链接</h2>

<ul>
<li><a href="https://blog.csdn.net/men_wen/article/details/70040026">CSDN - 跳跃表(skiplist)</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 对象Object]]></title>
    <link href="https://artikell.github.io/15286147511534.html"/>
    <updated>2018-06-10T15:12:31+08:00</updated>
    <id>https://artikell.github.io/15286147511534.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>在<em>Redis</em>中，对对象拥有一套管理的机制，包括引用、内存、以及淘汰机制，这套机制的的建立，便是Object结构体本身的设计，所以此次，我们通过相关的方面来了解<em>Object</em>对象。</p>

<h2 id="toc_1">主要的类型</h2>

<p>在对象系统中，共有6个类型：<code>string、list、set、zset、hash、stream</code>。</p>

<p>相对应的基础的数据结构也有7类：<code>string、adlist、ziplist、quicklist、dict、skiplist、inset</code></p>

<p>下面的表格将会列出各个类型对应的使用的数据结构：</p>

<table>
<thead>
<tr>
<th>Type_Encoding</th>
<th>DataStruct</th>
<th>Limit</th>
</tr>
</thead>

<tbody>
<tr>
<td>String_int</td>
<td>long long</td>
<td>Element is int</td>
</tr>
<tr>
<td>String_raw</td>
<td>sbs</td>
<td>Length &gt; 44</td>
</tr>
<tr>
<td>String_embstr</td>
<td>embstr</td>
<td>Length &lt;= 44</td>
</tr>
<tr>
<td>List_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
<tr>
<td>List_quicklist</td>
<td>quicklist</td>
<td>Size &gt; 64 or Count &gt; 512</td>
</tr>
<tr>
<td>Set_ht</td>
<td>dict</td>
<td>Element isn’t int or Cout &gt; 512</td>
</tr>
<tr>
<td>Set_intset</td>
<td>intset</td>
<td>Default</td>
</tr>
<tr>
<td>Hash_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
<tr>
<td>Hash_ht</td>
<td>dict</td>
<td>Size &gt; 64 or Count &gt; 512</td>
</tr>
<tr>
<td>Zset_skiplist</td>
<td>dict、skiplist</td>
<td>Size &gt; 64 or Count &gt; 128</td>
</tr>
<tr>
<td>Zset_ziplist</td>
<td>ziplist</td>
<td>Default</td>
</tr>
</tbody>
</table>

<p>大部分情况的转换都是根据元素个数与元素大小超过限制进行判断。当然这些限制也是可配置项：</p>

<pre><code>hash-max-ziplist-entries 512 
hash-max-ziplist-value 64 
list-max-ziplist-entries 512 
list-max-ziplist-value 64 
set-max-intset-entries 512 
zset-max-ziplist-entries 128 
zset-max-ziplist-value 64
</code></pre>

<h2 id="toc_2">Object的设计</h2>

<p><em>Object</em>的设计拥有所有对象系统共有的特征：<em>relcount、ptr、type</em>。细节的结构体如下：</p>

<pre><code>typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or
                            * LFU data (least significant 8 bits frequency
                            * and most significant 16 bits access time). */
    int refcount;
    void *ptr;
} robj;
</code></pre>

<p>结构体不难理解，拥有类型、编码、超时权重、引用次数以及所指内存。<br/>
其中<em>类型\编码</em>在上一节已经列举出来，相关的类型原理之后再进行描述。</p>

<h2 id="toc_3">对象的销毁以及共享</h2>

<p>在拥有对象引用属性时，系统就会考虑对象销毁的时机。对象系统提供了<em>decrRefCount</em>和<em>incrRefCount</em>2个方法，前者用于减少引用数，后者相反。</p>

<p>所以，当<em>Redis</em>使用完对象时，会调用<em>decrRefCount</em>方法来减少引用数，当发现引用数为1时，说明当前对象需要被销毁，对象系统会主动调用相关类型的销毁函数进行内存清理。</p>

<p>当然，<em>Redis</em>为了高效，提供了共享对象，其中包含<em>1~10000</em>中间的所有数字，创建时将其的引用数设置为无穷大，同时在减少引用数的时候，判断引用数是否为无穷大，是则不进行引用数减少，提高了内存利用率</p>

<h2 id="toc_4">总结</h2>

<p>关于Redis的对象系统，其实没有什么需要过多的介绍，对于对象来说，<em>Redis</em>本身对不同的类型进行了多态化的分解，导致主要的操作都分散在各个部分中，包括淘汰策略、以及内存分配等。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 字典扫描算法]]></title>
    <link href="https://artikell.github.io/15285709665764.html"/>
    <updated>2018-06-10T03:02:46+08:00</updated>
    <id>https://artikell.github.io/15285709665764.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p>字典扫描算法包含了2个特别精巧的位运算算法，2者保证了整个扫描过程即使穿插了重哈希操作也不会顺序混合。</p>

<h2 id="toc_1">问题一：反转一个数</h2>

<p>如何快速反转一个数，正常往往都是<em>O(n)</em>的算法，虽然数字正常不会超过64位，但是，<em>Redis</em>使用了更加位运算将其复杂度减低至了<em>O(logn)</em>。</p>

<p>首先，考虑对于一个二进制数：11010100(212)，如何进行反转？</p>

<p>第一次反转，反转4位：</p>

<pre><code>mask = 0000 1111
1101 0100 &gt;&gt; 4 &amp; 0000 1111 = 0000 1101
1101 0100 &lt;&lt; 4 &amp; 1111 0000 = 0100 0000
0000 1101 | 0100 0000 = 0100 1101
</code></pre>

<p>第二次反转，反转2位：</p>

<pre><code>mask = 0000 1111 ^ 0011 1100  = 0011 0011
0100 1101 &gt;&gt; 2 &amp; 0011 0011 = 0001 0011
0100 1101 &lt;&lt; 2 &amp; 1100 1100 = 0000 0100
0001 0011 | 0000 0100 = 0001 0111
</code></pre>

<p>第三次反转，反转1位：</p>

<pre><code>mask = 0110 0110 ^ 0011 0011  = 0101 0101
0001 0111 &gt;&gt; 1 &amp; 0101 0101 = 0000 0001
0001 0111 &lt;&lt; 1 &amp; 1010 1010 = 0010 1010
0000 0001 | 0010 1010 = 0010 1011
</code></pre>

<p>其实可以发现关键的点就是<em>mask</em>的生成，规律如下：</p>

<pre><code>1. 0000 1111
2. 0011 0011
3. 0101 0101
</code></pre>

<p>通过位运算来反转二进制数。</p>

<h2 id="toc_2">问题二：遍历变长字典</h2>

<p>答案是：从高位遍历到低位。</p>

<p>遍历的情况分为3种：未进行重哈希、扩大字典、缩小字典。对于未进行重哈希的情况就不进行描述。</p>

<h3 id="toc_3">优点</h3>

<ol>
<li>提供键空间的遍历操作，支持游标，复杂度O(1), 整体遍历一遍只需要O(N)；</li>
<li>提供结果模式匹配；</li>
<li>支持一次返回的数据条数设置，但仅仅是个hints，有时候返回的会多；</li>
<li>弱状态，所有状态只需要客户端需要维护一个游标；</li>
</ol>

<h3 id="toc_4">缺点</h3>

<ol>
<li>无法提供完整的快照遍历，也就是中间如果有数据修改，可能有些涉及改动的数据遍历不到；</li>
<li>每次返回的数据条数不一定，极度依赖内部实现；</li>
<li>返回的数据可能有重复，应用层必须能够处理重入逻辑；</li>
</ol>

<h2 id="toc_5">相关链接</h2>

<ul>
<li><a href="http://chenzhenianqing.com/articles/1090.html">Redis Scan迭代器遍历操作原理</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 淘汰策略解读]]></title>
    <link href="https://artikell.github.io/15285605915126.html"/>
    <updated>2018-06-10T00:09:51+08:00</updated>
    <id>https://artikell.github.io/15285605915126.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">前言</h2>

<p><em>Redis</em>本身是一款高效的内存数据库，内存数据库中很重要的一点在于能很好的利用并管理内存，这也衍生出了内存淘汰策略，这和操作系统的内存页管理机制相同，拥有各种淘汰算法，例如：FIFO、LRU、OPT等，这次我们主要是讨论一下关于<em>Redis</em>本身的内存淘汰策略。</p>

<!--more-->

<h2 id="toc_1">过期键淘汰逻辑</h2>

<p>淘汰逻辑<em>Redis</em>本身存在2种方式的淘汰并存，这样做的目的也是为了提高效率。</p>

<h3 id="toc_2">惰性淘汰逻辑</h3>

<p><em>Redis</em>当键值已经超出失效时间时，是无法做到及时的将内存进行空闲出来，同时考虑到及时的将内存空闲出来会需要有十分高的成本。<br/>
于是<em>Redis</em>将淘汰功能，下发至各个命令操作中，当有客户端对相关的键进行访问时，命令将会调用<em>expireIfNeeded</em>方法来判断键值是否已经失效，若是，则将其删除。</p>

<pre><code>int expireIfNeeded(redisDb *db, robj *key) {
    mstime_t when = getExpire(db,key);
    
    mstime_t now;

    if (when &lt; 0) return 0;

    if (server.loading) return 0;

    now = server.lua_caller ? server.lua_time_start : mstime();

    if (server.masterhost != NULL) return now &gt; when;

    if (now &lt;= when) return 0;

    server.stat_expiredkeys++;
    propagateExpire(db,key,server.lazyfree_lazy_expire);
    notifyKeyspaceEvent(NOTIFY_EXPIRED,
        &quot;expired&quot;,key,db-&gt;id);
    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                         dbSyncDelete(db,key);
}
</code></pre>

<p><em>expireIfNeeded</em>函数大致逻辑如下：<br/>
1. 获取当前键的失效时间<br/>
2. 判断失效时间是否小于0，是则表示不失效<br/>
3. 判断当前服务器是否正在加载数据信息<br/>
4. 获取当前时间<br/>
5. 判断是否已经失效<br/>
6. 统计失效键信息<br/>
7. 发送失效键信息至其余节点<br/>
8. 发送键失效通知给订阅通道<br/>
9. 键值删除</p>

<blockquote>
<p>其中键删除操作包括同步删除和异步删除，这次不进行细讲</p>
</blockquote>

<h3 id="toc_3">主动淘汰逻辑</h3>

<p>消极方法的缺点是，如果<em>key</em>迟迟不被访问，就会占用很多内存空间。 所以就产生的主动淘汰：此方法利用了<em>Redis</em>的时间事件，即每隔一段时间就中断一下完成一些指定操作，其中就包括检查并删除失效主键。<br/>
主动淘汰机制相关的配置项为<em>set-active-expire</em>，主要的调用位置为：<em>beforeSleep</em> 和 <em>databasesCron</em> ，一个是事件循环前触发，一个是数据库定时触发。</p>

<pre><code>void activeExpireCycle(int type) {
    static unsigned int current_db = 0; /* Last DB tested. */
    static int timelimit_exit = 0;      /* Time limit hit in previous call? */
    static long long last_fast_cycle = 0; /* When last fast cycle ran. */

    int j, iteration = 0;
    int dbs_per_call = CRON_DBS_PER_CALL;
    long long start = ustime(), timelimit, elapsed;

    if (clientsArePaused()) return;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {
        if (!timelimit_exit) return;
        if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;
        last_fast_cycle = start;
    }

    if (dbs_per_call &gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;
    timelimit_exit = 0;
    if (timelimit &lt;= 0) timelimit = 1;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */

    long total_sampled = 0;
    long total_expired = 0;

    for (j = 0; j &lt; dbs_per_call &amp;&amp; timelimit_exit == 0; j++) {
        int expired;
        redisDb *db = server.db+(current_db % server.dbnum);

        current_db++;
        do {
            unsigned long num, slots;
            long long now, ttl_sum;
            int ttl_samples;
            iteration++;

            if ((num = dictSize(db-&gt;expires)) == 0) {
                db-&gt;avg_ttl = 0;
                break;
            }
            slots = dictSlots(db-&gt;expires);
            now = mstime();
            
            if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;
                (num*100/slots &lt; 1)) break;

            expired = 0;
            ttl_sum = 0;
            ttl_samples = 0;

            if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)
                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;

            while (num--) {
                dictEntry *de;
                long long ttl;

                if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;
                ttl = dictGetSignedIntegerVal(de)-now;
                if (activeExpireCycleTryExpire(db,de,now)) expired++;
                if (ttl &gt; 0) {
                    /* We want the average TTL of keys yet not expired. */
                    ttl_sum += ttl;
                    ttl_samples++;
                }
                total_sampled++;
            }
            total_expired += expired;

            if (ttl_samples) {
                long long avg_ttl = ttl_sum/ttl_samples;

                if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;
                db-&gt;avg_ttl = (db-&gt;avg_ttl/50)*49 + (avg_ttl/50);
            }

            if ((iteration &amp; 0xf) == 0) { /* check once every 16 iterations. */
                elapsed = ustime()-start;
                if (elapsed &gt; timelimit) {
                    timelimit_exit = 1;
                    server.stat_expired_time_cap_reached_count++;
                    break;
                }
            }
        } while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);
    }

    elapsed = ustime()-start;
    latencyAddSampleIfNeeded(&quot;expire-cycle&quot;,elapsed/1000);

    double current_perc;
    if (total_sampled) {
        current_perc = (double)total_expired/total_sampled;
    } else
        current_perc = 0;
    server.stat_expired_stale_perc = (current_perc*0.05)+
                                     (server.stat_expired_stale_perc*0.95);
}

</code></pre>

<p><em>activeExpireCycle</em>函数关键点如下：<br/>
1. 函数提供了 <em>ACTIVE_EXPIRE_CYCLE_FAST</em> 和 <em>ACTIVE_EXPIRE_CYCLE_SLOW</em> 2种模式，区别在于：FAST模式本身对时间有苛刻的要求，不允许淘汰键导致过高的延时，所以会有一个超时时间(1000ms)的限制。<br/>
2. 函数会遍历每个数据库，然后从过期键中获取20个值，若20个中淘汰了5个，则继续淘汰，尽可能的保证过期比例小于0.25。<br/>
3. 其中，函数会统计相关的超时情况以及淘汰时间等。</p>

<h2 id="toc_4">内存淘汰策略</h2>

<p>内存淘汰策略的设置项为<em>maxmemory-policy</em>，其中拥有6种策略：<br/>
1. <em>noeviction</em>策略(不淘汰策略)<br/>
    该策略不进行内存淘汰，当内存达到阀值后，将会报错。但该策略为默认策略，所以每次启用<em>Redis</em>服务时，最好是设置一下淘汰策略<br/>
2. <em>allkeys-lru</em>策略(主键lru策略)<br/>
    在主键空间中，优先移除最近未使用的key。<br/>
3. <em>volatile-lru</em>策略(过期键lru策略)<br/>
    在设置了过期时间的键空间中，优先移除最近未使用的key。<br/>
4. <em>allkeys-random</em>策略(主键随机淘汰策略)<br/>
    在主键空间中，随机移除某个key。<br/>
5. <em>volatile-random</em>策略(过期键随机淘汰策略)<br/>
    在设置了过期时间的键空间中，随机移除某个key。<br/>
6. <em>volatile-ttl</em>策略(过期键fifo策略)<br/>
    在设置了过期时间的键空间中，具有更早过期时间的key优先移除。</p>

<p>对于不同淘汰机制，也存在相关的使用场景：<br/>
1. <em>allkeys-lru</em>：如果我们的应用对缓存的访问符合幂律分布（也就是存在相对热点数据），或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择<em>allkeys-lru</em>策略。<br/>
2. <em>allkeys-random</em>：如果我们的应用对于缓存<em>key</em>的访问概率相等，则可以使用这个策略。<br/>
3. <em>volatile-ttl</em>：这种策略使得我们可以向<em>Redis</em>提示哪些<em>key</em>更适合被<em>eviction</em>。</p>

<h2 id="toc_5">内存淘汰逻辑</h2>

<p>内存超限淘汰机制与上述的过期键淘汰机制不同，它本身存在触发的条件是在于每次定时请求，若发现内存不足时，将会进行键值淘汰，来保证正常运行。</p>

<p>与过期键淘汰函数<em>expireIfNeeded</em>对应的函数为：<em>freeMemoryIfNeeded</em>函数，它将会在定时事件和脚本运行时进行内存检查。它主要的判断条件为当前服务是否设置了<em>maxmemory</em>，若设置了则需要进行内存淘汰。</p>

<p><em>freeMemoryIfNeeded</em>函数本身针对不同的淘汰策略会有不同的逻辑。主要分为随机淘汰和策略淘汰。</p>

<h3 id="toc_6">内存随机淘汰</h3>

<p>随机淘汰的实现相对简单，只需要对不同的空间进行随机筛选键，并进内存释放即可。</p>

<pre><code>for (i = 0; i &lt; server.dbnum; i++) {
    j = (++next_db) % server.dbnum;
    db = server.db+j;
    dict = (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM) ?
            db-&gt;dict : db-&gt;expires;
    if (dictSize(dict) != 0) {
        de = dictGetRandomKey(dict);
        bestkey = dictGetKey(de);
        bestdbid = j;
        break;
    }
}
</code></pre>

<h3 id="toc_7">内存策略淘汰</h3>

<p>待续，关键点：LRU算法</p>

<h2 id="toc_8">总结</h2>

<p><em>Redis</em>淘汰逻辑核心点不多，主要只是将整个淘汰工作分布至各个操作中，提高了整体的效率，同时也使用了异步删除等机制。之后还能衍生出集群的键值淘汰逻辑等。</p>

<h2 id="toc_9">参考链接</h2>

<ul>
<li><a href="https://blog.csdn.net/kl1106/article/details/79566594">CSDN - Redis缓存淘汰</a></li>
<li><a href="https://blog.csdn.net/lizhi_java/article/details/68953179">CSDN - 缓存淘汰策略</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World]]></title>
    <link href="https://artikell.github.io/15284948308748.html"/>
    <updated>2018-06-09T05:53:50+08:00</updated>
    <id>https://artikell.github.io/15284948308748.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
</feed>
